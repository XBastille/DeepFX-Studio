[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "ByteTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "DoubleTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "FloatTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "HalfTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "LongTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "ShortTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "as_tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "ByteTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "DoubleTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "FloatTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "HalfTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "LongTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "ShortTensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "as_tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "array",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "exp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tan",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "array",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "exp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "log",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tan",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tanh",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "imshow",
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "isExtraImport": true,
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "imshow",
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "isExtraImport": true,
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "importPath": "data_loader_cache",
        "description": "data_loader_cache",
        "isExtraImport": true,
        "detail": "data_loader_cache",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "normalize",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "normalize",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "normalize",
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "isExtraImport": true,
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "scipy.io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.io",
        "description": "scipy.io",
        "detail": "scipy.io",
        "documentation": {}
    },
    {
        "label": "scipy.misc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.misc",
        "description": "scipy.misc",
        "detail": "scipy.misc",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "tensorflow_hub",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow_hub",
        "description": "tensorflow_hub",
        "detail": "tensorflow_hub",
        "documentation": {}
    },
    {
        "label": "EagerTensor",
        "importPath": "tensorflow.python.framework.ops",
        "description": "tensorflow.python.framework.ops",
        "isExtraImport": true,
        "detail": "tensorflow.python.framework.ops",
        "documentation": {}
    },
    {
        "label": "EagerTensor",
        "importPath": "tensorflow.python.framework.ops",
        "description": "tensorflow.python.framework.ops",
        "isExtraImport": true,
        "detail": "tensorflow.python.framework.ops",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "RRDBNet",
        "importPath": "basicsr.archs.rrdbnet_arch",
        "description": "basicsr.archs.rrdbnet_arch",
        "isExtraImport": true,
        "detail": "basicsr.archs.rrdbnet_arch",
        "documentation": {}
    },
    {
        "label": "RRDBNet",
        "importPath": "basicsr.archs.rrdbnet_arch",
        "description": "basicsr.archs.rrdbnet_arch",
        "isExtraImport": true,
        "detail": "basicsr.archs.rrdbnet_arch",
        "documentation": {}
    },
    {
        "label": "load_file_from_url",
        "importPath": "basicsr.utils.download_util",
        "description": "basicsr.utils.download_util",
        "isExtraImport": true,
        "detail": "basicsr.utils.download_util",
        "documentation": {}
    },
    {
        "label": "load_file_from_url",
        "importPath": "basicsr.utils.download_util",
        "description": "basicsr.utils.download_util",
        "isExtraImport": true,
        "detail": "basicsr.utils.download_util",
        "documentation": {}
    },
    {
        "label": "load_file_from_url",
        "importPath": "basicsr.utils.download_util",
        "description": "basicsr.utils.download_util",
        "isExtraImport": true,
        "detail": "basicsr.utils.download_util",
        "documentation": {}
    },
    {
        "label": "load_file_from_url",
        "importPath": "basicsr.utils.download_util",
        "description": "basicsr.utils.download_util",
        "isExtraImport": true,
        "detail": "basicsr.utils.download_util",
        "documentation": {}
    },
    {
        "label": "RealESRGANer",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "RealESRGANer",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "enum",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "enum",
        "description": "enum",
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "IntEnum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractproperty",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractproperty",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "device",
        "importPath": "deoldify",
        "description": "deoldify",
        "isExtraImport": true,
        "detail": "deoldify",
        "documentation": {}
    },
    {
        "label": "device",
        "importPath": "deoldify",
        "description": "deoldify",
        "isExtraImport": true,
        "detail": "deoldify",
        "documentation": {}
    },
    {
        "label": "device",
        "importPath": "deoldify",
        "description": "deoldify",
        "isExtraImport": true,
        "detail": "deoldify",
        "documentation": {}
    },
    {
        "label": "device",
        "importPath": "deoldify",
        "description": "deoldify",
        "isExtraImport": true,
        "detail": "deoldify",
        "documentation": {}
    },
    {
        "label": "fastai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fastai",
        "description": "fastai",
        "detail": "fastai",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai",
        "description": "fastai",
        "isExtraImport": true,
        "detail": "fastai",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai",
        "description": "fastai",
        "isExtraImport": true,
        "detail": "fastai",
        "documentation": {}
    },
    {
        "label": "DatasetType",
        "importPath": "fastai.basic_data",
        "description": "fastai.basic_data",
        "isExtraImport": true,
        "detail": "fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataBunch",
        "importPath": "fastai.basic_data",
        "description": "fastai.basic_data",
        "isExtraImport": true,
        "detail": "fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DatasetType",
        "importPath": "fastai.basic_data",
        "description": "fastai.basic_data",
        "isExtraImport": true,
        "detail": "fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataBunch",
        "importPath": "fastai.basic_data",
        "description": "fastai.basic_data",
        "isExtraImport": true,
        "detail": "fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.basic_train",
        "description": "fastai.basic_train",
        "isExtraImport": true,
        "detail": "fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.core",
        "description": "fastai.core",
        "isExtraImport": true,
        "detail": "fastai.core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.core",
        "description": "fastai.core",
        "isExtraImport": true,
        "detail": "fastai.core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.core",
        "description": "fastai.core",
        "isExtraImport": true,
        "detail": "fastai.core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.core",
        "description": "fastai.core",
        "isExtraImport": true,
        "detail": "fastai.core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision",
        "description": "fastai.vision",
        "isExtraImport": true,
        "detail": "fastai.vision",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision.data",
        "description": "fastai.vision.data",
        "isExtraImport": true,
        "detail": "fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision.data",
        "description": "fastai.vision.data",
        "isExtraImport": true,
        "detail": "fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision.image",
        "description": "fastai.vision.image",
        "isExtraImport": true,
        "detail": "fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.vision.image",
        "description": "fastai.vision.image",
        "isExtraImport": true,
        "detail": "fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "NormType",
        "importPath": "fastai.layers",
        "description": "fastai.layers",
        "isExtraImport": true,
        "detail": "fastai.layers",
        "documentation": {}
    },
    {
        "label": "NormType",
        "importPath": "fastai.layers",
        "description": "fastai.layers",
        "isExtraImport": true,
        "detail": "fastai.layers",
        "documentation": {}
    },
    {
        "label": "SplitFuncOrIdxList",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_init",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_device",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "SplitFuncOrIdxList",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_init",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_device",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.torch_core",
        "description": "fastai.torch_core",
        "isExtraImport": true,
        "detail": "fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "cnn_config",
        "importPath": "fastai.vision.learner",
        "description": "fastai.vision.learner",
        "isExtraImport": true,
        "detail": "fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_body",
        "importPath": "fastai.vision.learner",
        "description": "fastai.vision.learner",
        "isExtraImport": true,
        "detail": "fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "cnn_config",
        "importPath": "fastai.vision.learner",
        "description": "fastai.vision.learner",
        "isExtraImport": true,
        "detail": "fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_body",
        "importPath": "fastai.vision.learner",
        "description": "fastai.vision.learner",
        "isExtraImport": true,
        "detail": "fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BufferedWriter",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BufferedWriter",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "ffmpeg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ffmpeg",
        "description": "ffmpeg",
        "detail": "ffmpeg",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "yt_dlp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yt_dlp",
        "description": "yt_dlp",
        "detail": "yt_dlp",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "get_ipython",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "get_ipython",
        "importPath": "IPython",
        "description": "IPython",
        "isExtraImport": true,
        "detail": "IPython",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "clear_output",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "clear_output",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "clear_output",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "clear_output",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.display",
        "description": "IPython.display",
        "isExtraImport": true,
        "detail": "IPython.display",
        "documentation": {}
    },
    {
        "label": "Axes",
        "importPath": "matplotlib.axes",
        "description": "matplotlib.axes",
        "isExtraImport": true,
        "detail": "matplotlib.axes",
        "documentation": {}
    },
    {
        "label": "Axes",
        "importPath": "matplotlib.axes",
        "description": "matplotlib.axes",
        "isExtraImport": true,
        "detail": "matplotlib.axes",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "format_time",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "MasterBar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "ProgressBar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "master_bar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "IN_NOTEBOOK",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "format_time",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "format_time",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "MasterBar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "ProgressBar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "master_bar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "IN_NOTEBOOK",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "format_time",
        "importPath": "fastprogress.fastprogress",
        "description": "fastprogress.fastprogress",
        "isExtraImport": true,
        "detail": "fastprogress.fastprogress",
        "documentation": {}
    },
    {
        "label": "_unflatten_dense_tensors",
        "importPath": "torch._utils",
        "description": "torch._utils",
        "isExtraImport": true,
        "detail": "torch._utils",
        "documentation": {}
    },
    {
        "label": "_unflatten_dense_tensors",
        "importPath": "torch._utils",
        "description": "torch._utils",
        "isExtraImport": true,
        "detail": "torch._utils",
        "documentation": {}
    },
    {
        "label": "parameters_to_vector",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "spectral_norm",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "weight_norm",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "parameters_to_vector",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "spectral_norm",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "weight_norm",
        "importPath": "torch.nn.utils",
        "description": "torch.nn.utils",
        "isExtraImport": true,
        "detail": "torch.nn.utils",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Event",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "tracemalloc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tracemalloc",
        "description": "tracemalloc",
        "detail": "tracemalloc",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "fastai.callback",
        "description": "fastai.callback",
        "isExtraImport": true,
        "detail": "fastai.callback",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.callback",
        "description": "fastai.callback",
        "isExtraImport": true,
        "detail": "fastai.callback",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "fastai.callback",
        "description": "fastai.callback",
        "isExtraImport": true,
        "detail": "fastai.callback",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.callback",
        "description": "fastai.callback",
        "isExtraImport": true,
        "detail": "fastai.callback",
        "documentation": {}
    },
    {
        "label": "WeightedRandomSampler",
        "importPath": "torch.utils.data.sampler",
        "description": "torch.utils.data.sampler",
        "isExtraImport": true,
        "detail": "torch.utils.data.sampler",
        "documentation": {}
    },
    {
        "label": "WeightedRandomSampler",
        "importPath": "torch.utils.data.sampler",
        "description": "torch.utils.data.sampler",
        "isExtraImport": true,
        "detail": "torch.utils.data.sampler",
        "documentation": {}
    },
    {
        "label": "statistics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statistics",
        "description": "statistics",
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "Queue",
        "importPath": "queue",
        "description": "queue",
        "isExtraImport": true,
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "torchvision.utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "jupyter_contrib_nbextensions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jupyter_contrib_nbextensions",
        "description": "jupyter_contrib_nbextensions",
        "detail": "jupyter_contrib_nbextensions",
        "documentation": {}
    },
    {
        "label": "nbformat",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nbformat",
        "description": "nbformat",
        "detail": "nbformat",
        "documentation": {}
    },
    {
        "label": "nbconvert",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nbconvert",
        "description": "nbconvert",
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "HTMLExporter",
        "importPath": "nbconvert",
        "description": "nbconvert",
        "isExtraImport": true,
        "detail": "nbconvert",
        "documentation": {}
    },
    {
        "label": "Preprocessor",
        "importPath": "nbconvert.preprocessors",
        "description": "nbconvert.preprocessors",
        "isExtraImport": true,
        "detail": "nbconvert.preprocessors",
        "documentation": {}
    },
    {
        "label": "ExecutePreprocessor",
        "importPath": "nbconvert.preprocessors",
        "description": "nbconvert.preprocessors",
        "isExtraImport": true,
        "detail": "nbconvert.preprocessors",
        "documentation": {}
    },
    {
        "label": "Preprocessor",
        "importPath": "nbconvert.preprocessors",
        "description": "nbconvert.preprocessors",
        "isExtraImport": true,
        "detail": "nbconvert.preprocessors",
        "documentation": {}
    },
    {
        "label": "ExecutePreprocessor",
        "importPath": "nbconvert.preprocessors",
        "description": "nbconvert.preprocessors",
        "isExtraImport": true,
        "detail": "nbconvert.preprocessors",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "traitlets.config",
        "description": "traitlets.config",
        "isExtraImport": true,
        "detail": "traitlets.config",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "traitlets.config",
        "description": "traitlets.config",
        "isExtraImport": true,
        "detail": "traitlets.config",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "abc",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "abc",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "currentframe",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "getframeinfo",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "ismodule",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "currentframe",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "getframeinfo",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "ismodule",
        "importPath": "inspect",
        "description": "inspect",
        "isExtraImport": true,
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "importlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib",
        "description": "importlib",
        "detail": "importlib",
        "documentation": {}
    },
    {
        "label": "pkgutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkgutil",
        "description": "pkgutil",
        "detail": "pkgutil",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "HTML",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "Markdown",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "display",
        "importPath": "IPython.core.display",
        "description": "IPython.core.display",
        "isExtraImport": true,
        "detail": "IPython.core.display",
        "documentation": {}
    },
    {
        "label": "NotebookNotary",
        "importPath": "nbformat.sign",
        "description": "nbformat.sign",
        "isExtraImport": true,
        "detail": "nbformat.sign",
        "documentation": {}
    },
    {
        "label": "NotebookNotary",
        "importPath": "nbformat.sign",
        "description": "nbformat.sign",
        "isExtraImport": true,
        "detail": "nbformat.sign",
        "documentation": {}
    },
    {
        "label": "typing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "typing",
        "description": "typing",
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Collection",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Hashable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NewType",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "AnyStr",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Collection",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Hashable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterator",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NewType",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "page",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "page",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "page",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "page",
        "importPath": "IPython.core",
        "description": "IPython.core",
        "isExtraImport": true,
        "detail": "IPython.core",
        "documentation": {}
    },
    {
        "label": "nbdoc",
        "importPath": "fastai.gen_doc",
        "description": "fastai.gen_doc",
        "isExtraImport": true,
        "detail": "fastai.gen_doc",
        "documentation": {}
    },
    {
        "label": "nbdoc",
        "importPath": "fastai.gen_doc",
        "description": "fastai.gen_doc",
        "isExtraImport": true,
        "detail": "fastai.gen_doc",
        "documentation": {}
    },
    {
        "label": "bz2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bz2",
        "description": "bz2",
        "detail": "bz2",
        "documentation": {}
    },
    {
        "label": "concurrent",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent",
        "description": "concurrent",
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "html",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "html",
        "description": "html",
        "detail": "html",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "permutations",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "permutations",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "numbers",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numbers",
        "description": "numbers",
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Number",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Integral",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Integral",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Number",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Integral",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "Integral",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "attrgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "attrgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "itemgetter",
        "importPath": "operator",
        "description": "operator",
        "isExtraImport": true,
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "which",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "weakref",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "weakref",
        "description": "weakref",
        "detail": "weakref",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "InitVar",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "InitVar",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "set_trace",
        "importPath": "pdb",
        "description": "pdb",
        "isExtraImport": true,
        "detail": "pdb",
        "documentation": {}
    },
    {
        "label": "set_trace",
        "importPath": "pdb",
        "description": "pdb",
        "isExtraImport": true,
        "detail": "pdb",
        "documentation": {}
    },
    {
        "label": "set_trace",
        "importPath": "pdb",
        "description": "pdb",
        "isExtraImport": true,
        "detail": "pdb",
        "documentation": {}
    },
    {
        "label": "set_trace",
        "importPath": "pdb",
        "description": "pdb",
        "isExtraImport": true,
        "detail": "pdb",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Series",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "DataFrame",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Series",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "scipy.special",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.special",
        "description": "scipy.special",
        "detail": "scipy.special",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "patches",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "patheffects",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "patches",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "patheffects",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "Patch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "Patch",
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "isExtraImport": true,
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "BatchSampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "TensorDataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "BatchSampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Sampler",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "TensorDataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "is_categorical_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "is_numeric_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "is_numeric_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "is_categorical_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "is_numeric_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "is_numeric_dtype",
        "importPath": "pandas.api.types",
        "description": "pandas.api.types",
        "isExtraImport": true,
        "detail": "pandas.api.types",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "matplotlib.cm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.cm",
        "description": "matplotlib.cm",
        "detail": "matplotlib.cm",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "ORTH",
        "importPath": "spacy.symbols",
        "description": "spacy.symbols",
        "isExtraImport": true,
        "detail": "spacy.symbols",
        "documentation": {}
    },
    {
        "label": "ORTH",
        "importPath": "spacy.symbols",
        "description": "spacy.symbols",
        "isExtraImport": true,
        "detail": "spacy.symbols",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "fastprogress",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fastprogress",
        "description": "fastprogress",
        "detail": "fastprogress",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ctypes",
        "description": "ctypes",
        "isExtraImport": true,
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "ctypes",
        "description": "ctypes",
        "isExtraImport": true,
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "torch.utils.model_zoo",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.model_zoo",
        "description": "torch.utils.model_zoo",
        "detail": "torch.utils.model_zoo",
        "documentation": {}
    },
    {
        "label": "wrap",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "wrap",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "ipywidgets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Layout",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "widgets",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "BoundedIntText",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Button",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Dropdown",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "HBox",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Layout",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Output",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "VBox",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "widgets",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Layout",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "widgets",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "BoundedIntText",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Box",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Button",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Dropdown",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "HBox",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Layout",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Output",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "VBox",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "widgets",
        "importPath": "ipywidgets",
        "description": "ipywidgets",
        "isExtraImport": true,
        "detail": "ipywidgets",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "default_collate",
        "importPath": "torch.utils.data.dataloader",
        "description": "torch.utils.data.dataloader",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataloader",
        "documentation": {}
    },
    {
        "label": "default_collate",
        "importPath": "torch.utils.data.dataloader",
        "description": "torch.utils.data.dataloader",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataloader",
        "documentation": {}
    },
    {
        "label": "plot_sixel",
        "importPath": "fastai.sixel",
        "description": "fastai.sixel",
        "isExtraImport": true,
        "detail": "fastai.sixel",
        "documentation": {}
    },
    {
        "label": "plot_sixel",
        "importPath": "fastai.sixel",
        "description": "fastai.sixel",
        "isExtraImport": true,
        "detail": "fastai.sixel",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "TextLMDataBunch",
        "importPath": "fastai.text",
        "description": "fastai.text",
        "isExtraImport": true,
        "detail": "fastai.text",
        "documentation": {}
    },
    {
        "label": "TextLMDataBunch",
        "importPath": "fastai.text",
        "description": "fastai.text",
        "isExtraImport": true,
        "detail": "fastai.text",
        "documentation": {}
    },
    {
        "label": "DataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedSampler",
        "importPath": "torch.utils.data.distributed",
        "description": "torch.utils.data.distributed",
        "isExtraImport": true,
        "detail": "torch.utils.data.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedSampler",
        "importPath": "torch.utils.data.distributed",
        "description": "torch.utils.data.distributed",
        "isExtraImport": true,
        "detail": "torch.utils.data.distributed",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.script",
        "description": "fastai.script",
        "isExtraImport": true,
        "detail": "fastai.script",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "fastai.script",
        "description": "fastai.script",
        "isExtraImport": true,
        "detail": "fastai.script",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "DeviceId",
        "importPath": "deoldify.device_id",
        "description": "deoldify.device_id",
        "isExtraImport": true,
        "detail": "deoldify.device_id",
        "documentation": {}
    },
    {
        "label": "DeviceId",
        "importPath": "deoldify.device_id",
        "description": "deoldify.device_id",
        "isExtraImport": true,
        "detail": "deoldify.device_id",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "deoldify.visualize",
        "description": "deoldify.visualize",
        "isExtraImport": true,
        "detail": "deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "deoldify.visualize",
        "description": "deoldify.visualize",
        "isExtraImport": true,
        "detail": "deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "MTCNN",
        "importPath": "facenet_pytorch",
        "description": "facenet_pytorch",
        "isExtraImport": true,
        "detail": "facenet_pytorch",
        "documentation": {}
    },
    {
        "label": "MTCNN",
        "importPath": "facenet_pytorch",
        "description": "facenet_pytorch",
        "isExtraImport": true,
        "detail": "facenet_pytorch",
        "documentation": {}
    },
    {
        "label": "onnxruntime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "onnxruntime",
        "description": "onnxruntime",
        "detail": "onnxruntime",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "AppConfig",
        "importPath": "django.apps",
        "description": "django.apps",
        "isExtraImport": true,
        "detail": "django.apps",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "IntegrityError",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "django.db",
        "description": "django.db",
        "isExtraImport": true,
        "detail": "django.db",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "TestCase",
        "importPath": "django.test",
        "description": "django.test",
        "isExtraImport": true,
        "detail": "django.test",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "include",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "reverse",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "login_required",
        "importPath": "django.contrib.auth.decorators",
        "description": "django.contrib.auth.decorators",
        "isExtraImport": true,
        "detail": "django.contrib.auth.decorators",
        "documentation": {}
    },
    {
        "label": "login_required",
        "importPath": "django.contrib.auth.decorators",
        "description": "django.contrib.auth.decorators",
        "isExtraImport": true,
        "detail": "django.contrib.auth.decorators",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "HttpResponseRedirect",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "Component",
        "importPath": "django_components",
        "description": "django_components",
        "isExtraImport": true,
        "detail": "django_components",
        "documentation": {}
    },
    {
        "label": "register",
        "importPath": "django_components",
        "description": "django_components",
        "isExtraImport": true,
        "detail": "django_components",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "django_components",
        "description": "django_components",
        "isExtraImport": true,
        "detail": "django_components",
        "documentation": {}
    },
    {
        "label": "get_asgi_application",
        "importPath": "django.core.asgi",
        "description": "django.core.asgi",
        "isExtraImport": true,
        "detail": "django.core.asgi",
        "documentation": {}
    },
    {
        "label": "dotenv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dotenv",
        "description": "dotenv",
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "get_wsgi_application",
        "importPath": "django.core.wsgi",
        "description": "django.core.wsgi",
        "isExtraImport": true,
        "detail": "django.core.wsgi",
        "documentation": {}
    },
    {
        "label": "authenticate",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "get_backends",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "login",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "logout",
        "importPath": "django.contrib.auth",
        "description": "django.contrib.auth",
        "isExtraImport": true,
        "detail": "django.contrib.auth",
        "documentation": {}
    },
    {
        "label": "User",
        "importPath": "django.contrib.auth.models",
        "description": "django.contrib.auth.models",
        "isExtraImport": true,
        "detail": "django.contrib.auth.models",
        "documentation": {}
    },
    {
        "label": "REBNCONV",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class REBNCONV(nn.Module):\n    def __init__(self, in_ch=3, out_ch=3, dirate=1, stride=1):\n        super(REBNCONV, self).__init__()\n        self.conv_s1 = nn.Conv2d(\n            in_ch, out_ch, 3, padding=1 * dirate, dilation=1 * dirate, stride=stride\n        )\n        self.bn_s1 = nn.BatchNorm2d(out_ch)\n        self.relu_s1 = nn.ReLU(inplace=True)\n    def forward(self, x):\n        hx = x",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU7",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class RSU7(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3, img_size=512):\n        super(RSU7, self).__init__()\n        self.in_ch = in_ch\n        self.mid_ch = mid_ch\n        self.out_ch = out_ch\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)  ## 1 -> 1/2\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU6",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class RSU6(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU6, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU5",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class RSU5(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU5, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class RSU4(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4F",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class RSU4F(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4F, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "myrebnconv",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class myrebnconv(nn.Module):\n    def __init__(\n        self,\n        in_ch=3,\n        out_ch=1,\n        kernel_size=3,\n        stride=1,\n        padding=1,\n        dilation=1,\n        groups=1,",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetGTEncoder",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class ISNetGTEncoder(nn.Module):\n    def __init__(self, in_ch=1, out_ch=1):\n        super(ISNetGTEncoder, self).__init__()\n        self.conv_in = myrebnconv(\n            in_ch, 16, 3, stride=2, padding=1\n        )  # nn.Conv2d(in_ch,64,3,stride=2,padding=1)\n        self.stage1 = RSU7(16, 16, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 16, 64)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetDIS",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "class ISNetDIS(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1):\n        super(ISNetDIS, self).__init__()\n        self.conv_in = nn.Conv2d(in_ch, 64, 3, stride=2, padding=1)\n        self.pool_in = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage1 = RSU7(64, 32, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 32, 128)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage3 = RSU5(128, 64, 256)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "def muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion_kl",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "def muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "bce_loss",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "bce_loss = nn.BCELoss(size_average=True)\ndef muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "fea_loss",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "fea_loss = nn.MSELoss(size_average=True)\nkl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "kl_loss",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "kl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "l1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.models.isnet",
        "description": "DL_Model.IS-NET.models.isnet",
        "peekOfCode": "smooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "DL_Model.IS-NET.models.isnet",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.data_loader_cache",
        "description": "DL_Model.IS-NET.data_loader_cache",
        "peekOfCode": "def img_reader(img_path):\n    return io.imread(img_path)\ndef img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:",
        "detail": "DL_Model.IS-NET.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.data_loader_cache",
        "description": "DL_Model.IS-NET.data_loader_cache",
        "peekOfCode": "def img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:\n        return img_tensor, img.shape[:2]\n    img_tensor = torch.unsqueeze(img_tensor, 0)",
        "detail": "DL_Model.IS-NET.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "GOSNormalize",
        "kind": 6,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "class GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"\n    def __init__(self, mean=None, std=None):",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "load_image",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "def load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "build_model",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "def build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()\n        for layer in net.modules():\n            if isinstance(layer, nn.BatchNorm2d):\n                layer.float()\n    net.to(device)\n    if hypar[\"restore_model\"] != \"\":\n        net.load_state_dict(",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "def predict(net, inputs_val, shapes_val, hypar, device):\n    \"\"\"\n    Predicts the mask for the given input image.\n    Arguments:\n    net -- the neural network model used for prediction\n    inputs_val -- tensor of input images (shape: (1, C, H, W))\n    shapes_val -- tensor containing the original shape of the image\n    hypar -- dictionary of hyperparameters\n    device -- the device on which to perform the computations ('cuda' or 'cpu')\n    Returns:",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "save_inference",
        "kind": 2,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "def save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)\n    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nclass GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "transform = transforms.Compose([GOSNormalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])])\ndef load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "hypar",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "hypar = {\n    \"model_path\": \"saved_models\",\n    \"restore_model\": \"isnet.pth\",\n    \"interm_sup\": False,\n    \"model_digit\": \"full\",\n    \"seed\": 0,\n    \"cache_size\": [1024, 1024],\n    \"input_size\": [1024, 1024],\n    \"crop_size\": [1024, 1024],\n    \"model\": ISNetDIS(),",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "net = build_model(hypar, device)\ndef save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "input_path",
        "kind": 5,
        "importPath": "DL_Model.IS-NET.isnet_inference",
        "description": "DL_Model.IS-NET.isnet_inference",
        "peekOfCode": "input_path = \"your_image_path\"\nmask_path, rgba_path = save_inference(input_path)",
        "detail": "DL_Model.IS-NET.isnet_inference",
        "documentation": {}
    },
    {
        "label": "NeuralStyleTransfer",
        "kind": 6,
        "importPath": "DL_Model.NST.nst",
        "description": "DL_Model.NST.nst",
        "peekOfCode": "class NeuralStyleTransfer:\n    def __init__(self, model_path=None):\n        self.img_size = 400\n        self.pp = pprint.PrettyPrinter(indent=4)\n        self.model_path = model_path\n        self.vgg = self._load_vgg_model()\n        self.content_image = None\n        self.style_image = None\n        self.generated_image = None\n        self.optimizer = tf.keras.optimizers.Adam(",
        "detail": "DL_Model.NST.nst",
        "documentation": {}
    },
    {
        "label": "upscale_image",
        "kind": 2,
        "importPath": "DL_Model.Real-ERSGAN.ersgan_inference",
        "description": "DL_Model.Real-ERSGAN.ersgan_inference",
        "peekOfCode": "def upscale_image(input_path, output_path, model_name=\"RealESRGAN_x4plus\"):\n    if model_name == \"RealESRGAN_x4plus\":\n        model = RRDBNet(\n            num_in_ch=3,\n            num_out_ch=3,\n            num_feat=64,\n            num_block=23,\n            num_grow_ch=32,\n            scale=4,\n        )",
        "detail": "DL_Model.Real-ERSGAN.ersgan_inference",
        "documentation": {}
    },
    {
        "label": "RealESRGANer",
        "kind": 6,
        "importPath": "DL_Model.Real-ERSGAN.utils",
        "description": "DL_Model.Real-ERSGAN.utils",
        "peekOfCode": "class RealESRGANer:\n    \"\"\"\n    Implements Real-ESRGAN super-resolution model functionality\n    Arguments:\n    scale -- integer defining the upscaling factor\n    model_path -- string path to the model weights file\n    dni_weight -- optional weights for deep network interpolation\n    model -- the neural network model to be used\n    tile -- integer size of tiles for processing large images\n    tile_pad -- integer padding size for tiles",
        "detail": "DL_Model.Real-ERSGAN.utils",
        "documentation": {}
    },
    {
        "label": "ROOT_DIR",
        "kind": 5,
        "importPath": "DL_Model.Real-ERSGAN.utils",
        "description": "DL_Model.Real-ERSGAN.utils",
        "peekOfCode": "ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nclass RealESRGANer:\n    \"\"\"\n    Implements Real-ESRGAN super-resolution model functionality\n    Arguments:\n    scale -- integer defining the upscaling factor\n    model_path -- string path to the model weights file\n    dni_weight -- optional weights for deep network interpolation\n    model -- the neural network model to be used\n    tile -- integer size of tiles for processing large images",
        "detail": "DL_Model.Real-ERSGAN.utils",
        "documentation": {}
    },
    {
        "label": "DeviceException",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify._device",
        "description": "DL_Model.deoldify.deoldify._device",
        "peekOfCode": "class DeviceException(Exception):\n    pass\nclass _Device:\n    def __init__(self):\n        self.set(DeviceId.CPU)\n    def is_gpu(self):\n        \"\"\"Returns `True` if the current device is GPU, `False` otherwise.\"\"\"\n        return self.current() is not DeviceId.CPU\n    def current(self):\n        return self._current_device",
        "detail": "DL_Model.deoldify.deoldify._device",
        "documentation": {}
    },
    {
        "label": "_Device",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify._device",
        "description": "DL_Model.deoldify.deoldify._device",
        "peekOfCode": "class _Device:\n    def __init__(self):\n        self.set(DeviceId.CPU)\n    def is_gpu(self):\n        \"\"\"Returns `True` if the current device is GPU, `False` otherwise.\"\"\"\n        return self.current() is not DeviceId.CPU\n    def current(self):\n        return self._current_device\n    def set(self, device: DeviceId):\n        if device == DeviceId.CPU:",
        "detail": "DL_Model.deoldify.deoldify._device",
        "documentation": {}
    },
    {
        "label": "DeviceId",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.device_id",
        "description": "DL_Model.deoldify.deoldify.device_id",
        "peekOfCode": "class DeviceId(IntEnum):\n    GPU0 = (0,)\n    GPU1 = (1,)\n    GPU2 = (2,)\n    GPU3 = (3,)\n    GPU4 = (4,)\n    GPU5 = (5,)\n    GPU6 = (6,)\n    GPU7 = (7,)\n    CPU = 99",
        "detail": "DL_Model.deoldify.deoldify.device_id",
        "documentation": {}
    },
    {
        "label": "IFilter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.filters",
        "description": "DL_Model.deoldify.deoldify.filters",
        "peekOfCode": "class IFilter(ABC):\n    @abstractmethod\n    def filter(\n        self, orig_image: PilImage, filtered_image: PilImage, render_factor: int\n    ) -> PilImage:\n        pass\nclass BaseFilter(IFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__()\n        self.learn = learn",
        "detail": "DL_Model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "BaseFilter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.filters",
        "description": "DL_Model.deoldify.deoldify.filters",
        "peekOfCode": "class BaseFilter(IFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__()\n        self.learn = learn\n        if not device_settings.is_gpu():\n            self.learn.model = self.learn.model.cpu()\n        self.device = next(self.learn.model.parameters()).device\n        self.norm, self.denorm = normalize_funcs(*stats)\n    def _transform(self, image: PilImage) -> PilImage:\n        return image",
        "detail": "DL_Model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "ColorizerFilter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.filters",
        "description": "DL_Model.deoldify.deoldify.filters",
        "peekOfCode": "class ColorizerFilter(BaseFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__(learn=learn, stats=stats)\n        self.render_base = 16\n    def filter(\n        self,\n        orig_image: PilImage,\n        filtered_image: PilImage,\n        render_factor: int,\n        post_process: bool = True,",
        "detail": "DL_Model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "MasterFilter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.filters",
        "description": "DL_Model.deoldify.deoldify.filters",
        "peekOfCode": "class MasterFilter(BaseFilter):\n    def __init__(self, filters: List[IFilter], render_factor: int):\n        self.filters = filters\n        self.render_factor = render_factor\n    def filter(\n        self,\n        orig_image: PilImage,\n        filtered_image: PilImage,\n        render_factor: int = None,\n        post_process: bool = True,",
        "detail": "DL_Model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "gen_inference_wide",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_inference_wide(\n    root_folder: Path, weights_name: str, nf_factor: int = 2, arch=models.resnet101\n) -> Learner:\n    data = get_dummy_databunch()\n    learn = gen_learner_wide(\n        data=data, gen_loss=F.l1_loss, nf_factor=nf_factor, arch=arch\n    )\n    learn.path = root_folder\n    learn.load(weights_name)\n    learn.model.eval()",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_learner_wide",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_learner_wide(\n    data: ImageDataBunch, gen_loss, arch=models.resnet101, nf_factor: int = 2\n) -> Learner:\n    return unet_learner_wide(\n        data,\n        arch=arch,\n        wd=1e-3,\n        blur=True,\n        norm_type=NormType.Spectral,\n        self_attention=True,",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "unet_learner_wide",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def unet_learner_wide(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_inference_deep",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_inference_deep(\n    root_folder: Path, weights_name: str, arch=models.resnet34, nf_factor: float = 1.5\n) -> Learner:\n    data = get_dummy_databunch()\n    learn = gen_learner_deep(\n        data=data, gen_loss=F.l1_loss, arch=arch, nf_factor=nf_factor\n    )\n    learn.path = root_folder\n    learn.load(weights_name)\n    learn.model.eval()",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_learner_deep",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_learner_deep(\n    data: ImageDataBunch, gen_loss, arch=models.resnet34, nf_factor: float = 1.5\n) -> Learner:\n    return unet_learner_deep(\n        data,\n        arch,\n        wd=1e-3,\n        blur=True,\n        norm_type=NormType.Spectral,\n        self_attention=True,",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "unet_learner_deep",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.generators",
        "description": "DL_Model.deoldify.deoldify.generators",
        "peekOfCode": "def unet_learner_deep(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "DL_Model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "ModelImageVisualizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "class ModelImageVisualizer:\n    def __init__(self, filter: IFilter, results_dir: str = None):\n        self.filter = filter\n        self.results_dir = None if results_dir is None else Path(results_dir)\n        self.results_dir.mkdir(parents=True, exist_ok=True)\n    def _clean_mem(self):\n        torch.cuda.empty_cache()\n        # gc.collect()\n    def _open_pil_image(self, path: Path) -> Image:\n        return PIL.Image.open(path).convert(\"RGB\")",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "VideoColorizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "class VideoColorizer:\n    def __init__(self, vis: ModelImageVisualizer):\n        self.vis = vis\n        workfolder = Path(\"./video\")\n        self.source_folder = workfolder / \"source\"\n        self.bwframes_root = workfolder / \"bwframes\"\n        self.audio_root = workfolder / \"audio\"\n        self.colorframes_root = workfolder / \"colorframes\"\n        self.result_folder = workfolder / \"result\"\n    def _purge_images(self, dir):",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_watermarked",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_watermarked(pil_image: Image) -> Image:\n    try:\n        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n        (h, w) = image.shape[:2]\n        image = np.dstack([image, np.ones((h, w), dtype=\"uint8\") * 255])\n        pct = 0.05\n        full_watermark = cv2.imread(\n            \"./resource_images/watermark.png\", cv2.IMREAD_UNCHANGED\n        )\n        (fwH, fwW) = full_watermark.shape[:2]",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_video_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_video_colorizer(render_factor: int = 21) -> VideoColorizer:\n    return get_stable_video_colorizer(render_factor=render_factor)\ndef get_artistic_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> VideoColorizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_artistic_video_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_artistic_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> VideoColorizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n    return VideoColorizer(vis)",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_stable_video_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_stable_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeVideo_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 21,\n) -> VideoColorizer:\n    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n    return VideoColorizer(vis)",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_image_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_image_colorizer(\n    root_folder: Path = Path(\"./\"), render_factor: int = 35, artistic: bool = True\n) -> ModelImageVisualizer:\n    if artistic:\n        return get_artistic_image_colorizer(\n            root_folder=root_folder, render_factor=render_factor\n        )\n    else:\n        return get_stable_image_colorizer(\n            root_folder=root_folder, render_factor=render_factor",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_stable_image_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_stable_image_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeStable_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> ModelImageVisualizer:\n    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    return ModelImageVisualizer(filtr, results_dir=results_dir)\ndef get_artistic_image_colorizer(",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_artistic_image_colorizer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_artistic_image_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> ModelImageVisualizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    return ModelImageVisualizer(filtr, results_dir=results_dir)\ndef show_image_in_notebook(image_path: Path):",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "show_image_in_notebook",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def show_image_in_notebook(image_path: Path):\n    ipythondisplay.display(ipythonimage(str(image_path)))\ndef show_video_in_notebook(video_path: Path):\n    video = io.open(video_path, \"r+b\").read()\n    encoded = base64.b64encode(video)\n    ipythondisplay.display(\n        HTML(\n            data=\"\"\"<video alt=\"test\" autoplay\n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "show_video_in_notebook",
        "kind": 2,
        "importPath": "DL_Model.deoldify.deoldify.visualize",
        "description": "DL_Model.deoldify.deoldify.visualize",
        "peekOfCode": "def show_video_in_notebook(video_path: Path):\n    video = io.open(video_path, \"r+b\").read()\n    encoded = base64.b64encode(video)\n    ipythondisplay.display(\n        HTML(\n            data=\"\"\"<video alt=\"test\" autoplay\n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n             </video>\"\"\".format(\n                encoded.decode(\"ascii\")",
        "detail": "DL_Model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "CSVLogger",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "description": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "peekOfCode": "class CSVLogger(LearnerCallback):\n    \"A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.\"\n    def __init__(self, learn: Learner, filename: str = \"history\", append: bool = False):\n        super().__init__(learn)\n        self.filename, self.path, self.append = (\n            filename,\n            self.learn.path / f\"{filename}.csv\",\n            append,\n        )\n        self.add_time = True",
        "detail": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "description": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "peekOfCode": "__all__ = [\"CSVLogger\"]\nclass CSVLogger(LearnerCallback):\n    \"A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.\"\n    def __init__(self, learn: Learner, filename: str = \"history\", append: bool = False):\n        super().__init__(learn)\n        self.filename, self.path, self.append = (\n            filename,\n            self.learn.path / f\"{filename}.csv\",\n            append,\n        )",
        "detail": "DL_Model.deoldify.fastai.callbacks.csv_logger",
        "documentation": {}
    },
    {
        "label": "MixedPrecision",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "class MixedPrecision(LearnerCallback):\n    _order = 999  # Need to run after things that could call on_backward_begin and change the loss\n    \"Callback that handles mixed-precision training.\"\n    def __init__(\n        self,\n        learn: Learner,\n        loss_scale: float = None,\n        max_noskip: int = 1000,\n        dynamic: bool = True,\n        clip: float = None,",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "get_master",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def get_master(\n    layer_groups: ModuleList, flat_master: bool = False\n) -> Tuple[List[List[Tensor]], List[List[Tensor]]]:\n    \"Return two lists, one for the model parameters in FP16 and one for the master parameters in FP32.\"\n    split_params = split_no_wd_params(layer_groups)\n    model_params = [\n        [param for param in pg if param.requires_grad] for pg in split_params\n    ]\n    if flat_master:\n        master_params = []",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "model_g2master_g",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def model_g2master_g(\n    model_params: Sequence[Tensor],\n    master_params: Sequence[Tensor],\n    flat_master: bool = False,\n) -> None:\n    \"Copy the `model_params` gradients to `master_params` for the optimizer step.\"\n    if flat_master:\n        for model_group, master_group in zip(model_params, master_params):\n            if len(master_group) != 0:\n                if master_group[0].grad is None:",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "master2model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def master2model(\n    model_params: Sequence[Tensor],\n    master_params: Sequence[Tensor],\n    flat_master: bool = False,\n) -> None:\n    \"Copy `master_params` to `model_params`.\"\n    if flat_master:\n        for model_group, master_group in zip(model_params, master_params):\n            if len(model_group) != 0:\n                for model, master in zip(",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "grad_overflow",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def grad_overflow(param_group):\n    for group in param_group:\n        for p in group:\n            if p.grad is not None:\n                s = float(p.grad.data.float().sum())\n                if s == float(\"inf\") or s == float(\"-inf\") or s != s:\n                    return True\n    return False\nclass MixedPrecision(LearnerCallback):\n    _order = 999  # Need to run after things that could call on_backward_begin and change the loss",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.fp16",
        "description": "DL_Model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "__all__ = [\"MixedPrecision\"]\ndef get_master(\n    layer_groups: ModuleList, flat_master: bool = False\n) -> Tuple[List[List[Tensor]], List[List[Tensor]]]:\n    \"Return two lists, one for the model parameters in FP16 and one for the master parameters in FP32.\"\n    split_params = split_no_wd_params(layer_groups)\n    model_params = [\n        [param for param in pg if param.requires_grad] for pg in split_params\n    ]\n    if flat_master:",
        "detail": "DL_Model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "TrainingPhase",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "description": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "class TrainingPhase:\n    \"Schedule hyper-parameters for a phase of `length` iterations.\"\n    length: int\n    def __post_init__(self):\n        self.scheds = dict()\n    def schedule_hp(self, name, vals, anneal=None):\n        \"Adds a schedule for `name` between `vals` using `anneal`.\"\n        self.scheds[name] = Scheduler(vals, self.length, anneal)\n        return self\nclass GeneralScheduler(LearnerCallback):",
        "detail": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "GeneralScheduler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "description": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "class GeneralScheduler(LearnerCallback):\n    \"Schedule multiple `TrainingPhase` for a `Learner`.\"\n    def __init__(\n        self, learn: Learner, phases: Collection[TrainingPhase], start_epoch: int = None\n    ):\n        super().__init__(learn)\n        self.phases, self.start_epoch = phases, start_epoch\n    def on_train_begin(self, epoch: int, **kwargs: Any) -> None:\n        \"Initialize the schedulers for training.\"\n        res = {\"epoch\": self.start_epoch} if self.start_epoch is not None else None",
        "detail": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "description": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "__all__ = [\"GeneralScheduler\", \"TrainingPhase\"]\n@dataclass\nclass TrainingPhase:\n    \"Schedule hyper-parameters for a phase of `length` iterations.\"\n    length: int\n    def __post_init__(self):\n        self.scheds = dict()\n    def schedule_hp(self, name, vals, anneal=None):\n        \"Adds a schedule for `name` between `vals` using `anneal`.\"\n        self.scheds[name] = Scheduler(vals, self.length, anneal)",
        "detail": "DL_Model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "Hook",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class Hook:\n    \"Create a hook on `m` with `hook_func`.\"\n    def __init__(\n        self,\n        m: nn.Module,\n        hook_func: HookFunc,\n        is_forward: bool = True,\n        detach: bool = True,\n    ):\n        self.hook_func, self.detach, self.stored = hook_func, detach, None",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "Hooks",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class Hooks:\n    \"Create several hooks on the modules in `ms` with `hook_func`.\"\n    def __init__(\n        self,\n        ms: Collection[nn.Module],\n        hook_func: HookFunc,\n        is_forward: bool = True,\n        detach: bool = True,\n    ):\n        self.hooks = [Hook(m, hook_func, is_forward, detach) for m in ms]",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "HookCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"\n    def __init__(\n        self,\n        learn: Learner,\n        modules: Sequence[nn.Module] = None,\n        do_remove: bool = True,\n    ):\n        super().__init__(learn)\n        self.modules, self.do_remove = modules, do_remove",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "ActivationStats",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class ActivationStats(HookCallback):\n    \"Callback that record the mean and std of activations.\"\n    def on_train_begin(self, **kwargs):\n        \"Initialize stats.\"\n        super().on_train_begin(**kwargs)\n        self.stats = []\n    def hook(\n        self, m: nn.Module, i: Tensors, o: Tensors\n    ) -> Tuple[Rank0Tensor, Rank0Tensor]:\n        \"Take the mean and std of `o`.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_output",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_output(module: nn.Module, detach: bool = True, grad: bool = False) -> Hook:\n    \"Return a `Hook` that stores activations of `module` in `self.stored`\"\n    return Hook(module, _hook_inner, detach=detach, is_forward=not grad)\ndef hook_outputs(\n    modules: Collection[nn.Module], detach: bool = True, grad: bool = False\n) -> Hooks:\n    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)\nclass HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_outputs",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_outputs(\n    modules: Collection[nn.Module], detach: bool = True, grad: bool = False\n) -> Hooks:\n    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)\nclass HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"\n    def __init__(\n        self,\n        learn: Learner,",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "dummy_batch",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def dummy_batch(m: nn.Module, size: tuple = (64, 64)) -> Tensor:\n    \"Create a dummy batch to go through `m` with `size`.\"\n    ch_in = in_channels(m)\n    return one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.0, 1.0)\ndef dummy_eval(m: nn.Module, size: tuple = (64, 64)):\n    \"Pass a `dummy_batch` in evaluation mode in `m` with `size`.\"\n    m.eval()\n    return m(dummy_batch(m, size))\n    # return m.eval()(dummy_batch(m, size))\ndef model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "dummy_eval",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def dummy_eval(m: nn.Module, size: tuple = (64, 64)):\n    \"Pass a `dummy_batch` in evaluation mode in `m` with `size`.\"\n    m.eval()\n    return m(dummy_batch(m, size))\n    # return m.eval()(dummy_batch(m, size))\ndef model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model `m` to get the various sizes of activations.\"\n    with hook_outputs(m) as hooks:\n        x = dummy_eval(m, size)\n        return [o.stored.shape for o in hooks]",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "model_sizes",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model `m` to get the various sizes of activations.\"\n    with hook_outputs(m) as hooks:\n        x = dummy_eval(m, size)\n        return [o.stored.shape for o in hooks]\ndef num_features_model(m: nn.Module) -> int:\n    \"Return the number of output features for `model`.\"\n    sz = 64\n    while True:\n        try:",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "num_features_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def num_features_model(m: nn.Module) -> int:\n    \"Return the number of output features for `model`.\"\n    sz = 64\n    while True:\n        try:\n            return model_sizes(m, size=(sz, sz))[-1][1]\n        except Exception as e:\n            sz *= 2\n            if sz > 2048:\n                raise",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "total_params",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def total_params(m: nn.Module) -> int:\n    params, trainable = 0, False\n    if hasattr(m, \"weight\") and hasattr(m.weight, \"size\"):\n        params += m.weight.numel()\n        trainable = m.weight.requires_grad\n    if hasattr(m, \"bias\") and hasattr(m.bias, \"size\"):\n        params += m.bias.numel()\n    return params, trainable\ndef hook_params(modules: Collection[nn.Module]) -> Hooks:\n    return Hooks(modules, lambda m, i, o: total_params(m))",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_params",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_params(modules: Collection[nn.Module]) -> Hooks:\n    return Hooks(modules, lambda m, i, o: total_params(m))\ndef params_size(\n    m: Union[nn.Module, Learner], size: tuple = (3, 64, 64)\n) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model to get the various sizes. Returns (res,x,hooks) if `full`\"\n    if isinstance(m, Learner):\n        if m.data.is_empty:\n            raise Exception(\n                \"This is an empty `Learner` and `Learner.summary` requires some data to pass through the model.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "params_size",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def params_size(\n    m: Union[nn.Module, Learner], size: tuple = (3, 64, 64)\n) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model to get the various sizes. Returns (res,x,hooks) if `full`\"\n    if isinstance(m, Learner):\n        if m.data.is_empty:\n            raise Exception(\n                \"This is an empty `Learner` and `Learner.summary` requires some data to pass through the model.\"\n            )\n        ds_type = (",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "get_layer_name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def get_layer_name(layer: nn.Module) -> str:\n    return str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\ndef layers_info(m: Collection[nn.Module]) -> Collection[namedtuple]:\n    func = lambda m: list(map(get_layer_name, flatten_model(m)))\n    layers_names = func(m.model) if isinstance(m, Learner) else func(m)\n    layers_sizes, layers_params, layers_trainable = params_size(m)\n    layer_info = namedtuple(\n        \"Layer_Information\", [\"Layer\", \"OutputSize\", \"Params\", \"Trainable\"]\n    )\n    return list(",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "layers_info",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def layers_info(m: Collection[nn.Module]) -> Collection[namedtuple]:\n    func = lambda m: list(map(get_layer_name, flatten_model(m)))\n    layers_names = func(m.model) if isinstance(m, Learner) else func(m)\n    layers_sizes, layers_params, layers_trainable = params_size(m)\n    layer_info = namedtuple(\n        \"Layer_Information\", [\"Layer\", \"OutputSize\", \"Params\", \"Trainable\"]\n    )\n    return list(\n        map(layer_info, layers_names, layers_sizes, layers_params, layers_trainable)\n    )",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "model_summary",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def model_summary(m: Learner, n: int = 70):\n    \"Print a summary of `m` using a output text width of `n` chars\"\n    info = layers_info(m)\n    header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Trainable\"]\n    res = m.model.__class__.__name__ + \"\\n\"\n    res += \"=\" * n + \"\\n\"\n    res += f\"{header[0]:<20} {header[1]:<20} {header[2]:<10} {header[3]:<10}\\n\"\n    res += \"=\" * n + \"\\n\"\n    total_params = 0\n    total_trainable_params = 0",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "__all__ = [\n    \"ActivationStats\",\n    \"Hook\",\n    \"HookCallback\",\n    \"Hooks\",\n    \"hook_output\",\n    \"hook_outputs\",\n    \"model_sizes\",\n    \"num_features_model\",\n    \"model_summary\",",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "Learner.summary",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.hooks",
        "description": "DL_Model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "Learner.summary = model_summary",
        "detail": "DL_Model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "LossMetrics",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "description": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "peekOfCode": "class LossMetrics(LearnerCallback):\n    \"Add `loss_func.metrics` to metrics named by `loss_func.metric_names`\"\n    _order = -20  # Needs to run before the recorder\n    def on_train_begin(self, **kwargs):\n        \"Add the metrics names to the `Recorder`.\"\n        self.names = ifnone(self.learn.loss_func.metric_names, [])\n        if not self.names:\n            warn(\"LossMetrics requested but no loss_func.metric_names provided\")\n        self.learn.recorder.add_metric_names(self.names)\n    def on_epoch_begin(self, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "description": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "peekOfCode": "__all__ = [\"LossMetrics\"]\nclass LossMetrics(LearnerCallback):\n    \"Add `loss_func.metrics` to metrics named by `loss_func.metric_names`\"\n    _order = -20  # Needs to run before the recorder\n    def on_train_begin(self, **kwargs):\n        \"Add the metrics names to the `Recorder`.\"\n        self.names = ifnone(self.learn.loss_func.metric_names, [])\n        if not self.names:\n            warn(\"LossMetrics requested but no loss_func.metric_names provided\")\n        self.learn.recorder.add_metric_names(self.names)",
        "detail": "DL_Model.deoldify.fastai.callbacks.loss_metrics",
        "documentation": {}
    },
    {
        "label": "LRFinder",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "description": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "peekOfCode": "class LRFinder(LearnerCallback):\n    \"Causes `learn` to go on a mock training from `start_lr` to `end_lr` for `num_it` iterations.\"\n    def __init__(\n        self,\n        learn: Learner,\n        start_lr: float = 1e-7,\n        end_lr: float = 10,\n        num_it: int = 100,\n        stop_div: bool = True,\n    ):",
        "detail": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "description": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "peekOfCode": "__all__ = [\"LRFinder\"]\nclass LRFinder(LearnerCallback):\n    \"Causes `learn` to go on a mock training from `start_lr` to `end_lr` for `num_it` iterations.\"\n    def __init__(\n        self,\n        learn: Learner,\n        start_lr: float = 1e-7,\n        end_lr: float = 10,\n        num_it: int = 100,\n        stop_div: bool = True,",
        "detail": "DL_Model.deoldify.fastai.callbacks.lr_finder",
        "documentation": {}
    },
    {
        "label": "PeakMemMetric",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.mem",
        "description": "DL_Model.deoldify.fastai.callbacks.mem",
        "peekOfCode": "class PeakMemMetric(LearnerCallback):\n    \"Callback that measures used and peaked general and GPU memory.\"\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner):\n        super().__init__(learn)\n        assert torch.cuda.is_available(), \"pytorch CUDA is required\"\n        preload_pytorch()\n    def peak_monitor_start(self):\n        self.peak_monitoring = True\n        # start RAM tracing",
        "detail": "DL_Model.deoldify.fastai.callbacks.mem",
        "documentation": {}
    },
    {
        "label": "StopAfterNBatches",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.misc",
        "description": "DL_Model.deoldify.fastai.callbacks.misc",
        "peekOfCode": "class StopAfterNBatches(Callback):\n    \"Stop training after n batches of the first epoch.\"\n    def __init__(self, n_batches: int = 2):\n        self.stop, self.n_batches = False, n_batches - 1  # iteration starts from 0\n    def on_batch_end(self, iteration, **kwargs):\n        if iteration == self.n_batches:\n            return {\"stop_epoch\": True, \"stop_training\": True, \"skip_validate\": True}",
        "detail": "DL_Model.deoldify.fastai.callbacks.misc",
        "documentation": {}
    },
    {
        "label": "MixUpCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.mixup",
        "description": "DL_Model.deoldify.fastai.callbacks.mixup",
        "peekOfCode": "class MixUpCallback(LearnerCallback):\n    \"Callback that creates the mixed-up input and target.\"\n    def __init__(\n        self,\n        learn: Learner,\n        alpha: float = 0.4,\n        stack_x: bool = False,\n        stack_y: bool = True,\n    ):\n        super().__init__(learn)",
        "detail": "DL_Model.deoldify.fastai.callbacks.mixup",
        "documentation": {}
    },
    {
        "label": "MixUpLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.mixup",
        "description": "DL_Model.deoldify.fastai.callbacks.mixup",
        "peekOfCode": "class MixUpLoss(Module):\n    \"Adapt the loss function `crit` to go with mixup.\"\n    def __init__(self, crit, reduction=\"mean\"):\n        super().__init__()\n        if hasattr(crit, \"reduction\"):\n            self.crit = crit\n            self.old_red = crit.reduction\n            setattr(self.crit, \"reduction\", \"none\")\n        else:\n            self.crit = partial(crit, reduction=\"none\")",
        "detail": "DL_Model.deoldify.fastai.callbacks.mixup",
        "documentation": {}
    },
    {
        "label": "MLFlowTracker",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.mlflow",
        "description": "DL_Model.deoldify.fastai.callbacks.mlflow",
        "peekOfCode": "class MLFlowTracker(LearnerCallback):\n    \"A `TrackerCallback` that tracks the loss and metrics into MLFlow\"\n    def __init__(\n        self,\n        learn: Learner,\n        exp_name: str,\n        params: dict,\n        nb_path: str,\n        uri: str = \"http://localhost:5000\",\n    ):",
        "detail": "DL_Model.deoldify.fastai.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "OneCycleScheduler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "description": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "peekOfCode": "class OneCycleScheduler(LearnerCallback):\n    \"Manage 1-Cycle style training as outlined in Leslie Smith's [paper](https://arxiv.org/pdf/1803.09820.pdf).\"\n    def __init__(\n        self,\n        learn: Learner,\n        lr_max: float,\n        moms: Floats = (0.95, 0.85),\n        div_factor: float = 25.0,\n        pct_start: float = 0.3,\n        final_div: float = None,",
        "detail": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "description": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "peekOfCode": "__all__ = [\"OneCycleScheduler\"]\nclass OneCycleScheduler(LearnerCallback):\n    \"Manage 1-Cycle style training as outlined in Leslie Smith's [paper](https://arxiv.org/pdf/1803.09820.pdf).\"\n    def __init__(\n        self,\n        learn: Learner,\n        lr_max: float,\n        moms: Floats = (0.95, 0.85),\n        div_factor: float = 25.0,\n        pct_start: float = 0.3,",
        "detail": "DL_Model.deoldify.fastai.callbacks.one_cycle",
        "documentation": {}
    },
    {
        "label": "OverSamplingCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "description": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "peekOfCode": "class OverSamplingCallback(LearnerCallback):\n    def __init__(self, learn: Learner, weights: torch.Tensor = None):\n        super().__init__(learn)\n        self.labels = self.learn.data.train_dl.dataset.y.items\n        _, counts = np.unique(self.labels, return_counts=True)\n        self.weights = (\n            weights\n            if weights is not None\n            else torch.DoubleTensor((1 / counts)[self.labels])\n        )",
        "detail": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "description": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "peekOfCode": "__all__ = [\"OverSamplingCallback\"]\nclass OverSamplingCallback(LearnerCallback):\n    def __init__(self, learn: Learner, weights: torch.Tensor = None):\n        super().__init__(learn)\n        self.labels = self.learn.data.train_dl.dataset.y.items\n        _, counts = np.unique(self.labels, return_counts=True)\n        self.weights = (\n            weights\n            if weights is not None\n            else torch.DoubleTensor((1 / counts)[self.labels])",
        "detail": "DL_Model.deoldify.fastai.callbacks.oversampling",
        "documentation": {}
    },
    {
        "label": "RNNTrainer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.rnn",
        "description": "DL_Model.deoldify.fastai.callbacks.rnn",
        "peekOfCode": "class RNNTrainer(LearnerCallback):\n    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n    def __init__(self, learn: Learner, alpha: float = 0.0, beta: float = 0.0):\n        super().__init__(learn)\n        self.not_min += [\"raw_out\", \"out\"]\n        self.alpha, self.beta = alpha, beta\n    def on_epoch_begin(self, **kwargs):\n        \"Reset the hidden state of the model.\"\n        self.learn.model.reset()\n    def on_loss_begin(self, last_output: Tuple[Tensor, Tensor, Tensor], **kwargs):",
        "detail": "DL_Model.deoldify.fastai.callbacks.rnn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.rnn",
        "description": "DL_Model.deoldify.fastai.callbacks.rnn",
        "peekOfCode": "__all__ = [\"RNNTrainer\"]\nclass RNNTrainer(LearnerCallback):\n    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n    def __init__(self, learn: Learner, alpha: float = 0.0, beta: float = 0.0):\n        super().__init__(learn)\n        self.not_min += [\"raw_out\", \"out\"]\n        self.alpha, self.beta = alpha, beta\n    def on_epoch_begin(self, **kwargs):\n        \"Reset the hidden state of the model.\"\n        self.learn.model.reset()",
        "detail": "DL_Model.deoldify.fastai.callbacks.rnn",
        "documentation": {}
    },
    {
        "label": "LearnerTensorboardWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class LearnerTensorboardWriter(LearnerCallback):\n    \"Broadly useful callback for Learners that writes to Tensorboard.  Writes model histograms, losses/metrics, and gradient stats.\"\n    def __init__(\n        self,\n        learn: Learner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GANTensorboardWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GANTensorboardWriter(LearnerTensorboardWriter):\n    \"Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(\n        self,\n        learn: GANLearner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageGenTensorboardWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageGenTensorboardWriter(LearnerTensorboardWriter):\n    \"Callback for non-GAN image generating Learners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(\n        self,\n        learn: Learner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "TBWriteRequest",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class TBWriteRequest(ABC):\n    \"A request object for Tensorboard writes.  Useful for queuing up and executing asynchronous writes.\"\n    def __init__(self, tbwriter: SummaryWriter, iteration: int):\n        super().__init__()\n        self.tbwriter = tbwriter\n        self.iteration = iteration\n    @abstractmethod\n    def write(self) -> None:\n        pass\n# SummaryWriter writes tend to block quite a bit.  This gets around that and greatly boosts performance.",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "AsyncTBWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class AsyncTBWriter:\n    \"Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(self):\n        super().__init__()\n        self.stop_request = Event()\n        self.queue = Queue()\n        self.thread = Thread(target=self._queue_processor, daemon=True)\n        self.thread.start()\n    def request_write(self, request: TBWriteRequest) -> None:\n        \"Queues up an asynchronous write request to Tensorboard.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelImageSet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelImageSet:\n    \"Convenience object that holds the original, real(target) and generated versions of a single image fed to a model.\"\n    @staticmethod\n    def get_list_from_model(learn: Learner, ds_type: DatasetType, batch: Tuple) -> []:\n        \"Factory method to convert a batch of model images to a list of ModelImageSet.\"\n        image_sets = []\n        x, y = batch[0], batch[1]\n        preds = []\n        preds = learn.pred_batch(ds_type=ds_type, batch=(x, y), reconstruct=True)\n        for orig_px, real_px, gen in zip(x, y, preds):",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "HistogramTBRequest",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class HistogramTBRequest(TBWriteRequest):\n    \"Request object for model histogram writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, iteration: int, tbwriter: SummaryWriter, name: str\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.params = [\n            (name, values.clone().detach().cpu())\n            for (name, values) in model.named_parameters()\n        ]",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "HistogramTBWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class HistogramTBWriter:\n    \"Writes model histograms to Tensorboard.\"\n    def __init__(self):\n        super().__init__()\n    def write(\n        self,\n        model: nn.Module,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        name: str = \"model\",",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelStatsTBRequest",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelStatsTBRequest(TBWriteRequest):\n    \"Request object for model gradient statistics writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, iteration: int, tbwriter: SummaryWriter, name: str\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.gradients = [\n            x.grad.clone().detach().cpu()\n            for x in model.parameters()\n            if x.grad is not None",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelStatsTBWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelStatsTBWriter:\n    \"Writes model gradient statistics to Tensorboard.\"\n    def write(\n        self,\n        model: nn.Module,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        name: str = \"model_stats\",\n    ) -> None:\n        \"Writes model gradient statistics to Tensorboard.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageTBRequest",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageTBRequest(TBWriteRequest):\n    \"Request object for model image output writes to Tensorboard.\"\n    def __init__(\n        self,\n        learn: Learner,\n        batch: Tuple,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        ds_type: DatasetType,\n    ):",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageTBWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageTBWriter:\n    \"Writes model image output to Tensorboard.\"\n    def __init__(self):\n        super().__init__()\n    def write(\n        self,\n        learn: Learner,\n        trn_batch: Tuple,\n        val_batch: Tuple,\n        iteration: int,",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GraphTBRequest",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GraphTBRequest(TBWriteRequest):\n    \"Request object for model histogram writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, tbwriter: SummaryWriter, input_to_model: torch.Tensor\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=0)\n        self.model, self.input_to_model = model, input_to_model\n    def write(self) -> None:\n        \"Writes single model graph to Tensorboard.\"\n        self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GraphTBWriter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GraphTBWriter:\n    \"Writes model network graph to Tensorboard.\"\n    def write(\n        self, model: nn.Module, tbwriter: SummaryWriter, input_to_model: torch.Tensor\n    ) -> None:\n        \"Writes model graph to Tensorboard.\"\n        request = GraphTBRequest(\n            model=model, tbwriter=tbwriter, input_to_model=input_to_model\n        )\n        asyncTBWriter.request_write(request)",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "__all__ = [\n    \"LearnerTensorboardWriter\",\n    \"GANTensorboardWriter\",\n    \"ImageGenTensorboardWriter\",\n]\n# ---Example usage (applies to any of the callbacks)---\n# proj_id = 'Colorize'\n# tboard_path = Path('data/tensorboard/' + proj_id)\n# learn.callback_fns.append(partial(GANTensorboardWriter, base_dir=tboard_path, name='GanLearner'))\nclass LearnerTensorboardWriter(LearnerCallback):",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "asyncTBWriter",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "description": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "asyncTBWriter = AsyncTBWriter()\nclass ModelImageSet:\n    \"Convenience object that holds the original, real(target) and generated versions of a single image fed to a model.\"\n    @staticmethod\n    def get_list_from_model(learn: Learner, ds_type: DatasetType, batch: Tuple) -> []:\n        \"Factory method to convert a batch of model images to a list of ModelImageSet.\"\n        image_sets = []\n        x, y = batch[0], batch[1]\n        preds = []\n        preds = learn.pred_batch(ds_type=ds_type, batch=(x, y), reconstruct=True)",
        "detail": "DL_Model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "TerminateOnNaNCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TerminateOnNaNCallback(Callback):\n    \"A `Callback` that terminates training if loss is NaN.\"\n    def __init__(self):\n        self.stop = False\n    def on_batch_end(self, last_loss, epoch, num_batch, **kwargs: Any) -> None:\n        \"Test if `last_loss` is NaN and interrupts training.\"\n        if self.stop:\n            return True  # to skip validation after stopping during training\n        if torch.isnan(last_loss):\n            print(",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "TrackerCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TrackerCallback(LearnerCallback):\n    \"A `LearnerCallback` that keeps track of the best value in `monitor`.\"\n    def __init__(self, learn: Learner, monitor: str = \"valid_loss\", mode: str = \"auto\"):\n        super().__init__(learn)\n        self.monitor, self.mode = monitor, mode\n        if self.mode not in [\"auto\", \"min\", \"max\"]:\n            warn(\n                f'{self.__class__} mode {self.mode} is invalid, falling back to \"auto\" mode.'\n            )\n            self.mode = \"auto\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "EarlyStoppingCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class EarlyStoppingCallback(TrackerCallback):\n    \"A `TrackerCallback` that terminates training when monitored quantity stops improving.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        min_delta: int = 0,\n        patience: int = 0,\n    ):",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "SaveModelCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class SaveModelCallback(TrackerCallback):\n    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        every: str = \"improvement\",\n        name: str = \"bestmodel\",\n    ):",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateauCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class ReduceLROnPlateauCallback(TrackerCallback):\n    \"A `TrackerCallback` that reduces learning rate when a metric has stopped improving.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        patience: int = 0,\n        factor: float = 0.2,\n        min_delta: int = 0,",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "TrackEpochCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TrackEpochCallback(LearnerCallback):\n    _order = -20  # Need to run before fit_one_cycle\n    def __init__(self, learn: Learner, name: str = \"epoch\", epoch_offset: int = None):\n        \"Store completed epoch number in `learn.model_dir/name`.\"\n        super().__init__(learn)\n        learn._test_writeable_path()\n        self.path = learn.path / learn.model_dir / name\n        if epoch_offset is None:\n            if os.path.isfile(self.path):\n                with self.path.open(\"r\") as f:",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callbacks.tracker",
        "description": "DL_Model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "__all__ = [\n    \"TerminateOnNaNCallback\",\n    \"EarlyStoppingCallback\",\n    \"SaveModelCallback\",\n    \"TrackerCallback\",\n    \"ReduceLROnPlateauCallback\",\n    \"TrackEpochCallback\",\n]\nclass TerminateOnNaNCallback(Callback):\n    \"A `Callback` that terminates training if loss is NaN.\"",
        "detail": "DL_Model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "read_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,\n        remove_undoc_cells,\n    )",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "convert_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,\n        remove_undoc_cells,\n    )\n    nb = read_nb(fname)\n    nb[\"cells\"] = remove_undoc_cells(nb[\"cells\"])\n    nb[\"cells\"] = remove_code_cell_jupyter_widget_state_elem(nb[\"cells\"])\n    fname = Path(fname).absolute()",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "convert_all",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def convert_all(folder, dest_path=\".\", force_all=False):\n    \"Convert modified notebooks in `folder` to html pages in `dest_path`.\"\n    path = Path(folder)\n    changed_cnt = 0\n    for fname in path.glob(\"*.ipynb\"):\n        # only rebuild modified files\n        fname_out = Path(dest_path) / fname.with_suffix(\".html\").name\n        if not force_all and fname_out.exists():\n            in_mod = os.path.getmtime(fname)\n            out_mod = os.path.getmtime(fname_out)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "__all__ = [\"read_nb\", \"convert_nb\", \"convert_all\"]\nexporter = HTMLExporter(Config())\nexporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter = HTMLExporter(Config())\nexporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.exclude_input_prompt",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.exclude_output_prompt",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.template_file",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "description": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "path = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,",
        "detail": "DL_Model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "strip_fastai",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.core",
        "description": "DL_Model.deoldify.fastai.gen_doc.core",
        "peekOfCode": "def strip_fastai(s):\n    return re.sub(r\"^fastai\\.\", \"\", s)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.core",
        "documentation": {}
    },
    {
        "label": "InfoMixin",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "class InfoMixin(object):\n    @classmethod\n    def _get_doc(cls):\n        \"\"\"Return documentary of class\n        By default it returns docstring of class, but it can be overridden\n        for example for cases like merging own docstring with parent\n        \"\"\"\n        return cls.__doc__\n    @classmethod\n    def get_info(cls):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "trim",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"\n    # Convert tabs to spaces (following the normal Python rules)\n    # and split into a list of lines:\n    lines = docstring.expandtabs().splitlines()\n    # Determine minimum indentation (first line doesn't count):\n    indent = sys.maxsize\n    for line in lines[1:]:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "reindent",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def reindent(string):\n    return \"\\n\".join(l.strip() for l in string.strip().split(\"\\n\"))\ndef parse_docstring(docstring):\n    \"\"\"Parse the docstring into its components.\n    :return: a dictionary of form\n              {\n                  \"short_description\": ...,\n                  \"long_description\": ...,\n                  \"params\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"vals\": [{\"name\": ..., \"doc\": ...}, ...],",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "parse_docstring",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def parse_docstring(docstring):\n    \"\"\"Parse the docstring into its components.\n    :return: a dictionary of form\n              {\n                  \"short_description\": ...,\n                  \"long_description\": ...,\n                  \"params\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"vals\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"return\": ...\n              }",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "__all__ = [\"parse_docstring\"]\nFIELDS = \"param|val\"  # supported fields\nPARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "FIELDS",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "FIELDS = \"param|val\"  # supported fields\nPARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "PARAM_OR_RETURN_REGEX",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "PARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "RETURN_REGEX",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "RETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "NEW_REGEX",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "description": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "NEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"\n    # Convert tabs to spaces (following the normal Python rules)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "TestRegistry",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "class TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None\n    missing_this_tests = set()\n    # logic for checking whether each test calls `this_tests`:\n    # 1. `this_tests_check` is set to True during test's 'setup' stage if it wasn't skipped\n    # 2. if the test is dynamically skipped `this_tests_check` is set to False\n    # 3. `this_tests` sets this flag to False when it's successfully completes\n    # 4. if during the 'teardown' stage `this_tests_check` is still True then we",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "a2k",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def a2k(a):\n    return \"::\".join([a[\"file\"], a[\"test\"]]), a[\"line\"]\ndef k2a(k, v):\n    f, t = k.split(\"::\")\n    return {\"file\": f, \"line\": v, \"test\": t}\n# merge by key that is a combination of 2 values: test, file\ndef merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "k2a",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def k2a(k, v):\n    f, t = k.split(\"::\")\n    return {\"file\": f, \"line\": v, \"test\": t}\n# merge by key that is a combination of 2 values: test, file\ndef merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "merge_lists",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]\n    return a\ndef this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "merge_registries",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]\n    return a\ndef this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "this_tests",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")\n    else:\n        return None\n    module = subpaths.pop(0)\n    if module in sys.modules:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "str2func",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")\n    else:\n        return None\n    module = subpaths.pop(0)\n    if module in sys.modules:\n        obj = sys.modules[module]\n    else:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_func_fq_name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_func_fq_name(func):\n    if ismodule(func):\n        return func.__name__\n    if isinstance(func, str):\n        func = str2func(func)\n    name = None\n    if hasattr(func, \"__qualname__\"):\n        name = func.__qualname__\n    elif hasattr(func, \"__name__\"):\n        name = func.__name__",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_parent_func",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_parent_func(lineno, lines, ignore_missing=False):\n    \"Find any lines where `elt` is called and return the parent test function\"\n    for idx, l in enumerate(reversed(lines[:lineno])):\n        if re.match(f\"\\s*def test\", l):\n            return (lineno - idx), l  # 1 based index for github\n        if re.match(f\"\\w+\", l):\n            break  # top level indent - out of function scope\n    if ignore_missing:\n        return None\n    raise LookupError(",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "relative_test_path",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def relative_test_path(test_file: Path) -> str:\n    \"Path relative to the `fastai` parent directory\"\n    test_file = Path(test_file)\n    testdir_idx = list(reversed(test_file.parts)).index(\"tests\")\n    return \"/\".join(test_file.parts[-(testdir_idx + 1) :])\ndef get_lines(file):\n    with open(file, \"r\") as f:\n        return f.readlines()",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_lines",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_lines(file):\n    with open(file, \"r\") as f:\n        return f.readlines()",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "__all__ = [\"this_tests\"]\nDB_NAME = \"test_registry.json\"\ndef _json_set_default(obj):\n    if isinstance(obj, set):\n        return list(obj)\n    raise TypeError\nclass TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "DB_NAME",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "description": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "DB_NAME = \"test_registry.json\"\ndef _json_set_default(obj):\n    if isinstance(obj, set):\n        return list(obj)\n    raise TypeError\nclass TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None\n    missing_this_tests = set()",
        "detail": "DL_Model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "ExecuteShowDocPreprocessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "class ExecuteShowDocPreprocessor(ExecutePreprocessor):\n    \"An ExecutePreprocessor that only executes show_doc cells\"\n    def preprocess_cell(self, cell, resources, index):\n        if \"source\" in cell and cell.cell_type == \"code\":\n            if IMPORT_RE.search(cell[\"source\"]) or SHOW_DOC_RE.search(cell[\"source\"]):\n                return super().preprocess_cell(cell, resources, index)\n        return cell, resources\ndef execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    \"Execute notebook `fname` with `metadata` for preprocessing.\"\n    # Any module used in the notebook that isn't inside must be in the same directory as this script",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_empty_notebook",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_empty_notebook():\n    \"Default notbook with the minimum metadata.\"\n    # TODO: check python version and nbformat\n    return {\n        \"metadata\": {\n            \"kernelspec\": {\n                \"display_name\": \"Python 3\",\n                \"language\": \"python\",\n                \"name\": \"python3\",\n            },",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_md_cell",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_md_cell(source, metadata=None):\n    \"Markdown cell containing `source` with `metadata`.\"\n    return {\n        \"cell_type\": \"markdown\",\n        \"metadata\": {} if metadata is None else metadata,\n        \"source\": source,\n    }\ndef get_empty_cell(ctype=\"markdown\"):\n    \"Empty cell of type `ctype`.\"\n    return {\"cell_type\": ctype, \"metadata\": {}, \"source\": []}",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_empty_cell",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_empty_cell(ctype=\"markdown\"):\n    \"Empty cell of type `ctype`.\"\n    return {\"cell_type\": ctype, \"metadata\": {}, \"source\": []}\ndef get_code_cell(code, hidden=False):\n    \"Code cell containing `code` that may be `hidden`.\"\n    return {\n        \"cell_type\": \"code\",\n        \"execution_count\": 0,\n        \"metadata\": {\"hide_input\": hidden, \"trusted\": True},\n        \"source\": code,",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_code_cell",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_code_cell(code, hidden=False):\n    \"Code cell containing `code` that may be `hidden`.\"\n    return {\n        \"cell_type\": \"code\",\n        \"execution_count\": 0,\n        \"metadata\": {\"hide_input\": hidden, \"trusted\": True},\n        \"source\": code,\n        \"outputs\": [],\n    }\ndef get_doc_cell(func_name):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_doc_cell",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_doc_cell(func_name):\n    \"Code cell with the command to show the doc of `func_name`.\"\n    code = f\"show_doc({func_name})\"\n    return get_code_cell(code, True)\ndef get_global_vars(mod):\n    \"Return globally assigned variables.\"\n    # https://stackoverflow.com/questions/8820276/docstring-for-variable/31764368#31764368\n    import ast\n    import re\n    with open(mod.__file__, \"r\") as f:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_global_vars",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_global_vars(mod):\n    \"Return globally assigned variables.\"\n    # https://stackoverflow.com/questions/8820276/docstring-for-variable/31764368#31764368\n    import ast\n    import re\n    with open(mod.__file__, \"r\") as f:\n        fstr = f.read()\n    flines = fstr.splitlines()\n    d = {}\n    for node in ast.walk(ast.parse(fstr)):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "write_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def write_nb(nb, nb_path, mode=\"w\"):\n    with open(nb_path, mode) as f:\n        f.write(nbformat.writes(nbformat.from_dict(nb), version=4))\nclass ExecuteShowDocPreprocessor(ExecutePreprocessor):\n    \"An ExecutePreprocessor that only executes show_doc cells\"\n    def preprocess_cell(self, cell, resources, index):\n        if \"source\" in cell and cell.cell_type == \"code\":\n            if IMPORT_RE.search(cell[\"source\"]) or SHOW_DOC_RE.search(cell[\"source\"]):\n                return super().preprocess_cell(cell, resources, index)\n        return cell, resources",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "execute_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    \"Execute notebook `fname` with `metadata` for preprocessing.\"\n    # Any module used in the notebook that isn't inside must be in the same directory as this script\n    with open(fname) as f:\n        nb = nbformat.read(f, as_version=4)\n    ep_class = ExecuteShowDocPreprocessor if show_doc_only else ExecutePreprocessor\n    ep = ep_class(timeout=600, kernel_name=\"python3\")\n    metadata = metadata or {}\n    ep.preprocess(nb, metadata)\n    if save:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "create_module_page",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def create_module_page(mod, dest_path, force=False):\n    \"Create the documentation notebook for module `mod_name` in path `dest_path`\"\n    nb = get_empty_notebook()\n    mod_name = mod.__name__\n    strip_name = strip_fastai(mod_name)\n    init_cell = [\n        get_md_cell(f\"## Title for {strip_name} (use plain english, not module name!)\"),\n        get_md_cell(\"Type an introduction of the package here.\"),\n    ]\n    cells = [",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_module_names",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_module_names(path_dir, exclude=None):\n    if exclude is None:\n        exclude = _default_exclude\n    \"Search a given `path_dir` and return all the modules contained inside except those in `exclude`\"\n    files = sorted(\n        path_dir.glob(\"*\"), key=lambda x: (x.is_dir(), x.name), reverse=True\n    )  # directories first\n    res = [f\"{path_dir.name}\"]\n    for f in files:\n        if f.is_dir() and f.name in exclude:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb(fname):\n    \"Read a notebook in `fname` and return its corresponding json\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\nSHOW_DOC_RE = re.compile(r\"show_doc\\(([\\w\\.]*)\")\ndef read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb_content",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":\n            for match in SHOW_DOC_RE.findall(cell[\"source\"]):\n                doc_fns[match] = i\n    return doc_fns\ndef read_nb_types(cells):\n    doc_fns = {}",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb_types",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb_types(cells):\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"markdown\":\n            match = re.match(r\"^(?:<code>|`)?(\\w*)\\s*=\\s*\", cell[\"source\"])\n            if match is not None:\n                doc_fns[match.group(1)] = i\n    return doc_fns\ndef link_markdown_cells(cells, modules):\n    \"Create documentation links for all cells in markdown with backticks.\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "link_markdown_cells",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def link_markdown_cells(cells, modules):\n    \"Create documentation links for all cells in markdown with backticks.\"\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"markdown\":\n            cell[\"source\"] = link_docstring(modules, cell[\"source\"])\ndef get_insert_idx(pos_dict, name):\n    \"Return the position to insert a given function doc in a notebook.\"\n    keys, i = list(pos_dict.keys()), 0\n    while i < len(keys) and str.lower(keys[i]) < str.lower(name):\n        i += 1",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_insert_idx",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_insert_idx(pos_dict, name):\n    \"Return the position to insert a given function doc in a notebook.\"\n    keys, i = list(pos_dict.keys()), 0\n    while i < len(keys) and str.lower(keys[i]) < str.lower(name):\n        i += 1\n    if i == len(keys):\n        return -1\n    else:\n        return pos_dict[keys[i]]\ndef update_pos(pos_dict, start_key, nbr=2):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_pos",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_pos(pos_dict, start_key, nbr=2):\n    \"Update the `pos_dict` by moving all positions after `start_key` by `nbr`.\"\n    for key, idx in pos_dict.items():\n        if str.lower(key) >= str.lower(start_key):\n            pos_dict[key] += nbr\n    return pos_dict\ndef insert_cells(cells, pos_dict, ft_name, append=False):\n    \"Insert the function doc `cells` at their correct position and updates `pos_dict`.\"\n    idx = get_insert_idx(pos_dict, ft_name)\n    if append or idx == -1:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "insert_cells",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def insert_cells(cells, pos_dict, ft_name, append=False):\n    \"Insert the function doc `cells` at their correct position and updates `pos_dict`.\"\n    idx = get_insert_idx(pos_dict, ft_name)\n    if append or idx == -1:\n        cells += [get_doc_cell(ft_name), get_empty_cell()]\n    else:\n        cells.insert(idx, get_doc_cell(ft_name))\n        cells.insert(idx + 1, get_empty_cell())\n        pos_dict = update_pos(pos_dict, ft_name, 2)\n    return cells, pos_dict",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_doc_path",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_doc_path(mod, dest_path):\n    strip_name = strip_fastai(mod.__name__)\n    return os.path.join(dest_path, f\"{strip_name}.ipynb\")\ndef generate_missing_metadata(dest_file):\n    fn = Path(dest_file)\n    meta_fn = fn.parent / \"jekyll_metadata.ipynb\"\n    if not fn.exists() or not meta_fn.exists():\n        return print(\"Could not find notebooks:\", fn, meta_fn)\n    metadata_nb = read_nb(meta_fn)\n    if has_metadata_cell(metadata_nb[\"cells\"], fn.name):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "generate_missing_metadata",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def generate_missing_metadata(dest_file):\n    fn = Path(dest_file)\n    meta_fn = fn.parent / \"jekyll_metadata.ipynb\"\n    if not fn.exists() or not meta_fn.exists():\n        return print(\"Could not find notebooks:\", fn, meta_fn)\n    metadata_nb = read_nb(meta_fn)\n    if has_metadata_cell(metadata_nb[\"cells\"], fn.name):\n        return\n    nb = read_nb(fn)\n    jmd = nb[\"metadata\"].get(\"jekyll\", {})",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_nb_metadata",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_nb_metadata(\n    nb_path=None, title=None, summary=None, keywords=\"fastai\", overwrite=True, **kwargs\n):\n    \"Creates jekyll metadata for given notebook path.\"\n    nb = read_nb(nb_path)\n    data = {\"title\": title, \"summary\": summary, \"keywords\": keywords, **kwargs}\n    data = {k: v for (k, v) in data.items() if v is not None}  # remove none values\n    if not data:\n        return\n    nb[\"metadata\"][\"jekyll\"] = data",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "has_metadata_cell",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def has_metadata_cell(cells, fn):\n    for c in cells:\n        if re.search(f\"update_nb_metadata\\('{fn}'\", c[\"source\"]):\n            return c\ndef stringify(s):\n    return f\"'{s}'\" if isinstance(s, str) else s\nIMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def stringify(s):\n    return f\"'{s}'\" if isinstance(s, str) else s\nIMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_imported_modules",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])\n        if cell[\"cell_type\"] == \"code\"\n    ]\n    parts = nb_module_name.split(\".\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_top_level_modules",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_top_level_modules(num_levels=1):\n    mod_dir = Path(import_mod(\"fastai\").__file__).parent\n    filtered_n = filter(lambda x: x.count(\".\") <= num_levels, get_module_names(mod_dir))\n    return sorted(\n        filtered_n, key=lambda s: s.count(\".\"), reverse=True\n    )  # Submodules first (sorted by periods)\nNEW_FT_HEADER = \"## New Methods - Please document or move to the undocumented section\"\nUNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "parse_sections",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):\n                current_section = new_cells\n        current_section.append(cell)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "remove_undoc_cells",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def remove_undoc_cells(cells):\n    old, _, _ = parse_sections(cells)\n    return old\n# currently code vbox sub-cells mainly\ndef remove_code_cell_jupyter_widget_state_elem(cells):\n    for c in cells:\n        if c[\"cell_type\"] == \"code\":\n            if \"outputs\" in c:\n                c[\"outputs\"] = [\n                    l",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "remove_code_cell_jupyter_widget_state_elem",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def remove_code_cell_jupyter_widget_state_elem(cells):\n    for c in cells:\n        if c[\"cell_type\"] == \"code\":\n            if \"outputs\" in c:\n                c[\"outputs\"] = [\n                    l\n                    for l in c[\"outputs\"]\n                    if not (\n                        \"data\" in l\n                        and \"application/vnd.jupyter.widget-view+json\" in l.data",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_module_page",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_module_page(mod, dest_path=\".\"):\n    \"Update the documentation notebook of a given module.\"\n    doc_path = get_doc_path(mod, dest_path)\n    strip_name = strip_fastai(mod.__name__)\n    nb = read_nb(doc_path)\n    cells = nb[\"cells\"]\n    link_markdown_cells(cells, get_imported_modules(cells, mod.__name__))\n    type_dict = read_nb_types(cells)\n    gvar_map = get_global_vars(mod)\n    for name in get_exports(mod):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "link_nb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def link_nb(nb_path):\n    nb = read_nb(nb_path)\n    cells = nb[\"cells\"]\n    link_markdown_cells(cells, get_imported_modules(cells, Path(nb_path).stem))\n    write_nb(nb, nb_path)\n    NotebookNotary().sign(read_nb(nb_path))\ndef get_module_from_notebook(doc_path):\n    \"Find module given a source path. Assume it belongs to fastai directory\"\n    return f\"fastai.{Path(doc_path).stem}\"\ndef check_nbconvert_version():",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_module_from_notebook",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_module_from_notebook(doc_path):\n    \"Find module given a source path. Assume it belongs to fastai directory\"\n    return f\"fastai.{Path(doc_path).stem}\"\ndef check_nbconvert_version():\n    import nbconvert\n    assert nbconvert.version_info >= (\n        5,\n        4,\n        0,\n    ), \"Please update nbconvert to >=5.4 for consistent .html output\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "check_nbconvert_version",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def check_nbconvert_version():\n    import nbconvert\n    assert nbconvert.version_info >= (\n        5,\n        4,\n        0,\n    ), \"Please update nbconvert to >=5.4 for consistent .html output\"\ndef update_notebooks(\n    source_path,\n    dest_path=None,",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_notebooks",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_notebooks(\n    source_path,\n    dest_path=None,\n    update_html=True,\n    document_new_fns=False,\n    update_nb_links=True,\n    html_path=None,\n    force=False,\n):\n    \"`source_path` can be a directory or a file. Assume all modules reside in the fastai directory.\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "__all__ = [\n    \"create_module_page\",\n    \"update_module_page\",\n    \"import_mod\",\n    \"link_nb\",\n    \"update_notebooks\",\n    \"generate_missing_metadata\",\n    \"update_nb_metadata\",\n]\ndef get_empty_notebook():",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "_default_exclude",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "_default_exclude = [\".ipynb_checkpoints\", \"__pycache__\", \"__init__.py\", \"imports\"]\ndef get_module_names(path_dir, exclude=None):\n    if exclude is None:\n        exclude = _default_exclude\n    \"Search a given `path_dir` and return all the modules contained inside except those in `exclude`\"\n    files = sorted(\n        path_dir.glob(\"*\"), key=lambda x: (x.is_dir(), x.name), reverse=True\n    )  # directories first\n    res = [f\"{path_dir.name}\"]\n    for f in files:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "SHOW_DOC_RE",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "SHOW_DOC_RE = re.compile(r\"show_doc\\(([\\w\\.]*)\")\ndef read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":\n            for match in SHOW_DOC_RE.findall(cell[\"source\"]):\n                doc_fns[match] = i\n    return doc_fns\ndef read_nb_types(cells):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "IMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])\n        if cell[\"cell_type\"] == \"code\"\n    ]",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "NEW_FT_HEADER",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "NEW_FT_HEADER = \"## New Methods - Please document or move to the undocumented section\"\nUNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "UNDOC_HEADER",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "UNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):\n                current_section = new_cells",
        "detail": "DL_Model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "is_enum",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"\n    if is_fastai_class(arg_type):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "link_type",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"\n    if is_fastai_class(arg_type):\n        return f\"[{arg_name}]({get_fn_link(arg_type)})\"\n    return arg_name",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "is_fastai_class",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def is_fastai_class(t):\n    return belongs_to_module(t, MODULE_NAME)\ndef belongs_to_module(t, module_name):\n    \"Check if `t` belongs to `module_name`.\"\n    if hasattr(t, \"__func__\"):\n        return belongs_to_module(t.__func__, module_name)\n    if not inspect.getmodule(t):\n        return False\n    return inspect.getmodule(t).__name__.startswith(module_name)\ndef code_esc(s):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "belongs_to_module",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def belongs_to_module(t, module_name):\n    \"Check if `t` belongs to `module_name`.\"\n    if hasattr(t, \"__func__\"):\n        return belongs_to_module(t.__func__, module_name)\n    if not inspect.getmodule(t):\n        return False\n    return inspect.getmodule(t).__name__.startswith(module_name)\ndef code_esc(s):\n    return f\"`{s}`\"\ndef type_repr(t):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "code_esc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def code_esc(s):\n    return f\"`{s}`\"\ndef type_repr(t):\n    if t in _typing_names:\n        return link_type(t, _typing_names[t])\n    if isinstance(t, partial):\n        return partial_repr(t)\n    if hasattr(t, \"__forward_arg__\"):\n        return link_type(t.__forward_arg__)\n    elif getattr(t, \"__args__\", None):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "type_repr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def type_repr(t):\n    if t in _typing_names:\n        return link_type(t, _typing_names[t])\n    if isinstance(t, partial):\n        return partial_repr(t)\n    if hasattr(t, \"__forward_arg__\"):\n        return link_type(t.__forward_arg__)\n    elif getattr(t, \"__args__\", None):\n        args = t.__args__\n        if len(args) == 2 and args[1] == type(None):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "partial_repr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def partial_repr(t):\n    args = (t.func,) + t.args + tuple([f\"{k}={v}\" for k, v in t.keywords.items()])\n    reprs = \", \".join([link_type(o) for o in args])\n    return f\"<code>partial(</code>{reprs}<code>)</code>\"\ndef anno_repr(a):\n    return type_repr(a)\ndef format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "anno_repr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def anno_repr(a):\n    return type_repr(a)\ndef format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"\n    if hasattr(p, \"annotation\") and p.annotation != p.empty:\n        res += f\":{anno_repr(p.annotation)}\"\n    if p.default != p.empty:\n        default = getattr(p.default, \"func\", p.default)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_param",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"\n    if hasattr(p, \"annotation\") and p.annotation != p.empty:\n        res += f\":{anno_repr(p.annotation)}\"\n    if p.default != p.empty:\n        default = getattr(p.default, \"func\", p.default)\n        default = getattr(default, \"__name__\", default)\n        res += f\"=***`{repr(default)}`***\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_ft_def",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_ft_def(func, full_name: str = None) -> str:\n    \"Format and link `func` definition to show in documentation\"\n    sig = inspect.signature(func)\n    name = f\"<code>{full_name or func.__name__}</code>\"\n    fmt_params = [\n        format_param(param)\n        for name, param in sig.parameters.items()\n        if name not in (\"self\", \"cls\")\n    ]\n    arg_str = f\"({', '.join(fmt_params)})\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_enum_doc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_enum_doc(elt, full_name: str) -> str:\n    \"Formatted enum documentation.\"\n    vals = \", \".join(elt.__members__.keys())\n    return f\"{code_esc(full_name)}\", f\"<code>Enum</code> = [{vals}]\"\ndef get_cls_doc(elt, full_name: str) -> str:\n    \"Class definition.\"\n    parent_class = inspect.getclasstree([elt])[-1][0][1][0]\n    name, args = format_ft_def(elt, full_name)\n    if parent_class != object:\n        args += f\" :: {link_type(parent_class, include_bt=True)}\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_cls_doc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_cls_doc(elt, full_name: str) -> str:\n    \"Class definition.\"\n    parent_class = inspect.getclasstree([elt])[-1][0][1][0]\n    name, args = format_ft_def(elt, full_name)\n    if parent_class != object:\n        args += f\" :: {link_type(parent_class, include_bt=True)}\"\n    return name, args\ndef show_doc(\n    elt,\n    doc_string: bool = True,",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_doc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_doc(\n    elt,\n    doc_string: bool = True,\n    full_name: str = None,\n    arg_comments: dict = None,\n    title_level=None,\n    alt_doc_string: str = \"\",\n    ignore_warn: bool = False,\n    markdown=True,\n    show_tests=True,",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "md2html",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def md2html(md):\n    if nbconvert.__version__ < \"5.5.0\":\n        return HTMLExporter().markdown2html(md)\n    else:\n        return HTMLExporter().markdown2html(defaultdict(lambda: defaultdict(dict)), md)\ndef doc(elt):\n    \"Show `show_doc` info in preview window along with link to full docs.\"\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, \"__func__\", elt)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def doc(elt):\n    \"Show `show_doc` info in preview window along with link to full docs.\"\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, \"__func__\", elt)\n    md = show_doc(elt, markdown=False)\n    if is_fastai_class(elt):\n        md += f'\\n\\n<a href=\"{get_fn_link(elt)}\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a>'\n    output = md2html(md)\n    use_relative_links = True",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_docstring",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_docstring(\n    elt, arg_comments: dict = {}, alt_doc_string: str = \"\", ignore_warn: bool = False\n) -> str:\n    \"Merge and format the docstring definition with `arg_comments` and `alt_doc_string`.\"\n    parsed = \"\"\n    doc = parse_docstring(inspect.getdoc(elt))\n    description = (\n        alt_doc_string or f\"{doc['short_description']} {doc['long_description']}\"\n    )\n    if description:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "replace_link",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def replace_link(m):\n    keyword = m.group(1) or m.group(2)\n    elt = find_elt(_modvars, keyword)\n    if elt is None:\n        return m.group()\n    return link_type(elt, arg_name=keyword)\n# Finds all places with a backtick but only if it hasn't already been linked\nBT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"\n)  # matches [`key`](link) or `key`",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "link_docstring",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def link_docstring(modules, docstring: str, overwrite: bool = False) -> str:\n    \"Search `docstring` for backticks and attempt to link those functions to respective documentation.\"\n    mods = listify(modules)\n    for mod in mods:\n        _modvars.update(mod.__dict__)  # concat all module definitions\n    return re.sub(BT_REGEX, replace_link, docstring)\ndef find_elt(modvars, keyword, match_last=False):\n    \"Attempt to resolve keywords such as Learner.lr_find. `match_last` starts matching from last component.\"\n    keyword = strip_fastai(keyword)\n    if keyword in modvars:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "find_elt",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def find_elt(modvars, keyword, match_last=False):\n    \"Attempt to resolve keywords such as Learner.lr_find. `match_last` starts matching from last component.\"\n    keyword = strip_fastai(keyword)\n    if keyword in modvars:\n        return modvars[keyword]\n    comps = keyword.split(\".\")\n    comp_elt = modvars.get(comps[0])\n    if hasattr(comp_elt, \"__dict__\"):\n        return find_elt(comp_elt.__dict__, \".\".join(comps[1:]), match_last=match_last)\ndef import_mod(mod_name: str, ignore_errors=False):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "import_mod",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def import_mod(mod_name: str, ignore_errors=False):\n    \"Return module from `mod_name`.\"\n    splits = str.split(mod_name, \".\")\n    try:\n        if len(splits) > 1:\n            mod = importlib.import_module(\".\" + \".\".join(splits[1:]), splits[0])\n        else:\n            mod = importlib.import_module(mod_name)\n        return mod\n    except:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_doc_from_name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_doc_from_name(\n    mod_name,\n    ft_name: str,\n    doc_string: bool = True,\n    arg_comments: dict = {},\n    alt_doc_string: str = \"\",\n):\n    \"Show documentation for `ft_name`, see `show_doc`.\"\n    mod = import_mod(mod_name)\n    splits = str.split(ft_name, \".\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_exports",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_exports(mod):\n    public_names = mod.__all__ if hasattr(mod, \"__all__\") else dir(mod)\n    # public_names.sort(key=str.lower)\n    return [o for o in public_names if not o.startswith(\"_\")]\ndef get_ft_names(mod, include_inner=False) -> List[str]:\n    \"Return all the functions of module `mod`.\"\n    # If the module has an attribute __all__, it picks those.\n    # Otherwise, it returns all the functions defined inside a module.\n    fn_names = []\n    for elt_name in get_exports(mod):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_ft_names",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_ft_names(mod, include_inner=False) -> List[str]:\n    \"Return all the functions of module `mod`.\"\n    # If the module has an attribute __all__, it picks those.\n    # Otherwise, it returns all the functions defined inside a module.\n    fn_names = []\n    for elt_name in get_exports(mod):\n        elt = getattr(mod, elt_name)\n        # This removes the files imported from elsewhere\n        try:\n            fname = inspect.getfile(elt)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_inner_fts",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_inner_fts(elt) -> List[str]:\n    \"List the inner functions of a class.\"\n    fts = []\n    for ft_name in elt.__dict__.keys():\n        if ft_name.startswith(\"_\"):\n            continue\n        ft = getattr(elt, ft_name)\n        if inspect.isfunction(ft):\n            fts.append(f\"{elt.__name__}.{ft_name}\")\n        if inspect.ismethod(ft):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_module_toc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_module_toc(mod_name):\n    \"Display table of contents for given `mod_name`.\"\n    mod = import_mod(mod_name)\n    ft_names = mod.__all__ if hasattr(mod, \"__all__\") else get_ft_names(mod)\n    ft_names.sort(key=str.lower)\n    tabmat = \"\"\n    for ft_name in ft_names:\n        tabmat += f\"- [{ft_name}](#{ft_name})\\n\"\n        elt = getattr(mod, ft_name)\n        if inspect.isclass(elt) and not is_enum(elt.__class__):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_video",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_video(url):\n    \"Display video in `url`.\"\n    data = f'<iframe width=\"560\" height=\"315\" src=\"{url}\" frameborder=\"0\" allowfullscreen></iframe>'\n    return display(HTML(data))\ndef show_video_from_youtube(code, start=0):\n    \"Display video from Youtube with a `code` and a `start` time.\"\n    url = f\"https://www.youtube.com/embed/{code}?start={start}&amp;rel=0&amp;controls=0&amp;showinfo=0\"\n    return show_video(url)\ndef get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_video_from_youtube",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_video_from_youtube(code, start=0):\n    \"Display video from Youtube with a `code` and a `start` time.\"\n    url = f\"https://www.youtube.com/embed/{code}?start={start}&amp;rel=0&amp;controls=0&amp;showinfo=0\"\n    return show_video(url)\ndef get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):\n        return fn.__qualname__\n    if inspect.ismethod(fn):\n        return fn_name(fn.__self__) + \".\" + fn_name(fn)\n    return fn_name(fn)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_anchor",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):\n        return fn.__qualname__\n    if inspect.ismethod(fn):\n        return fn_name(fn.__self__) + \".\" + fn_name(fn)\n    return fn_name(fn)\ndef fn_name(ft) -> str:\n    if ft.__hash__ and ft in _typing_names:\n        return _typing_names[ft]\n    if hasattr(ft, \"__name__\"):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "fn_name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def fn_name(ft) -> str:\n    if ft.__hash__ and ft in _typing_names:\n        return _typing_names[ft]\n    if hasattr(ft, \"__name__\"):\n        return ft.__name__\n    elif hasattr(ft, \"_name\") and ft._name:\n        return ft._name\n    elif hasattr(ft, \"__origin__\"):\n        return str(ft.__origin__).split(\".\")[-1]\n    else:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_fn_link",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_fn_link(ft) -> str:\n    \"Return function link to notebook documentation of `ft`. Private functions link to source code\"\n    ft = getattr(ft, \"__func__\", ft)\n    anchor = strip_fastai(get_anchor(ft))\n    module_name = strip_fastai(get_module_name(ft))\n    base = \"\" if use_relative_links else FASTAI_DOCS\n    return f\"{base}/{module_name}.html#{anchor}\"\ndef get_module_name(ft) -> str:\n    return inspect.getmodule(ft).__name__\ndef get_pytorch_link(ft) -> str:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_module_name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_module_name(ft) -> str:\n    return inspect.getmodule(ft).__name__\ndef get_pytorch_link(ft) -> str:\n    \"Returns link to pytorch docs of `ft`.\"\n    name = ft.__name__\n    ext = \".html\"\n    if name == \"device\":\n        return f\"{PYTORCH_DOCS}tensor_attributes{ext}#torch-device\"\n    if name == \"Tensor\":\n        return f\"{PYTORCH_DOCS}tensors{ext}#torch-tensor\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_pytorch_link",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_pytorch_link(ft) -> str:\n    \"Returns link to pytorch docs of `ft`.\"\n    name = ft.__name__\n    ext = \".html\"\n    if name == \"device\":\n        return f\"{PYTORCH_DOCS}tensor_attributes{ext}#torch-device\"\n    if name == \"Tensor\":\n        return f\"{PYTORCH_DOCS}tensors{ext}#torch-tensor\"\n    if name.startswith(\"torchvision\"):\n        doc_path = get_module_name(ft).replace(\".\", \"/\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_source_link",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_source_link(file, line, display_text=\"[source]\", **kwargs) -> str:\n    \"Returns github link for given file\"\n    link = f\"{SOURCE_URL}{file}#L{line}\"\n    if display_text is None:\n        return link\n    return (\n        f'<a href=\"{link}\" class=\"source_link\" style=\"float:right\">{display_text}</a>'\n    )\ndef get_function_source(ft, **kwargs) -> str:\n    \"Returns link to `ft` in source code.\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_function_source",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_function_source(ft, **kwargs) -> str:\n    \"Returns link to `ft` in source code.\"\n    try:\n        line = inspect.getsourcelines(ft)[1]\n    except Exception:\n        return \"\"\n    mod_path = get_module_name(ft).replace(\".\", \"/\") + \".py\"\n    return get_source_link(mod_path, line, **kwargs)\ndef title_md(s: str, title_level: int, markdown=True):\n    res = \"#\" * title_level",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "title_md",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def title_md(s: str, title_level: int, markdown=True):\n    res = \"#\" * title_level\n    if title_level:\n        res += \" \"\n    return Markdown(res + s) if markdown else (res + s)\ndef jekyll_div(s, c, h, icon=None):\n    icon = ifnone(icon, c)\n    res = f'<div markdown=\"span\" class=\"alert alert-{c}\" role=\"alert\"><i class=\"fa fa-{c}-circle\"></i> <b>{h}: </b>{s}</div>'\n    display(Markdown(res))\ndef jekyll_note(s):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_div",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_div(s, c, h, icon=None):\n    icon = ifnone(icon, c)\n    res = f'<div markdown=\"span\" class=\"alert alert-{c}\" role=\"alert\"><i class=\"fa fa-{c}-circle\"></i> <b>{h}: </b>{s}</div>'\n    display(Markdown(res))\ndef jekyll_note(s):\n    return jekyll_div(s, \"info\", \"Note\")\ndef jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_note",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_note(s):\n    return jekyll_div(s, \"info\", \"Note\")\ndef jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_warn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_important",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "__all__ = [\n    \"get_fn_link\",\n    \"link_docstring\",\n    \"show_doc\",\n    \"get_ft_names\",\n    \"md2html\",\n    \"get_exports\",\n    \"show_video\",\n    \"show_video_from_youtube\",\n    \"import_mod\",",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "MODULE_NAME",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "MODULE_NAME = \"fastai\"\nSOURCE_URL = \"https://github.com/fastai/fastai/blob/master/\"\nPYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "SOURCE_URL",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "SOURCE_URL = \"https://github.com/fastai/fastai/blob/master/\"\nPYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "PYTORCH_DOCS",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "PYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "FASTAI_DOCS",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "FASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "use_relative_links",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "use_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "_typing_names",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "arg_prefixes",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "arg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "_modvars",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "_modvars = {}\ndef replace_link(m):\n    keyword = m.group(1) or m.group(2)\n    elt = find_elt(_modvars, keyword)\n    if elt is None:\n        return m.group()\n    return link_type(elt, arg_name=keyword)\n# Finds all places with a backtick but only if it hasn't already been linked\nBT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "BT_REGEX",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "BT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"\n)  # matches [`key`](link) or `key`\ndef link_docstring(modules, docstring: str, overwrite: bool = False) -> str:\n    \"Search `docstring` for backticks and attempt to link those functions to respective documentation.\"\n    mods = listify(modules)\n    for mod in mods:\n        _modvars.update(mod.__dict__)  # concat all module definitions\n    return re.sub(BT_REGEX, replace_link, docstring)\ndef find_elt(modvars, keyword, match_last=False):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_test",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def show_test(elt) -> str:\n    \"Show associated tests for a fastai function/class\"\n    md = build_tests_markdown(elt)\n    display(Markdown(md))\ndef doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:\n        page.page({\"text/html\": output})",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "doctest",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:\n        page.page({\"text/html\": output})\n    except:\n        display(Markdown(md))\ndef build_tests_markdown(elt):\n    fn_name = nbdoc.fn_name(elt)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "build_tests_markdown",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def build_tests_markdown(elt):\n    fn_name = nbdoc.fn_name(elt)\n    md = \"\"\n    db_matches = [get_links(t) for t in lookup_db(elt)]\n    md += tests2md(db_matches, \"\")\n    try:\n        related = [get_links(t) for t in find_related_tests(elt)]\n        other_tests = [k for k in OrderedDict.fromkeys(related) if k not in db_matches]\n        md += tests2md(other_tests, f\"Some other tests where `{fn_name}` is used:\")\n    except OSError as e:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "tests2md",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def tests2md(tests, type_label: str):\n    if not tests:\n        return \"\"\n    md = [f\"\\n\\n{type_label}\"] + [\n        f\"* `{cmd}` {link}\" for link, cmd in sorted(tests, key=lambda k: k[1])\n    ]\n    return \"\\n\".join(md)\ndef get_pytest_html(elt, anchor_id: str) -> Tuple[str, str]:\n    md = build_tests_markdown(elt)\n    html = nbdoc.md2html(md).replace(",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_pytest_html",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_pytest_html(elt, anchor_id: str) -> Tuple[str, str]:\n    md = build_tests_markdown(elt)\n    html = nbdoc.md2html(md).replace(\n        \"\\n\", \"\"\n    )  # nbconverter fails to parse markdown if it has both html and '\\n'\n    anchor_id = anchor_id.replace(\".\", \"-\") + \"-pytest\"\n    link, body = get_pytest_card(html, anchor_id)\n    return link, body\ndef get_pytest_card(html, anchor_id):\n    \"creates a collapsible bootstrap card for `show_test`\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_pytest_card",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_pytest_card(html, anchor_id):\n    \"creates a collapsible bootstrap card for `show_test`\"\n    link = f'<a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#{anchor_id}\" style=\"float:right; padding-right:10px\">[test]</a>'\n    body = (\n        f'<div class=\"collapse\" id=\"{anchor_id}\"><div class=\"card card-body pytest_card\">'\n        f'<a type=\"button\" data-toggle=\"collapse\" data-target=\"#{anchor_id}\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a>'\n        f\"{html}\"\n        \"</div></div>\"\n    )\n    return link, body",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "lookup_db",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def lookup_db(elt) -> List[Dict]:\n    \"Finds `this_test` entries from test_registry.json\"\n    db_file = Path(abspath(join(dirname(__file__), \"..\"))) / DB_NAME\n    if not db_file.exists():\n        raise Exception(\n            f'Could not find {db_file}. Please make sure it exists at \"{db_file}\" or run `make test`'\n        )\n    with open(db_file, \"r\") as f:\n        db = json.load(f)\n    key = get_func_fq_name(elt)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_related_tests",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_related_tests(elt) -> Tuple[List[Dict], List[Dict]]:\n    \"Searches `fastai/tests` folder for any test functions related to `elt`\"\n    related_matches = []\n    for test_file in find_test_files(elt):\n        fuzzy_matches = find_test_matches(elt, test_file)\n        related_matches.extend(fuzzy_matches)\n    return related_matches\ndef get_tests_dir(elt) -> Path:\n    \"Absolute path of `fastai/tests` directory\"\n    test_dir = Path(__file__).parent.parent.parent.resolve() / \"tests\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_tests_dir",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_tests_dir(elt) -> Path:\n    \"Absolute path of `fastai/tests` directory\"\n    test_dir = Path(__file__).parent.parent.parent.resolve() / \"tests\"\n    if not test_dir.exists():\n        raise OSError(\"Could not find test directory at this location:\", test_dir)\n    return test_dir\ndef get_file(elt) -> str:\n    if hasattr(elt, \"__wrapped__\"):\n        elt = elt.__wrapped__\n    if not nbdoc.is_fastai_class(elt):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_file",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_file(elt) -> str:\n    if hasattr(elt, \"__wrapped__\"):\n        elt = elt.__wrapped__\n    if not nbdoc.is_fastai_class(elt):\n        return None\n    return inspect.getfile(elt)\ndef find_test_files(elt, exact_match: bool = False) -> List[Path]:\n    \"Searches in `fastai/tests` directory for module tests\"\n    test_dir = get_tests_dir(elt)\n    matches = [",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_test_files",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_test_files(elt, exact_match: bool = False) -> List[Path]:\n    \"Searches in `fastai/tests` directory for module tests\"\n    test_dir = get_tests_dir(elt)\n    matches = [\n        test_dir / o.name for o in os.scandir(test_dir) if _is_file_match(elt, o.name)\n    ]\n    # if len(matches) != 1: raise Error('Could not find exact file match:', matches)\n    return matches\ndef _is_file_match(elt, file_name: str, exact_match: bool = False) -> bool:\n    fp = get_file(elt)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_test_matches",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_test_matches(elt, test_file: Path) -> Tuple[List[Dict], List[Dict]]:\n    \"Find all functions in `test_file` related to `elt`\"\n    lines = get_lines(test_file)\n    rel_path = relative_test_path(test_file)\n    fn_name = get_qualname(elt) if not inspect.ismodule(elt) else \"\"\n    return fuzzy_test_match(fn_name, lines, rel_path)\ndef get_qualname(elt):\n    return elt.__qualname__ if hasattr(elt, \"__qualname__\") else fn_name(elt)\ndef separate_comp(qualname: str):\n    if not isinstance(qualname, str):",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_qualname",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_qualname(elt):\n    return elt.__qualname__ if hasattr(elt, \"__qualname__\") else fn_name(elt)\ndef separate_comp(qualname: str):\n    if not isinstance(qualname, str):\n        qualname = get_qualname(qualname)\n    parts = qualname.split(\".\")\n    parts[-1] = remove_underscore(parts[-1])\n    if len(parts) == 1:\n        return [], parts[0]\n    return parts[:-1], parts[-1]",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "separate_comp",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def separate_comp(qualname: str):\n    if not isinstance(qualname, str):\n        qualname = get_qualname(qualname)\n    parts = qualname.split(\".\")\n    parts[-1] = remove_underscore(parts[-1])\n    if len(parts) == 1:\n        return [], parts[0]\n    return parts[:-1], parts[-1]\ndef remove_underscore(fn_name):\n    if fn_name and fn_name[0] == \"_\":",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "remove_underscore",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def remove_underscore(fn_name):\n    if fn_name and fn_name[0] == \"_\":\n        return fn_name[1:]  # remove private method underscore prefix\n    return fn_name\ndef fuzzy_test_match(\n    fn_name: str, lines: List[Dict], rel_path: str\n) -> List[TestFunctionMatch]:\n    \"Find any lines where `fn_name` is invoked and return the parent test function\"\n    fuzzy_line_matches = _fuzzy_line_match(fn_name, lines)\n    fuzzy_matches = [",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "fuzzy_test_match",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def fuzzy_test_match(\n    fn_name: str, lines: List[Dict], rel_path: str\n) -> List[TestFunctionMatch]:\n    \"Find any lines where `fn_name` is invoked and return the parent test function\"\n    fuzzy_line_matches = _fuzzy_line_match(fn_name, lines)\n    fuzzy_matches = [\n        get_parent_func(lno, lines, ignore_missing=True)\n        for lno, _ in fuzzy_line_matches\n    ]\n    fuzzy_matches = list(filter(None.__ne__, fuzzy_matches))",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_lines",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_lines(file: Path) -> List[str]:\n    with open(file, \"r\") as f:\n        return f.readlines()\ndef map_test(test_file, line, line_text):\n    \"Creates dictionary test format to match doctest api\"\n    test_name = re.match(f\"\\s*def (test_\\w*)\", line_text).groups(0)[0]\n    return {\"file\": test_file, \"line\": line, \"test\": test_name}\ndef get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "map_test",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def map_test(test_file, line, line_text):\n    \"Creates dictionary test format to match doctest api\"\n    test_name = re.match(f\"\\s*def (test_\\w*)\", line_text).groups(0)[0]\n    return {\"file\": test_file, \"line\": line, \"test\": test_name}\ndef get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)\ndef pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_links",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)\ndef pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "pytest_command",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "__all__ = [\n    \"show_test\",\n    \"doctest\",\n    \"find_related_tests\",\n    \"lookup_db\",\n    \"find_test_matches\",\n    \"find_test_files\",\n    \"fuzzy_test_match\",\n    \"get_pytest_html\",\n]",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "TestFunctionMatch",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "description": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "TestFunctionMatch = namedtuple(\"TestFunctionMatch\", [\"line_number\", \"line\"])\ndef show_test(elt) -> str:\n    \"Show associated tests for a fastai function/class\"\n    md = build_tests_markdown(elt)\n    display(Markdown(md))\ndef doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:",
        "detail": "DL_Model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "try_import",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.imports.core",
        "description": "DL_Model.deoldify.fastai.imports.core",
        "peekOfCode": "def try_import(module):\n    \"Try to import `module`. Returns module's object on success, None on failure\"\n    try:\n        return importlib.import_module(module)\n    except:\n        return None\ndef have_min_pkg_version(package, version):\n    \"Check whether we have at least `version` of `package`. Returns True on success, False otherwise.\"\n    try:\n        pkg_resources.require(f\"{package}>={version}\")",
        "detail": "DL_Model.deoldify.fastai.imports.core",
        "documentation": {}
    },
    {
        "label": "have_min_pkg_version",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.imports.core",
        "description": "DL_Model.deoldify.fastai.imports.core",
        "peekOfCode": "def have_min_pkg_version(package, version):\n    \"Check whether we have at least `version` of `package`. Returns True on success, False otherwise.\"\n    try:\n        pkg_resources.require(f\"{package}>={version}\")\n        return True\n    except:\n        return False",
        "detail": "DL_Model.deoldify.fastai.imports.core",
        "documentation": {}
    },
    {
        "label": "TabularLine",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularLine(ItemBase):\n    \"Basic item for tabular data.\"\n    def __init__(self, cats, conts, classes, names):\n        self.cats, self.conts, self.classes, self.names = cats, conts, classes, names\n        self.data = [tensor(cats), tensor(conts)]\n    def __str__(self):\n        res = \"\"\n        for c, n in zip(self.cats, self.names[: len(self.cats)]):\n            res += f\"{n} {(self.classes[n][c])}; \"\n        for c, n in zip(self.conts, self.names[len(self.cats) :]):",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularProcessor(PreProcessor):\n    \"Regroup the `procs` in one `PreProcessor`.\"\n    def __init__(self, ds: ItemBase = None, procs=None):\n        procs = ifnone(procs, ds.procs if ds is not None else None)\n        self.procs = listify(procs)\n    def process_one(self, item):\n        df = pd.DataFrame([item, item])\n        for proc in self.procs:\n            proc(df, test=True)\n        if len(self.cat_names) != 0:",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularDataBunch(DataBunch):\n    \"Create a `DataBunch` suitable for tabular data.\"\n    @classmethod\n    def from_df(\n        cls,\n        path,\n        df: DataFrame,\n        dep_var: str,\n        valid_idx: Collection[int],\n        procs: OptTabTfms = None,",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularList(ItemList):\n    \"Basic `ItemList` for tabular data.\"\n    _item_cls = TabularLine\n    _processor = TabularProcessor\n    _bunch = TabularDataBunch\n    def __init__(\n        self,\n        items: Iterator,\n        cat_names: OptStrList = None,\n        cont_names: OptStrList = None,",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "emb_sz_rule",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "def emb_sz_rule(n_cat: int) -> int:\n    return min(600, round(1.6 * n_cat**0.56))\ndef def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz\nclass TabularLine(ItemBase):\n    \"Basic item for tabular data.\"",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "def_emb_sz",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "def def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz\nclass TabularLine(ItemBase):\n    \"Basic item for tabular data.\"\n    def __init__(self, cats, conts, classes, names):\n        self.cats, self.conts, self.classes, self.names = cats, conts, classes, names",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "tabular_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "def tabular_learner(\n    data: DataBunch,\n    layers: Collection[int],\n    emb_szs: Dict[str, int] = None,\n    metrics=None,\n    ps: Collection[float] = None,\n    emb_drop: float = 0.0,\n    y_range: OptRange = None,\n    use_bn: bool = True,\n    **learn_kwargs,",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "__all__ = [\n    \"TabularDataBunch\",\n    \"TabularLine\",\n    \"TabularList\",\n    \"TabularProcessor\",\n    \"tabular_learner\",\n]\nOptTabTfms = Optional[Collection[TabularProc]]\n# def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat//2)+1)\ndef emb_sz_rule(n_cat: int) -> int:",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "OptTabTfms",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.data",
        "description": "DL_Model.deoldify.fastai.tabular.data",
        "peekOfCode": "OptTabTfms = Optional[Collection[TabularProc]]\n# def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat//2)+1)\ndef emb_sz_rule(n_cat: int) -> int:\n    return min(600, round(1.6 * n_cat**0.56))\ndef def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz",
        "detail": "DL_Model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularModel",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.models",
        "description": "DL_Model.deoldify.fastai.tabular.models",
        "peekOfCode": "class TabularModel(Module):\n    \"Basic model for tabular data.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        n_cont: int,\n        out_sz: int,\n        layers: Collection[int],\n        ps: Collection[float] = None,\n        emb_drop: float = 0.0,",
        "detail": "DL_Model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.models",
        "description": "DL_Model.deoldify.fastai.tabular.models",
        "peekOfCode": "__all__ = [\"TabularModel\"]\nclass TabularModel(Module):\n    \"Basic model for tabular data.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        n_cont: int,\n        out_sz: int,\n        layers: Collection[int],\n        ps: Collection[float] = None,",
        "detail": "DL_Model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.from_learner",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.models",
        "description": "DL_Model.deoldify.fastai.tabular.models",
        "peekOfCode": "ClassificationInterpretation.from_learner = _cl_int_from_learner\nClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\ndef _learner_interpret(learn: Learner, ds_type: DatasetType = DatasetType.Valid):\n    \"Create a 'ClassificationInterpretation' object from 'learner' on 'ds_type'.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\nLearner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_top_losses",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.models",
        "description": "DL_Model.deoldify.fastai.tabular.models",
        "peekOfCode": "ClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\ndef _learner_interpret(learn: Learner, ds_type: DatasetType = DatasetType.Valid):\n    \"Create a 'ClassificationInterpretation' object from 'learner' on 'ds_type'.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\nLearner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.models",
        "description": "DL_Model.deoldify.fastai.tabular.models",
        "peekOfCode": "Learner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "TabularProc",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class TabularProc:\n    \"A processor for tabular dataframes.\"\n    cat_names: StrList\n    cont_names: StrList\n    def __call__(self, df: DataFrame, test: bool = False):\n        \"Apply the correct function to `df` depending on `test`.\"\n        func = self.apply_test if test else self.apply_train\n        func(df)\n    def apply_train(self, df: DataFrame):\n        \"Function applied to `df` if it's the train set.\"",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "Categorify",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class Categorify(TabularProc):\n    \"Transform the categorical variables to that type.\"\n    def apply_train(self, df: DataFrame):\n        \"Transform `self.cat_names` columns in categorical.\"\n        self.categories = {}\n        for n in self.cat_names:\n            df.loc[:, n] = df.loc[:, n].astype(\"category\").cat.as_ordered()\n            self.categories[n] = df[n].cat.categories\n    def apply_test(self, df: DataFrame):\n        \"Transform `self.cat_names` columns in categorical using the codes decided in `apply_train`.\"",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "FillMissing",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class FillMissing(TabularProc):\n    \"Fill the missing values in continuous columns.\"\n    fill_strategy: FillStrategy = FillStrategy.MEDIAN\n    add_col: bool = True\n    fill_val: float = 0.0\n    def apply_train(self, df: DataFrame):\n        \"Fill missing values in `self.cont_names` according to `self.fill_strategy`.\"\n        self.na_dict = {}\n        for name in self.cont_names:\n            if pd.isnull(df[name]).sum():",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class Normalize(TabularProc):\n    \"Normalize the continuous variables.\"\n    def apply_train(self, df: DataFrame):\n        \"Compute the means and stds of `self.cont_names` columns to normalize them.\"\n        self.means, self.stds = {}, {}\n        for n in self.cont_names:\n            assert is_numeric_dtype(\n                df[n]\n            ), f\"\"\"Cannot normalize '{n}' column as it isn't numerical.\n                Are you sure it doesn't belong in the categorical set of columns?\"\"\"",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "make_date",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def make_date(df: DataFrame, date_field: str):\n    \"Make sure `df[field_name]` is of the right date type.\"\n    field_dtype = df[date_field].dtype\n    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        field_dtype = np.datetime64\n    if not np.issubdtype(field_dtype, np.datetime64):\n        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\ndef cyclic_dt_feat_names(time: bool = True, add_linear: bool = False) -> List[str]:\n    \"Return feature names of date/time cycles as produced by `cyclic_dt_features`.\"\n    fs = [\"cos\", \"sin\"]",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cyclic_dt_feat_names",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cyclic_dt_feat_names(time: bool = True, add_linear: bool = False) -> List[str]:\n    \"Return feature names of date/time cycles as produced by `cyclic_dt_features`.\"\n    fs = [\"cos\", \"sin\"]\n    attr = [\n        f\"{r}_{f}\" for r in \"weekday day_month month_year day_year\".split() for f in fs\n    ]\n    if time:\n        attr += [f\"{r}_{f}\" for r in \"hour clock min sec\".split() for f in fs]\n    if add_linear:\n        attr.append(\"year_lin\")",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cyclic_dt_features",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cyclic_dt_features(\n    d: Union[date, datetime], time: bool = True, add_linear: bool = False\n) -> List[float]:\n    \"Calculate the cos and sin of date/time cycles.\"\n    tt, fs = d.timetuple(), [np.cos, np.sin]\n    day_year, days_month = tt.tm_yday, calendar.monthrange(d.year, d.month)[1]\n    days_year = 366 if calendar.isleap(d.year) else 365\n    rs = (\n        d.weekday() / 7,\n        (d.day - 1) / days_month,",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_cyclic_datepart",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_cyclic_datepart(\n    df: DataFrame,\n    field_name: str,\n    prefix: str = None,\n    drop: bool = True,\n    time: bool = False,\n    add_linear: bool = False,\n):\n    \"Helper function that adds trigonometric date/time features to a date in the column `field_name` of `df`.\"\n    make_date(df, field_name)",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_datepart",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_datepart(\n    df: DataFrame,\n    field_name: str,\n    prefix: str = None,\n    drop: bool = True,\n    time: bool = False,\n):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    make_date(df, field_name)\n    field = df[field_name]",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_elapsed_times",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_elapsed_times(\n    df: DataFrame, field_names: Collection[str], date_field: str, base_field: str\n):\n    field_names = listify(field_names)\n    # Make sure date_field is a date and base_field a bool\n    df[field_names] = df[field_names].astype(\"bool\")\n    make_date(df, date_field)\n    work_df = df[field_names + [date_field, base_field]]\n    work_df = work_df.sort_values([base_field, date_field])\n    work_df = _get_elapsed(work_df, field_names, date_field, base_field, \"After\")",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cont_cat_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cont_cat_split(df, max_card=20, dep_var=None) -> Tuple[List, List]:\n    \"Helper function that returns column names of cont and cat variables from given df.\"\n    cont_names, cat_names = [], []\n    for label in df:\n        if label == dep_var:\n            continue\n        if (\n            df[label].dtype == int\n            and df[label].unique().shape[0] > max_card\n            or df[label].dtype == float",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "__all__ = [\n    \"add_datepart\",\n    \"cont_cat_split\",\n    \"Categorify\",\n    \"FillMissing\",\n    \"FillStrategy\",\n    \"Normalize\",\n    \"TabularProc\",\n    \"add_elapsed_times\",\n    \"make_date\",",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "FillStrategy",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.tabular.transform",
        "description": "DL_Model.deoldify.fastai.tabular.transform",
        "peekOfCode": "FillStrategy = IntEnum(\"FillStrategy\", \"MEDIAN COMMON CONSTANT\")\n@dataclass\nclass FillMissing(TabularProc):\n    \"Fill the missing values in continuous columns.\"\n    fill_strategy: FillStrategy = FillStrategy.MEDIAN\n    add_col: bool = True\n    fill_val: float = 0.0\n    def apply_train(self, df: DataFrame):\n        \"Fill missing values in `self.cont_names` according to `self.fill_strategy`.\"\n        self.na_dict = {}",
        "detail": "DL_Model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "RNNDropout",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class RNNDropout(Module):\n    \"Dropout with probability `p` that is consistent on the seq_len dimension.\"\n    def __init__(self, p: float = 0.5):\n        self.p = p\n    def forward(self, x: Tensor) -> Tensor:\n        if not self.training or self.p == 0.0:\n            return x\n        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n        return x * m\nclass WeightDropout(Module):",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "WeightDropout",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class WeightDropout(Module):\n    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n    def __init__(\n        self,\n        module: nn.Module,\n        weight_p: float,\n        layer_names: Collection[str] = [\"weight_hh_l0\"],\n    ):\n        self.module, self.weight_p, self.layer_names = module, weight_p, layer_names\n        for layer in self.layer_names:",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "EmbeddingDropout",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class EmbeddingDropout(Module):\n    \"Apply dropout with probabily `embed_p` to an embedding layer `emb`.\"\n    def __init__(self, emb: nn.Module, embed_p: float):\n        self.emb, self.embed_p = emb, embed_p\n        self.pad_idx = self.emb.padding_idx\n        if self.pad_idx is None:\n            self.pad_idx = -1\n    def forward(self, words: LongTensor, scale: Optional[float] = None) -> Tensor:\n        if self.training and self.embed_p != 0:\n            size = (self.emb.weight.size(0), 1)",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "AWD_LSTM",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class AWD_LSTM(Module):\n    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182.\"\n    initrange = 0.1\n    def __init__(\n        self,\n        vocab_sz: int,\n        emb_sz: int,\n        n_hid: int,\n        n_layers: int,\n        pad_token: int = 1,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "LinearDecoder",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class LinearDecoder(Module):\n    \"To go on top of a RNNCore module and create a Language Model.\"\n    initrange = 0.1\n    def __init__(\n        self,\n        n_out: int,\n        n_hid: int,\n        output_p: float,\n        tie_encoder: nn.Module = None,\n        bias: bool = True,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "SequentialRNN",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class SequentialRNN(nn.Sequential):\n    \"A sequential module that passes the reset call to its children.\"\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \"reset\"):\n                c.reset()\ndef awd_lstm_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n    return groups + [[model[0].encoder, model[0].encoder_dp, model[1]]]",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "TextClassificationInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class TextClassificationInterpretation(ClassificationInterpretation):\n    \"\"\"Provides an interpretation of classification based on input sensitivity.\n    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n    \"\"\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "dropout_mask",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def dropout_mask(x: Tensor, sz: Collection[int], p: float):\n    \"Return a dropout mask of the same type as `x`, size `sz`, with probability `p` to cancel an element.\"\n    return x.new(*sz).bernoulli_(1 - p).div_(1 - p)\nclass RNNDropout(Module):\n    \"Dropout with probability `p` that is consistent on the seq_len dimension.\"\n    def __init__(self, p: float = 0.5):\n        self.p = p\n    def forward(self, x: Tensor) -> Tensor:\n        if not self.training or self.p == 0.0:\n            return x",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_lm_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def awd_lstm_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n    return groups + [[model[0].encoder, model[0].encoder_dp, model[1]]]\ndef awd_lstm_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[model[0].module.encoder, model[0].module.encoder_dp]]\n    groups += [\n        [rnn, dp] for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)\n    ]",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_clas_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def awd_lstm_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[model[0].module.encoder, model[0].module.encoder_dp]]\n    groups += [\n        [rnn, dp] for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)\n    ]\n    return groups + [[model[1]]]\nawd_lstm_lm_config = dict(\n    emb_sz=400,\n    n_hid=1152,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "value2rgba",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "piece_attn_html",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(\n            f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>'\n        )",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "show_piece_attn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def show_piece_attn(*args, **kwargs):\n    from IPython.display import HTML, display\n    display(HTML(piece_attn_html(*args, **kwargs)))\ndef _eval_dropouts(mod):\n    module_name = mod.__class__.__name__\n    if \"Dropout\" in module_name or \"BatchNorm\" in module_name:\n        mod.training = False\n    for module in mod.children():\n        _eval_dropouts(module)\nclass TextClassificationInterpretation(ClassificationInterpretation):",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "__all__ = [\n    \"EmbeddingDropout\",\n    \"LinearDecoder\",\n    \"AWD_LSTM\",\n    \"RNNDropout\",\n    \"SequentialRNN\",\n    \"WeightDropout\",\n    \"dropout_mask\",\n    \"awd_lstm_lm_split\",\n    \"awd_lstm_clas_split\",",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_lm_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "awd_lstm_lm_config = dict(\n    emb_sz=400,\n    n_hid=1152,\n    n_layers=3,\n    pad_token=1,\n    qrnn=False,\n    bidir=False,\n    output_p=0.1,\n    hidden_p=0.15,\n    input_p=0.25,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_clas_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "description": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "awd_lstm_clas_config = dict(\n    emb_sz=400,\n    n_hid=1152,\n    n_layers=3,\n    pad_token=1,\n    qrnn=False,\n    bidir=False,\n    output_p=0.4,\n    hidden_p=0.3,\n    input_p=0.4,",
        "detail": "DL_Model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "ForgetMultGPU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class ForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,\n    ):\n        if batch_first:",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "BwdForgetMultGPU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class BwdForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,\n    ):\n        if batch_first:",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "QRNNLayer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class QRNNLayer(Module):\n    \"Apply a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\"\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int = None,\n        save_prev_x: bool = False,\n        zoneout: float = 0,\n        window: int = 1,\n        output_gate: bool = True,",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "QRNN",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class QRNN(Module):\n    \"Apply a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\"\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        n_layers: int = 1,\n        bias: bool = True,\n        batch_first: bool = True,\n        dropout: float = 0,",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "dispatch_cuda",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "def dispatch_cuda(cuda_class, cpu_func, x):\n    return cuda_class.apply if x.device.type == \"cuda\" else cpu_func\nclass ForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "forget_mult_CPU",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "def forget_mult_CPU(\n    x: Tensor,\n    f: Tensor,\n    hidden_init: Optional[Tensor] = None,\n    batch_first: bool = True,\n    backward: bool = False,\n):\n    result = []\n    dim = 1 if batch_first else 0\n    forgets = f.split(1, dim=dim)",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.qrnn",
        "description": "DL_Model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "__all__ = [\"QRNNLayer\", \"QRNN\"]\nimport fastai\nif torch.cuda.is_available():\n    fastai_path = Path(fastai.__path__[0]) / \"text\" / \"models\"\n    files = [\"forget_mult_cuda.cpp\", \"forget_mult_cuda_kernel.cu\"]\n    forget_mult_cuda = load(\n        name=\"forget_mult_cuda\", sources=[fastai_path / f for f in files]\n    )\n    files = [\"bwd_forget_mult_cuda.cpp\", \"bwd_forget_mult_cuda_kernel.cu\"]\n    bwd_forget_mult_cuda = load(",
        "detail": "DL_Model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "PositionalEncoding",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class PositionalEncoding(Module):\n    \"Encode the position with a sinusoid.\"\n    def __init__(self, d: int):\n        self.register_buffer(\"freq\", 1 / (10000 ** (torch.arange(0.0, d, 2.0) / d)))\n    def forward(self, pos: Tensor):\n        inp = torch.ger(pos, self.freq)\n        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n        return enc\nclass GeLU(Module):\n    def forward(self, x):",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "GeLU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class GeLU(Module):\n    def forward(self, x):\n        return (\n            0.5\n            * x\n            * (\n                1\n                + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))\n            )\n        )",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Swish",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class Swish(Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n_activ_func = {\n    Activation.ReLU: nn.ReLU(inplace=True),\n    Activation.GeLU: GeLU(),\n    Activation.Swish: Swish(),\n}\ndef feed_forward(\n    d_model: int,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "MultiHeadAttention",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class MultiHeadAttention(Module):\n    \"MutiHeadAttention.\"\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int = None,\n        resid_p: float = 0.0,\n        attn_p: float = 0.0,\n        bias: bool = True,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "MultiHeadRelativeAttention",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class MultiHeadRelativeAttention(MultiHeadAttention):\n    \"MutiHeadAttention with relative positional encoding.\"\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int,\n        resid_p: float = 0.0,\n        attn_p: float = 0.0,\n        bias: bool = True,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "DecoderLayer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class DecoderLayer(Module):\n    \"Basic block of a Transformer model.\"\n    # Can't use Sequential directly cause more than one input...\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int,\n        d_inner: int,\n        resid_p: float = 0.0,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Transformer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class Transformer(Module):\n    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n    def __init__(\n        self,\n        vocab_sz: int,\n        ctx_len: int,\n        n_layers: int,\n        n_heads: int,\n        d_model: int,\n        d_head: int,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerXL",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class TransformerXL(Module):\n    \"TransformerXL model: https://arxiv.org/abs/1901.02860.\"\n    def __init__(\n        self,\n        vocab_sz: int,\n        ctx_len: int,\n        n_layers: int,\n        n_heads: int,\n        d_model: int,\n        d_head: int,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "feed_forward",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def feed_forward(\n    d_model: int,\n    d_ff: int,\n    ff_p: float = 0.0,\n    act: Activation = Activation.ReLU,\n    double_drop: bool = True,\n):\n    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n    if double_drop:\n        layers.append(nn.Dropout(ff_p))",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "init_transformer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def init_transformer(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Linear\") != -1:\n        if hasattr(m, \"weight\") and m.weight is not None:\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        if hasattr(m, \"bias\") and m.bias is not None:\n            nn.init.constant_(m.bias, 0.0)\n    elif classname.find(\"LayerNorm\") != -1:\n        if hasattr(m, \"weight\") and m.weight is not None:\n            nn.init.normal_(m.weight, 1.0, 0.02)",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_lm_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmer_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0]\n    n = len(encoder.layers) // 3\n    groups = [\n        list(encoder.layers[:n]),\n        list(encoder.layers[n : 2 * n]),\n        list(encoder.layers[2 * n :]),\n    ]\n    return groups + [[encoder.encoder, model[1]]]",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_clas_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmer_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0].module\n    n = len(encoder.layers) // 3\n    groups = [\n        [encoder.encoder],\n        list(encoder.layers[:n]),\n        list(encoder.layers[n : 2 * n]),\n        list(encoder.layers[2 * n :]),\n    ]",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_lm_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmerXL_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0]\n    n = len(encoder.layers) // 3\n    groups = [\n        list(encoder.layers[:n])\n        + [ParameterModule(encoder.u), ParameterModule(encoder.v)]\n    ]\n    return groups + [\n        list(encoder.layers[n : 2 * n]),",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_clas_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmerXL_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0].module\n    n = len(encoder.layers) // 3\n    groups = [\n        [encoder.encoder],\n        list(encoder.layers[:n])\n        + [ParameterModule(encoder.u), ParameterModule(encoder.v)],\n    ]\n    return groups + [",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "__all__ = [\n    \"Activation\",\n    \"PositionalEncoding\",\n    \"GeLU\",\n    \"Swish\",\n    \"feed_forward\",\n    \"MultiHeadAttention\",\n    \"MultiHeadRelativeAttention\",\n    \"DecoderLayer\",\n    \"Transformer\",",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Activation",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "Activation = Enum(\"Activation\", \"ReLU Swish GeLU\")\nclass PositionalEncoding(Module):\n    \"Encode the position with a sinusoid.\"\n    def __init__(self, d: int):\n        self.register_buffer(\"freq\", 1 / (10000 ** (torch.arange(0.0, d, 2.0) / d)))\n    def forward(self, pos: Tensor):\n        inp = torch.ger(pos, self.freq)\n        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n        return enc\nclass GeLU(Module):",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "_activ_func",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "_activ_func = {\n    Activation.ReLU: nn.ReLU(inplace=True),\n    Activation.GeLU: GeLU(),\n    Activation.Swish: Swish(),\n}\ndef feed_forward(\n    d_model: int,\n    d_ff: int,\n    ff_p: float = 0.0,\n    act: Activation = Activation.ReLU,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_lm_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmer_lm_config = dict(\n    ctx_len=512,\n    n_layers=12,\n    n_heads=12,\n    d_model=768,\n    d_head=64,\n    d_inner=3072,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_clas_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmer_clas_config = dict(\n    ctx_len=512,\n    n_layers=12,\n    n_heads=12,\n    d_model=768,\n    d_head=64,\n    d_inner=3072,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_lm_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmerXL_lm_config = dict(\n    ctx_len=150,\n    n_layers=12,\n    n_heads=10,\n    d_model=410,\n    d_head=41,\n    d_inner=2100,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_clas_config",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.models.transformer",
        "description": "DL_Model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmerXL_clas_config = dict(\n    ctx_len=150,\n    n_layers=12,\n    n_heads=10,\n    d_model=410,\n    d_head=41,\n    d_inner=2100,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "DL_Model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "LanguageModelPreLoader",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[\n                i % len(self.idx)\n                if self.forward",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SortSampler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class SortSampler(Sampler):\n    \"Go through the text data by order of length.\"\n    def __init__(self, data_source: NPArrayList, key: KeyFunc):\n        self.data_source, self.key = data_source, key\n    def __len__(self) -> int:\n        return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range_of(self.data_source), key=self.key, reverse=True))\nclass SortishSampler(Sampler):\n    \"Go through the text data by order of length with a bit of randomness.\"",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SortishSampler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class SortishSampler(Sampler):\n    \"Go through the text data by order of length with a bit of randomness.\"\n    def __init__(self, data_source: NPArrayList, key: KeyFunc, bs: int):\n        self.data_source, self.key, self.bs = data_source, key, bs\n    def __len__(self) -> int:\n        return len(self.data_source)\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs * 50\n        ck_idx = [idxs[i : i + sz] for i in range(0, len(idxs), sz)]",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class TextDataBunch(DataBunch):\n    \"General class to get a `DataBunch` for NLP. Subclassed by `TextLMDataBunch` and `TextClasDataBunch`.\"\n    @classmethod\n    def from_ids(\n        cls,\n        path: PathOrStr,\n        vocab: Vocab,\n        train_ids: Collection[Collection[int]],\n        valid_ids: Collection[Collection[int]],\n        test_ids: Collection[Collection[int]] = None,",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextLMDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class TextLMDataBunch(TextDataBunch):\n    \"Create a `TextDataBunch` suitable for training a language model.\"\n    @classmethod\n    def create(\n        cls,\n        train_ds,\n        valid_ds,\n        test_ds=None,\n        path: PathOrStr = \".\",\n        no_check: bool = False,",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextClasDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class TextClasDataBunch(TextDataBunch):\n    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n    @classmethod\n    def create(\n        cls,\n        train_ds,\n        valid_ds,\n        test_ds=None,\n        path: PathOrStr = \".\",\n        bs: int = 32,",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "Text",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class Text(ItemBase):\n    \"Basic item for <code>text</code> data in numericalized `ids`.\"\n    def __init__(self, ids, text):\n        self.data, self.text = np.array(ids, dtype=np.int64), text\n    def __str__(self):\n        return str(self.text)\nclass TokenizeProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes the texts in `ds`.\"\n    def __init__(\n        self,",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TokenizeProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class TokenizeProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes the texts in `ds`.\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        tokenizer: Tokenizer = None,\n        chunksize: int = 10000,\n        mark_fields: bool = False,\n        include_bos: bool = True,\n        include_eos: bool = False,",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "NumericalizeProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class NumericalizeProcessor(PreProcessor):\n    \"`PreProcessor` that numericalizes the tokens in `ds`.\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        vocab: Vocab = None,\n        max_vocab: int = 60000,\n        min_freq: int = 3,\n    ):\n        vocab = ifnone(vocab, ds.vocab if ds is not None else None)",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "OpenFileProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class OpenFileProcessor(PreProcessor):\n    \"`PreProcessor` that opens the filenames and read the texts.\"\n    def process(self, ds: Collection):\n        ds.items = array([self.process_one(item) for item in ds.items], dtype=np.object)\n    def process_one(self, item):\n        return open_text(item) if isinstance(item, Path) else item\nclass TextList(ItemList):\n    \"Basic `ItemList` for text data.\"\n    _bunch = TextClasDataBunch\n    _processor = [TokenizeProcessor, NumericalizeProcessor]",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class TextList(ItemList):\n    \"Basic `ItemList` for text data.\"\n    _bunch = TextClasDataBunch\n    _processor = [TokenizeProcessor, NumericalizeProcessor]\n    _is_lm = False\n    def __init__(\n        self, items: Iterator, vocab: Vocab = None, pad_idx: int = 1, sep=\" \", **kwargs\n    ):\n        super().__init__(items, **kwargs)\n        self.vocab, self.pad_idx, self.sep = vocab, pad_idx, sep",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "LMLabelList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class LMLabelList(EmptyLabelList):\n    \"Basic `ItemList` for dummy labels.\"\n    def __init__(self, items: Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = CrossEntropyFlat()\nclass LMTextList(TextList):\n    \"Special `TextList` for a language model.\"\n    _bunch = TextLMDataBunch\n    _is_lm = True\ndef _join_texts(",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "LMTextList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class LMTextList(TextList):\n    \"Special `TextList` for a language model.\"\n    _bunch = TextLMDataBunch\n    _is_lm = True\ndef _join_texts(\n    texts: Collection[str],\n    mark_fields: bool = False,\n    include_bos: bool = True,\n    include_eos: bool = False,\n):",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SPProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "class SPProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes and numericalizes with `sentencepiece`\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        vocab_sz: int = None,\n        max_vocab_sz: int = 30000,\n        model_type: str = \"unigram\",",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "pad_collate",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "def pad_collate(\n    samples: BatchSamples,\n    pad_idx: int = 1,\n    pad_first: bool = True,\n    backwards: bool = False,\n) -> Tuple[LongTensor, LongTensor]:\n    \"Function that collect samples and adds padding. Flips token order if needed\"\n    samples = to_data(samples)\n    max_len = max([len(s[0]) for s in samples])\n    res = torch.zeros(len(samples), max_len).long() + pad_idx",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "open_text",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "def open_text(fn: PathOrStr, enc=\"utf-8\"):\n    \"Read the text in `fn`.\"\n    with open(fn, \"r\", encoding=enc) as f:\n        return \"\".join(f.readlines())\nclass Text(ItemBase):\n    \"Basic item for <code>text</code> data in numericalized `ids`.\"\n    def __init__(self, ids, text):\n        self.data, self.text = np.array(ids, dtype=np.int64), text\n    def __str__(self):\n        return str(self.text)",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "apply_rules",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "def apply_rules(text, pre_rules=None, post_rules=None):\n    \"Apply `pre_rules` and `post_rules` to `text`\"\n    text = text.strip(\" \")\n    for r in ifnone(pre_rules, defaults.text_pre_rules):\n        text = r(text)\n    toks = text.split()\n    for r in ifnone(post_rules, defaults.text_post_rules):\n        toks = r(toks)\n    return \" \".join(toks)\ndef get_default_size(texts, max_vocab_sz):",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "get_default_size",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "def get_default_size(texts, max_vocab_sz):\n    \"Either max_vocab_sz or one quarter of the number of unique words in `texts`\"\n    cnt = Counter()\n    for t in texts:\n        cnt.update(t.split())\n        if len(cnt) // 4 > max_vocab_sz:\n            return max_vocab_sz\n    res = len(cnt) // 4\n    while res % 8 != 0:\n        res += 1",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "train_sentencepiece",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "def train_sentencepiece(\n    texts: Collection[str],\n    path: PathOrStr,\n    pre_rules: ListRules = None,\n    post_rules: ListRules = None,\n    vocab_sz: int = None,\n    max_vocab_sz: int = 30000,\n    model_type: str = \"unigram\",\n    max_sentence_len: int = 20480,\n    lang=\"en\",",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "__all__ = [\n    \"LanguageModelPreLoader\",\n    \"SortSampler\",\n    \"SortishSampler\",\n    \"TextList\",\n    \"pad_collate\",\n    \"TextDataBunch\",\n    \"TextLMDataBunch\",\n    \"TextClasDataBunch\",\n    \"Text\",",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextMtd",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "TextMtd = IntEnum(\"TextMtd\", \"DF TOK IDS\")\ntext_extensions = {\".txt\"}\nclass LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "text_extensions",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "text_extensions = {\".txt\"}\nclass LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[\n                i % len(self.idx)",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "full_char_coverage_langs",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.data",
        "description": "DL_Model.deoldify.fastai.text.data",
        "peekOfCode": "full_char_coverage_langs = [\n    \"bg\",\n    \"cs\",\n    \"da\",\n    \"de\",\n    \"el\",\n    \"en\",\n    \"es\",\n    \"et\",\n    \"fi\",",
        "detail": "DL_Model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextClassificationInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.interpret",
        "description": "DL_Model.deoldify.fastai.text.interpret",
        "peekOfCode": "class TextClassificationInterpretation(ClassificationInterpretation):\n    \"\"\"Provides an interpretation of classification based on input sensitivity.\n    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n    \"\"\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,",
        "detail": "DL_Model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "value2rgba",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.interpret",
        "description": "DL_Model.deoldify.fastai.text.interpret",
        "peekOfCode": "def value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []",
        "detail": "DL_Model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "piece_attn_html",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.interpret",
        "description": "DL_Model.deoldify.fastai.text.interpret",
        "peekOfCode": "def piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(\n            f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>'\n        )",
        "detail": "DL_Model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "show_piece_attn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.interpret",
        "description": "DL_Model.deoldify.fastai.text.interpret",
        "peekOfCode": "def show_piece_attn(*args, **kwargs):\n    from IPython.display import HTML, display\n    display(HTML(piece_attn_html(*args, **kwargs)))\ndef _eval_dropouts(mod):\n    module_name = mod.__class__.__name__\n    if \"Dropout\" in module_name or \"BatchNorm\" in module_name:\n        mod.training = False\n    for module in mod.children():\n        _eval_dropouts(module)\nclass TextClassificationInterpretation(ClassificationInterpretation):",
        "detail": "DL_Model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.interpret",
        "description": "DL_Model.deoldify.fastai.text.interpret",
        "peekOfCode": "__all__ = [\"TextClassificationInterpretation\"]\ndef value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:",
        "detail": "DL_Model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "RNNLearner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "class RNNLearner(Learner):\n    \"Basic class for a `Learner` in NLP.\"\n    def __init__(\n        self,\n        data: DataBunch,\n        model: nn.Module,\n        split_func: OptSplitFunc = None,\n        clip: float = None,\n        alpha: float = 2.0,\n        beta: float = 1.0,",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "LanguageLearner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "class LanguageLearner(RNNLearner):\n    \"Subclass of RNNLearner for predictions.\"\n    def predict(\n        self,\n        text: str,\n        n_words: int = 1,\n        no_unk: bool = True,\n        temperature: float = 1.0,\n        min_p: float = None,\n        sep: str = \" \",",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "PoolingLinearClassifier",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "class PoolingLinearClassifier(Module):\n    \"Create a linear classifier with pooling.\"\n    def __init__(self, layers: Collection[int], drops: Collection[float]):\n        mod_layers = []\n        if len(drops) != len(layers) - 1:\n            raise ValueError(\"Number of layers and dropout values do not match.\")\n        activs = [nn.ReLU(inplace=True)] * (len(layers) - 2) + [None]\n        for n_in, n_out, p, actn in zip(layers[:-1], layers[1:], drops, activs):\n            mod_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn)\n        self.layers = nn.Sequential(*mod_layers)",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "MultiBatchEncoder",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "class MultiBatchEncoder(Module):\n    \"Create an encoder over `module` that can process a full sentence.\"\n    def __init__(self, bptt: int, max_len: int, module: nn.Module, pad_idx: int = 1):\n        self.max_len, self.bptt, self.module, self.pad_idx = (\n            max_len,\n            bptt,\n            module,\n            pad_idx,\n        )\n    def concat(self, arrs: Collection[Tensor]) -> Tensor:",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "convert_weights",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def convert_weights(\n    wgts: Weights, stoi_wgts: Dict[str, int], itos_new: Collection[str]\n) -> Weights:\n    \"Convert the model `wgts` to go with a new vocabulary.\"\n    dec_bias, enc_wgts = wgts.get(\"1.decoder.bias\", None), wgts[\"0.encoder.weight\"]\n    wgts_m = enc_wgts.mean(0)\n    if dec_bias is not None:\n        bias_m = dec_bias.mean(0)\n    new_w = enc_wgts.new_zeros((len(itos_new), enc_wgts.size(1))).zero_()\n    if dec_bias is not None:",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "decode_spec_tokens",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def decode_spec_tokens(tokens):\n    new_toks, rule, arg = [], None, None\n    for t in tokens:\n        if t in [TK_MAJ, TK_UP, TK_REP, TK_WREP]:\n            rule = t\n        elif rule is None:\n            new_toks.append(t)\n        elif rule == TK_MAJ:\n            new_toks.append(t[:1].upper() + t[1:].lower())\n            rule = None",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "get_language_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def get_language_model(\n    arch: Callable, vocab_sz: int, config: dict = None, drop_mult: float = 1.0\n):\n    \"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\n    meta = _model_meta[arch]\n    config = ifnone(config, meta[\"config_lm\"]).copy()\n    for k in config.keys():\n        if k.endswith(\"_p\"):\n            config[k] *= drop_mult\n    tie_weights, output_p, out_bias = map(",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "language_model_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def language_model_learner(\n    data: DataBunch,\n    arch,\n    config: dict = None,\n    drop_mult: float = 1.0,\n    pretrained: bool = True,\n    pretrained_fnames: OptStrTuple = None,\n    **learn_kwargs,\n) -> \"LanguageLearner\":\n    \"Create a `Learner` with a language model from `data` and `arch`.\"",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "masked_concat_pool",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def masked_concat_pool(outputs, mask):\n    \"Pool MultiBatchEncoder outputs into one vector [last_hidden, max_pool, avg_pool].\"\n    output = outputs[-1]\n    avg_pool = output.masked_fill(mask[:, :, None], 0).mean(dim=1)\n    avg_pool *= (\n        output.size(1)\n        / (output.size(1) - mask.type(avg_pool.dtype).sum(dim=1))[:, None]\n    )\n    max_pool = output.masked_fill(mask[:, :, None], -float(\"inf\")).max(dim=1)[0]\n    x = torch.cat([output[:, -1], max_pool, avg_pool], 1)",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "get_text_classifier",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def get_text_classifier(\n    arch: Callable,\n    vocab_sz: int,\n    n_class: int,\n    bptt: int = 70,\n    max_len: int = 20 * 70,\n    config: dict = None,\n    drop_mult: float = 1.0,\n    lin_ftrs: Collection[int] = None,\n    ps: Collection[float] = None,",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "text_classifier_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "def text_classifier_learner(\n    data: DataBunch,\n    arch: Callable,\n    bptt: int = 70,\n    max_len: int = 70 * 20,\n    config: dict = None,\n    pretrained: bool = True,\n    drop_mult: float = 1.0,\n    lin_ftrs: Collection[int] = None,\n    ps: Collection[float] = None,",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "__all__ = [\n    \"RNNLearner\",\n    \"LanguageLearner\",\n    \"convert_weights\",\n    \"decode_spec_tokens\",\n    \"get_language_model\",\n    \"language_model_learner\",\n    \"MultiBatchEncoder\",\n    \"get_text_classifier\",\n    \"text_classifier_learner\",",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "_model_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.learner",
        "description": "DL_Model.deoldify.fastai.text.learner",
        "peekOfCode": "_model_meta = {\n    AWD_LSTM: {\n        \"hid_name\": \"emb_sz\",\n        \"url\": URLs.WT103_FWD,\n        \"url_bwd\": URLs.WT103_BWD,\n        \"config_lm\": awd_lstm_lm_config,\n        \"split_lm\": awd_lstm_lm_split,\n        \"config_clas\": awd_lstm_clas_config,\n        \"split_clas\": awd_lstm_clas_split,\n    },",
        "detail": "DL_Model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "BaseTokenizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "class BaseTokenizer:\n    \"Basic class for a tokenizer function.\"\n    def __init__(self, lang: str):\n        self.lang = lang\n    def tokenizer(self, t: str) -> List[str]:\n        return t.split(\" \")\n    def add_special_cases(self, toks: Collection[str]):\n        pass\nclass SpacyTokenizer(BaseTokenizer):\n    \"Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.\"",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "SpacyTokenizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "class SpacyTokenizer(BaseTokenizer):\n    \"Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.\"\n    def __init__(self, lang: str):\n        self.tok = spacy.blank(lang, disable=[\"parser\", \"tagger\", \"ner\"])\n    def tokenizer(self, t: str) -> List[str]:\n        return [t.text for t in self.tok.tokenizer(t)]\n    def add_special_cases(self, toks: Collection[str]):\n        for w in toks:\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\ndef spec_add_spaces(t: str) -> str:",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "Tokenizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "class Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"\n    def __init__(\n        self,\n        tok_func: Callable = SpacyTokenizer,\n        lang: str = \"en\",\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        special_cases: Collection[str] = None,\n        n_cpus: int = None,",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "Vocab",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "class Vocab:\n    \"Contain the correspondence between numbers and tokens and numericalize.\"\n    def __init__(self, itos: Collection[str]):\n        self.itos = itos\n        self.stoi = collections.defaultdict(\n            int, {v: k for k, v in enumerate(self.itos)}\n        )\n    def numericalize(self, t: Collection[str]) -> List[int]:\n        \"Convert a list of tokens `t` to their ids.\"\n        return [self.stoi[w] for w in t]",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "spec_add_spaces",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def spec_add_spaces(t: str) -> str:\n    \"Add spaces around / and # in `t`. \\n\"\n    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\ndef rm_useless_spaces(t: str) -> str:\n    \"Remove multiple spaces in `t`.\"\n    return re.sub(\" {2,}\", \" \", t)\ndef replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "rm_useless_spaces",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def rm_useless_spaces(t: str) -> str:\n    \"Remove multiple spaces in `t`.\"\n    return re.sub(\" {2,}\", \" \", t)\ndef replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_REP} {len(cc)+1} {c} \"\n    re_rep = re.compile(r\"(\\S)(\\1{3,})\")\n    return re_rep.sub(_replace_rep, t)",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_rep",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_REP} {len(cc)+1} {c} \"\n    re_rep = re.compile(r\"(\\S)(\\1{3,})\")\n    return re_rep.sub(_replace_rep, t)\ndef replace_wrep(t: str) -> str:\n    \"Replace word repetitions in `t`.\"\n    def _replace_wrep(m: Collection[str]) -> str:",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_wrep",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_wrep(t: str) -> str:\n    \"Replace word repetitions in `t`.\"\n    def _replace_wrep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_WREP} {len(cc.split())+1} {c} \"\n    re_wrep = re.compile(r\"(\\b\\w+\\W+)(\\1{3,})\")\n    return re_wrep.sub(_replace_wrep, t)\ndef fix_html(x: str) -> str:\n    \"List of replacements from html strings in `x`.\"\n    re1 = re.compile(r\"  +\")",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "fix_html",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def fix_html(x: str) -> str:\n    \"List of replacements from html strings in `x`.\"\n    re1 = re.compile(r\"  +\")\n    x = (\n        x.replace(\"#39;\", \"'\")\n        .replace(\"amp;\", \"&\")\n        .replace(\"#146;\", \"'\")\n        .replace(\"nbsp;\", \" \")\n        .replace(\"#36;\", \"$\")\n        .replace(\"\\\\n\", \"\\n\")",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_all_caps",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_all_caps(x: Collection[str]) -> Collection[str]:\n    \"Replace tokens in ALL CAPS in `x` by their lower version and add `TK_UP` before.\"\n    res = []\n    for t in x:\n        if t.isupper() and len(t) > 1:\n            res.append(TK_UP)\n            res.append(t.lower())\n        else:\n            res.append(t)\n    return res",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "deal_caps",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "def deal_caps(x: Collection[str]) -> Collection[str]:\n    \"Replace all Capitalized tokens in `x` by their lower version and add `TK_MAJ` before.\"\n    res = []\n    for t in x:\n        if t == \"\":\n            continue\n        if t[0].isupper() and len(t) > 1 and t[1:].islower():\n            res.append(TK_MAJ)\n        res.append(t.lower())\n    return res",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "__all__ = [\n    \"BaseTokenizer\",\n    \"SpacyTokenizer\",\n    \"Tokenizer\",\n    \"Vocab\",\n    \"fix_html\",\n    \"replace_all_caps\",\n    \"replace_rep\",\n    \"replace_wrep\",\n    \"rm_useless_spaces\",",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_spec_tok",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_spec_tok = [UNK, PAD, BOS, EOS, FLD, TK_MAJ, TK_UP, TK_REP, TK_WREP]\nclass BaseTokenizer:\n    \"Basic class for a tokenizer function.\"\n    def __init__(self, lang: str):\n        self.lang = lang\n    def tokenizer(self, t: str) -> List[str]:\n        return t.split(\" \")\n    def add_special_cases(self, toks: Collection[str]):\n        pass\nclass SpacyTokenizer(BaseTokenizer):",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_pre_rules",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_pre_rules = [\n    fix_html,\n    replace_rep,\n    replace_wrep,\n    spec_add_spaces,\n    rm_useless_spaces,\n]\ndefaults.text_post_rules = [replace_all_caps, deal_caps]\nclass Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_post_rules",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.text.transform",
        "description": "DL_Model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_post_rules = [replace_all_caps, deal_caps]\nclass Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"\n    def __init__(\n        self,\n        tok_func: Callable = SpacyTokenizer,\n        lang: str = \"en\",\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        special_cases: Collection[str] = None,",
        "detail": "DL_Model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "get_env",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.collect_env",
        "description": "DL_Model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def get_env(name):\n    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n    res = os.environ.get(name, \"\")\n    return res if len(res) else \"Unknown\"\ndef show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []\n    opt_mods = []",
        "detail": "DL_Model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "show_install",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.collect_env",
        "description": "DL_Model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []\n    opt_mods = []\n    rep.append([\"=== Software ===\", None])\n    rep.append([\"python\", platform.python_version()])\n    rep.append([\"fastai\", fastai.__version__])\n    rep.append([\"fastprogress\", fastprogress.__version__])",
        "detail": "DL_Model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "pypi_module_version_is_available",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.collect_env",
        "description": "DL_Model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def pypi_module_version_is_available(module, version):\n    \"Check whether module==version is available on pypi\"\n    # returns True/False (or None if failed to execute the check)\n    # using a hack that when passing \"module==\" w/ no version number to pip\n    # it \"fails\" and returns all the available versions in stderr\n    try:\n        cmd = f\"pip install {module}==\"\n        result = subprocess.run(\n            cmd.split(),\n            shell=False,",
        "detail": "DL_Model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "check_perf",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.collect_env",
        "description": "DL_Model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def check_perf():\n    \"Suggest how to improve the setup to speed things up\"\n    from packaging import version\n    from PIL import Image, features\n    print(\"Running performance checks.\")\n    # libjpeg_turbo check\n    print(\"\\n*** libjpeg-turbo status\")\n    if version.parse(Image.PILLOW_VERSION) >= version.parse(\"5.3.9\"):\n        if features.check_feature(\"libjpeg_turbo\"):\n            print(\" libjpeg-turbo is on\")",
        "detail": "DL_Model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.collect_env",
        "description": "DL_Model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "__all__ = [\"show_install\", \"check_perf\"]\ndef get_env(name):\n    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n    res = os.environ.get(name, \"\")\n    return res if len(res) else \"Unknown\"\ndef show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []",
        "detail": "DL_Model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "gpu_mem_restore_ctx",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "class gpu_mem_restore_ctx:\n    \"context manager to reclaim RAM if an exception happened under ipython\"\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if not exc_val:\n            return True\n        traceback.clear_frames(exc_tb)\n        gc.collect()\n        raise exc_type(exc_val).with_traceback(exc_tb) from None",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "is_in_ipython",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv(\"_\", \"\"))\n    if (\n        \"jupyter-notebook\" in program_name\n        or \"ipython\" in program_name  # jupyter-notebook\n        or \"JPY_PARENT_PID\" in os.environ  # ipython\n    ):  # ipython-notebook\n        return True\n    else:",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "is_in_colab",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def is_in_colab():\n    \"Is the code running in Google Colaboratory?\"\n    if not IS_IN_IPYTHON:\n        return False\n    try:\n        from google import colab\n        return True\n    except:\n        return False\nIS_IN_COLAB = is_in_colab()",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "get_ref_free_exc_info",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def get_ref_free_exc_info():\n    \"Free traceback from references to locals() in each frame to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n    type, val, tb = sys.exc_info()\n    traceback.clear_frames(tb)\n    return (type, val, tb)\ndef gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        tb_clear_frames = os.environ.get(\"FASTAI_TB_CLEAR_FRAMES\", None)",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "gpu_mem_restore",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        tb_clear_frames = os.environ.get(\"FASTAI_TB_CLEAR_FRAMES\", None)\n        if not IS_IN_IPYTHON or tb_clear_frames == \"0\":\n            return func(*args, **kwargs)\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "IS_IN_IPYTHON",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "IS_IN_IPYTHON = is_in_ipython()\ndef is_in_colab():\n    \"Is the code running in Google Colaboratory?\"\n    if not IS_IN_IPYTHON:\n        return False\n    try:\n        from google import colab\n        return True\n    except:\n        return False",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "IS_IN_COLAB",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.ipython",
        "description": "DL_Model.deoldify.fastai.utils.ipython",
        "peekOfCode": "IS_IN_COLAB = is_in_colab()\ndef get_ref_free_exc_info():\n    \"Free traceback from references to locals() in each frame to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n    type, val, tb = sys.exc_info()\n    traceback.clear_frames(tb)\n    return (type, val, tb)\ndef gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "GPUMemTrace",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "class GPUMemTrace:\n    \"Trace allocated and peaked GPU memory usage (deltas).\"\n    def __init__(self, silent=False, ctx=None, on_exit_report=True):\n        assert torch.cuda.is_available(), \"pytorch CUDA is required\"\n        self.silent = silent  # shortcut to turn off all reports from constructor\n        self.ctx = ctx  # default context note in report\n        self.on_exit_report = (\n            on_exit_report  # auto-report on ctx manager exit (default: True)\n        )\n        self.start()",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "preload_pytorch",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "b2mb",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:\n        id = torch.cuda.current_device()\n    try:",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:\n        id = torch.cuda.current_device()\n    try:\n        handle = pynvml.nvmlDeviceGetHandleByIndex(id)\n        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n        return GPUMemory(*(map(b2mb, [info.total, info.free, info.used])))",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_all",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_all():\n    \"get total, used and free memory (in MBs) for each available gpu\"\n    if not use_gpu:\n        return []\n    return list(map(gpu_mem_get, range(pynvml.nvmlDeviceGetCount())))\ndef gpu_mem_get_free():\n    \"get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().free\ndef gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_free",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_free():\n    \"get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().free\ndef gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().free\ndef gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_free_no_cache",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().free\ndef gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used\ndef gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used\ndef gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n    return b2mb(info.used)\ndef gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used_fast",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n    return b2mb(info.used)\ndef gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().used\ndef gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used_no_cache",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().used\ndef gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"\n    mem_all = gpu_mem_get_all()\n    if not len(mem_all):\n        return None, 0\n    free_all = np.array([x.free for x in mem_all])",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_with_max_free_mem",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"\n    mem_all = gpu_mem_get_all()\n    if not len(mem_all):\n        return None, 0\n    free_all = np.array([x.free for x in mem_all])\n    id = np.argmax(free_all)\n    return id, free_all[id]\nclass GPUMemTrace:\n    \"Trace allocated and peaked GPU memory usage (deltas).\"",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_trace",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_trace(func):\n    \"A decorator that runs `GPUMemTrace` w/ report on func\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        with GPUMemTrace(ctx=func.__qualname__, on_exit_report=True):\n            return func(*args, **kwargs)\n    return wrapper\ndef reduce_mem_usage(df):\n    \"\"\"iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "reduce_mem_usage",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "def reduce_mem_usage(df):\n    \"\"\"iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    # Removed from debugging\n    columns = df.columns\n    # .drop('index')\n    for col in columns:",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "use_gpu",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "use_gpu = torch.cuda.is_available()\nGPUMemory = namedtuple(\"GPUMemory\", [\"total\", \"free\", \"used\"])\nif use_gpu:\n    pynvml = load_pynvml_env()\ndef preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "GPUMemory",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.mem",
        "description": "DL_Model.deoldify.fastai.utils.mem",
        "peekOfCode": "GPUMemory = namedtuple(\"GPUMemory\", [\"total\", \"free\", \"used\"])\nif use_gpu:\n    pynvml = load_pynvml_env()\ndef preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"",
        "detail": "DL_Model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "progress_disabled_ctx",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.utils.mod_display",
        "description": "DL_Model.deoldify.fastai.utils.mod_display",
        "peekOfCode": "class progress_disabled_ctx:\n    \"Context manager to disable the progress update bar and Recorder print.\"\n    def __init__(self, learn: Learner):\n        self.learn = learn\n    def __enter__(self):\n        # silence progress bar\n        fastprogress.fastprogress.NO_BAR = True\n        (\n            fastai.basic_train.master_bar,\n            fastai.basic_train.progress_bar,",
        "detail": "DL_Model.deoldify.fastai.utils.mod_display",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.mod_display",
        "description": "DL_Model.deoldify.fastai.utils.mod_display",
        "peekOfCode": "__all__ = [\"progress_disabled_ctx\"]\nclass progress_disabled_ctx:\n    \"Context manager to disable the progress update bar and Recorder print.\"\n    def __init__(self, learn: Learner):\n        self.learn = learn\n    def __enter__(self):\n        # silence progress bar\n        fastprogress.fastprogress.NO_BAR = True\n        (\n            fastai.basic_train.master_bar,",
        "detail": "DL_Model.deoldify.fastai.utils.mod_display",
        "documentation": {}
    },
    {
        "label": "load_pynvml_env",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "description": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "def load_pynvml_env():\n    import pynvml  # nvidia-ml-py3\n    #\n    # BEGIN: Temporary workaround for nvml.dll load issue in Win10 (continued)\n    _LoadNvmlLibrary()\n    pynvml.nvmlLib = nvmlLib\n    #\n    # END: Temporary workaround for nvml.dll load issue in Win10\n    #\n    if platform.system() == \"Darwin\":",
        "detail": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "nvmlLib",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "description": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "nvmlLib = None\nlibLoadLock = threading.Lock()\ndef _LoadNvmlLibrary():\n    \"\"\"\n    Load the library if it isn't loaded already\n    \"\"\"\n    global nvmlLib\n    if nvmlLib == None:\n        libLoadLock.acquire()\n        try:",
        "detail": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "libLoadLock",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "description": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "libLoadLock = threading.Lock()\ndef _LoadNvmlLibrary():\n    \"\"\"\n    Load the library if it isn't loaded already\n    \"\"\"\n    global nvmlLib\n    if nvmlLib == None:\n        libLoadLock.acquire()\n        try:\n            if nvmlLib == None:",
        "detail": "DL_Model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.utils.show_install",
        "description": "DL_Model.deoldify.fastai.utils.show_install",
        "peekOfCode": "def main(show_nvidia_smi: Param(opt=False, nargs=\"?\", type=bool) = False):\n    return show_install(show_nvidia_smi)",
        "detail": "DL_Model.deoldify.fastai.utils.show_install",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def get_model(\n    model_name: str,\n    pretrained: bool,\n    seq: bool = False,\n    pname: str = \"imagenet\",\n    **kwargs,\n):\n    pretrained = pname if pretrained else None\n    model = getattr(pretrainedmodels, model_name)(pretrained=pretrained, **kwargs)\n    return nn.Sequential(*model.children()) if seq else model",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "inceptionv4",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def inceptionv4(pretrained: bool = False):\n    model = get_model(\"inceptionv4\", pretrained)\n    all_layers = list(model.children())\n    return nn.Sequential(*all_layers[0], *all_layers[1:])\nmodel_meta[inceptionv4] = {\"cut\": -2, \"split\": lambda m: (m[0][11], m[1])}\ndef nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "nasnetamobile",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "pnasnet5large",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[pnasnet5large] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "inceptionresnetv2",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)\ndef dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "dpn92",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "xception_cadene",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnet50",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnet101",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnext50_32x4d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnext101_32x4d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "senet154",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "pretrainedmodels",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "pretrainedmodels = try_import(\"pretrainedmodels\")\nif not pretrainedmodels:\n    raise Exception(\n        \"Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`\"\n    )\n__all__ = [\n    \"inceptionv4\",\n    \"inceptionresnetv2\",\n    \"nasnetamobile\",\n    \"dpn92\",",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "__all__ = [\n    \"inceptionv4\",\n    \"inceptionresnetv2\",\n    \"nasnetamobile\",\n    \"dpn92\",\n    \"xception_cadene\",\n    \"se_resnet50\",\n    \"se_resnet101\",\n    \"se_resnext50_32x4d\",\n    \"senet154\",",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[inceptionv4]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[inceptionv4] = {\"cut\": -2, \"split\": lambda m: (m[0][11], m[1])}\ndef nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[nasnetamobile]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[pnasnet5large] = {\n    \"cut\": noop,",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[pnasnet5large]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[pnasnet5large] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)\ndef dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[inceptionresnetv2]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[dpn92]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[xception_cadene]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[senet154]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "_se_resnet_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnet50]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnet101]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnext50_32x4d]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnext101_32x4d]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "description": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "DL_Model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "ResLayer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.darknet",
        "description": "DL_Model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "class ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"\n    def __init__(self, ni: int):\n        self.conv1 = conv_bn_lrelu(ni, ni // 2, ks=1)\n        self.conv2 = conv_bn_lrelu(ni // 2, ni, ks=3)\n    def forward(self, x):\n        return x + self.conv2(self.conv1(x))\nclass Darknet(Module):\n    \"https://github.com/pjreddie/darknet\"\n    def make_group_layer(self, ch_in: int, num_blocks: int, stride: int = 1):",
        "detail": "DL_Model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "Darknet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.darknet",
        "description": "DL_Model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "class Darknet(Module):\n    \"https://github.com/pjreddie/darknet\"\n    def make_group_layer(self, ch_in: int, num_blocks: int, stride: int = 1):\n        \"starts with conv layer - `ch_in` channels in - then has `num_blocks` `ResLayer`\"\n        return [conv_bn_lrelu(ch_in, ch_in * 2, stride=stride)] + [\n            (ResLayer(ch_in * 2)) for i in range(num_blocks)\n        ]\n    def __init__(self, num_blocks: Collection[int], num_classes: int, nf=32):\n        \"create darknet with `nf` and `num_blocks` layers\"\n        layers = [conv_bn_lrelu(3, nf, ks=3, stride=1)]",
        "detail": "DL_Model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "conv_bn_lrelu",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.darknet",
        "description": "DL_Model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "def conv_bn_lrelu(ni: int, nf: int, ks: int = 3, stride: int = 1) -> nn.Sequential:\n    \"Create a seuence Conv2d->BatchNorm2d->LeakyReLu layer.\"\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks // 2),\n        nn.BatchNorm2d(nf),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True),\n    )\nclass ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"\n    def __init__(self, ni: int):",
        "detail": "DL_Model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.darknet",
        "description": "DL_Model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "__all__ = [\"Darknet\", \"ResLayer\"]\ndef conv_bn_lrelu(ni: int, nf: int, ks: int = 3, stride: int = 1) -> nn.Sequential:\n    \"Create a seuence Conv2d->BatchNorm2d->LeakyReLu layer.\"\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks // 2),\n        nn.BatchNorm2d(nf),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True),\n    )\nclass ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"",
        "detail": "DL_Model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):\n        identity = x if self.downsample is None else self.downsample(x)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class Bottleneck(Module):\n    expansion = 4\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = act_conv(ni, nf, 1)\n        self.conv2 = act_conv(nf, nf, stride=stride)\n        self.conv3 = act_conv(nf, nf * self.expansion, 1)\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "PResNet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class PResNet(Module):\n    def __init__(self, block, layers, num_classes=1000):\n        self.ni = 64\n        super().__init__()\n        self.conv1 = conv_act(3, 16, stride=2)\n        self.conv2 = conv_act(16, 32)\n        self.conv3 = conv_act(32, 64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "init_cnn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():\n        init_cnn(l)\ndef conv(ni, nf, ks=3, stride=1, bias=False):",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef conv_layer(conv_1st, ni, nf, ks=3, stride=1, zero_bn=False, bias=False):\n    bn = nn.BatchNorm2d(nf if conv_1st else ni)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    res = [act_fn(), bn]\n    cn = conv(ni, nf, ks, stride=stride, bias=bias)\n    res.insert(0 if conv_1st else 2, cn)\n    return nn.Sequential(*res)\ndef conv_act(*args, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv_layer(conv_1st, ni, nf, ks=3, stride=1, zero_bn=False, bias=False):\n    bn = nn.BatchNorm2d(nf if conv_1st else ni)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    res = [act_fn(), bn]\n    cn = conv(ni, nf, ks, stride=stride, bias=bias)\n    res.insert(0 if conv_1st else 2, cn)\n    return nn.Sequential(*res)\ndef conv_act(*args, **kwargs):\n    return conv_layer(True, *args, **kwargs)\ndef act_conv(*args, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv_act",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv_act(*args, **kwargs):\n    return conv_layer(True, *args, **kwargs)\ndef act_conv(*args, **kwargs):\n    return conv_layer(False, *args, **kwargs)\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "act_conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def act_conv(*args, **kwargs):\n    return conv_layer(False, *args, **kwargs)\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)\n        self.downsample = downsample\n        self.stride = stride",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet(block, n_layers, name, pre=False, **kwargs):\n    model = PResNet(block, n_layers, **kwargs)\n    # if pre: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    if pre:\n        model.load_state_dict(torch.load(model_urls[name]))\n    return model\ndef presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet18",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)\ndef presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet34",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)\ndef presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet50",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet101",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet152",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "__all__ = [\"PResNet\", \"presnet18\", \"presnet34\", \"presnet50\", \"presnet101\", \"presnet152\"]\nact_fn = nn.ReLU\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "act_fn",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "act_fn = nn.ReLU\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():\n        init_cnn(l)",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "model_urls",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.presnet",
        "description": "DL_Model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "model_urls = dict(presnet34=\"presnet34\", presnet50=\"presnet50\")\ndef presnet(block, n_layers, name, pre=False, **kwargs):\n    model = PResNet(block, n_layers, **kwargs)\n    # if pre: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    if pre:\n        model.load_state_dict(torch.load(model_urls[name]))\n    return model\ndef presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "UnetBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.unet",
        "description": "DL_Model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "class UnetBlock(Module):\n    \"A quasi-UNet block, using `PixelShuffle_ICNR upsampling`.\"\n    def __init__(\n        self,\n        up_in_c: int,\n        x_in_c: int,\n        hook: Hook,\n        final_div: bool = True,\n        blur: bool = False,\n        leaky: float = None,",
        "detail": "DL_Model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "DynamicUnet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.unet",
        "description": "DL_Model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "class DynamicUnet(SequentialEx):\n    \"Create a U-Net from a given architecture.\"\n    def __init__(\n        self,\n        encoder: nn.Module,\n        n_classes: int,\n        img_size: Tuple[int, int] = (256, 256),\n        blur: bool = False,\n        blur_final=True,\n        self_attention: bool = False,",
        "detail": "DL_Model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.unet",
        "description": "DL_Model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "__all__ = [\"DynamicUnet\", \"UnetBlock\"]\ndef _get_sfs_idxs(sizes: Sizes) -> List[int]:\n    \"Get the indexes of the layers where the size of the activation changes.\"\n    feature_szs = [size[-1] for size in sizes]\n    sfs_idxs = list(\n        np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0]\n    )\n    if feature_szs[0] != feature_szs[1]:\n        sfs_idxs = [0] + sfs_idxs\n    return sfs_idxs",
        "detail": "DL_Model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.wrn",
        "description": "DL_Model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "class BasicBlock(Module):\n    \"Block to from a wide ResNet.\"\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv2d(ni, nf, 1, stride) if ni != nf else noop\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)",
        "detail": "DL_Model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "WideResNet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.wrn",
        "description": "DL_Model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "class WideResNet(Module):\n    \"Wide ResNet with `num_groups` and a width of `k`.\"\n    def __init__(\n        self,\n        num_groups: int,\n        N: int,\n        num_classes: int,\n        k: int = 1,\n        drop_p: float = 0.0,\n        start_nf: int = 16,",
        "detail": "DL_Model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "bn_relu_conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.wrn",
        "description": "DL_Model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "def bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = _bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv2d(ni, nf, ks, stride))\nclass BasicBlock(Module):\n    \"Block to from a wide ResNet.\"\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None",
        "detail": "DL_Model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "wrn_22",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.wrn",
        "description": "DL_Model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "def wrn_22():\n    \"Wide ResNet with 22 layers.\"\n    return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.0)",
        "detail": "DL_Model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.wrn",
        "description": "DL_Model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "__all__ = [\"BasicBlock\", \"WideResNet\", \"wrn_22\"]\ndef _bn(ni, init_zero=False):\n    \"Batchnorm layer with 0 initialization\"\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = _bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv2d(ni, nf, ks, stride))",
        "detail": "DL_Model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "ConvSkip",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "class ConvSkip(Module):\n    def __init__(self, ni, nf=None, act=True):\n        self.nf, self.ni = nf, ni\n        if self.nf is None:\n            self.nf = ni\n        self.conv = conv(ni, nf, stride=2, act=False)\n        self.m = nn.Sequential(sep_conv(ni, ni, act=act), sep_conv(ni, nf, pool=True))\n    def forward(self, x):\n        return self.conv(x) + self.m(x)\ndef middle_flow(nf):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "sep_conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def sep_conv(ni, nf, pad=None, pool=False, act=True):\n    layers = [nn.ReLU()] if act else []\n    layers += [\n        nn.Conv2d(ni, ni, 3, 1, 1, groups=ni, bias=False),\n        nn.Conv2d(ni, nf, 1, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if pool:\n        layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def conv(ni, nf, ks=1, stride=1, pad=None, act=True):\n    if pad is None:\n        pad = ks // 2\n    layers = [\n        nn.Conv2d(ni, nf, ks, stride, pad, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if act:\n        layers.append(nn.ReLU())\n    return nn.Sequential(*layers)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "middle_flow",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def middle_flow(nf):\n    layers = [sep_conv(nf, nf) for i in range(3)]\n    return SequentialEx(*layers, MergeLayer())\ndef xception(c, k=8, n_middle=8):\n    \"Preview version of Xception network. Not tested yet - use at own risk. No pretrained model yet.\"\n    layers = [\n        conv(3, k * 4, 3, 2),\n        conv(k * 4, k * 8, 3),\n        ConvSkip(k * 8, k * 16, act=False),\n        ConvSkip(k * 16, k * 32),",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "xception",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def xception(c, k=8, n_middle=8):\n    \"Preview version of Xception network. Not tested yet - use at own risk. No pretrained model yet.\"\n    layers = [\n        conv(3, k * 4, 3, 2),\n        conv(k * 4, k * 8, 3),\n        ConvSkip(k * 8, k * 16, act=False),\n        ConvSkip(k * 16, k * 32),\n        ConvSkip(k * 32, k * 91),\n    ]\n    for i in range(n_middle):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xception",
        "description": "DL_Model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "__all__ = [\"xception\"]\ndef sep_conv(ni, nf, pad=None, pool=False, act=True):\n    layers = [nn.ReLU()] if act else []\n    layers += [\n        nn.Conv2d(ni, ni, 3, 1, 1, groups=ni, bias=False),\n        nn.Conv2d(ni, nf, 1, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if pool:\n        layers.append(nn.MaxPool2d(2))",
        "detail": "DL_Model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():\n        init_cnn(l)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "ResBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class ResBlock(Module):\n    def __init__(self, expansion, ni, nh, stride=1):\n        nf, ni = nh * expansion, ni * expansion\n        layers = (\n            [\n                conv_layer(ni, nh, 3, stride=stride),\n                conv_layer(nh, nf, 3, zero_bn=True, act=False),\n            ]\n            if expansion == 1\n            else [",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "XResNet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class XResNet(nn.Sequential):\n    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n        stem = []\n        sizes = [c_in, 32, 32, 64]\n        for i in range(3):\n            stem.append(conv_layer(sizes[i], sizes[i + 1], stride=2 if i == 0 else 1))\n            # nf = filt_sz(c_in*9)\n            # stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n            # c_in = nf\n        block_szs = [64 // expansion, 64, 128, 256, 512]",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "init_cnn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():\n        init_cnn(l)\ndef conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef noop(x):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef noop(x):\n    return x\ndef conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "noop",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def noop(x):\n    return x\ndef conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)\n    return nn.Sequential(*layers)\nclass ResBlock(Module):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)\n    return nn.Sequential(*layers)\nclass ResBlock(Module):\n    def __init__(self, expansion, ni, nh, stride=1):\n        nf, ni = nh * expansion, ni * expansion",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "filt_sz",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def filt_sz(recep):\n    return min(64, 2 ** math.floor(math.log2(recep * 0.75)))\nclass XResNet(nn.Sequential):\n    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n        stem = []\n        sizes = [c_in, 32, 32, 64]\n        for i in range(3):\n            stem.append(conv_layer(sizes[i], sizes[i + 1], stride=2 if i == 0 else 1))\n            # nf = filt_sz(c_in*9)\n            # stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "xresnet",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def xresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n    model = XResNet(expansion, n_layers, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\nme = sys.modules[__name__]\nfor n, e, l in [\n    [18, 1, [2, 2, 2, 2]],\n    [34, 1, [3, 4, 6, 3]],\n    [50, 4, [3, 4, 6, 3]],",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "__all__ = [\"XResNet\", \"xresnet18\", \"xresnet34\", \"xresnet50\", \"xresnet101\", \"xresnet152\"]\n# or: ELU+init (a=0.54; gain=1.55)\nact_fn = nn.ReLU(inplace=True)\nclass Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "act_fn",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "act_fn = nn.ReLU(inplace=True)\nclass Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "me",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "me = sys.modules[__name__]\nfor n, e, l in [\n    [18, 1, [2, 2, 2, 2]],\n    [34, 1, [3, 4, 6, 3]],\n    [50, 4, [3, 4, 6, 3]],\n    [101, 4, [3, 4, 23, 3]],\n    [152, 4, [3, 8, 36, 3]],\n]:\n    name = f\"xresnet{n}\"\n    setattr(me, name, partial(xresnet, expansion=e, n_layers=l, name=name))",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class BasicBlock(Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class Bottleneck(Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "XResNet",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class XResNet(Module):\n    def __init__(self, block, layers, c_out=1000):\n        self.inplanes = 64\n        super(XResNet, self).__init__()\n        self.conv1 = conv2d(3, 32, 2)\n        self.conv2 = conv2d(32, 32, 1)\n        self.conv3 = conv2d(32, 64, 1)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "conv3x3",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(\n        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n    )\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "conv2d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def conv2d(ni, nf, stride):\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=3, stride=stride, padding=1, bias=False),\n        nn.BatchNorm2d(nf),\n        nn.ReLU(inplace=True),\n    )\nclass XResNet(Module):\n    def __init__(self, block, layers, c_out=1000):\n        self.inplanes = 64\n        super(XResNet, self).__init__()",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet18",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet18\"]))\n    return model\ndef xresnet34_2(pretrained=False, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet34_2",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet34_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet34\"]))\n    return model\ndef xresnet50_2(pretrained=False, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet50_2",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet50_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet50\"]))\n    return model\ndef xresnet101(pretrained=False, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet101",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet101\"]))\n    return model\ndef xresnet152(pretrained=False, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet152",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet152\"]))\n    return model",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "description": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "__all__ = [\n    \"XResNet\",\n    \"xresnet18\",\n    \"xresnet34_2\",\n    \"xresnet50_2\",\n    \"xresnet101\",\n    \"xresnet152\",\n]\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(",
        "detail": "DL_Model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "ResnetBlock",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class ResnetBlock(Module):\n    def __init__(\n        self,\n        dim: int,\n        pad_mode: str = \"reflection\",\n        norm_layer: nn.Module = None,\n        dropout: float = 0.0,\n        bias: bool = True,\n    ):\n        assert pad_mode in [",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGAN",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGAN(Module):\n    def __init__(\n        self,\n        ch_in: int,\n        ch_out: int,\n        n_features: int = 64,\n        disc_layers: int = 3,\n        gen_blocks: int = 6,\n        lsgan: bool = True,\n        drop: float = 0.0,",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "AdaptiveLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class AdaptiveLoss(Module):\n    def __init__(self, crit):\n        self.crit = crit\n    def forward(self, output, target: bool):\n        targ = (\n            output.new_ones(*output.size())\n            if target\n            else output.new_zeros(*output.size())\n        )\n        return self.crit(output, targ)",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGanLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGanLoss(Module):\n    def __init__(\n        self,\n        cgan: nn.Module,\n        lambda_A: float = 10.0,\n        lambda_B: float = 10,\n        lambda_idt: float = 0.5,\n        lsgan: bool = True,\n    ):\n        self.cgan, self.l_A, self.l_B, self.l_idt = cgan, lambda_A, lambda_B, lambda_idt",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGANTrainer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGANTrainer(LearnerCallback):\n    \"`LearnerCallback` that handles cycleGAN Training.\"\n    _order = -20\n    def _set_trainable(self, D_A=False, D_B=False):\n        gen = (not D_A) and (not D_B)\n        requires_grad(self.learn.model.G_A, gen)\n        requires_grad(self.learn.model.G_B, gen)\n        requires_grad(self.learn.model.D_A, D_A)\n        requires_grad(self.learn.model.D_B, D_B)\n        if not gen:",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "convT_norm_relu",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def convT_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    stride: int = 2,\n    bias: bool = True,\n):\n    return [\n        nn.ConvTranspose2d(",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "pad_conv_norm_relu",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def pad_conv_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    pad_mode: str,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    bias: bool = True,\n    pad=1,\n    stride: int = 1,\n    activ: bool = True,",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "resnet_generator",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def resnet_generator(\n    ch_in: int,\n    ch_out: int,\n    n_ftrs: int = 64,\n    norm_layer: nn.Module = None,\n    dropout: float = 0.0,\n    n_blocks: int = 6,\n    pad_mode: str = \"reflection\",\n) -> nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "conv_norm_lr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def conv_norm_lr(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module = None,\n    ks: int = 3,\n    bias: bool = True,\n    pad: int = 1,\n    stride: int = 1,\n    activ: bool = True,\n    slope: float = 0.2,",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "critic",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def critic(\n    ch_in: int,\n    n_ftrs: int = 64,\n    n_layers: int = 3,\n    norm_layer: nn.Module = None,\n    sigmoid: bool = False,\n) -> nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n    bias = norm_layer == nn.InstanceNorm2d\n    layers = conv_norm_lr(ch_in, n_ftrs, ks=4, stride=2, pad=1)",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.cyclegan",
        "description": "DL_Model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "__all__ = [\"CycleGAN\", \"CycleGanLoss\", \"AdaptiveLoss\", \"CycleGANTrainer\"]\ndef convT_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    stride: int = 2,\n    bias: bool = True,\n):\n    return [",
        "detail": "DL_Model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "ImageDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,\n        lls: LabelLists,\n        bs: int = 64,\n        val_bs: int = None,\n        ds_tfms: Optional[TfmList] = None,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ImageList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageList(ItemList):\n    \"`ItemList` suitable for computer vision.\"\n    _bunch, _square_show, _square_show_res = ImageDataBunch, True, True\n    def __init__(\n        self, *args, convert_mode=\"RGB\", after_open: Callable = None, **kwargs\n    ):\n        super().__init__(*args, **kwargs)\n        self.convert_mode, self.after_open = convert_mode, after_open\n        self.copy_new += [\"convert_mode\", \"after_open\"]\n        self.c, self.sizes = 3, {}",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectCategoryProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectCategoryProcessor(MultiCategoryProcessor):\n    \"`PreProcessor` for labelled bounding boxes.\"\n    def __init__(self, ds: ItemList, pad_idx: int = 0):\n        super().__init__(ds)\n        self.pad_idx = pad_idx\n        self.state_attrs.append(\"pad_idx\")\n    def process(self, ds: ItemList):\n        ds.pad_idx = self.pad_idx\n        super().process(ds)\n    def process_one(self, item):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectCategoryList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectCategoryList(MultiCategoryList):\n    \"`ItemList` for labelled bounding boxes.\"\n    _processor = ObjectCategoryProcessor\n    def get(self, i):\n        return ImageBBox.create(\n            *_get_size(self.x, i),\n            *self.items[i],\n            classes=self.classes,\n            pad_idx=self.pad_idx,\n        )",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectItemList(ImageList):\n    \"`ItemList` suitable for object detection.\"\n    _label_cls, _square_show_res = ObjectCategoryList, False\nclass SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds: ItemList):\n        self.classes = ds.classes\n    def process(self, ds: ItemList):\n        ds.classes, ds.c = self.classes, len(self.classes)\nclass SegmentationLabelList(ImageList):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds: ItemList):\n        self.classes = ds.classes\n    def process(self, ds: ItemList):\n        ds.classes, ds.c = self.classes, len(self.classes)\nclass SegmentationLabelList(ImageList):\n    \"`ItemList` for segmentation masks.\"\n    _processor = SegmentationProcessor\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationLabelList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationLabelList(ImageList):\n    \"`ItemList` for segmentation masks.\"\n    _processor = SegmentationProcessor\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\"classes\")\n        self.classes, self.loss_func = classes, CrossEntropyFlat(axis=1)\n    def open(self, fn):\n        return open_mask(fn)\n    def analyze_pred(self, pred, thresh: float = 0.5):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationItemList(ImageList):\n    \"`ItemList` suitable for segmentation tasks.\"\n    _label_cls, _square_show_res = SegmentationLabelList, False\nclass PointsProcessor(PreProcessor):\n    \"`PreProcessor` that stores the number of targets for point regression.\"\n    def __init__(self, ds: ItemList):\n        self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds: ItemList):\n        ds.c = self.c\nclass PointsLabelList(ItemList):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsProcessor(PreProcessor):\n    \"`PreProcessor` that stores the number of targets for point regression.\"\n    def __init__(self, ds: ItemList):\n        self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds: ItemList):\n        ds.c = self.c\nclass PointsLabelList(ItemList):\n    \"`ItemList` for points.\"\n    _processor = PointsProcessor\n    def __init__(self, items: Iterator, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsLabelList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsLabelList(ItemList):\n    \"`ItemList` for points.\"\n    _processor = PointsProcessor\n    def __init__(self, items: Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = MSELossFlat()\n    def get(self, i):\n        o = super().get(i)\n        return ImagePoints(FlowField(_get_size(self.x, i), o), scale=True)\n    def analyze_pred(self, pred, thresh: float = 0.5):",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsItemList(ImageList):\n    \"`ItemList` for `Image` to `ImagePoints` tasks.\"\n    _label_cls, _square_show_res = PointsLabelList, False\nclass ImageImageList(ImageList):\n    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n    _label_cls, _square_show, _square_show_res = ImageList, False, False\n    def show_xys(\n        self,\n        xs,\n        ys,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ImageImageList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageImageList(ImageList):\n    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n    _label_cls, _square_show, _square_show_res = ImageList, False, False\n    def show_xys(\n        self,\n        xs,\n        ys,\n        imgsize: int = 4,\n        figsize: Optional[Tuple[int, int]] = None,\n        **kwargs,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "get_image_files",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def get_image_files(\n    c: PathOrStr, check_ext: bool = True, recurse=False\n) -> FilePathList:\n    \"Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.\"\n    return get_files(\n        c, extensions=(image_extensions if check_ext else None), recurse=recurse\n    )\ndef get_annotations(fname, prefix=None):\n    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n    annot_dict = json.load(open(fname))",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "get_annotations",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def get_annotations(fname, prefix=None):\n    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n    annot_dict = json.load(open(fname))\n    id2images, id2bboxes, id2cats = (\n        {},\n        collections.defaultdict(list),\n        collections.defaultdict(list),\n    )\n    classes = {}\n    for o in annot_dict[\"categories\"]:",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "bb_pad_collate",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def bb_pad_collate(\n    samples: BatchSamples, pad_idx: int = 0\n) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:\n    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n    if isinstance(samples[0][1], int):\n        return data_collate(samples)\n    max_len = max([len(s[1].data[1]) for s in samples])\n    bboxes = torch.zeros(len(samples), max_len, 4)\n    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n    imgs = []",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def normalize(x: TensorImage, mean, std: Tensor) -> TensorImage:\n    \"Normalize `x` with `mean` and `std`.\"\n    return (x - mean[..., None, None]) / std[..., None, None]\ndef denormalize(x: TensorImage, mean, std: Tensor, do_x: bool = True) -> TensorImage:\n    \"Denormalize `x` with `mean` and `std`.\"\n    return (\n        x.cpu().float() * std[..., None, None] + mean[..., None, None]\n        if do_x\n        else x.cpu()\n    )",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "denormalize",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def denormalize(x: TensorImage, mean, std: Tensor, do_x: bool = True) -> TensorImage:\n    \"Denormalize `x` with `mean` and `std`.\"\n    return (\n        x.cpu().float() * std[..., None, None] + mean[..., None, None]\n        if do_x\n        else x.cpu()\n    )\ndef _normalize_batch(\n    b: Tuple[Tensor, Tensor],\n    mean: Tensor,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "normalize_funcs",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def normalize_funcs(\n    mean: Tensor, std: Tensor, do_x: bool = True, do_y: bool = False\n) -> Tuple[Callable, Callable]:\n    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n    mean, std = tensor(mean), tensor(std)\n    return (\n        partial(_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n        partial(denormalize, mean=mean, std=std, do_x=do_x),\n    )\ncifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "channel_view",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,\n        lls: LabelLists,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "download_image",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def download_image(url, dest, timeout=4):\n    try:\n        r = download_url(\n            url, dest, overwrite=True, show_progress=False, timeout=timeout\n        )\n    except Exception as e:\n        print(f\"Error {url} {e}\")\ndef _download_image_inner(dest, url, i, timeout=4):\n    suffix = re.findall(r\"\\.\\w+?(?=(?:\\?|$))\", url)\n    suffix = suffix[0] if len(suffix) > 0 else \".jpg\"",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "download_images",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def download_images(\n    urls: Collection[str],\n    dest: PathOrStr,\n    max_pics: int = 1000,\n    max_workers: int = 8,\n    timeout=4,\n):\n    \"Download images listed in text file `urls` to path `dest`, at most `max_pics`\"\n    urls = open(urls).read().strip().split(\"\\n\")[:max_pics]\n    dest = Path(dest)",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "resize_to",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def resize_to(img, targ_sz: int, use_min: bool = False):\n    \"Size to resize to, to hit `targ_sz` at same aspect ratio, in PIL coords (i.e w*h)\"\n    w, h = img.size\n    min_sz = (min if use_min else max)(w, h)\n    ratio = targ_sz / min_sz\n    return int(w * ratio), int(h * ratio)\ndef verify_image(\n    file: Path,\n    idx: int,\n    delete: bool,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "verify_image",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def verify_image(\n    file: Path,\n    idx: int,\n    delete: bool,\n    max_size: Union[int, Tuple[int, int]] = None,\n    dest: Path = None,\n    n_channels: int = 3,\n    interp=PIL.Image.BILINEAR,\n    ext: str = None,\n    img_format: str = None,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "verify_images",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "def verify_images(\n    path: PathOrStr,\n    delete: bool = True,\n    max_workers: int = 4,\n    max_size: Union[int] = None,\n    recurse: bool = False,\n    dest: PathOrStr = \".\",\n    n_channels: int = 3,\n    interp=PIL.Image.BILINEAR,\n    ext: str = None,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "__all__ = [\n    \"get_image_files\",\n    \"denormalize\",\n    \"get_annotations\",\n    \"ImageDataBunch\",\n    \"ImageList\",\n    \"normalize\",\n    \"normalize_funcs\",\n    \"resize_to\",\n    \"channel_view\",",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "image_extensions",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "image_extensions = set(\n    k for k, v in mimetypes.types_map.items() if v.startswith(\"image/\")\n)\ndef get_image_files(\n    c: PathOrStr, check_ext: bool = True, recurse=False\n) -> FilePathList:\n    \"Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.\"\n    return get_files(\n        c, extensions=(image_extensions if check_ext else None), recurse=recurse\n    )",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "cifar_stats",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "cifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nimagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "imagenet_stats",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nimagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "imagenet_stats_inception",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "imagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "mnist_stats",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "mnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "LabelLists.pre_transform",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "LabelLists.pre_transform = _ll_pre_transform\nDataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "DataBunch.pre_transform",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "DataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "LabelLists.presize",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "LabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "DataBunch.presize",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.data",
        "description": "DL_Model.deoldify.fastai.vision.data",
        "peekOfCode": "DataBunch.presize = _presize",
        "detail": "DL_Model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "GANModule",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANModule(Module):\n    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n    def __init__(\n        self,\n        generator: nn.Module = None,\n        critic: nn.Module = None,\n        gen_mode: bool = False,\n    ):\n        self.gen_mode = gen_mode\n        if generator:",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANLoss(GANModule):\n    \"Wrapper around `loss_funcC` (for the critic) and `loss_funcG` (for the generator).\"\n    def __init__(\n        self, loss_funcG: Callable, loss_funcC: Callable, gan_model: GANModule\n    ):\n        super().__init__()\n        self.loss_funcG, self.loss_funcC, self.gan_model = (\n            loss_funcG,\n            loss_funcC,\n            gan_model,",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANTrainer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANTrainer(LearnerCallback):\n    \"Handles GAN Training.\"\n    _order = -20\n    def __init__(\n        self,\n        learn: Learner,\n        switch_eval: bool = False,\n        clip: float = None,\n        beta: float = 0.98,\n        gen_first: bool = False,",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "FixedGANSwitcher",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class FixedGANSwitcher(LearnerCallback):\n    \"Switcher to do `n_crit` iterations of the critic then `n_gen` iterations of the generator.\"\n    def __init__(\n        self,\n        learn: Learner,\n        n_crit: Union[int, Callable] = 1,\n        n_gen: Union[int, Callable] = 1,\n    ):\n        super().__init__(learn)\n        self.n_crit, self.n_gen = n_crit, n_gen",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AdaptiveGANSwitcher",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class AdaptiveGANSwitcher(LearnerCallback):\n    \"Switcher that goes back to generator/critic when the loss goes below `gen_thresh`/`crit_thresh`.\"\n    def __init__(\n        self, learn: Learner, gen_thresh: float = None, critic_thresh: float = None\n    ):\n        super().__init__(learn)\n        self.gen_thresh, self.critic_thresh = gen_thresh, critic_thresh\n    def on_batch_end(self, last_loss, **kwargs):\n        \"Switch the model if necessary.\"\n        if self.gan_trainer.gen_mode:",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANLearner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANLearner(Learner):\n    \"A `Learner` suitable for GANs.\"\n    def __init__(\n        self,\n        data: DataBunch,\n        generator: nn.Module,\n        critic: nn.Module,\n        gen_loss_func: LossFunction,\n        crit_loss_func: LossFunction,\n        switcher: Callback = None,",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "NoisyItem",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class NoisyItem(ItemBase):\n    \"An random `ItemBase` of size `noise_sz`.\"\n    def __init__(self, noise_sz):\n        self.obj, self.data = noise_sz, torch.randn(noise_sz, 1, 1)\n    def __str__(self):\n        return \"\"\n    def apply_tfms(self, tfms, **kwargs):\n        return self\nclass GANItemList(ImageList):\n    \"`ItemList` suitable for GANs.\"",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANItemList(ImageList):\n    \"`ItemList` suitable for GANs.\"\n    _label_cls = ImageList\n    def __init__(self, items, noise_sz: int = 100, **kwargs):\n        super().__init__(items, **kwargs)\n        self.noise_sz = noise_sz\n        self.copy_new.append(\"noise_sz\")\n    def get(self, i):\n        return NoisyItem(self.noise_sz)\n    def reconstruct(self, t):",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANDiscriminativeLR",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANDiscriminativeLR(LearnerCallback):\n    \"`Callback` that handles multiplying the learning rate by `mult_lr` for the critic.\"\n    def __init__(self, learn: Learner, mult_lr: float = 5.0):\n        super().__init__(learn)\n        self.mult_lr = mult_lr\n    def on_batch_begin(self, train, **kwargs):\n        \"Multiply the current lr if necessary.\"\n        if not self.learn.gan_trainer.gen_mode and train:\n            self.learn.opt.lr *= self.mult_lr\n    def on_step_end(self, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AdaptiveLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "class AdaptiveLoss(Module):\n    \"Expand the `target` to match the `output` size before applying `crit`.\"\n    def __init__(self, crit):\n        self.crit = crit\n    def forward(self, output, target):\n        return self.crit(output, target[:, None].expand_as(output).float())\ndef accuracy_thresh_expand(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AvgFlatten",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def AvgFlatten():\n    \"Takes the average of the input.\"\n    return Lambda(lambda x: x.mean(0).view(1))\ndef basic_critic(\n    in_size: int,\n    n_channels: int,\n    n_features: int = 64,\n    n_extra_layers: int = 0,\n    **conv_kwargs,\n):",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "basic_critic",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def basic_critic(\n    in_size: int,\n    n_channels: int,\n    n_features: int = 64,\n    n_extra_layers: int = 0,\n    **conv_kwargs,\n):\n    \"A basic critic for images `n_channels` x `in_size` x `in_size`.\"\n    layers = [\n        conv_layer(",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "basic_generator",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def basic_generator(\n    in_size: int,\n    n_channels: int,\n    noise_sz: int = 100,\n    n_features: int = 64,\n    n_extra_layers=0,\n    **conv_kwargs,\n):\n    \"A basic generator from `noise_sz` to images `n_channels` x `in_size` x `in_size`.\"\n    cur_size, cur_ftrs = 4, n_features // 2",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "gan_loss_from_func",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def gan_loss_from_func(loss_gen, loss_crit, weights_gen: Tuple[float, float] = None):\n    \"Define loss functions for a GAN from `loss_gen` and `loss_crit`.\"\n    def _loss_G(fake_pred, output, target, weights_gen=weights_gen):\n        ones = fake_pred.new_ones(fake_pred.shape[0])\n        weights_gen = ifnone(weights_gen, (1.0, 1.0))\n        return weights_gen[0] * loss_crit(fake_pred, ones) + weights_gen[1] * loss_gen(\n            output, target\n        )\n    def _loss_C(real_pred, fake_pred):\n        ones = real_pred.new_ones(real_pred.shape[0])",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "gan_critic",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def gan_critic(n_channels: int = 3, nf: int = 128, n_blocks: int = 3, p: int = 0.15):\n    \"Critic to train a `GAN`.\"\n    layers = [\n        _conv(n_channels, nf, ks=4, stride=2),\n        nn.Dropout2d(p / 2),\n        res_block(nf, dense=True, **_conv_args),\n    ]\n    nf *= 2  # after dense block\n    for i in range(n_blocks):\n        layers += [",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "accuracy_thresh_expand",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "def accuracy_thresh_expand(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"\n    if sigmoid:\n        y_pred = y_pred.sigmoid()\n    return (\n        ((y_pred > thresh) == y_true[:, None].expand_as(y_pred).byte()).float().mean()\n    )",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "__all__ = [\n    \"basic_critic\",\n    \"basic_generator\",\n    \"GANModule\",\n    \"GANLoss\",\n    \"GANTrainer\",\n    \"FixedGANSwitcher\",\n    \"AdaptiveGANSwitcher\",\n    \"GANLearner\",\n    \"NoisyItem\",",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "_conv_args",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.gan",
        "description": "DL_Model.deoldify.fastai.vision.gan",
        "peekOfCode": "_conv_args = dict(leaky=0.2, norm_type=NormType.Spectral)\ndef _conv(ni: int, nf: int, ks: int = 3, stride: int = 1, **kwargs):\n    return conv_layer(ni, nf, ks=ks, stride=stride, **_conv_args, **kwargs)\ndef gan_critic(n_channels: int = 3, nf: int = 128, n_blocks: int = 3, p: int = 0.15):\n    \"Critic to train a `GAN`.\"\n    layers = [\n        _conv(n_channels, nf, ks=4, stride=2),\n        nn.Dropout2d(p / 2),\n        res_block(nf, dense=True, **_conv_args),\n    ]",
        "detail": "DL_Model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "FlowField",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class FlowField:\n    \"Wrap together some coords `flow` with a `size`.\"\n    size: Tuple[int, int]\n    flow: Tensor\nCoordFunc = Callable[[FlowField, ArgStar, KWArgs], LogitTensorImage]\nclass Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "Image",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None\n        self._flow = None\n        self._affine_mat = None\n        self.sample_kwargs = {}\n    def set_sample(self, **kwargs) -> \"ImageBase\":\n        \"Set parameters that control how we `grid_sample` the image after transforms are applied.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImageSegment",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImageSegment(Image):\n    \"Support applying transforms to segmentation masks data in `px`.\"\n    def lighting(self, func: LightingFunc, *args: Any, **kwargs: Any) -> \"Image\":\n        return self\n    def refresh(self):\n        self.sample_kwargs[\"mode\"] = \"nearest\"\n        return super().refresh()\n    @property\n    def data(self) -> TensorImage:\n        \"Return this image pixels as a `LongTensor`.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImagePoints",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImagePoints(Image):\n    \"Support applying transforms to a `flow` of points.\"\n    def __init__(self, flow: FlowField, scale: bool = True, y_first: bool = True):\n        if scale:\n            flow = scale_flow(flow)\n        if y_first:\n            flow.flow = flow.flow.flip(1)\n        self._flow = flow\n        self._affine_mat = None\n        self.flow_func = []",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImageBBox",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImageBBox(ImagePoints):\n    \"Support applying transforms to a `flow` of bounding boxes.\"\n    def __init__(\n        self,\n        flow: FlowField,\n        scale: bool = True,\n        y_first: bool = True,\n        labels: Collection = None,\n        classes: dict = None,\n        pad_idx: int = 0,",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "Transform",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class Transform:\n    \"Utility class for adding probability and wrapping support to transform `func`.\"\n    _wrap = None\n    order = 0\n    def __init__(self, func: Callable, order: Optional[int] = None):\n        \"Create a transform for `func` and assign it an priority `order`, attach to `Image` class.\"\n        if order is not None:\n            self.order = order\n        self.func = func\n        self.func.__name__ = func.__name__[",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "RandTransform",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class RandTransform:\n    \"Wrap `Transform` to add randomized execution.\"\n    tfm: Transform\n    kwargs: dict\n    p: float = 1.0\n    resolved: dict = field(default_factory=dict)\n    do_run: bool = True\n    is_random: bool = True\n    use_on_y: bool = True\n    def __post_init__(self):",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmAffine",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmAffine(Transform):\n    \"Decorator for affine tfm funcs.\"\n    order, _wrap = 5, \"affine\"\nclass TfmPixel(Transform):\n    \"Decorator for pixel tfm funcs.\"\n    order, _wrap = 10, \"pixel\"\nclass TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmPixel",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmPixel(Transform):\n    \"Decorator for pixel tfm funcs.\"\n    order, _wrap = 10, \"pixel\"\nclass TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmCoord",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmCrop",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:\n    \"Calc `x` to nearest multiple of `mult`.\"\n    return (int(x / mult + 0.5) * mult) if mult is not None else x\ndef _get_crop_target(",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmLighting",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:\n    \"Calc `x` to nearest multiple of `mult`.\"\n    return (int(x / mult + 0.5) * mult) if mult is not None else x\ndef _get_crop_target(\n    target_px: Union[int, TensorImageSize], mult: int = None\n) -> Tuple[int, int]:\n    \"Calc crop shape of `target_px` to nearest multiple of `mult`.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "pil2tensor",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def pil2tensor(image: Union[NPImage, NPArray], dtype: np.dtype) -> TensorImage:\n    \"Convert PIL style `image` array to torch style image tensor.\"\n    a = np.asarray(image)\n    if a.ndim == 2:\n        a = np.expand_dims(a, 2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False))\ndef image2np(image: Tensor) -> np.ndarray:\n    \"Convert from torch style `image` to numpy/matplotlib style.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "image2np",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def image2np(image: Tensor) -> np.ndarray:\n    \"Convert from torch style `image` to numpy/matplotlib style.\"\n    res = image.cpu().permute(1, 2, 0).numpy()\n    return res[..., 0] if res.shape[2] == 1 else res\ndef bb2hw(a: Collection[int]) -> np.ndarray:\n    \"Convert bounding box points from (width,height,center) to (height,width,top,left).\"\n    return np.array([a[1], a[0], a[3] - a[1], a[2] - a[0]])\ndef tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "bb2hw",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def bb2hw(a: Collection[int]) -> np.ndarray:\n    \"Convert bounding box points from (width,height,center) to (height,width,top,left).\"\n    return np.array([a[1], a[0], a[3] - a[1], a[2] - a[0]])\ndef tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:\n        raise RuntimeError(\"Expected size to be an int or a tuple, got a string.\")\n    return listify(size, 2) if isinstance(size, int) else listify(size[-2:], 2)\ndef _draw_outline(o: Patch, lw: int):\n    \"Outline bounding box onto image `Patch`.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "tis2hw",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:\n        raise RuntimeError(\"Expected size to be an int or a tuple, got a string.\")\n    return listify(size, 2) if isinstance(size, int) else listify(size[-2:], 2)\ndef _draw_outline(o: Patch, lw: int):\n    \"Outline bounding box onto image `Patch`.\"\n    o.set_path_effects(\n        [patheffects.Stroke(linewidth=lw, foreground=\"black\"), patheffects.Normal()]\n    )",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_image",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_image(\n    fn: PathOrStr,\n    div: bool = True,\n    convert_mode: str = \"RGB\",\n    cls: type = Image,\n    after_open: Callable = None,\n) -> Image:\n    \"Return `Image` object created from image in file `fn`.\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)  # EXIF warning from TiffPlugin",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_mask",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_mask(\n    fn: PathOrStr, div=False, convert_mode=\"L\", after_open: Callable = None\n) -> ImageSegment:\n    \"Return `ImageSegment` object create from mask in file `fn`. If `div`, divides pixel values by 255.\"\n    return open_image(\n        fn, div=div, convert_mode=convert_mode, cls=ImageSegment, after_open=after_open\n    )\ndef open_mask_rle(mask_rle: str, shape: Tuple[int, int]) -> ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_mask_rle",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_mask_rle(mask_rle: str, shape: Tuple[int, int]) -> ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(shape[1], shape[0], -1)\n    return ImageSegment(x.permute(2, 0, 1))\ndef rle_encode(img: NPArrayMask) -> str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(), [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "rle_encode",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def rle_encode(img: NPArrayMask) -> str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(), [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(str(x) for x in runs)\ndef rle_decode(mask_rle: str, shape: Tuple[int, int]) -> NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "rle_decode",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def rle_decode(mask_rle: str, shape: Tuple[int, int]) -> NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n    for low, up in zip(starts, ends):\n        img[low:up] = 1\n    return img.reshape(shape)",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_image",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_image(\n    img: Image,\n    ax: plt.Axes = None,\n    figsize: tuple = (3, 3),\n    hide_axis: bool = True,\n    cmap: str = \"binary\",\n    alpha: float = None,\n    **kwargs,\n) -> plt.Axes:\n    \"Display `Image` in notebook.\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "scale_flow",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def scale_flow(flow, to_unit=True):\n    \"Scale the coords in `flow` to -1/1 or the image size depending on `to_unit`.\"\n    s = tensor([flow.size[0] / 2, flow.size[1] / 2])[None]\n    if to_unit:\n        flow.flow = flow.flow / s - 1\n    else:\n        flow.flow = (flow.flow + 1) * s\n    return flow\ndef _remove_points_out(flow: FlowField):\n    pad_mask = (",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "plot_flat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def plot_flat(r, c, figsize):\n    \"Shortcut for `enumerate(subplots.flatten())`\"\n    return enumerate(plt.subplots(r, c, figsize=figsize)[1].flatten())\ndef plot_multi(\n    func: Callable[[int, int, plt.Axes], None],\n    r: int = 1,\n    c: int = 1,\n    figsize: Tuple = (12, 6),\n):\n    \"Call `func` for every combination of `r,c` on a subplot\"",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "plot_multi",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def plot_multi(\n    func: Callable[[int, int, plt.Axes], None],\n    r: int = 1,\n    c: int = 1,\n    figsize: Tuple = (12, 6),\n):\n    \"Call `func` for every combination of `r,c` on a subplot\"\n    axes = plt.subplots(r, c, figsize=figsize)[1]\n    for i in range(r):\n        for j in range(c):",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_multi",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_multi(\n    func: Callable[[int, int], Image], r: int = 1, c: int = 1, figsize: Tuple = (9, 9)\n):\n    \"Call `func(i,j).show(ax)` for every combination of `r,c`\"\n    plot_multi(lambda i, j, ax: func(i, j).show(ax), r, c, figsize=figsize)\ndef show_all(\n    imgs: Collection[Image], r: int = 1, c: Optional[int] = None, figsize=(12, 6)\n):\n    \"Show all `imgs` using `r` rows\"\n    imgs = listify(imgs)",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_all",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_all(\n    imgs: Collection[Image], r: int = 1, c: Optional[int] = None, figsize=(12, 6)\n):\n    \"Show all `imgs` using `r` rows\"\n    imgs = listify(imgs)\n    if c is None:\n        c = len(imgs) // r\n    for i, ax in plot_flat(r, c, figsize):\n        imgs[i].show(ax)",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "__all__ = [\n    \"PIL\",\n    \"Image\",\n    \"ImageBBox\",\n    \"ImageSegment\",\n    \"ImagePoints\",\n    \"FlowField\",\n    \"RandTransform\",\n    \"TfmAffine\",\n    \"TfmCoord\",",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ResizeMethod",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "ResizeMethod = IntEnum(\"ResizeMethod\", \"CROP PAD SQUISH NO\")\ndef pil2tensor(image: Union[NPImage, NPArray], dtype: np.dtype) -> TensorImage:\n    \"Convert PIL style `image` array to torch style image tensor.\"\n    a = np.asarray(image)\n    if a.ndim == 2:\n        a = np.expand_dims(a, 2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False))\ndef image2np(image: Tensor) -> np.ndarray:",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "CoordFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.image",
        "description": "DL_Model.deoldify.fastai.vision.image",
        "peekOfCode": "CoordFunc = Callable[[FlowField, ArgStar, KWArgs], LogitTensorImage]\nclass Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None\n        self._flow = None\n        self._affine_mat = None\n        self.sample_kwargs = {}\n    def set_sample(self, **kwargs) -> \"ImageBase\":",
        "detail": "DL_Model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "SegmentationInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.interpret",
        "description": "DL_Model.deoldify.fastai.vision.interpret",
        "peekOfCode": "class SegmentationInterpretation(Interpretation):\n    \"Interpretation methods for segmenatation models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "DL_Model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "ObjectDetectionInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.vision.interpret",
        "description": "DL_Model.deoldify.fastai.vision.interpret",
        "peekOfCode": "class ObjectDetectionInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "DL_Model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.interpret",
        "description": "DL_Model.deoldify.fastai.vision.interpret",
        "peekOfCode": "__all__ = [\"SegmentationInterpretation\", \"ObjectDetectionInterpretation\"]\nclass SegmentationInterpretation(Interpretation):\n    \"Interpretation methods for segmenatation models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,",
        "detail": "DL_Model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "cnn_config",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def cnn_config(arch):\n    \"Get the metadata associated with `arch`.\"\n    # torch.backends.cudnn.benchmark = True\n    return model_meta.get(arch, _default_meta)\ndef has_pool_type(m):\n    if is_pool_type(m):\n        return True\n    for l in m.children():\n        if has_pool_type(l):\n            return True",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "has_pool_type",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def has_pool_type(m):\n    if is_pool_type(m):\n        return True\n    for l in m.children():\n        if has_pool_type(l):\n            return True\n    return False\ndef create_body(\n    arch: Callable, pretrained: bool = True, cut: Optional[Union[int, Callable]] = None\n):",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_body",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_body(\n    arch: Callable, pretrained: bool = True, cut: Optional[Union[int, Callable]] = None\n):\n    \"Cut off the body of a typically pretrained `model` at `cut` (int) or cut the model as specified by `cut(model)` (function).\"\n    model = arch(pretrained=pretrained)\n    cut = ifnone(cut, cnn_config(arch)[\"cut\"])\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int):",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_head",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_head(\n    nf: int,\n    nc: int,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    concat_pool: bool = True,\n    bn_final: bool = False,\n):\n    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_cnn_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_cnn_model(\n    base_arch: Callable,\n    nc: int,\n    cut: Union[int, Callable] = None,\n    pretrained: bool = True,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    custom_head: Optional[nn.Module] = None,\n    bn_final: bool = False,\n    concat_pool: bool = True,",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "cnn_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def cnn_learner(\n    data: DataBunch,\n    base_arch: Callable,\n    cut: Union[int, Callable] = None,\n    pretrained: bool = True,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    custom_head: Optional[nn.Module] = None,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    bn_final: bool = False,",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_cnn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_cnn(data, base_arch, **kwargs):\n    warn(\"`create_cnn` is deprecated and is now named `cnn_learner`.\")\n    return cnn_learner(data, base_arch, **kwargs)\ndef unet_learner(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "unet_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "def unet_learner(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "__all__ = [\n    \"cnn_learner\",\n    \"create_cnn\",\n    \"create_cnn_model\",\n    \"create_body\",\n    \"create_head\",\n    \"unet_learner\",\n]\n# By default split models between first and second layer\ndef _default_split(m: nn.Module):",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_default_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_default_meta = {\"cut\": None, \"split\": _default_split}\n_resnet_meta = {\"cut\": -2, \"split\": _resnet_split}\n_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_resnet_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_resnet_meta = {\"cut\": -2, \"split\": _resnet_split}\n_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_squeezenet_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_densenet_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_vgg_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_alexnet_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},\n    models.densenet121: {**_densenet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "model_meta",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "model_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},\n    models.densenet121: {**_densenet_meta},\n    models.densenet169: {**_densenet_meta},",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.GradCAM",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.GradCAM = _cl_int_gradcam\ndef _cl_int_plot_top_losses(\n    self,\n    k,\n    largest=True,\n    figsize=(12, 12),\n    heatmap: bool = False,\n    heatmap_thresh: int = 16,\n    return_fig: bool = None,\n) -> Optional[plt.Figure]:",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.from_learner",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.from_learner = _cl_int_from_learner\nClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\nClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_top_losses",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\nClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_multi_top_losses",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.learner",
        "description": "DL_Model.deoldify.fastai.vision.learner",
        "peekOfCode": "Learner.interpret = _learner_interpret",
        "detail": "DL_Model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "rand_pad",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_zoom",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_crop",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad\n    return [zoom_fn(scale=scale, p=p), crop_fn()]\ndef _find_coeffs(orig_pts: Points, targ_pts: Points) -> Tensor:\n    \"Find 8 coeff mentioned [here](https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/).\"",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom_crop",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad\n    return [zoom_fn(scale=scale, p=p), crop_fn()]\ndef _find_coeffs(orig_pts: Points, targ_pts: Points) -> Tensor:\n    \"Find 8 coeff mentioned [here](https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/).\"\n    matrix = []\n    # The equations we'll need to solve.\n    for p1, p2 in zip(targ_pts, orig_pts):",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "get_transforms",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def get_transforms(\n    do_flip: bool = True,\n    flip_vert: bool = False,\n    max_rotate: float = 10.0,\n    max_zoom: float = 1.1,\n    max_lighting: float = 0.2,\n    max_warp: float = 0.2,\n    p_affine: float = 0.75,\n    p_lighting: float = 0.75,\n    xtra_tfms: Optional[Collection[Transform]] = None,",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_resize_crop",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_resize_crop(\n    size: int, max_scale: float = 2.0, ratios: Tuple[float, float] = (0.75, 1.33)\n):\n    \"Randomly resize and crop the image to a ratio in `ratios` after a zoom of `max_scale`.\"\n    return [\n        zoom_squish(\n            scale=(1.0, max_scale, 8),\n            squish=(*ratios, 8),\n            invert=(0.5, 8),\n            row_pct=(0.0, 1.0),",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "__all__ = [\n    \"brightness\",\n    \"contrast\",\n    \"crop\",\n    \"crop_pad\",\n    \"cutout\",\n    \"dihedral\",\n    \"dihedral_affine\",\n    \"flip_affine\",\n    \"flip_lr\",",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "_pad_mode_convert",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "_pad_mode_convert = {\n    \"reflection\": \"reflect\",\n    \"zeros\": \"constant\",\n    \"border\": \"replicate\",\n}\n# NB: Although TfmLighting etc can be used as decorators, that doesn't work in Windows,\n#    so we do it manually for now.\ndef _brightness(x, change: uniform):\n    \"Apply `change` in brightness of image `x`.\"\n    return x.add_(scipy.special.logit(change))",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "brightness",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "brightness = TfmLighting(_brightness)\ndef _contrast(x, scale: log_uniform):\n    \"Apply `scale` to contrast of image `x`.\"\n    return x.mul_(scale)\ncontrast = TfmLighting(_contrast)\ndef _rotate(degrees: uniform):\n    \"Rotate image by `degrees`.\"\n    angle = degrees * math.pi / 180\n    return [\n        [float(cos(angle)), float(-sin(angle)), 0.0],",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "contrast",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "contrast = TfmLighting(_contrast)\ndef _rotate(degrees: uniform):\n    \"Rotate image by `degrees`.\"\n    angle = degrees * math.pi / 180\n    return [\n        [float(cos(angle)), float(-sin(angle)), 0.0],\n        [float(sin(angle)), float(cos(angle)), 0.0],\n        [0.0, 0.0, 1.0],\n    ]\nrotate = TfmAffine(_rotate)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rotate",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "rotate = TfmAffine(_rotate)\ndef _get_zoom_mat(sw: float, sh: float, c: float, r: float) -> AffineMatrix:\n    \"`sw`,`sh` scale width,height - `c`,`r` focus col,row.\"\n    return [[sw, 0, c], [0, sh, r], [0, 0, 1.0]]\ndef _zoom(scale: uniform = 1.0, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Zoom image by `scale`. `row_pct`,`col_pct` select focal point of zoom.\"\n    s = 1 - 1 / scale\n    col_c = s * (2 * col_pct - 1)\n    row_c = s * (2 * row_pct - 1)\n    return _get_zoom_mat(1 / scale, 1 / scale, col_c, row_c)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "zoom = TfmAffine(_zoom)\ndef _squish(scale: uniform = 1.0, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Squish image by `scale`. `row_pct`,`col_pct` select focal point of zoom.\"\n    if scale <= 1:\n        col_c = (1 - scale) * (2 * col_pct - 1)\n        return _get_zoom_mat(scale, 1, col_c, 0.0)\n    else:\n        row_c = (1 - 1 / scale) * (2 * row_pct - 1)\n        return _get_zoom_mat(1, 1 / scale, 0.0, row_c)\nsquish = TfmAffine(_squish)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "squish",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "squish = TfmAffine(_squish)\ndef _jitter(c, magnitude: uniform):\n    \"Replace pixels by random neighbors at `magnitude`.\"\n    c.flow.add_((torch.rand_like(c.flow) - 0.5) * magnitude * 2)\n    return c\njitter = TfmCoord(_jitter)\ndef _flip_lr(x):\n    \"Flip `x` horizontally.\"\n    # return x.flip(2)\n    if isinstance(x, ImagePoints):",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "jitter",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "jitter = TfmCoord(_jitter)\ndef _flip_lr(x):\n    \"Flip `x` horizontally.\"\n    # return x.flip(2)\n    if isinstance(x, ImagePoints):\n        x.flow.flow[..., 0] *= -1\n        return x\n    return tensor(np.ascontiguousarray(np.array(x)[..., ::-1]))\nflip_lr = TfmPixel(_flip_lr)\ndef _flip_affine() -> TfmAffine:",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "flip_lr",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "flip_lr = TfmPixel(_flip_lr)\ndef _flip_affine() -> TfmAffine:\n    \"Flip `x` horizontally.\"\n    return [[-1, 0, 0.0], [0, 1, 0], [0, 0, 1.0]]\nflip_affine = TfmAffine(_flip_affine)\ndef _dihedral(x, k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    flips = []\n    if k & 1:\n        flips.append(1)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "flip_affine",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "flip_affine = TfmAffine(_flip_affine)\ndef _dihedral(x, k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    flips = []\n    if k & 1:\n        flips.append(1)\n    if k & 2:\n        flips.append(2)\n    if flips:\n        x = torch.flip(x, flips)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "dihedral",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "dihedral = TfmPixel(_dihedral)\ndef _dihedral_affine(k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    x = -1 if k & 1 else 1\n    y = -1 if k & 2 else 1\n    if k & 4:\n        return [[0, x, 0.0], [y, 0, 0], [0, 0, 1.0]]\n    return [[x, 0, 0.0], [0, y, 0], [0, 0, 1.0]]\ndihedral_affine = TfmAffine(_dihedral_affine)\ndef _pad_coord(x, row_pad: int, col_pad: int, mode=\"zeros\"):",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "dihedral_affine",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "dihedral_affine = TfmAffine(_dihedral_affine)\ndef _pad_coord(x, row_pad: int, col_pad: int, mode=\"zeros\"):\n    # TODO: implement other padding modes than zeros?\n    h, w = x.size\n    pad = torch.Tensor([w / (w + 2 * col_pad), h / (h + 2 * row_pad)])\n    x.flow = FlowField((h + 2 * row_pad, w + 2 * col_pad), x.flow.flow * pad[None])\n    return x\ndef _pad_default(x, padding: int, mode=\"reflection\"):\n    \"Pad `x` with `padding` pixels. `mode` fills in space ('zeros','reflection','border').\"\n    mode = _pad_mode_convert[mode]",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "pad",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "pad = TfmPixel(_pad, order=-10)\ndef _cutout(x, n_holes: uniform_int = 1, length: uniform_int = 40):\n    \"Cut out `n_holes` number of square holes of size `length` in image at random locations.\"\n    h, w = x.shape[1:]\n    for n in range(n_holes):\n        h_y = np.random.randint(0, h)\n        h_x = np.random.randint(0, w)\n        y1 = int(np.clip(h_y - length / 2, 0, h))\n        y2 = int(np.clip(h_y + length / 2, 0, h))\n        x1 = int(np.clip(h_x - length / 2, 0, w))",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "cutout",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "cutout = TfmPixel(_cutout, order=20)\ndef _rgb_randomize(x, channel: int = None, thresh: float = 0.3):\n    \"Randomize one of the channels of the input image\"\n    if channel is None:\n        channel = np.random.randint(0, x.shape[0] - 1)\n    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n    return x\nrgb_randomize = TfmPixel(_rgb_randomize)\ndef _minus_epsilon(row_pct: float, col_pct: float, eps: float = 1e-7):\n    if row_pct == 1.0:",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rgb_randomize",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "rgb_randomize = TfmPixel(_rgb_randomize)\ndef _minus_epsilon(row_pct: float, col_pct: float, eps: float = 1e-7):\n    if row_pct == 1.0:\n        row_pct -= 1e-7\n    if col_pct == 1.0:\n        col_pct -= 1e-7\n    return row_pct, col_pct\ndef _crop_default(x, size, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Crop `x` to `size` pixels. `row_pct`,`col_pct` select focal point of crop.\"\n    rows, cols = tis2hw(size)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "crop",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "crop = TfmPixel(_crop)\ndef _crop_pad_default(\n    x, size, padding_mode=\"reflection\", row_pct: uniform = 0.5, col_pct: uniform = 0.5\n):\n    \"Crop and pad tfm - `row_pct`,`col_pct` sets focal point.\"\n    padding_mode = _pad_mode_convert[padding_mode]\n    size = tis2hw(size)\n    if x.shape[1:] == torch.Size(size):\n        return x\n    rows, cols = size",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "crop_pad",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "crop_pad = TfmCrop(_crop_pad)\ndef _image_maybe_add_crop_pad(img, tfms):\n    tfm_names = [tfm.__name__ for tfm in tfms]\n    return [crop_pad()] + tfms if \"crop_pad\" not in tfm_names else tfms\nImage._maybe_add_crop_pad = _image_maybe_add_crop_pad\nrand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "Image._maybe_add_crop_pad",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "Image._maybe_add_crop_pad = _image_maybe_add_crop_pad\nrand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_pos",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "rand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "_orig_pts",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "_orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\ndef _do_perspective_warp(c: FlowField, targ_pts: Points, invert=False):\n    \"Apply warp to `targ_pts` from `_orig_pts` to `c` `FlowField`.\"\n    if invert:\n        return _apply_perspective(c, _find_coeffs(targ_pts, _orig_pts))\n    return _apply_perspective(c, _find_coeffs(_orig_pts, targ_pts))\ndef _perspective_warp(c, magnitude: partial(uniform, size=8) = 0, invert=False):\n    \"Apply warp of `magnitude` to `c`.\"\n    magnitude = magnitude.view(4, 2)\n    targ_pts = [[x + m for x, m in zip(xs, ms)] for xs, ms in zip(_orig_pts, magnitude)]",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "perspective_warp",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "perspective_warp = TfmCoord(_perspective_warp)\ndef _symmetric_warp(c, magnitude: partial(uniform, size=4) = 0, invert=False):\n    \"Apply symmetric warp of `magnitude` to `c`.\"\n    m = listify(magnitude, 4)\n    targ_pts = [\n        [-1 - m[3], -1 - m[1]],\n        [-1 - m[2], 1 + m[1]],\n        [1 + m[3], -1 - m[0]],\n        [1 + m[2], 1 + m[0]],\n    ]",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "symmetric_warp",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "symmetric_warp = TfmCoord(_symmetric_warp)\ndef _tilt(c, direction: uniform_int, magnitude: uniform = 0, invert=False):\n    \"Tilt `c` field with random `direction` and `magnitude`.\"\n    orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n    if direction == 0:\n        targ_pts = [[-1, -1], [-1, 1], [1, -1 - magnitude], [1, 1 + magnitude]]\n    elif direction == 1:\n        targ_pts = [[-1, -1 - magnitude], [-1, 1 + magnitude], [1, -1], [1, 1]]\n    elif direction == 2:\n        targ_pts = [[-1, -1], [-1 - magnitude, 1], [1, -1], [1 + magnitude, 1]]",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "tilt",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "tilt = TfmCoord(_tilt)\ndef _skew(c, direction: uniform_int, magnitude: uniform = 0, invert=False):\n    \"Skew `c` field with random `direction` and `magnitude`.\"\n    orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n    if direction == 0:\n        targ_pts = [[-1 - magnitude, -1], [-1, 1], [1, -1], [1, 1]]\n    elif direction == 1:\n        targ_pts = [[-1, -1 - magnitude], [-1, 1], [1, -1], [1, 1]]\n    elif direction == 2:\n        targ_pts = [[-1, -1], [-1 - magnitude, 1], [1, -1], [1, 1]]",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "skew",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "skew = TfmCoord(_skew)\ndef get_transforms(\n    do_flip: bool = True,\n    flip_vert: bool = False,\n    max_rotate: float = 10.0,\n    max_zoom: float = 1.1,\n    max_lighting: float = 0.2,\n    max_warp: float = 0.2,\n    p_affine: float = 0.75,\n    p_lighting: float = 0.75,",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom_squish",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.transform",
        "description": "DL_Model.deoldify.fastai.vision.transform",
        "peekOfCode": "zoom_squish = TfmCoord(_zoom_squish)\ndef rand_resize_crop(\n    size: int, max_scale: float = 2.0, ratios: Tuple[float, float] = (0.75, 1.33)\n):\n    \"Randomly resize and crop the image to a ratio in `ratios` after a zoom of `max_scale`.\"\n    return [\n        zoom_squish(\n            scale=(1.0, max_scale, 8),\n            squish=(*ratios, 8),\n            invert=(0.5, 8),",
        "detail": "DL_Model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.tta",
        "description": "DL_Model.deoldify.fastai.vision.tta",
        "peekOfCode": "__all__ = []\ndef _tta_only(\n    learn: Learner,\n    ds_type: DatasetType = DatasetType.Valid,\n    activ: nn.Module = None,\n    scale: float = 1.35,\n) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset",
        "detail": "DL_Model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "Learner.tta_only",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.tta",
        "description": "DL_Model.deoldify.fastai.vision.tta",
        "peekOfCode": "Learner.tta_only = _tta_only\ndef _TTA(\n    learn: Learner,\n    beta: float = 0.4,\n    scale: float = 1.35,\n    ds_type: DatasetType = DatasetType.Valid,\n    activ: nn.Module = None,\n    with_loss: bool = False,\n) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"",
        "detail": "DL_Model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "Learner.TTA",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.vision.tta",
        "description": "DL_Model.deoldify.fastai.vision.tta",
        "peekOfCode": "Learner.TTA = _TTA",
        "detail": "DL_Model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "ClassConfusion",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.widgets.class_confusion",
        "description": "DL_Model.deoldify.fastai.widgets.class_confusion",
        "peekOfCode": "class ClassConfusion:\n    \"Plot the most confused datapoints and statistics for the models misses.\"\n    def __init__(\n        self,\n        interp: ClassificationInterpretation,\n        classlist: list,\n        is_ordered: bool = False,\n        cut_off: int = 100,\n        varlist: list = None,\n        figsize: tuple = (8, 8),",
        "detail": "DL_Model.deoldify.fastai.widgets.class_confusion",
        "documentation": {}
    },
    {
        "label": "DatasetFormatter",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "description": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "class DatasetFormatter:\n    \"Returns a dataset with the appropriate format and file indices to be displayed.\"\n    @classmethod\n    def from_toplosses(cls, learn, n_imgs=None, **kwargs):\n        \"Gets indices with top losses.\"\n        train_ds, train_idxs = cls.get_toplosses_idxs(learn, n_imgs, **kwargs)\n        return train_ds, train_idxs\n    @classmethod\n    def get_toplosses_idxs(cls, learn, n_imgs, **kwargs):\n        \"Sorts `ds_type` dataset by top losses and returns dataset and sorted indices.\"",
        "detail": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "ImageCleaner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "description": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "class ImageCleaner:\n    \"Displays images for relabeling or deletion and saves changes in `path` as 'cleaned.csv'.\"\n    def __init__(self, dataset, fns_idxs, path, batch_size: int = 5, duplicates=False):\n        self._all_images, self._batch = [], []\n        self._path = Path(path)\n        self._batch_size = batch_size\n        if duplicates:\n            self._batch_size = 2\n        self._duplicates = duplicates\n        self._labels = dataset.classes",
        "detail": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "description": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "__all__ = [\"DatasetFormatter\", \"ImageCleaner\"]\nclass DatasetFormatter:\n    \"Returns a dataset with the appropriate format and file indices to be displayed.\"\n    @classmethod\n    def from_toplosses(cls, learn, n_imgs=None, **kwargs):\n        \"Gets indices with top losses.\"\n        train_ds, train_idxs = cls.get_toplosses_idxs(learn, n_imgs, **kwargs)\n        return train_ds, train_idxs\n    @classmethod\n    def get_toplosses_idxs(cls, learn, n_imgs, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "ImageDownloader",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "description": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "class ImageDownloader:\n    \"\"\"\n    Displays a widget that allows searching and downloading images from google images search\n    in a Jupyter Notebook or Lab.\n    \"\"\"\n    def __init__(self, path: Union[Path, str] = \"data\"):\n        \"Setup path to save images to, init the UI, and render the widgets.\"\n        self._path = Path(path)\n        self._ui = self._init_ui()\n        self.render()",
        "detail": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "download_google_images",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "description": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "def download_google_images(\n    path: PathOrStr,\n    search_term: str,\n    size: str = \">400*300\",\n    n_images: int = 10,\n    format: str = \"jpg\",\n    max_workers: int = defaults.cpus,\n    timeout: int = 4,\n) -> FilePathList:\n    \"\"\"",
        "detail": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "description": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "__all__ = [\"ImageDownloader\", \"download_google_images\"]\n_img_sizes = {\n    \">400*300\": \"isz:lt,islt:qsvga\",\n    \">640*480\": \"isz:lt,islt:vga\",\n    \">800*600\": \"isz:lt,islt:svga\",\n    \">1024*768\": \"visz:lt,islt:xga\",\n    \">2MP\": \"isz:lt,islt:2mp\",\n    \">4MP\": \"isz:lt,islt:4mp\",\n    \">6MP\": \"isz:lt,islt:6mp\",\n    \">8MP\": \"isz:lt,islt:8mp\",",
        "detail": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "_img_sizes",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "description": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "_img_sizes = {\n    \">400*300\": \"isz:lt,islt:qsvga\",\n    \">640*480\": \"isz:lt,islt:vga\",\n    \">800*600\": \"isz:lt,islt:svga\",\n    \">1024*768\": \"visz:lt,islt:xga\",\n    \">2MP\": \"isz:lt,islt:2mp\",\n    \">4MP\": \"isz:lt,islt:4mp\",\n    \">6MP\": \"isz:lt,islt:6mp\",\n    \">8MP\": \"isz:lt,islt:8mp\",\n    \">10MP\": \"isz:lt,islt:10mp\",",
        "detail": "DL_Model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "DeviceDataLoader",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "class DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate\n    def __post_init__(self):\n        self.dl.collate_fn = self.collate_fn\n        self.tfms = listify(self.tfms)\n    def __len__(self) -> int:",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "class DataBunch:\n    \"Bind `train_dl`,`valid_dl` and `test_dl` in a data object.\"\n    def __init__(\n        self,\n        train_dl: DataLoader,\n        valid_dl: DataLoader,\n        fix_dl: DataLoader = None,\n        test_dl: Optional[DataLoader] = None,\n        device: torch.device = None,\n        dl_tfms: Optional[Collection[Callable]] = None,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "intercept_args",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "def intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,\n    collate_fn=default_collate,\n    pin_memory=True,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader___getattr__",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "def DataLoader___getattr__(dl, k: str) -> Any:\n    return getattr(dl.dataset, k)\nDataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader___setstate__",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "def DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "def load_data(\n    path: PathOrStr,\n    file: PathLikeOrBinaryStream = \"data_save.pkl\",\n    bs: int = 64,\n    val_bs: int = None,\n    num_workers: int = defaults.cpus,\n    dl_tfms: Optional[Collection[Callable]] = None,\n    device: torch.device = None,\n    collate_fn: Callable = data_collate,\n    no_check: bool = False,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DatasetType",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "DatasetType = Enum(\"DatasetType\", \"Train Valid Test Single Fix\")\n__all__ = [\"DataBunch\", \"DeviceDataLoader\", \"DatasetType\", \"load_data\"]\nold_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "__all__ = [\"DataBunch\", \"DeviceDataLoader\", \"DatasetType\", \"load_data\"]\nold_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "old_dl_init",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "old_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,\n    collate_fn=default_collate,",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "torch.utils.data.DataLoader.__init__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "torch.utils.data.DataLoader.__init__ = intercept_args\ndef DataLoader___getattr__(dl, k: str) -> Any:\n    return getattr(dl.dataset, k)\nDataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader.__getattr__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "DataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader.__setstate__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_data",
        "description": "DL_Model.deoldify.fastai.basic_data",
        "peekOfCode": "DataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate\n    def __post_init__(self):\n        self.dl.collate_fn = self.collate_fn",
        "detail": "DL_Model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "BasicLearner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class BasicLearner:\n    model: nn.Module\n    loss_func: LossFunction\n    opt: optim.Optimizer\n    data: DataBunch\ndef fit(\n    epochs: int,\n    learn: BasicLearner,\n    callbacks: Optional[CallbackList] = None,\n    metrics: OptMetrics = None,",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Learner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class Learner:\n    \"Trainer for `model` using `data` to minimize `loss_func` with optimizer `opt_func`.\"\n    data: DataBunch\n    model: nn.Module\n    opt_func: Callable = AdamW\n    loss_func: Callable = None\n    metrics: Collection[Callable] = None\n    true_wd: bool = True\n    bn_wd: bool = True\n    wd: Floats = defaults.wd",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "RecordOnCPU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class RecordOnCPU(Callback):\n    \"Store the `input` and `target` going through the model on the CPU.\"\n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        self.input, self.target = to_cpu(last_input), to_cpu(last_target)\nclass LearnerCallback(Callback):\n    \"Base class for creating callbacks for a `Learner`.\"\n    def __init__(self, learn):\n        self._learn = weakref.ref(learn)\n        self.exclude, self.not_min = [\"_learn\"], []\n        setattr(self.learn, self.cb_name, self)",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "LearnerCallback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class LearnerCallback(Callback):\n    \"Base class for creating callbacks for a `Learner`.\"\n    def __init__(self, learn):\n        self._learn = weakref.ref(learn)\n        self.exclude, self.not_min = [\"_learn\"], []\n        setattr(self.learn, self.cb_name, self)\n    def __getattr__(self, k):\n        return getattr(self.learn, k)\n    def __setstate__(self, data: Any):\n        self.__dict__.update(data)",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Recorder",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class Recorder(LearnerCallback):\n    \"A `LearnerCallback` that records epoch, loss, opt and metric data during training.\"\n    _order = -10\n    def __init__(self, learn: Learner, add_time: bool = True, silent: bool = False):\n        super().__init__(learn)\n        self.opt = self.learn.opt\n        self.train_dl = self.learn.data.train_dl\n        self.no_val, self.silent, self.add_time = False, silent, add_time\n    def on_train_begin(\n        self, pbar: PBar, metrics_names: Collection[str], **kwargs: Any",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "FakeOptimizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "class FakeOptimizer:\n    def step(self):\n        pass\n    def zero_grad(self):\n        pass\ndef load_callback(class_func, state, learn: Learner):\n    init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)\n    res = (\n        class_func(learn, **init_kwargs)\n        if issubclass(class_func, LearnerCallback)",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "loss_batch",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],\n    batch_multiplier: int = 1,\n) -> Tuple[Union[Tensor, int, float, str]]:",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "get_preds",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def get_preds(\n    model: nn.Module,\n    dl: DataLoader,\n    pbar: Optional[PBar] = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    activ: nn.Module = None,\n    loss_func: OptLossFunc = None,\n    n_batch: Optional[int] = None,\n) -> List[Tensor]:\n    \"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def validate(\n    model: nn.Module,\n    dl: DataLoader,\n    loss_func: OptLossFunc = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    pbar: Optional[PBar] = None,\n    average=True,\n    n_batch: Optional[int] = None,\n) -> Iterator[Tuple[Union[Tensor, int], ...]]:\n    \"Calculate `loss_func` of `model` on `dl` in evaluation mode.\"",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "train_epoch",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def train_epoch(\n    model: nn.Module, dl: DataLoader, opt: optim.Optimizer, loss_func: LossFunction\n) -> None:\n    \"Simple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`.\"\n    model.train()\n    for xb, yb in dl:\n        loss = loss_func(model(xb), yb)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "fit",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def fit(\n    epochs: int,\n    learn: BasicLearner,\n    callbacks: Optional[CallbackList] = None,\n    metrics: OptMetrics = None,\n    batch_multiplier: int = 1,\n) -> None:\n    \"Fit the `model` on `data` and learn using `loss_func` and `opt`.\"\n    assert (\n        len(learn.data.train_dl) != 0",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "load_callback",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def load_callback(class_func, state, learn: Learner):\n    init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)\n    res = (\n        class_func(learn, **init_kwargs)\n        if issubclass(class_func, LearnerCallback)\n        else class_func(**init_kwargs)\n    )\n    for k, v in others.items():\n        setattr(res, k, v)\n    return res",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "load_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "def load_learner(\n    path: PathOrStr,\n    file: PathLikeOrBinaryStream = \"export.pkl\",\n    test: ItemList = None,\n    **db_kwargs,\n):\n    \"Load a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\"\n    source = Path(path) / file if is_pathlike(file) else file\n    state = (\n        torch.load(source, map_location=\"cpu\")",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "__all__ = [\n    \"Learner\",\n    \"LearnerCallback\",\n    \"Recorder\",\n    \"RecordOnCPU\",\n    \"fit\",\n    \"loss_batch\",\n    \"train_epoch\",\n    \"validate\",\n    \"get_preds\",",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.lr",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.lr = slice(3e-3)\ndefaults.wd = 1e-2\ndefaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.wd",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.wd = 1e-2\ndefaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.extra_callbacks",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.extra_callback_fns",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],\n    batch_multiplier: int = 1,",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "loss_func_name2activ",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basic_train",
        "description": "DL_Model.deoldify.fastai.basic_train",
        "peekOfCode": "loss_func_name2activ = {\n    \"cross_entropy_loss\": F.softmax,\n    \"nll_loss\": torch.exp,\n    \"poisson_nll_loss\": torch.exp,\n    \"kl_div_loss\": torch.exp,\n    \"bce_with_logits_loss\": torch.sigmoid,\n    \"cross_entropy\": F.softmax,\n    \"kl_div\": torch.exp,\n    \"binary_cross_entropy_with_logits\": torch.sigmoid,\n}",
        "detail": "DL_Model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.basics",
        "description": "DL_Model.deoldify.fastai.basics",
        "peekOfCode": "__all__ = [o for o in dir(sys.modules[__name__]) if not o.startswith(\"_\")] + [\n    \"__version__\"\n]",
        "detail": "DL_Model.deoldify.fastai.basics",
        "documentation": {}
    },
    {
        "label": "OptimWrapper",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class OptimWrapper:\n    \"Basic wrapper around `opt` to simplify hyper-parameters changes.\"\n    def __init__(\n        self,\n        opt: optim.Optimizer,\n        wd: Floats = 0.0,\n        true_wd: bool = False,\n        bn_wd: bool = True,\n    ):\n        assert not isinstance(opt, OptimWrapper)",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "Callback",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class Callback:\n    \"Base class for callbacks that want to record values, dynamically change learner params, etc.\"\n    _order = 0\n    def on_train_begin(self, **kwargs: Any) -> None:\n        \"To initialize constants in the callback.\"\n        pass\n    def on_epoch_begin(self, **kwargs: Any) -> None:\n        \"At the beginning of each epoch.\"\n        pass\n    def on_batch_begin(self, **kwargs: Any) -> None:",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "SmoothenValue",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class SmoothenValue:\n    \"Create a smooth moving average for a value (loss, etc) using `beta`.\"\n    def __init__(self, beta: float):\n        self.beta, self.n, self.mov_avg = beta, 0, 0\n    def add_value(self, val: float) -> None:\n        \"Add `val` to calculate updated smoothed value.\"\n        self.n += 1\n        self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * val\n        self.smooth = self.mov_avg / (1 - self.beta**self.n)\nCallbackList = Collection[Callback]",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CallbackHandler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class CallbackHandler:\n    \"Manage all of the registered `callbacks` and `metrics`, smoothing loss by momentum `beta`.\"\n    callbacks: CallbackList = None\n    metrics: CallbackList = None\n    beta: float = 0.98\n    def __post_init__(self) -> None:\n        \"Initialize smoother and learning stats.\"\n        self.callbacks = ifnone(self.callbacks, [])\n        self.metrics = ifnone(self.metrics, [])\n        self.metrics = [",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "AverageMetric",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class AverageMetric(Callback):\n    \"Wrap a `func` in a callback for metrics computation.\"\n    def __init__(self, func):\n        # If func has a __name__ use this one else it should be a partial\n        name = func.__name__ if hasattr(func, \"__name__\") else func.func.__name__\n        self.func, self.name = func, name\n        self.world = num_distrib()\n    def on_epoch_begin(self, **kwargs):\n        \"Set the inner value to 0.\"\n        self.val, self.count = 0.0, 0",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "Scheduler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "class Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None\n    ):\n        self.start, self.end = (vals[0], vals[1]) if is_tuple(vals) else (vals, 0)\n        self.n_iter = max(1, n_iter)\n        if func is None:\n            self.func = annealing_linear if is_tuple(vals) else annealing_no\n        else:",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_no",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_no(start: Number, end: Number, pct: float) -> Number:\n    \"No annealing, always return `start`.\"\n    return start\ndef annealing_linear(start: Number, end: Number, pct: float) -> Number:\n    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start + pct * (end - start)\ndef annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_linear",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_linear(start: Number, end: Number, pct: float) -> Number:\n    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start + pct * (end - start)\ndef annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_exp",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out\ndef do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_cos",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out\ndef do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree\ndef annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "do_annealing_poly",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree\ndef annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)\nclass Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_poly",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)\nclass Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None\n    ):\n        self.start, self.end = (vals[0], vals[1]) if is_tuple(vals) else (vals, 0)\n        self.n_iter = max(1, n_iter)",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "__all__ = [\n    \"AverageMetric\",\n    \"Callback\",\n    \"CallbackHandler\",\n    \"OptimWrapper\",\n    \"SmoothenValue\",\n    \"Scheduler\",\n    \"annealing_cos\",\n    \"CallbackList\",\n    \"annealing_exp\",",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CallbackList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.callback",
        "description": "DL_Model.deoldify.fastai.callback",
        "peekOfCode": "CallbackList = Collection[Callback]\ndef _get_init_state():\n    return {\"epoch\": 0, \"iteration\": 0, \"num_batch\": 0, \"skip_validate\": False}\n@dataclass\nclass CallbackHandler:\n    \"Manage all of the registered `callbacks` and `metrics`, smoothing loss by momentum `beta`.\"\n    callbacks: CallbackList = None\n    metrics: CallbackList = None\n    beta: float = 0.98\n    def __post_init__(self) -> None:",
        "detail": "DL_Model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CollabProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class CollabProcessor(TabularProcessor):\n    \"Subclass `TabularProcessor for `process_one`.\"\n    def process_one(self, item):\n        res = super().process_one(item)\n        return CollabLine(res.cats, res.conts, res.classes, res.names)\nclass CollabLine(TabularLine):\n    \"Base item for collaborative filtering, subclasses `TabularLine`.\"\n    def __init__(self, cats, conts, classes, names):\n        super().__init__(cats, conts, classes, names)\n        self.data = [self.data[0][0], self.data[0][1]]",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabLine",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class CollabLine(TabularLine):\n    \"Base item for collaborative filtering, subclasses `TabularLine`.\"\n    def __init__(self, cats, conts, classes, names):\n        super().__init__(cats, conts, classes, names)\n        self.data = [self.data[0][0], self.data[0][1]]\nclass CollabList(TabularList):\n    \"Base `ItemList` for collaborative filtering, subclasses `TabularList`.\"\n    _item_cls, _label_cls, _processor = CollabLine, FloatList, CollabProcessor\n    def reconstruct(self, t: Tensor):\n        return CollabLine(tensor(t), tensor([]), self.classes, self.col_names)",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class CollabList(TabularList):\n    \"Base `ItemList` for collaborative filtering, subclasses `TabularList`.\"\n    _item_cls, _label_cls, _processor = CollabLine, FloatList, CollabProcessor\n    def reconstruct(self, t: Tensor):\n        return CollabLine(tensor(t), tensor([]), self.classes, self.col_names)\nclass EmbeddingNN(TabularModel):\n    \"Subclass `TabularModel` to create a NN suitable for collaborative filtering.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "EmbeddingNN",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class EmbeddingNN(TabularModel):\n    \"Subclass `TabularModel` to create a NN suitable for collaborative filtering.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        layers: Collection[int] = None,\n        ps: Collection[float] = None,\n        emb_drop: float = 0.0,\n        y_range: OptRange = None,\n        use_bn: bool = True,",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "EmbeddingDotBias",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class EmbeddingDotBias(Module):\n    \"Base dot model for collaborative filtering.\"\n    def __init__(\n        self,\n        n_factors: int,\n        n_users: int,\n        n_items: int,\n        y_range: Tuple[float, float] = None,\n    ):\n        self.y_range = y_range",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabDataBunch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class CollabDataBunch(DataBunch):\n    \"Base `DataBunch` for collaborative filtering.\"\n    @classmethod\n    def from_df(\n        cls,\n        ratings: DataFrame,\n        valid_pct: float = 0.2,\n        user_name: Optional[str] = None,\n        item_name: Optional[str] = None,\n        rating_name: Optional[str] = None,",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabLearner",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "class CollabLearner(Learner):\n    \"`Learner` suitable for collaborative filtering.\"\n    def get_idx(self, arr: Collection, is_item: bool = True):\n        \"Fetch item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)\"\n        m = self.model.eval().cpu()\n        requires_grad(m, False)\n        u_class, i_class = self.data.train_ds.x.classes.values()\n        classes = i_class if is_item else u_class\n        c2i = {v: k for k, v in enumerate(classes)}\n        try:",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "collab_learner",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "def collab_learner(\n    data,\n    n_factors: int = None,\n    use_nn: bool = False,\n    emb_szs: Dict[str, int] = None,\n    layers: Collection[int] = None,\n    ps: Collection[float] = None,\n    emb_drop: float = 0.0,\n    y_range: OptRange = None,\n    use_bn: bool = True,",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.collab",
        "description": "DL_Model.deoldify.fastai.collab",
        "peekOfCode": "__all__ = [\n    *tabular.__all__,\n    \"EmbeddingDotBias\",\n    \"EmbeddingNN\",\n    \"collab_learner\",\n    \"CollabDataBunch\",\n    \"CollabLine\",\n    \"CollabList\",\n    \"CollabLearner\",\n]",
        "detail": "DL_Model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "PrePostInitMeta",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):\n            pass\n        @functools.wraps(old_init)\n        def _init(self, *args, **kwargs):\n            self.__pre_init__()",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ItemBase",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__} {str(self)}\"\n    def show(self, ax: plt.Axes, **kwargs):\n        \"Subclass this method if you want to customize the way this `ItemBase` is shown on `ax`.\"\n        ax.set_title(str(self))\n    def apply_tfms(self, tfms: Collection, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "EmptyLabel",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class EmptyLabel(ItemBase):\n    \"Should be used for a dummy label.\"\n    def __init__(self):\n        self.obj, self.data = 0, 0\n    def __str__(self):\n        return \"\"\n    def __hash__(self):\n        return hash(str(self))\nclass Category(ItemBase):\n    \"Basic class for single classification labels.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Category",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class Category(ItemBase):\n    \"Basic class for single classification labels.\"\n    def __init__(self, data, obj):\n        self.data, self.obj = data, obj\n    def __int__(self):\n        return int(self.data)\n    def __str__(self):\n        return str(self.obj)\n    def __hash__(self):\n        return hash(str(self))",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "MultiCategory",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class MultiCategory(ItemBase):\n    \"Basic class for multi-classification labels.\"\n    def __init__(self, data, obj, raw):\n        self.data, self.obj, self.raw = data, obj, raw\n    def __str__(self):\n        return \";\".join([str(o) for o in self.obj])\n    def __hash__(self):\n        return hash(str(self))\nclass FloatItem(ItemBase):\n    \"Basic class for float items.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "FloatItem",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class FloatItem(ItemBase):\n    \"Basic class for float items.\"\n    def __init__(self, obj):\n        self.data, self.obj = np.array(obj).astype(np.float32), obj\n    def __str__(self):\n        return str(self.obj)\n    def __hash__(self):\n        return hash(str(self))\ndef _treat_html(o: str) -> str:\n    o = str(o)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PrettyString",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "class PrettyString(str):\n    \"Little hack to get strings to show properly in Jupyter.\"\n    def __repr__(self):\n        return self\ndef float_or_x(x):\n    \"Tries to convert to float, returns x if it can't\"\n    try:\n        return float(x)\n    except:\n        return x",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "num_cpus",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_listy",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_tuple",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_dict",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_pathlike",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "noop",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):\n            pass\n        @functools.wraps(old_init)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def chunks(l: Collection, n: int) -> Iterable:\n    \"Yield successive `n`-sized chunks from `l`.\"\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\ndef recurse(func: Callable, x: Any, *args, **kwargs) -> Any:\n    if is_listy(x):\n        return [recurse(func, o, *args, **kwargs) for o in x]\n    if is_dict(x):\n        return {k: recurse(func, v, *args, **kwargs) for k, v in x.items()}\n    return func(x, *args, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "recurse",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def recurse(func: Callable, x: Any, *args, **kwargs) -> Any:\n    if is_listy(x):\n        return [recurse(func, o, *args, **kwargs) for o in x]\n    if is_dict(x):\n        return {k: recurse(func, v, *args, **kwargs) for k, v in x.items()}\n    return func(x, *args, **kwargs)\ndef first_el(x: Any) -> Any:\n    \"Recursively get the first element of `x`.\"\n    if is_listy(x):\n        return first_el(x[0])",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "first_el",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def first_el(x: Any) -> Any:\n    \"Recursively get the first element of `x`.\"\n    if is_listy(x):\n        return first_el(x[0])\n    if is_dict(x):\n        return first_el(x[list(x.keys())[0]])\n    return x\ndef to_int(b: Any) -> Union[int, List[int]]:\n    \"Recursively convert `b` to an int or list/dict of ints; raises exception if not convertible.\"\n    return recurse(lambda x: int(x), b)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "to_int",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def to_int(b: Any) -> Union[int, List[int]]:\n    \"Recursively convert `b` to an int or list/dict of ints; raises exception if not convertible.\"\n    return recurse(lambda x: int(x), b)\ndef ifnone(a: Any, b: Any) -> Any:\n    \"`a` if `a` is not None, otherwise `b`.\"\n    return b if a is None else a\ndef is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ifnone",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def ifnone(a: Any, b: Any) -> Any:\n    \"`a` if `a` is not None, otherwise `b`.\"\n    return b if a is None else a\ndef is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is1d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:\n        res.sort()\n    return res\ndef idx_dict(a):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "uniqueify",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:\n        res.sort()\n    return res\ndef idx_dict(a):\n    \"Create a dictionary value to index from `a`.\"\n    return {v: k for k, v in enumerate(a)}\ndef find_classes(folder: Path) -> FilePathList:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "idx_dict",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def idx_dict(a):\n    \"Create a dictionary value to index from `a`.\"\n    return {v: k for k, v in enumerate(a)}\ndef find_classes(folder: Path) -> FilePathList:\n    \"List of label subdirectories in imagenet-style `folder`.\"\n    classes = [d for d in folder.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n    assert len(classes) > 0\n    return sorted(classes, key=lambda d: d.name)\ndef arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "find_classes",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def find_classes(folder: Path) -> FilePathList:\n    \"List of label subdirectories in imagenet-style `folder`.\"\n    classes = [d for d in folder.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n    assert len(classes) > 0\n    return sorted(classes, key=lambda d: d.name)\ndef arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"\n    assert all(\n        [len(arr) == len(arrs[0]) for arr in arrs]\n    ), \"All arrays should have same length\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "arrays_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"\n    assert all(\n        [len(arr) == len(arrs[0]) for arr in arrs]\n    ), \"All arrays should have same length\"\n    mask = array(mask)\n    return list(zip(*[(a[mask], a[~mask]) for a in map(np.array, arrs)]))\ndef random_split(valid_pct: float, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Randomly split `arrs` with `valid_pct` ratio. good for creating validation set.\"\n    assert (",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "random_split",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def random_split(valid_pct: float, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Randomly split `arrs` with `valid_pct` ratio. good for creating validation set.\"\n    assert (\n        valid_pct >= 0 and valid_pct <= 1\n    ), \"Validation set percentage should be between 0 and 1\"\n    is_train = np.random.uniform(size=(len(arrs[0]),)) > valid_pct\n    return arrays_split(is_train, *arrs)\ndef listify(p: OptListOrItem = None, q: OptListOrItem = None):\n    \"Make `p` listy and the same length as `q`.\"\n    if p is None:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "listify",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def listify(p: OptListOrItem = None, q: OptListOrItem = None):\n    \"Make `p` listy and the same length as `q`.\"\n    if p is None:\n        p = []\n    elif isinstance(p, str):\n        p = [p]\n    elif not isinstance(p, Iterable):\n        p = [p]\n    # Rank 0 tensors in PyTorch are Iterable but don't have a length.\n    else:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "camel2snake",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])\ndef extract_kwargs(names: Collection[str], kwargs: KWArgs):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "even_mults",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])\ndef extract_kwargs(names: Collection[str], kwargs: KWArgs):\n    \"Extract the keys in `names` from the `kwargs`.\"\n    new_kwargs = {}\n    for arg_name in names:\n        if arg_name in kwargs:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "extract_kwargs",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def extract_kwargs(names: Collection[str], kwargs: KWArgs):\n    \"Extract the keys in `names` from the `kwargs`.\"\n    new_kwargs = {}\n    for arg_name in names:\n        if arg_name in kwargs:\n            arg_val = kwargs.pop(arg_name)\n            new_kwargs[arg_name] = arg_val\n    return new_kwargs, kwargs\ndef partition(a: Collection, sz: int) -> List[Collection]:\n    \"Split iterables `a` in equal parts of size `sz`\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "partition",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def partition(a: Collection, sz: int) -> List[Collection]:\n    \"Split iterables `a` in equal parts of size `sz`\"\n    return [a[i : i + sz] for i in range(0, len(a), sz)]\ndef partition_by_cores(a: Collection, n_cpus: int) -> List[Collection]:\n    \"Split data in `a` equally among `n_cpus` cores\"\n    return partition(a, len(a) // n_cpus + 1)\ndef series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "partition_by_cores",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def partition_by_cores(a: Collection, n_cpus: int) -> List[Collection]:\n    \"Split data in `a` equally among `n_cpus` cores\"\n    return partition(a, len(a) // n_cpus + 1)\ndef series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()\nTfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "series2cat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()\nTfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "recurse_eq",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def recurse_eq(arr1, arr2):\n    if is_listy(arr1):\n        return (\n            is_listy(arr2)\n            and len(arr1) == len(arr2)\n            and np.all([recurse_eq(x, y) for x, y in zip(arr1, arr2)])\n        )\n    else:\n        return np.all(np.atleast_1d(arr1 == arr2))\ndef download_url(",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "download_url",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def download_url(\n    url: str,\n    dest: str,\n    overwrite: bool = False,\n    pbar: ProgressBar = None,\n    show_progress=True,\n    chunk_size=1024 * 1024,\n    timeout=4,\n    retries=5,\n) -> None:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "range_of",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def range_of(x):\n    \"Create a range from 0 to `len(x)`.\"\n    return list(range(len(x)))\ndef arange_of(x):\n    \"Same as `range_of` but returns an array.\"\n    return np.arange(len(x))\nPath.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "arange_of",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def arange_of(x):\n    \"Same as `range_of` but returns an array.\"\n    return np.arange(len(x))\nPath.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "join_path",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "join_paths",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:\n        lines = f.readlines()\n    return np.array([l.strip() for l in lines])\ndef save_texts(fname: PathOrStr, texts: Collection[str]):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "loadtxt_str",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:\n        lines = f.readlines()\n    return np.array([l.strip() for l in lines])\ndef save_texts(fname: PathOrStr, texts: Collection[str]):\n    \"Save in `fname` the content of `texts`.\"\n    with open(fname, \"w\") as f:\n        for t in texts:\n            f.write(f\"{t}\\n\")",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "save_texts",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def save_texts(fname: PathOrStr, texts: Collection[str]):\n    \"Save in `fname` the content of `texts`.\"\n    with open(fname, \"w\") as f:\n        for t in texts:\n            f.write(f\"{t}\\n\")\ndef df_names_to_idx(names: IntsOrStrs, df: DataFrame):\n    \"Return the column indexes of `names` in `df`.\"\n    if not is_listy(names):\n        names = [names]\n    if isinstance(names[0], int):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "df_names_to_idx",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def df_names_to_idx(names: IntsOrStrs, df: DataFrame):\n    \"Return the column indexes of `names` in `df`.\"\n    if not is_listy(names):\n        names = [names]\n    if isinstance(names[0], int):\n        return names\n    return [df.columns.get_loc(c) for c in names]\ndef one_hot(x: Collection[int], c: int):\n    \"One-hot encode `x` with `c` classes.\"\n    res = np.zeros((c,), np.float32)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "one_hot",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def one_hot(x: Collection[int], c: int):\n    \"One-hot encode `x` with `c` classes.\"\n    res = np.zeros((c,), np.float32)\n    res[listify(x)] = 1.0\n    return res\ndef index_row(\n    a: Union[Collection, pd.DataFrame, pd.Series], idxs: Collection[int]\n) -> Any:\n    \"Return the slice of `a` corresponding to `idxs`.\"\n    if a is None:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "index_row",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def index_row(\n    a: Union[Collection, pd.DataFrame, pd.Series], idxs: Collection[int]\n) -> Any:\n    \"Return the slice of `a` corresponding to `idxs`.\"\n    if a is None:\n        return a\n    if isinstance(a, (pd.DataFrame, pd.Series)):\n        res = a.iloc[idxs]\n        if isinstance(res, (pd.DataFrame, pd.Series)):\n            return res.copy()",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "func_args",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def func_args(func) -> bool:\n    \"Return the arguments of `func`.\"\n    code = func.__code__\n    return code.co_varnames[: code.co_argcount]\ndef has_arg(func, arg) -> bool:\n    \"Check if `func` accepts `arg`.\"\n    return arg in func_args(func)\ndef split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "has_arg",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def has_arg(func, arg) -> bool:\n    \"Check if `func` accepts `arg`.\"\n    return arg in func_args(func)\ndef split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)\n    func_kwargs = {a: kwargs.pop(a) for a in args if a in kwargs}\n    return func_kwargs, kwargs\ndef array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "split_kwargs_by_func",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)\n    func_kwargs = {a: kwargs.pop(a) for a in args if a in kwargs}\n    return func_kwargs, kwargs\ndef array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"\n    if not isinstance(a, collections.abc.Sized) and not getattr(\n        a, \"__array_interface__\", False\n    ):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "array",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"\n    if not isinstance(a, collections.abc.Sized) and not getattr(\n        a, \"__array_interface__\", False\n    ):\n        a = list(a)\n    if (\n        np.int_ == np.int32\n        and dtype is None\n        and is_listy(a)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "text2html_table",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def text2html_table(items: Collection[Collection[str]]) -> str:\n    \"Put the texts in `items` in an HTML table, `widths` are the widths of the columns in %.\"\n    html_code = f\"\"\"<table border=\"1\" class=\"dataframe\">\"\"\"\n    html_code += f\"\"\"  <thead>\\n    <tr style=\"text-align: right;\">\\n\"\"\"\n    for i in items[0]:\n        html_code += f\"      <th>{_treat_html(i)}</th>\"\n    html_code += f\"    </tr>\\n  </thead>\\n  <tbody>\"\n    html_code += \"  <tbody>\"\n    for line in items[1:]:\n        html_code += \"    <tr>\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "parallel",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def parallel(func, arr: Collection, max_workers: int = None, leave=False):\n    \"Call `func` on every element of `arr` in parallel using `max_workers`.\"\n    max_workers = ifnone(max_workers, defaults.cpus)\n    if max_workers < 2:\n        results = [\n            func(o, i)\n            for i, o in progress_bar(enumerate(arr), total=len(arr), leave=leave)\n        ]\n    else:\n        with ProcessPoolExecutor(max_workers=max_workers) as ex:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "subplots",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def subplots(\n    rows: int,\n    cols: int,\n    imgsize: int = 4,\n    figsize: Optional[Tuple[int, int]] = None,\n    title=None,\n    **kwargs,\n):\n    \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n    figsize = ifnone(figsize, (imgsize * cols, imgsize * rows))",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "show_some",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def show_some(items: Collection, n_max: int = 5, sep: str = \",\"):\n    \"Return the representation of the first  `n_max` elements in `items`.\"\n    if items is None or len(items) == 0:\n        return \"\"\n    res = sep.join([f\"{o}\" for o in items[:n_max]])\n    if len(items) > n_max:\n        res += \"...\"\n    return res\ndef get_tmp_file(dir=None):\n    \"Create and return a tmp filename, optionally at a specific path. `os.remove` when done with it.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "get_tmp_file",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def get_tmp_file(dir=None):\n    \"Create and return a tmp filename, optionally at a specific path. `os.remove` when done with it.\"\n    with tempfile.NamedTemporaryFile(delete=False, dir=dir) as f:\n        return f.name\ndef compose(funcs: List[Callable]) -> Callable:\n    \"Compose `funcs`\"\n    def compose_(funcs, x, *args, **kwargs):\n        for f in listify(funcs):\n            x = f(x, *args, **kwargs)\n        return x",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "compose",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def compose(funcs: List[Callable]) -> Callable:\n    \"Compose `funcs`\"\n    def compose_(funcs, x, *args, **kwargs):\n        for f in listify(funcs):\n            x = f(x, *args, **kwargs)\n        return x\n    return partial(compose_, funcs)\nclass PrettyString(str):\n    \"Little hack to get strings to show properly in Jupyter.\"\n    def __repr__(self):",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "float_or_x",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def float_or_x(x):\n    \"Tries to convert to float, returns x if it can't\"\n    try:\n        return float(x)\n    except:\n        return x\ndef bunzip(fn: PathOrStr):\n    \"bunzip `fn`, raising exception if output already exists\"\n    fn = Path(fn)\n    assert fn.exists(), f\"{fn} doesn't exist\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "bunzip",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def bunzip(fn: PathOrStr):\n    \"bunzip `fn`, raising exception if output already exists\"\n    fn = Path(fn)\n    assert fn.exists(), f\"{fn} doesn't exist\"\n    out_fn = fn.with_suffix(\"\")\n    assert not out_fn.exists(), f\"{out_fn} already exists\"\n    with bz2.BZ2File(fn, \"rb\") as src, out_fn.open(\"wb\") as dst:\n        for d in iter(lambda: src.read(1024 * 1024), b\"\"):\n            dst.write(d)\n@contextmanager",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "working_directory",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "def working_directory(path: PathOrStr):\n    \"Change working directory to `path` and return to previous on exit.\"\n    prev_cwd = Path.cwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(prev_cwd)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "AnnealFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "AnnealFunc = Callable[[Number, Number, float], Number]\nArgStar = Collection[Any]\nBatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ArgStar",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ArgStar = Collection[Any]\nBatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "BatchSamples",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "BatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "DataFrameOrChunks",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "DataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "FilePathList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "FilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Floats",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Floats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ImgLabel",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ImgLabels",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "IntsOrStrs",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "IntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "KeyFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "KeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "KWArgs",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "KWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListOrItem",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListRules",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListSizes",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "ListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayableList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "NPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "NPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayMask",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "NPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPImage",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "NPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptDataFrame",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptListOrItem",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptRange",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStrTuple",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStats",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PathOrStr",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "PathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PathLikeOrBinaryStream",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "PathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PBar",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "PBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Point",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Point = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Points",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Points = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Sizes",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Sizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "SplitArrayList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "SplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "StartOptEnd",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "StartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "StrList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "StrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Tokens",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Tokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStrList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "OptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_default_cpus",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)\ndef is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "defaults",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "defaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)\ndef is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_camel_re1",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "_camel_re1 = re.compile(\"(.)([A-Z][a-z]+)\")\n_camel_re2 = re.compile(\"([a-z0-9])([A-Z])\")\ndef camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_camel_re2",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "_camel_re2 = re.compile(\"([a-z0-9])([A-Z])\")\ndef camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "TfmList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "TfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__} {str(self)}\"\n    def show(self, ax: plt.Axes, **kwargs):\n        \"Subclass this method if you want to customize the way this `ItemBase` is shown on `ax`.\"\n        ax.set_title(str(self))",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Path.ls",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.core",
        "description": "DL_Model.deoldify.fastai.core",
        "peekOfCode": "Path.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"",
        "detail": "DL_Model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PreProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class PreProcessor:\n    \"Basic class for a processor that will be applied to items at the end of the data block API.\"\n    def __init__(self, ds: Collection = None):\n        self.ref_ds = ds\n    def process_one(self, item: Any):\n        return item\n    def process(self, ds: Collection):\n        ds.items = array([self.process_one(item) for item in ds.items])\nPreProcessors = Union[PreProcessor, Collection[PreProcessor]]\nfastai_types[PreProcessors] = \"PreProcessors\"",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "ItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,\n    )\n    def __init__(",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "EmptyLabelList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class EmptyLabelList(ItemList):\n    \"Basic `ItemList` for dummy labels.\"\n    def get(self, i):\n        return EmptyLabel()\n    def reconstruct(self, t: Tensor, x: Tensor = None):\n        if len(t.size()) == 0:\n            return EmptyLabel()\n        return (\n            self.x.reconstruct(t, x)\n            if has_arg(self.x.reconstruct, \"x\")",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryProcessor(PreProcessor):\n    \"`PreProcessor` that create `classes` from `ds.items` and handle the mapping.\"\n    def __init__(self, ds: ItemList):\n        self.create_classes(ds.classes)\n        self.state_attrs, self.warns = [\"classes\"], []\n    def create_classes(self, classes):\n        self.classes = classes\n        if classes is not None:\n            self.c2i = {v: k for k, v in enumerate(classes)}\n    def generate_classes(self, items):",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryListBase",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryListBase(ItemList):\n    \"Basic `ItemList` for classification.\"\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):\n        self.classes = classes\n        self.filter_missing_y = True\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\"classes\")\n    @property\n    def c(self):\n        return len(self.classes)",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryList(CategoryListBase):\n    \"Basic `ItemList` for single classification labels.\"\n    _processor = CategoryProcessor\n    def __init__(\n        self,\n        items: Iterator,\n        classes: Collection = None,\n        label_delim: str = None,\n        **kwargs,\n    ):",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MultiCategoryProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class MultiCategoryProcessor(CategoryProcessor):\n    \"`PreProcessor` that create `classes` from `ds.items` and handle the mapping.\"\n    def __init__(self, ds: ItemList, one_hot: bool = False):\n        super().__init__(ds)\n        self.one_hot = one_hot\n        self.state_attrs.append(\"one_hot\")\n    def process_one(self, item):\n        if self.one_hot or isinstance(item, EmptyLabel):\n            return item\n        res = [super(MultiCategoryProcessor, self).process_one(o) for o in item]",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MultiCategoryList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class MultiCategoryList(CategoryListBase):\n    \"Basic `ItemList` for multi-classification labels.\"\n    _processor = MultiCategoryProcessor\n    def __init__(\n        self,\n        items: Iterator,\n        classes: Collection = None,\n        label_delim: str = None,\n        one_hot: bool = False,\n        **kwargs,",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "FloatList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class FloatList(ItemList):\n    \"`ItemList` suitable for storing the floats in items for regression. Will add a `log` if this flag is `True`.\"\n    def __init__(\n        self, items: Iterator, log: bool = False, classes: Collection = None, **kwargs\n    ):\n        super().__init__(np.array(items, dtype=np.float32), **kwargs)\n        self.log = log\n        self.copy_new.append(\"log\")\n        self.c = self.items.shape[1] if len(self.items.shape) > 1 else 1\n        self.loss_func = MSELossFlat()",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "ItemLists",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class ItemLists:\n    \"An `ItemList` for each of `train` and `valid` (optional `test`).\"\n    def __init__(self, path: PathOrStr, train: ItemList, valid: ItemList):\n        self.path, self.train, self.valid, self.test = Path(path), train, valid, None\n        if not self.train.ignore_empty and len(self.train.items) == 0:\n            warn(\n                \"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\"\n            )\n        if not self.valid.ignore_empty and len(self.valid.items) == 0:\n            warn(",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "LabelLists",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class LabelLists(ItemLists):\n    \"A `LabelList` for each of `train` and `valid` (optional `test`).\"\n    def get_processors(self):\n        \"Read the default class processors if none have been set.\"\n        procs_x, procs_y = listify(self.train.x._processor), listify(\n            self.train.y._processor\n        )\n        xp = ifnone(self.train.x.processor, [p(ds=self.train.x) for p in procs_x])\n        yp = ifnone(self.train.y.processor, [p(ds=self.train.y) for p in procs_y])\n        return xp, yp",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "LabelList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class LabelList(Dataset):\n    \"A list of inputs `x` and labels `y` with optional `tfms`.\"\n    def __init__(\n        self,\n        x: ItemList,\n        y: ItemList,\n        tfms: TfmList = None,\n        tfm_y: bool = False,\n        **kwargs,\n    ):",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedProcessor",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedProcessor(PreProcessor):\n    def __init__(\n        self, procs: Collection[Union[PreProcessor, Collection[PreProcessor]]]\n    ):\n        self.procs = procs\n    def process_one(self, item: Any):\n        res = []\n        for procs, i in zip(self.procs, item):\n            for p in procs:\n                i = p.process_one(i)",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedItem",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedItem(ItemBase):\n    def __init__(self, items):\n        self.obj = items\n        self.data = [item.data for item in items]\n    def __repr__(self):\n        return \"\\n\".join(\n            [f\"{self.__class__.__name__}\"] + [repr(item) for item in self.obj]\n        )\n    def apply_tfms(self, tfms: Collection, **kwargs):\n        self.obj = [item.apply_tfms(t, **kwargs) for item, t in zip(self.obj, tfms)]",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedItemList",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedItemList(ItemList):\n    def __init__(\n        self,\n        item_lists,\n        path: PathOrStr = None,\n        label_cls: Callable = None,\n        inner_df: Any = None,\n        x: \"ItemList\" = None,\n        ignore_empty: bool = False,\n        processor=None,",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "get_files",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "def get_files(\n    path: PathOrStr,\n    extensions: Collection[str] = None,\n    recurse: bool = False,\n    include: Optional[Collection[str]] = None,\n    presort: bool = False,\n) -> FilePathList:\n    \"Return list of files in `path` that have a suffix in `extensions`; optionally `recurse`.\"\n    if recurse:\n        res = []",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "__all__ = [\n    \"ItemList\",\n    \"CategoryList\",\n    \"MultiCategoryList\",\n    \"MultiCategoryProcessor\",\n    \"LabelList\",\n    \"ItemLists\",\n    \"get_files\",\n    \"PreProcessor\",\n    \"LabelLists\",",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "PreProcessors",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "PreProcessors = Union[PreProcessor, Collection[PreProcessor]]\nfastai_types[PreProcessors] = \"PreProcessors\"\nclass ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "fastai_types[PreProcessors]",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "fastai_types[PreProcessors] = \"PreProcessors\"\nclass ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,\n    )",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "DataBunch.load_empty",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.data_block",
        "description": "DL_Model.deoldify.fastai.data_block",
        "peekOfCode": "DataBunch.load_empty = _databunch_load_empty\nclass MixedProcessor(PreProcessor):\n    def __init__(\n        self, procs: Collection[Union[PreProcessor, Collection[PreProcessor]]]\n    ):\n        self.procs = procs\n    def process_one(self, item: Any):\n        res = []\n        for procs, i in zip(self.procs, item):\n            for p in procs:",
        "detail": "DL_Model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "URLs",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "class URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"\n    S3_MODEL = f\"{S3}modelzoo/\"\n    # main datasets",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "class Config:\n    \"Creates a default config file 'config.yml' in $FASTAI_HOME (default `~/.fastai/`)\"\n    DEFAULT_CONFIG_LOCATION = os.path.expanduser(os.getenv(\"FASTAI_HOME\", \"~/.fastai\"))\n    DEFAULT_CONFIG_PATH = DEFAULT_CONFIG_LOCATION + \"/config.yml\"\n    DEFAULT_CONFIG = {\n        \"data_path\": DEFAULT_CONFIG_LOCATION + \"/data\",\n        \"data_archive_path\": DEFAULT_CONFIG_LOCATION + \"/data\",\n        \"model_path\": DEFAULT_CONFIG_LOCATION + \"/models\",\n    }\n    @classmethod",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "url2name",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def url2name(url):\n    return url.split(\"/\")[-1]\n# TODO: simplify this mess\ndef url2path(url, data=True, ext: str = \".tgz\"):\n    \"Change `url` to a path.\"\n    name = url2name(url)\n    return (\n        datapath4file(name, ext=ext, archive=False)\n        if data\n        else modelpath4file(name, ext=ext)",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "url2path",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def url2path(url, data=True, ext: str = \".tgz\"):\n    \"Change `url` to a path.\"\n    name = url2name(url)\n    return (\n        datapath4file(name, ext=ext, archive=False)\n        if data\n        else modelpath4file(name, ext=ext)\n    )\ndef _url2tgz(url, data=True, ext: str = \".tgz\"):\n    return (",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "modelpath4file",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def modelpath4file(filename, ext: str = \".tgz\"):\n    \"Return model path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"models\" / filename\n    if local_path.exists() or local_path.with_suffix(ext).exists():\n        return local_path\n    else:\n        return Config.model_path() / filename\ndef datapath4file(filename, ext: str = \".tgz\", archive=True):\n    \"Return data path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"data\" / filename",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "datapath4file",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def datapath4file(filename, ext: str = \".tgz\", archive=True):\n    \"Return data path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"data\" / filename\n    if local_path.exists() or local_path.with_suffix(ext).exists():\n        return local_path\n    elif archive:\n        return Config.data_archive_path() / filename\n    else:\n        return Config.data_path() / filename\ndef download_data(",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "download_data",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def download_data(\n    url: str, fname: PathOrStr = None, data: bool = True, ext: str = \".tgz\"\n) -> Path:\n    \"Download `url` to destination `fname`.\"\n    fname = Path(ifnone(fname, _url2tgz(url, data, ext=ext)))\n    os.makedirs(fname.parent, exist_ok=True)\n    if not fname.exists():\n        print(f\"Downloading {url}\")\n        download_url(f\"{url}{ext}\", fname)\n    return fname",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "untar_data",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "def untar_data(\n    url: str,\n    fname: PathOrStr = None,\n    dest: PathOrStr = None,\n    data=True,\n    force_download=False,\n) -> Path:\n    \"Download `url` to `fname` if `dest` doesn't exist, and un-tgz to folder `dest`.\"\n    dest = url2path(url, data) if dest is None else Path(dest) / url2name(url)\n    fname = Path(ifnone(fname, _url2tgz(url, data)))",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "__all__ = [\n    \"URLs\",\n    \"Config\",\n    \"untar_data\",\n    \"download_data\",\n    \"datapath4file\",\n    \"url2name\",\n    \"url2path\",\n]\nMODEL_URL = \"http://files.fast.ai/models/\"",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "MODEL_URL",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "MODEL_URL = \"http://files.fast.ai/models/\"\nURL = \"http://files.fast.ai/data/examples/\"\nclass URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "URL = \"http://files.fast.ai/data/examples/\"\nclass URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"\n    S3_MODEL = f\"{S3}modelzoo/\"",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "_checks",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.datasets",
        "description": "DL_Model.deoldify.fastai.datasets",
        "peekOfCode": "_checks = {\n    URLs.ADULT_SAMPLE: (968212, \"64eb9d7e23732de0b138f7372d15492f\"),\n    URLs.AG_NEWS: (11784419, \"b86f328f4dbd072486591cb7a5644dcd\"),\n    URLs.AMAZON_REVIEWS_POLARITY: (688339454, \"676f7e5208ec343c8274b4bb085bc938\"),\n    URLs.AMAZON_REVIEWS: (643695014, \"4a1196cf0adaea22f4bc3f592cddde90\"),\n    URLs.BIWI_HEAD_POSE: (452316199, \"00f4ccf66e8cba184bc292fdc08fb237\"),\n    URLs.BIWI_SAMPLE: (593774, \"9179f4c1435f4b291f0d5b072d60c2c9\"),\n    URLs.CALTECH_101: (131740031, \"d673425306e98ee4619fcdeef8a0e876\"),\n    URLs.CAMVID: (598913237, \"648371e4f3a833682afb39b08a3ce2aa\"),\n    URLs.CAMVID_TINY: (2314212, \"2cf6daf91b7a2083ecfa3e9968e9d915\"),",
        "detail": "DL_Model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "ParallelTrainer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "class ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module\nclass DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):\n        super().__init__(learn)",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedTrainer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "class DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):\n        super().__init__(learn)\n        self.cuda_id, self.train_sampler = cuda_id, None\n    def _change_dl(self, dl, shuffle):\n        old_dl = dl\n        sampler = OurDistributedSampler(dl.dataset, shuffle=shuffle)\n        new_dl = dl.new(shuffle=False, sampler=sampler)\n        return old_dl, new_dl, sampler",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedRecorder",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "class DistributedRecorder(LearnerCallback):\n    def __init__(self, learn: Learner, cuda_id: int = 0, cache_dir: PathOrStr = \"tmp\"):\n        super().__init__(learn)\n        self.cuda_id, self.cache_dir = cuda_id, cache_dir\n    def on_train_begin(self, **kwargs):\n        os.makedirs(self.learn.path / self.cache_dir, exist_ok=True)\n    def on_epoch_end(self, **kwargs):\n        self.save_stats()\n    def on_train_end(self, **kwargs):\n        self.save_stats()",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "OurDistributedSampler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "class OurDistributedSampler(DistributedSampler):\n    \"A sampler for language models with the option to not shuffle.\"\n    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True):\n        super().__init__(dataset, num_replicas=num_replicas, rank=rank)\n        self.shuffle = shuffle\n    def __iter__(self):\n        if self.shuffle:\n            g = torch.Generator()\n            g.manual_seed(self.epoch)\n            indices = torch.randperm(len(self.dataset), generator=g).tolist()",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "rnn_reset",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "def rnn_reset(self):\n    if hasattr(self.module, \"reset\"):\n        self.module.reset()\nDistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "read_metrics",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "def read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)\n    return losses, metrics\ndef setup_distrib(gpu: Any = None):",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "setup_distrib",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "def setup_distrib(gpu: Any = None):\n    if gpu is None:\n        return gpu\n    gpu = int(gpu)\n    torch.cuda.set_device(int(gpu))\n    if num_distrib() > 1:\n        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n    return gpu\nclass OurDistributedSampler(DistributedSampler):\n    \"A sampler for language models with the option to not shuffle.\"",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "__all__ = [\"DistributedRecorder\", \"DistributedTrainer\", \"read_metrics\", \"setup_distrib\"]\ndef rnn_reset(self):\n    if hasattr(self.module, \"reset\"):\n        self.module.reset()\nDistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel.reset",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "DistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module\nclass DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Learner.to_distributed",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "Learner.to_distributed = _learner_distributed\nLearner.to_parallel = _learner_parallel\ndef read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Learner.to_parallel",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.distributed",
        "description": "DL_Model.deoldify.fastai.distributed",
        "peekOfCode": "Learner.to_parallel = _learner_parallel\ndef read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)\n    return losses, metrics",
        "detail": "DL_Model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Statistic",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class Statistic:\n    name: str\n    param: float = 0.9  # e.g. for exp moving average\n    scope: StatScope = StatScope.Weight\n    init: float = 0.0  # starting value\n    @property\n    def buf(self):\n        return f\"{self.name}_buffer\"\n    def new_step(self):\n        \"Set state when computing statistics for Global or Group\"",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "ConstStatistic",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class ConstStatistic(Statistic):\n    @property\n    def buf(self):\n        return None\n    def new_step(self):\n        pass\n    def accumulate(self):\n        pass\n    def update(self, state, param, val=None, step=None):\n        return param",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "CounterStat",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class CounterStat(Statistic):\n    def __post_init__(self):\n        self.init, self._buf, self.name = 0, self.name, None\n    @property\n    def buf(self):\n        return self._buf\n    def new_step(self):\n        pass\n    def accumulate(self, val):\n        pass",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "AvgStatistic",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class AvgStatistic(Statistic):\n    decay: bool = False\n    debias: bool = False\n    def new_step(self):\n        self.val, self.count = 0.0, 0\n    def accumulate(self, val):\n        self.count += 1\n        self.val += self._get_val1(val)\n    def _get_val1(self, val):\n        return val.mean()",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "AvgSquare",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class AvgSquare(AvgStatistic):\n    def __init__(\n        self,\n        name: str,\n        param: float = 0.9,\n        scope=StatScope.Weight,\n        init: float = 0.0,\n        decay: bool = True,\n        debias: bool = False,\n    ):",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "GeneralOptimizer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class GeneralOptimizer(Optimizer):\n    def __init__(self, params, stats=None, on_step: Callable = None):\n        defaults = {s.name: s.param for s in listify(stats) if s.name is not None}\n        super().__init__(params, defaults)\n        (\n            self.global_stats,\n            self.group_stats,\n            self.layer_stats,\n            self.channel_stats,\n            self.weight_stats,",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "__all__ = [\n    \"StatScope\",\n    \"Statistic\",\n    \"ConstStatistic\",\n    \"AvgStatistic\",\n    \"AvgSquare\",\n    \"GeneralOptimizer\",\n]\nStatScope = Enum(\"StatScope\", \"Global Group Layer Channel Weight\")\n@dataclass",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "StatScope",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.general_optimizer",
        "description": "DL_Model.deoldify.fastai.general_optimizer",
        "peekOfCode": "StatScope = Enum(\"StatScope\", \"Global Group Layer Channel Weight\")\n@dataclass\nclass Statistic:\n    name: str\n    param: float = 0.9  # e.g. for exp moving average\n    scope: StatScope = StatScope.Weight\n    init: float = 0.0  # starting value\n    @property\n    def buf(self):\n        return f\"{self.name}_buffer\"",
        "detail": "DL_Model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.launch",
        "description": "DL_Model.deoldify.fastai.launch",
        "peekOfCode": "def main(\n    gpus: Param(\"The GPUs to use for distributed training\", str) = \"all\",\n    script: Param(\"Script to run\", str, opt=False) = \"\",\n    args: Param(\"Args to pass to script\", nargs=\"...\", opt=False) = \"\",\n):\n    \"PyTorch distributed training launch helper that spawns multiple distributed processes\"\n    # Loosely based on torch.distributed.launch\n    current_env = os.environ.copy()\n    gpus = list(range(torch.cuda.device_count())) if gpus == \"all\" else list(gpus)\n    current_env[\"WORLD_SIZE\"] = str(len(gpus))",
        "detail": "DL_Model.deoldify.fastai.launch",
        "documentation": {}
    },
    {
        "label": "Lambda",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class Lambda(Module):\n    \"Create a layer that simply calls `func` with `x`\"\n    def __init__(self, func: LambdaFunc):\n        self.func = func\n    def forward(self, x):\n        return self.func(x)\nclass View(Module):\n    \"Reshape `x` to `size`\"\n    def __init__(self, *size: int):\n        self.size = size",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "View",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class View(Module):\n    \"Reshape `x` to `size`\"\n    def __init__(self, *size: int):\n        self.size = size\n    def forward(self, x):\n        return x.view(self.size)\nclass ResizeBatch(Module):\n    \"Reshape `x` to `size`, keeping batch dim the same size\"\n    def __init__(self, *size: int):\n        self.size = size",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "ResizeBatch",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class ResizeBatch(Module):\n    \"Reshape `x` to `size`, keeping batch dim the same size\"\n    def __init__(self, *size: int):\n        self.size = size\n    def forward(self, x):\n        return x.view((x.size(0),) + self.size)\nclass Flatten(Module):\n    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n    def __init__(self, full: bool = False):\n        self.full = full",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class Flatten(Module):\n    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n    def __init__(self, full: bool = False):\n        self.full = full\n    def forward(self, x):\n        return x.view(-1) if self.full else x.view(x.size(0), -1)\ndef PoolFlatten() -> nn.Sequential:\n    \"Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result.\"\n    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())\nNormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PooledSelfAttention2d",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class PooledSelfAttention2d(Module):\n    \"Pooled self attention layer for 2d.\"\n    def __init__(self, n_channels: int):\n        self.n_channels = n_channels\n        self.theta = spectral_norm(conv2d(n_channels, n_channels // 8, 1))  # query\n        self.phi = spectral_norm(conv2d(n_channels, n_channels // 8, 1))  # key\n        self.g = spectral_norm(conv2d(n_channels, n_channels // 2, 1))  # value\n        self.o = spectral_norm(conv2d(n_channels // 2, n_channels, 1))\n        self.gamma = nn.Parameter(tensor([0.0]))\n    def forward(self, x):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SelfAttention",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class SelfAttention(Module):\n    \"Self attention layer for nd.\"\n    def __init__(self, n_channels: int):\n        self.query = conv1d(n_channels, n_channels // 8)\n        self.key = conv1d(n_channels, n_channels // 8)\n        self.value = conv1d(n_channels, n_channels)\n        self.gamma = nn.Parameter(tensor([0.0]))\n    def forward(self, x):\n        # Notation from https://arxiv.org/pdf/1805.08318.pdf\n        size = x.size()",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SequentialEx",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class SequentialEx(Module):\n    \"Like `nn.Sequential`, but with ModuleList semantics, and can access module input\"\n    def __init__(self, *layers):\n        self.layers = nn.ModuleList(layers)\n    def forward(self, x):\n        res = x\n        for l in self.layers:\n            res.orig = x\n            nres = l(res)\n            # print(l. + ' mean: ' + str(nres.abs().mean()))",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "MergeLayer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class MergeLayer(Module):\n    \"Merge a shortcut with the result of the module by adding them or concatenating thme if `dense=True`.\"\n    def __init__(self, dense: bool = False):\n        self.dense = dense\n    def forward(self, x):\n        return torch.cat([x, x.orig], dim=1) if self.dense else (x + x.orig)\ndef res_block(\n    nf,\n    dense: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SigmoidRange",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class SigmoidRange(Module):\n    \"Sigmoid module with range `(low,x_max)`\"\n    def __init__(self, low: int, high: int):\n        self.low, self.high = low, high\n    def forward(self, x):\n        return sigmoid_range(x, self.low, self.high)\nclass PartialLayer(Module):\n    \"Layer that applies `partial(func, **kwargs)`.\"\n    def __init__(self, func, **kwargs):\n        self.repr, self.func = f\"{func}({kwargs})\", partial(func, **kwargs)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PartialLayer",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class PartialLayer(Module):\n    \"Layer that applies `partial(func, **kwargs)`.\"\n    def __init__(self, func, **kwargs):\n        self.repr, self.func = f\"{func}({kwargs})\", partial(func, **kwargs)\n    def forward(self, x):\n        return self.func(x)\n    def __repr__(self):\n        return self.repr\nclass AdaptiveConcatPool2d(Module):\n    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "AdaptiveConcatPool2d",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class AdaptiveConcatPool2d(Module):\n    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"\n    def __init__(self, sz: Optional[int] = None):\n        \"Output will be 2*sz or 2 if sz is None\"\n        self.output_size = sz or 1\n        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n    def forward(self, x):\n        return torch.cat([self.mp(x), self.ap(x)], 1)\nclass Debugger(Module):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "Debugger",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class Debugger(Module):\n    \"A module to debug inside a model.\"\n    def forward(self, x: Tensor) -> Tensor:\n        set_trace()\n        return x\ndef icnr(x, scale=2, init=nn.init.kaiming_normal_):\n    \"ICNR init of `x`, with `scale` and `init` function.\"\n    ni, nf, h, w = x.shape\n    ni2 = int(ni / (scale**2))\n    k = init(torch.zeros([ni2, nf, h, w])).transpose(0, 1)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PixelShuffle_ICNR",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class PixelShuffle_ICNR(Module):\n    \"Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`, `icnr` init, and `weight_norm`.\"\n    def __init__(\n        self,\n        ni: int,\n        nf: int = None,\n        scale: int = 2,\n        blur: bool = False,\n        norm_type=NormType.Weight,\n        leaky: float = None,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "FlattenedLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class FlattenedLoss:\n    \"Same as `func`, but flattens input and target.\"\n    def __init__(\n        self,\n        func,\n        *args,\n        axis: int = -1,\n        floatify: bool = False,\n        is_2d: bool = True,\n        **kwargs,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "NoopLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class NoopLoss(Module):\n    \"Just returns the mean of the `output`.\"\n    def forward(self, output, *args):\n        return output.mean()\nclass WassersteinLoss(Module):\n    \"For WGAN.\"\n    def forward(self, real, fake):\n        return real.mean() - fake.mean()\ndef simple_cnn(\n    actns: Collection[int],",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "WassersteinLoss",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class WassersteinLoss(Module):\n    \"For WGAN.\"\n    def forward(self, real, fake):\n        return real.mean() - fake.mean()\ndef simple_cnn(\n    actns: Collection[int],\n    kernel_szs: Collection[int] = None,\n    strides: Collection[int] = None,\n    bn=False,\n) -> nn.Sequential:",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BatchNorm1dFlat",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class BatchNorm1dFlat(nn.BatchNorm1d):\n    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n    def forward(self, x):\n        if x.dim() == 2:\n            return super().forward(x)\n        *f, l = x.shape\n        x = x.contiguous().view(-1, l)\n        return super().forward(x).view(*f, l)\nclass LabelSmoothingCrossEntropy(Module):\n    def __init__(self, eps: float = 0.1, reduction=\"mean\"):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "LabelSmoothingCrossEntropy",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "class LabelSmoothingCrossEntropy(Module):\n    def __init__(self, eps: float = 0.1, reduction=\"mean\"):\n        self.eps, self.reduction = eps, reduction\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        if self.reduction == \"sum\":\n            loss = -log_preds.sum()\n        else:\n            loss = -log_preds.sum(dim=-1)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PoolFlatten",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def PoolFlatten() -> nn.Sequential:\n    \"Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result.\"\n    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())\nNormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")\ndef batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "batchnorm_2d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)\n    return bn\ndef bn_drop_lin(\n    n_in: int,\n    n_out: int,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "bn_drop_lin",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def bn_drop_lin(\n    n_in: int,\n    n_out: int,\n    bn: bool = True,\n    p: float = 0.0,\n    actn: Optional[nn.Module] = None,\n):\n    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n    layers = [nn.BatchNorm1d(n_in)] if bn else []\n    if p != 0:",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv1d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def conv1d(\n    ni: int, no: int, ks: int = 1, stride: int = 1, padding: int = 0, bias: bool = False\n):\n    \"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"\n    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n    nn.init.kaiming_normal_(conv.weight)\n    if bias:\n        conv.bias.data.zero_()\n    return spectral_norm(conv)\nclass PooledSelfAttention2d(Module):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv2d",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def conv2d(\n    ni: int,\n    nf: int,\n    ks: int = 3,\n    stride: int = 1,\n    padding: int = None,\n    bias=False,\n    init: LayerFunc = nn.init.kaiming_normal_,\n) -> nn.Conv2d:\n    \"Create and initialize `nn.Conv2d` layer. `padding` defaults to `ks//2`.\"",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv2d_trans",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def conv2d_trans(\n    ni: int, nf: int, ks: int = 2, stride: int = 2, padding: int = 0, bias=False\n) -> nn.ConvTranspose2d:\n    \"Create `nn.ConvTranspose2d` layer.\"\n    return nn.ConvTranspose2d(\n        ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias\n    )\ndef relu(inplace: bool = False, leaky: float = None):\n    \"Return a relu activation, maybe `leaky` and `inplace`.\"\n    return (",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "relu",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def relu(inplace: bool = False, leaky: float = None):\n    \"Return a relu activation, maybe `leaky` and `inplace`.\"\n    return (\n        nn.LeakyReLU(inplace=inplace, negative_slope=leaky)\n        if leaky is not None\n        else nn.ReLU(inplace=inplace)\n    )\ndef conv_layer(\n    ni: int,\n    nf: int,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def conv_layer(\n    ni: int,\n    nf: int,\n    ks: int = 3,\n    stride: int = 1,\n    padding: int = None,\n    bias: bool = None,\n    is_1d: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,\n    use_activ: bool = True,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "res_block",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def res_block(\n    nf,\n    dense: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,\n    bottle: bool = False,\n    **conv_kwargs,\n):\n    \"Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.\"\n    norm2 = norm_type\n    if not dense and (norm_type == NormType.Batch):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "sigmoid_range",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def sigmoid_range(x: Tensor, low: int, high: int):\n    \"Sigmoid function with range `(low, high)`\"\n    return torch.sigmoid(x) * (high - low) + low\nclass SigmoidRange(Module):\n    \"Sigmoid module with range `(low,x_max)`\"\n    def __init__(self, low: int, high: int):\n        self.low, self.high = low, high\n    def forward(self, x):\n        return sigmoid_range(x, self.low, self.high)\nclass PartialLayer(Module):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "icnr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def icnr(x, scale=2, init=nn.init.kaiming_normal_):\n    \"ICNR init of `x`, with `scale` and `init` function.\"\n    ni, nf, h, w = x.shape\n    ni2 = int(ni / (scale**2))\n    k = init(torch.zeros([ni2, nf, h, w])).transpose(0, 1)\n    k = k.contiguous().view(ni2, nf, -1)\n    k = k.repeat(1, 1, scale**2)\n    k = k.contiguous().view([nf, ni, h, w]).transpose(0, 1)\n    x.data.copy_(k)\nclass PixelShuffle_ICNR(Module):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "CrossEntropyFlat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def CrossEntropyFlat(*args, axis: int = -1, **kwargs):\n    \"Same as `nn.CrossEntropyLoss`, but flattens input and target.\"\n    return FlattenedLoss(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\ndef BCEWithLogitsFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BCEWithLogitsFlat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def BCEWithLogitsFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BCEFlat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef MSELossFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.MSELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.MSELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "MSELossFlat",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def MSELossFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.MSELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.MSELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\nclass NoopLoss(Module):\n    \"Just returns the mean of the `output`.\"\n    def forward(self, output, *args):\n        return output.mean()\nclass WassersteinLoss(Module):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "simple_cnn",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def simple_cnn(\n    actns: Collection[int],\n    kernel_szs: Collection[int] = None,\n    strides: Collection[int] = None,\n    bn=False,\n) -> nn.Sequential:\n    \"CNN with `conv_layer` defined by `actns`, `kernel_szs` and `strides`, plus batchnorm if `bn`.\"\n    nl = len(actns) - 1\n    kernel_szs = ifnone(kernel_szs, [3] * nl)\n    strides = ifnone(strides, [2] * nl)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def trunc_normal_(x: Tensor, mean: float = 0.0, std: float = 1.0) -> Tensor:\n    \"Truncated normal initialization.\"\n    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n    return x.normal_().fmod_(2).mul_(std).add_(mean)\ndef embedding(ni: int, nf: int) -> nn.Module:\n    \"Create an embedding layer.\"\n    emb = nn.Embedding(ni, nf)\n    # See https://arxiv.org/abs/1711.09160\n    with torch.no_grad():\n        trunc_normal_(emb.weight, std=0.01)",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "embedding",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "def embedding(ni: int, nf: int) -> nn.Module:\n    \"Create an embedding layer.\"\n    emb = nn.Embedding(ni, nf)\n    # See https://arxiv.org/abs/1711.09160\n    with torch.no_grad():\n        trunc_normal_(emb.weight, std=0.01)\n    return emb\nclass BatchNorm1dFlat(nn.BatchNorm1d):\n    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n    def forward(self, x):",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "__all__ = [\n    \"AdaptiveConcatPool2d\",\n    \"BCEWithLogitsFlat\",\n    \"BCEFlat\",\n    \"MSELossFlat\",\n    \"CrossEntropyFlat\",\n    \"Debugger\",\n    \"Flatten\",\n    \"Lambda\",\n    \"PoolFlatten\",",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "NormType",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.layers",
        "description": "DL_Model.deoldify.fastai.layers",
        "peekOfCode": "NormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")\ndef batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)\n    return bn\ndef bn_drop_lin(\n    n_in: int,",
        "detail": "DL_Model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "RegMetrics",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class RegMetrics(Callback):\n    \"Stores predictions and targets to perform calculations on epoch end.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = Tensor([]), Tensor([])\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        assert (\n            last_output.numel() == last_target.numel()\n        ), \"Expected same numbers of elements in pred & targ\"\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu()))",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "R2Score",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class R2Score(RegMetrics):\n    \"Computes the R2 score (coefficient of determination).\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, r2_score(self.preds, self.targs))\nclass ExplainedVariance(RegMetrics):\n    \"Computes the explained variance.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, explained_variance(self.preds, self.targs))\nclass RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ExplainedVariance",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class ExplainedVariance(RegMetrics):\n    \"Computes the explained variance.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, explained_variance(self.preds, self.targs))\nclass RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(\n            last_metrics, root_mean_squared_error(self.preds, self.targs)\n        )",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "RMSE",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(\n            last_metrics, root_mean_squared_error(self.preds, self.targs)\n        )\nclass ExpRMSPE(RegMetrics):\n    \"Computes the exponential of the root mean square error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, exp_rmspe(self.preds, self.targs))",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ExpRMSPE",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class ExpRMSPE(RegMetrics):\n    \"Computes the exponential of the root mean square error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, exp_rmspe(self.preds, self.targs))\n# Aliases\nmse = mean_squared_error\nmae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.cpu()\n        if self.n_classes == 0:",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "CMScores",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class CMScores(ConfusionMatrix):\n    \"Base class for metrics which rely on the calculation of the precision and/or recall score.\"\n    average: Optional[str] = \"binary\"  # `binary`, `micro`, `macro`, `weigthed` or None\n    pos_label: int = 1  # 0 or 1\n    eps: float = 1e-9\n    def _recall(self):\n        rec = torch.diag(self.cm) / self.cm.sum(dim=1)\n        if self.average is None:\n            return rec\n        else:",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Recall",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class Recall(CMScores):\n    \"Computes the Recall.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._recall())\nclass Precision(CMScores):\n    \"Computes the Precision.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._precision())\n@dataclass\nclass FBeta(CMScores):",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Precision",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class Precision(CMScores):\n    \"Computes the Precision.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._precision())\n@dataclass\nclass FBeta(CMScores):\n    \"Computes the F`beta` score.\"\n    beta: float = 2\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "FBeta",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class FBeta(CMScores):\n    \"Computes the F`beta` score.\"\n    beta: float = 2\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n        self.beta2 = self.beta**2\n        self.avg = self.average\n        if self.average != \"micro\":\n            self.average = None\n    def on_epoch_end(self, last_metrics, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "KappaScore",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class KappaScore(ConfusionMatrix):\n    \"Computes the rate of agreement (Cohens Kappa).\"\n    weights: Optional[str] = None  # None, `linear`, or `quadratic`\n    def on_epoch_end(self, last_metrics, **kwargs):\n        sum0 = self.cm.sum(dim=0)\n        sum1 = self.cm.sum(dim=1)\n        expected = torch.einsum(\"i,j->ij\", (sum0, sum1)) / sum0.sum()\n        if self.weights is None:\n            w = torch.ones((self.n_classes, self.n_classes))\n            w[self.x, self.x] = 0",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "MatthewsCorreff",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class MatthewsCorreff(ConfusionMatrix):\n    \"Computes the Matthews correlation coefficient.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        t_sum = self.cm.sum(dim=1)\n        p_sum = self.cm.sum(dim=0)\n        n_correct = torch.trace(self.cm)\n        n_samples = p_sum.sum()\n        cov_ytyp = n_correct * n_samples - torch.dot(t_sum, p_sum)\n        cov_ypyp = n_samples**2 - torch.dot(p_sum, p_sum)\n        cov_ytyt = n_samples**2 - torch.dot(t_sum, t_sum)",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Perplexity",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class Perplexity(Callback):\n    \"Perplexity metric for language models.\"\n    def on_epoch_begin(self, **kwargs):\n        self.loss, self.len = 0.0, 0\n    def on_batch_end(self, last_output, last_target, **kwargs):\n        self.loss += last_target.size(1) * CrossEntropyFlat()(last_output, last_target)\n        self.len += last_target.size(1)\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, torch.exp(self.loss / self.len))\ndef auc_roc_score(input: Tensor, targ: Tensor):",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "AUROC",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class AUROC(Callback):\n    \"Computes the area under the curve (AUC) score based on the receiver operator characteristic (ROC) curve. Restricted to binary classification tasks.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = LongTensor([]), Tensor([])\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        last_output = F.softmax(last_output, dim=1)[:, -1]\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu().long()))\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, auc_roc_score(self.preds, self.targs))",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "MultiLabelFbeta",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "class MultiLabelFbeta(LearnerCallback):\n    \"Computes the fbeta score for multilabel classification\"\n    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n    _order = -20\n    def __init__(\n        self, learn, beta=2, eps=1e-15, thresh=0.3, sigmoid=True, average=\"micro\"\n    ):\n        super().__init__(learn)\n        self.eps, self.thresh, self.sigmoid, self.average, self.beta2 = (\n            eps,",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "fbeta",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def fbeta(\n    y_pred: Tensor,\n    y_true: Tensor,\n    thresh: float = 0.2,\n    beta: float = 2,\n    eps: float = 1e-9,\n    sigmoid: bool = True,\n) -> Rank0Tensor:\n    \"Computes the f_beta between `preds` and `targets`\"\n    beta2 = beta**2",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def accuracy(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=-1).view(n, -1)\n    targs = targs.view(n, -1)\n    return (input == targs).float().mean()\ndef accuracy_thresh(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Computes accuracy when `y_pred` and `y_true` are the same size.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_thresh",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def accuracy_thresh(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Computes accuracy when `y_pred` and `y_true` are the same size.\"\n    if sigmoid:\n        y_pred = y_pred.sigmoid()\n    return ((y_pred > thresh) == y_true.byte()).float().mean()\ndef top_k_accuracy(input: Tensor, targs: Tensor, k: int = 5) -> Rank0Tensor:\n    \"Computes the Top-k accuracy (target is in the top k predictions).\"\n    input = input.topk(k=k, dim=-1)[1]",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "top_k_accuracy",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def top_k_accuracy(input: Tensor, targs: Tensor, k: int = 5) -> Rank0Tensor:\n    \"Computes the Top-k accuracy (target is in the top k predictions).\"\n    input = input.topk(k=k, dim=-1)[1]\n    targs = targs.unsqueeze(dim=-1).expand_as(input)\n    return (input == targs).max(dim=-1)[0].float().mean()\ndef foreground_acc(input, target, void_code):\n    \"Computes non-background accuracy, e.g. camvid for multiclass segmentation\"\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask] == target[mask]).float().mean()",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "foreground_acc",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def foreground_acc(input, target, void_code):\n    \"Computes non-background accuracy, e.g. camvid for multiclass segmentation\"\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask] == target[mask]).float().mean()\ndef error_rate(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"1 - `accuracy`\"\n    return 1 - accuracy(input, targs)\ndef dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "error_rate",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def error_rate(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"1 - `accuracy`\"\n    return 1 - accuracy(input, targs)\ndef dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8\n) -> Rank0Tensor:\n    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n, -1)\n    targs = targs.view(n, -1)",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "dice",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8\n) -> Rank0Tensor:\n    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n, -1)\n    targs = targs.view(n, -1)\n    intersect = (input * targs).sum().float()\n    union = (input + targs).sum().float()\n    if not iou:",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "psnr",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def psnr(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    return 10 * (1.0 / mean_squared_error(input, targs)).log10()\ndef exp_rmspe(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Exp RMSE between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    pred, targ = torch.exp(pred), torch.exp(targ)\n    pct_var = (targ - pred) / targ\n    return torch.sqrt((pct_var**2).mean())\ndef mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "exp_rmspe",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def exp_rmspe(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Exp RMSE between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    pred, targ = torch.exp(pred), torch.exp(targ)\n    pct_var = (targ - pred) / targ\n    return torch.sqrt((pct_var**2).mean())\ndef mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.abs(targ - pred).mean()",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.abs(targ - pred).mean()\ndef mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(pred, targ)\ndef root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(pred, targ)\ndef root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.sqrt(F.mse_loss(pred, targ))\ndef mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "root_mean_squared_error",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.sqrt(F.mse_loss(pred, targ))\ndef mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(torch.log(1 + pred), torch.log(1 + targ))\ndef explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_logarithmic_error",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(torch.log(1 + pred), torch.log(1 + targ))\ndef explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    var_pct = torch.var(targ - pred) / torch.var(targ)\n    return 1 - var_pct\ndef r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "explained_variance",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    var_pct = torch.var(targ - pred) / torch.var(targ)\n    return 1 - var_pct\ndef r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"R2 score (coefficient of determination) between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    u = torch.sum((targ - pred) ** 2)\n    d = torch.sum((targ - targ.mean()) ** 2)",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"R2 score (coefficient of determination) between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    u = torch.sum((targ - pred) ** 2)\n    d = torch.sum((targ - targ.mean()) ** 2)\n    return 1 - u / d\nclass RegMetrics(Callback):\n    \"Stores predictions and targets to perform calculations on epoch end.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = Tensor([]), Tensor([])",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "auc_roc_score",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def auc_roc_score(input: Tensor, targ: Tensor):\n    \"Computes the area under the receiver operator characteristic (ROC) curve using the trapezoid method. Restricted binary classification tasks.\"\n    fpr, tpr = roc_curve(input, targ)\n    d = fpr[1:] - fpr[:-1]\n    sl1, sl2 = [slice(None)], [slice(None)]\n    sl1[-1], sl2[-1] = slice(1, None), slice(None, -1)\n    return (d * (tpr[tuple(sl1)] + tpr[tuple(sl2)]) / 2.0).sum(-1)\ndef roc_curve(input: Tensor, targ: Tensor):\n    \"Computes the receiver operator characteristic (ROC) curve by determining the true positive ratio (TPR) and false positive ratio (FPR) for various classification thresholds. Restricted binary classification tasks.\"\n    targ = targ == 1",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "def roc_curve(input: Tensor, targ: Tensor):\n    \"Computes the receiver operator characteristic (ROC) curve by determining the true positive ratio (TPR) and false positive ratio (FPR) for various classification thresholds. Restricted binary classification tasks.\"\n    targ = targ == 1\n    desc_score_indices = torch.flip(input.argsort(-1), [-1])\n    input = input[desc_score_indices]\n    targ = targ[desc_score_indices]\n    d = input[1:] - input[:-1]\n    distinct_value_indices = torch.nonzero(d).transpose(0, 1)[0]\n    threshold_idxs = torch.cat(\n        (distinct_value_indices, LongTensor([len(targ) - 1]).to(targ.device))",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "__all__ = [\n    \"error_rate\",\n    \"accuracy\",\n    \"accuracy_thresh\",\n    \"dice\",\n    \"exp_rmspe\",\n    \"fbeta\",\n    \"FBeta\",\n    \"mse\",\n    \"mean_squared_error\",",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "mse = mean_squared_error\nmae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mae",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "mae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "msle",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "msle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.metrics",
        "description": "DL_Model.deoldify.fastai.metrics",
        "peekOfCode": "rmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.cpu()",
        "detail": "DL_Model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Param",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.script",
        "description": "DL_Model.deoldify.fastai.script",
        "peekOfCode": "class Param:\n    \"A parameter in a function used in `anno_parser` or `call_parse`\"\n    help: str = None\n    type: type = None\n    opt: bool = True\n    action: str = None\n    nargs: str = None\n    const: str = None\n    choices: str = None\n    required: bool = None",
        "detail": "DL_Model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "anno_parser",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.script",
        "description": "DL_Model.deoldify.fastai.script",
        "peekOfCode": "def anno_parser(func):\n    \"Look at params (annotated with `Param`) in func and return an `ArgumentParser`\"\n    p = ArgumentParser(description=func.__doc__)\n    for k, v in inspect.signature(func).parameters.items():\n        param = func.__annotations__.get(k, Param())\n        kwargs = param.kwargs\n        if v.default != inspect.Parameter.empty:\n            kwargs[\"default\"] = v.default\n        p.add_argument(f\"{param.pre}{k}\", **kwargs)\n    return p",
        "detail": "DL_Model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "call_parse",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.script",
        "description": "DL_Model.deoldify.fastai.script",
        "peekOfCode": "def call_parse(func):\n    \"Decorator to create a simple CLI from `func` using `anno_parser`\"\n    name = inspect.currentframe().f_back.f_globals[\"__name__\"]\n    if name == \"__main__\":\n        args = anno_parser(func).parse_args()\n        func(**args.__dict__)\n    else:\n        return func\ndef call_plac(f):\n    \"Decorator to create a simple CLI from `func` using `plac`\"",
        "detail": "DL_Model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "call_plac",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.script",
        "description": "DL_Model.deoldify.fastai.script",
        "peekOfCode": "def call_plac(f):\n    \"Decorator to create a simple CLI from `func` using `plac`\"\n    name = inspect.currentframe().f_back.f_globals[\"__name__\"]\n    if name == \"__main__\":\n        import plac\n        res = plac.call(f)\n        if callable(res):\n            res()\n    else:\n        return f",
        "detail": "DL_Model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "plot_sixel",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.sixel",
        "description": "DL_Model.deoldify.fastai.sixel",
        "peekOfCode": "def plot_sixel(fig=None):\n    if not libsixel:\n        warn(\n            \"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\"\n        )\n        return\n    if fig is None:\n        fig = plt.gcf()\n    fig.canvas.draw()\n    dpi = fig.get_dpi()",
        "detail": "DL_Model.deoldify.fastai.sixel",
        "documentation": {}
    },
    {
        "label": "libsixel",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.sixel",
        "description": "DL_Model.deoldify.fastai.sixel",
        "peekOfCode": "libsixel = try_import(\"libsixel\")\ndef _sixel_encode(data, width, height):\n    s = io.BytesIO()\n    output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)\n    dither = libsixel.sixel_dither_new(256)\n    w, h = int(width), int(height)\n    libsixel.sixel_dither_initialize(\n        dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888\n    )\n    libsixel.sixel_encode(data, w, h, 1, dither, output)",
        "detail": "DL_Model.deoldify.fastai.sixel",
        "documentation": {}
    },
    {
        "label": "Module",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "class Module(nn.Module, metaclass=PrePostInitMeta):\n    \"Same as `nn.Module`, but no need for subclasses to call `super().__init__`\"\n    def __pre_init__(self):\n        super().__init__()\n    def __init__(self):\n        pass\ndef np_address(x: np.ndarray) -> int:\n    \"Address of `x` in memory.\"\n    return x.__array_interface__[\"data\"][0]\ndef to_detach(b: Tensors, cpu: bool = True):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ParameterModule",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "class ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p\n    def forward(self, x):\n        return x\ndef children_and_parameters(m: nn.Module):\n    \"Return the children of `m` and its direct parameters not registered in modules.\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ModelOnCPU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "class ModelOnCPU:\n    \"A context manager to evaluate `model` on the CPU inside.\"\n    def __init__(self, model: nn.Module):\n        self.model = model\n    def __enter__(self):\n        self.device = one_param(self.model).device\n        return self.model.cpu()\n    def __exit__(self, type, value, traceback):\n        self.model = self.model.to(self.device)\nclass NoneReduceOnCPU:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "NoneReduceOnCPU",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "class NoneReduceOnCPU:\n    \"A context manager to evaluate `loss_func` with none reduce and weights on the CPU inside.\"\n    def __init__(self, loss_func: LossFunction):\n        self.loss_func, self.device, self.old_red = loss_func, None, None\n    def __enter__(self):\n        if hasattr(self.loss_func, \"weight\") and self.loss_func.weight is not None:\n            self.device = self.loss_func.weight.device\n            self.loss_func.weight = self.loss_func.weight.cpu()\n        if hasattr(self.loss_func, \"reduction\"):\n            self.old_red = getattr(self.loss_func, \"reduction\")",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "is_pool_type",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def is_pool_type(l: Callable):\n    return re.search(r\"Pool[123]d$\", l.__class__.__name__)\nno_wd_types = bn_types + (nn.LayerNorm,)\ndefaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "tensor",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):\n        x = (x,) + rest\n    # XXX: Pytorch bug in dataloader using num_workers>0; TODO: create repro and report\n    if is_listy(x) and len(x) == 0:\n        return tensor(0)\n    res = torch.tensor(x) if is_listy(x) else as_tensor(x)\n    if res.dtype is torch.int32:\n        warn(",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np_address",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def np_address(x: np.ndarray) -> int:\n    \"Address of `x` in memory.\"\n    return x.__array_interface__[\"data\"][0]\ndef to_detach(b: Tensors, cpu: bool = True):\n    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n    def _inner(x, cpu=True):\n        if not isinstance(x, Tensor):\n            return x\n        x = x.detach()\n        return x.cpu() if cpu else x",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_detach",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_detach(b: Tensors, cpu: bool = True):\n    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n    def _inner(x, cpu=True):\n        if not isinstance(x, Tensor):\n            return x\n        x = x.detach()\n        return x.cpu() if cpu else x\n    return recurse(_inner, b, cpu=cpu)\ndef to_data(b: ItemsList):\n    \"Recursively map lists of items in `b ` to their wrapped data.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_data",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_data(b: ItemsList):\n    \"Recursively map lists of items in `b ` to their wrapped data.\"\n    return recurse(lambda x: x.data if isinstance(x, ItemBase) else x, b)\ndef to_cpu(b: ItemsList):\n    \"Recursively map lists of tensors in `b ` to the cpu.\"\n    return recurse(lambda x: x.cpu() if isinstance(x, Tensor) else x, b)\ndef to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_cpu",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_cpu(b: ItemsList):\n    \"Recursively map lists of tensors in `b ` to the cpu.\"\n    return recurse(lambda x: x.cpu() if isinstance(x, Tensor) else x, b)\ndef to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_half",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,\n    )\ndef to_float(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_float",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_float(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.float()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,\n    )\ndef to_device(b: Tensors, device: torch.device):\n    \"Recursively put `b` on `device`.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_device",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_device(b: Tensors, device: torch.device):\n    \"Recursively put `b` on `device`.\"\n    device = ifnone(device, defaults.device)\n    return recurse(lambda x: x.to(device, non_blocking=True), b)\ndef data_collate(batch: ItemsList) -> Tensor:\n    \"Convert `batch` items to tensor data.\"\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\ndef requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "data_collate",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def data_collate(batch: ItemsList) -> Tensor:\n    \"Convert `batch` items to tensor data.\"\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\ndef requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())\n    if not ps:\n        return None\n    if b is None:\n        return ps[0].requires_grad",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "requires_grad",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())\n    if not ps:\n        return None\n    if b is None:\n        return ps[0].requires_grad\n    for p in ps:\n        p.requires_grad = b\ndef trainable_params(m: nn.Module) -> ParamList:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "trainable_params",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def trainable_params(m: nn.Module) -> ParamList:\n    \"Return list of trainable params in `m`.\"\n    res = filter(lambda p: p.requires_grad, m.parameters())\n    return res\ndef children(m: nn.Module) -> ModuleList:\n    \"Get children of `m`.\"\n    return list(m.children())\ndef num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "children",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def children(m: nn.Module) -> ModuleList:\n    \"Get children of `m`.\"\n    return list(m.children())\ndef num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))\ndef range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "num_children",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))\ndef range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "range_children",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p\n    def forward(self, x):\n        return x\ndef children_and_parameters(m: nn.Module):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "children_and_parameters",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def children_and_parameters(m: nn.Module):\n    \"Return the children of `m` and its direct parameters not registered in modules.\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])\n    for p in m.parameters():\n        if id(p) not in children_p:\n            children.append(ParameterModule(p))\n    return children\ndef flatten_model(m: nn.Module):\n    if num_children(m):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "flatten_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def flatten_model(m: nn.Module):\n    if num_children(m):\n        mapped = map(flatten_model, children_and_parameters(m))\n        return sum(mapped, [])\n    else:\n        return [m]\n# flatten_model = lambda m: sum(map(flatten_model,children_and_parameters(m)),[]) if num_children(m) else [m]\ndef first_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve first layer in a module `m`.\"\n    return flatten_model(m)[0]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "first_layer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def first_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve first layer in a module `m`.\"\n    return flatten_model(m)[0]\ndef last_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve last layer in a module `m`.\"\n    return flatten_model(m)[-1]\ndef split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "last_layer",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def last_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve last layer in a module `m`.\"\n    return flatten_model(m)[-1]\ndef split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:\n        idxs = [0] + idxs\n    if idxs[-1] != len(layers):\n        idxs.append(len(layers))",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_model_idx",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:\n        idxs = [0] + idxs\n    if idxs[-1] != len(layers):\n        idxs.append(len(layers))\n    return [nn.Sequential(*layers[i:j]) for i, j in zip(idxs[:-1], idxs[1:])]\ndef split_model(\n    model: nn.Module = None, splits: Collection[Union[nn.Module, ModuleList]] = None",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_model(\n    model: nn.Module = None, splits: Collection[Union[nn.Module, ModuleList]] = None\n):\n    \"Split `model` according to the layers in `splits`.\"\n    splits = listify(splits)\n    if isinstance(splits[0], nn.Module):\n        layers = flatten_model(model)\n        idxs = [layers.index(first_layer(s)) for s in splits]\n        return split_model_idx(model, idxs)\n    return [nn.Sequential(*s) for s in splits]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "get_param_groups",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def get_param_groups(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    return [\n        sum([list(trainable_params(c)) for c in l.children()], []) for l in layer_groups\n    ]\ndef split_no_wd_params(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    \"Separate the parameters in `layer_groups` between `no_wd_types` and  bias (`bias_types`) from the rest.\"\n    split_params = []\n    for l in layer_groups:\n        l1, l2 = [], []\n        for c in l.children():",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_no_wd_params",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_no_wd_params(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    \"Separate the parameters in `layer_groups` between `no_wd_types` and  bias (`bias_types`) from the rest.\"\n    split_params = []\n    for l in layer_groups:\n        l1, l2 = [], []\n        for c in l.children():\n            if isinstance(c, no_wd_types):\n                l2 += list(trainable_params(c))\n            elif isinstance(c, bias_types):\n                bias = c.bias if hasattr(c, \"bias\") else None",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "set_bn_eval",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def set_bn_eval(m: nn.Module) -> None:\n    \"Set bn layers in eval mode for all recursive children of `m`.\"\n    for l in m.children():\n        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n            l.eval()\n        set_bn_eval(l)\ndef batch_to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Set the input of batch `b` to half precision.\"\n    return [to_half(b[0]), b[1]]\ndef bn2float(module: nn.Module) -> nn.Module:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "batch_to_half",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def batch_to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Set the input of batch `b` to half precision.\"\n    return [to_half(b[0]), b[1]]\ndef bn2float(module: nn.Module) -> nn.Module:\n    \"If `module` is batchnorm don't use half precision.\"\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        bn2float(child)\n    return module",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bn2float",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def bn2float(module: nn.Module) -> nn.Module:\n    \"If `module` is batchnorm don't use half precision.\"\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        bn2float(child)\n    return module\ndef model2half(model: nn.Module) -> nn.Module:\n    \"Convert `model` to half precision except the batchnorm layers.\"\n    return bn2float(model.half())",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "model2half",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def model2half(model: nn.Module) -> nn.Module:\n    \"Convert `model` to half precision except the batchnorm layers.\"\n    return bn2float(model.half())\ndef init_default(m: nn.Module, func: LayerFunc = nn.init.kaiming_normal_) -> nn.Module:\n    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n    if func:\n        if hasattr(m, \"weight\"):\n            func(m.weight)\n        if hasattr(m, \"bias\") and hasattr(m.bias, \"data\"):\n            m.bias.data.fill_(0.0)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "init_default",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def init_default(m: nn.Module, func: LayerFunc = nn.init.kaiming_normal_) -> nn.Module:\n    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n    if func:\n        if hasattr(m, \"weight\"):\n            func(m.weight)\n        if hasattr(m, \"bias\") and hasattr(m.bias, \"data\"):\n            m.bias.data.fill_(0.0)\n    return m\ndef cond_init(m: nn.Module, init_func: LayerFunc):\n    \"Initialize the non-batchnorm layers of `m` with `init_func`.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "cond_init",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def cond_init(m: nn.Module, init_func: LayerFunc):\n    \"Initialize the non-batchnorm layers of `m` with `init_func`.\"\n    if (not isinstance(m, bn_types)) and requires_grad(m):\n        init_default(m, init_func)\ndef apply_leaf(m: nn.Module, f: LayerFunc):\n    \"Apply `f` to children of `m`.\"\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    for l in c:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_leaf",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def apply_leaf(m: nn.Module, f: LayerFunc):\n    \"Apply `f` to children of `m`.\"\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    for l in c:\n        apply_leaf(l, f)\ndef apply_init(m, init_func: LayerFunc):\n    \"Initialize all non-batchnorm layers of `m` with `init_func`.\"\n    apply_leaf(m, partial(cond_init, init_func=init_func))",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_init",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def apply_init(m, init_func: LayerFunc):\n    \"Initialize all non-batchnorm layers of `m` with `init_func`.\"\n    apply_leaf(m, partial(cond_init, init_func=init_func))\ndef in_channels(m: nn.Module) -> List[int]:\n    \"Return the shape of the first weight layer in `m`.\"\n    for l in flatten_model(m):\n        if hasattr(l, \"weight\"):\n            return l.weight.shape[1]\n    raise Exception(\"No weight layer\")\nclass ModelOnCPU:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "in_channels",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def in_channels(m: nn.Module) -> List[int]:\n    \"Return the shape of the first weight layer in `m`.\"\n    for l in flatten_model(m):\n        if hasattr(l, \"weight\"):\n            return l.weight.shape[1]\n    raise Exception(\"No weight layer\")\nclass ModelOnCPU:\n    \"A context manager to evaluate `model` on the CPU inside.\"\n    def __init__(self, model: nn.Module):\n        self.model = model",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "model_type",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def model_type(dtype):\n    \"Return the torch type corresponding to `dtype`.\"\n    return (\n        torch.float32\n        if np.issubdtype(dtype, np.floating)\n        else torch.int64\n        if np.issubdtype(dtype, np.integer)\n        else None\n    )\ndef np2model_tensor(a):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np2model_tensor",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def np2model_tensor(a):\n    \"Tranform numpy array `a` to a tensor of the same type.\"\n    dtype = model_type(a.dtype)\n    res = as_tensor(a)\n    if not dtype:\n        return res\n    return res.type(dtype)\ndef _pca(x, k=2):\n    \"Compute PCA of `x` with `k` dimensions.\"\n    x = x - torch.mean(x, 0)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "trange_of",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def trange_of(x):\n    \"Create a tensor from `range_of(x)`.\"\n    return torch.arange(len(x))\ndef to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_np",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:\n        return res\n    else:\n        return res.astype(dtype, copy=False)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "tensor__array__",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:\n        return res\n    else:\n        return res.astype(dtype, copy=False)\nTensor.__array__ = tensor__array__\nTensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "grab_idx",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)\n    return -(1 / x - 1).log()",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "logit",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)\n    return -(1 / x - 1).log()\ndef logit_(x: Tensor) -> Tensor:\n    \"Inplace logit of `x`, clamped to avoid inf\"\n    x.clamp_(1e-7, 1 - 1e-7)\n    return (x.reciprocal_().sub_(1)).log_().neg_()\ndef set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "logit_",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def logit_(x: Tensor) -> Tensor:\n    \"Inplace logit of `x`, clamped to avoid inf\"\n    x.clamp_(1e-7, 1 - 1e-7)\n    return (x.reciprocal_().sub_(1)).log_().neg_()\ndef set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\ndef uniform(",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "set_all_seed",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\ndef uniform(\n    low: Number, high: Number = None, size: Optional[List[int]] = None\n) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.\"\n    if high is None:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "uniform",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def uniform(\n    low: Number, high: Number = None, size: Optional[List[int]] = None\n) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.\"\n    if high is None:\n        high = low\n    return (\n        random.uniform(low, high)\n        if size is None\n        else torch.FloatTensor(*listify(size)).uniform_(low, high)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "log_uniform",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def log_uniform(low, high, size: Optional[List[int]] = None) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).\"\n    res = uniform(log(low), log(high), size)\n    return exp(res) if size is None else res.exp_()\ndef rand_bool(p: float, size: Optional[List[int]] = None) -> BoolOrTensor:\n    \"Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).\"\n    return uniform(0, 1, size) < p\ndef uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "rand_bool",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def rand_bool(p: float, size: Optional[List[int]] = None) -> BoolOrTensor:\n    \"Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).\"\n    return uniform(0, 1, size) < p\ndef uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (\n        random.randint(low, high)\n        if size is None\n        else torch.randint(low, high + 1, size)\n    )",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "uniform_int",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (\n        random.randint(low, high)\n        if size is None\n        else torch.randint(low, high + 1, size)\n    )\ndef one_param(m: nn.Module) -> Tensor:\n    \"Return the first parameter of `m`.\"\n    return next(m.parameters())",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "one_param",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def one_param(m: nn.Module) -> Tensor:\n    \"Return the first parameter of `m`.\"\n    return next(m.parameters())\ndef try_int(o: Any) -> Any:\n    \"Try to convert `o` to int, default to `o` if not possible.\"\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don't want to do this\n    if isinstance(o, (np.ndarray, Tensor)):\n        return o if o.ndim else int(o)\n    if isinstance(o, collections.abc.Sized) or getattr(o, \"__array_interface__\", False):\n        return o",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "try_int",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def try_int(o: Any) -> Any:\n    \"Try to convert `o` to int, default to `o` if not possible.\"\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don't want to do this\n    if isinstance(o, (np.ndarray, Tensor)):\n        return o if o.ndim else int(o)\n    if isinstance(o, collections.abc.Sized) or getattr(o, \"__array_interface__\", False):\n        return o\n    try:\n        return int(o)\n    except:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def get_model(model: nn.Module):\n    \"Return the model maybe wrapped inside `model`.\"\n    return (\n        model.module\n        if isinstance(model, (DistributedDataParallel, nn.DataParallel))\n        else model\n    )\ndef flatten_check(out: Tensor, targ: Tensor) -> Tensor:\n    \"Check that `out` and `targ` have the same number of elements and flatten them.\"\n    out, targ = out.contiguous().view(-1), targ.contiguous().view(-1)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "flatten_check",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def flatten_check(out: Tensor, targ: Tensor) -> Tensor:\n    \"Check that `out` and `targ` have the same number of elements and flatten them.\"\n    out, targ = out.contiguous().view(-1), targ.contiguous().view(-1)\n    assert len(out) == len(\n        targ\n    ), f\"Expected output and target to have the same number of elements but got {len(out)} and {len(targ)}.\"\n    return out, targ\n# Monkey-patch nn.DataParallel.reset\ndef _data_parallel_reset(self):\n    if hasattr(self.module, \"reset\"):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "remove_module_load",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def remove_module_load(state_dict):\n    \"\"\"create new OrderedDict that does not contain `module.`\"\"\"\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        new_state_dict[k[7:]] = v\n    return new_state_dict\ndef num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))\ndef rank_distrib():",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "num_distrib",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))\ndef rank_distrib():\n    \"Return the distributed rank of this process (if applicable).\"\n    return int(os.environ.get(\"RANK\", 0))\ndef add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "rank_distrib",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def rank_distrib():\n    \"Return the distributed rank of this process (if applicable).\"\n    return int(os.environ.get(\"RANK\", 0))\ndef add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):\n    \"Return a dictionary for updating `last_metrics` with `mets`.\"\n    last_metrics, mets = listify(last_metrics), listify(mets)\n    return {\"last_metrics\": last_metrics + mets}",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "add_metrics",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):\n    \"Return a dictionary for updating `last_metrics` with `mets`.\"\n    last_metrics, mets = listify(last_metrics), listify(mets)\n    return {\"last_metrics\": last_metrics + mets}\ndef try_save(state: Dict, path: Path = None, file: PathLikeOrBinaryStream = None):\n    target = open(path / file, \"wb\") if is_pathlike(file) else file\n    try:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "try_save",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def try_save(state: Dict, path: Path = None, file: PathLikeOrBinaryStream = None):\n    target = open(path / file, \"wb\") if is_pathlike(file) else file\n    try:\n        torch.save(state, target)\n    except OSError as e:\n        raise Exception(\n            f\"{e}\\n Can't write {path/file}. Pass an absolute writable pathlib obj `fname`.\"\n        )\ndef np_func(f):\n    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np_func",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "def np_func(f):\n    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"\n    def _inner(*args, **kwargs):\n        nargs = [to_np(arg) if isinstance(arg, Tensor) else arg for arg in args]\n        return tensor(f(*nargs, **kwargs))\n    functools.update_wrapper(_inner, f)\n    return _inner",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AffineMatrix",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "AffineMatrix = Tensor\nBoolOrTensor = Union[bool, Tensor]\nFloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "BoolOrTensor",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "BoolOrTensor = Union[bool, Tensor]\nFloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "FloatOrTensor",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "FloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "IntOrTensor",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "IntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ItemsList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "ItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LambdaFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "LambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LayerFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "LayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "ModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "NPArray",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "NPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptOptimizer",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "OptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ParamList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "ParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Rank0Tensor",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "Rank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "SplitFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "SplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "SplitFuncOrIdxList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "SplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorOrNumber",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorOrNumList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorImage",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorImageSize",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensors",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Weights",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "Weights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AffineFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "AffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "HookFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "HookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LogitTensorImage",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "LogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LossFunction",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "LossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricFuncList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricsList",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptLossFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "OptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptMetrics",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "OptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptSplitFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "OptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "PixelFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "PixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LightingFunc",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "LightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",\n    KeyFunc: \"KeyFunc\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "fastai_types",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "fastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",\n    KeyFunc: \"KeyFunc\",\n    KWArgs: \"KWArgs\",",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bn_types",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\nbias_types = (\n    nn.Linear,\n    nn.Conv1d,\n    nn.Conv2d,\n    nn.Conv3d,\n    nn.ConvTranspose1d,\n    nn.ConvTranspose2d,\n    nn.ConvTranspose3d,\n)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bias_types",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "bias_types = (\n    nn.Linear,\n    nn.Conv1d,\n    nn.Conv2d,\n    nn.Conv3d,\n    nn.ConvTranspose1d,\n    nn.ConvTranspose2d,\n    nn.ConvTranspose3d,\n)\ndef is_pool_type(l: Callable):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "no_wd_types",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "no_wd_types = bn_types + (nn.LayerNorm,)\ndefaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "defaults.device",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "defaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "AdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device\n    )\ntorch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "_old_torch_cuda_set_device",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device\n    )\ntorch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "torch.cuda.set_device",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "torch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):\n        x = (x,) + rest\n    # XXX: Pytorch bug in dataloader using num_workers>0; TODO: create repro and report\n    if is_listy(x) and len(x) == 0:\n        return tensor(0)\n    res = torch.tensor(x) if is_listy(x) else as_tensor(x)\n    if res.dtype is torch.int32:",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "torch.Tensor.pca",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "torch.Tensor.pca = _pca\ndef trange_of(x):\n    \"Create a tensor from `range_of(x)`.\"\n    return torch.arange(len(x))\ndef to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensor.__array__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensor.__array__ = tensor__array__\nTensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensor.ndim",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "nn.DataParallel.reset",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.torch_core",
        "description": "DL_Model.deoldify.fastai.torch_core",
        "peekOfCode": "nn.DataParallel.reset = _data_parallel_reset\ndef remove_module_load(state_dict):\n    \"\"\"create new OrderedDict that does not contain `module.`\"\"\"\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        new_state_dict[k[7:]] = v\n    return new_state_dict\ndef num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))",
        "detail": "DL_Model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ShowGraph",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()\n            x_bounds = (\n                0,",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "BnFreeze",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class BnFreeze(LearnerCallback):\n    \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n    def on_epoch_begin(self, **kwargs: Any) -> None:\n        \"Put bn layers in eval mode just after `model.train()`.\"\n        set_bn_eval(self.learn.model)\nclass GradientClipping(LearnerCallback):\n    \"Gradient clipping during training.\"\n    def __init__(self, learn: Learner, clip: float = 0.0):\n        super().__init__(learn)\n        self.clip = clip",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "GradientClipping",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class GradientClipping(LearnerCallback):\n    \"Gradient clipping during training.\"\n    def __init__(self, learn: Learner, clip: float = 0.0):\n        super().__init__(learn)\n        self.clip = clip\n    def on_backward_end(self, **kwargs):\n        \"Clip the gradient before the optimizer step.\"\n        if self.clip:\n            nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)\ndef clip_grad(learn: Learner, clip: float = 0.1) -> Learner:",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "AccumulateScheduler",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last\n    def on_train_begin(self, **kwargs):\n        \"check if loss is reduction\"\n        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n            warn(\"For better gradients consider 'reduction=sum'\")\n    def on_epoch_begin(self, **kwargs):",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Interpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class Interpretation:\n    \"Interpretation base class, can be inherited for task specific Interpretation classes\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class ClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "MultiLabelClassificationInterpretation",
        "kind": 6,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "class MultiLabelClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n        sigmoid: bool = True,",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "one_cycle_scheduler",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def one_cycle_scheduler(lr_max: float, **kwargs: Any) -> OneCycleScheduler:\n    \"Instantiate a `OneCycleScheduler` with `lr_max`.\"\n    return partial(OneCycleScheduler, lr_max=lr_max, **kwargs)\ndef fit_one_cycle(\n    learn: Learner,\n    cyc_len: int,\n    max_lr: Union[Floats, slice] = defaults.lr,\n    moms: Tuple[float, float] = (0.95, 0.85),\n    div_factor: float = 25.0,\n    pct_start: float = 0.3,",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "fit_one_cycle",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def fit_one_cycle(\n    learn: Learner,\n    cyc_len: int,\n    max_lr: Union[Floats, slice] = defaults.lr,\n    moms: Tuple[float, float] = (0.95, 0.85),\n    div_factor: float = 25.0,\n    pct_start: float = 0.3,\n    final_div: float = None,\n    wd: float = None,\n    callbacks: Optional[CallbackList] = None,",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "lr_find",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def lr_find(\n    learn: Learner,\n    start_lr: Floats = 1e-7,\n    end_lr: Floats = 10,\n    num_it: int = 100,\n    stop_div: bool = True,\n    wd: float = None,\n    batch_multiplier: int = 1,\n):\n    \"Explore lr from `start_lr` to `end_lr` over `num_it` iterations in `learn`. If `stop_div`, stops when loss diverges.\"",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "to_fp16",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def to_fp16(\n    learn: Learner,\n    loss_scale: float = None,\n    max_noskip: int = 1000,\n    dynamic: bool = True,\n    clip: float = None,\n    flat_master: bool = False,\n    max_scale: float = 2**24,\n) -> Learner:\n    \"Put `learn` in FP16 precision mode.\"",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "to_fp32",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def to_fp32(learn: Learner):\n    \"Put `learn` back to FP32 precision mode.\"\n    learn.data.remove_tfm(batch_to_half)\n    for cb in learn.callbacks:\n        if isinstance(cb, MixedPrecision):\n            learn.callbacks.remove(cb)\n    learn.model = learn.model.float()\n    return learn\ndef mixup(\n    learn: Learner, alpha: float = 0.4, stack_x: bool = False, stack_y: bool = True",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "mixup",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def mixup(\n    learn: Learner, alpha: float = 0.4, stack_x: bool = False, stack_y: bool = True\n) -> Learner:\n    \"Add mixup https://arxiv.org/abs/1710.09412 to `learn`.\"\n    learn.callback_fns.append(\n        partial(MixUpCallback, alpha=alpha, stack_x=stack_x, stack_y=stack_y)\n    )\n    return learn\nLearner.fit_one_cycle = fit_one_cycle\nLearner.lr_find = lr_find",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "clip_grad",
        "kind": 2,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "def clip_grad(learn: Learner, clip: float = 0.1) -> Learner:\n    \"Add gradient clipping of `clip` during training.\"\n    learn.callback_fns.append(partial(GradientClipping, clip=clip))\n    return learn\nLearner.clip_grad = clip_grad\nclass AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "__all__ = [\n    \"BnFreeze\",\n    \"GradientClipping\",\n    \"ShowGraph\",\n    \"Interpretation\",\n    \"ClassificationInterpretation\",\n    \"MultiLabelClassificationInterpretation\",\n    \"fit_one_cycle\",\n    \"lr_find\",\n    \"one_cycle_scheduler\",",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.fit_one_cycle",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.fit_one_cycle = fit_one_cycle\nLearner.lr_find = lr_find\nLearner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.lr_find",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.lr_find = lr_find\nLearner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.to_fp16",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.to_fp32",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.mixup",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()\n            x_bounds = (",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.clip_grad",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.clip_grad = clip_grad\nclass AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last\n    def on_train_begin(self, **kwargs):\n        \"check if loss is reduction\"\n        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n            warn(\"For better gradients consider 'reduction=sum'\")",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.train",
        "description": "DL_Model.deoldify.fastai.train",
        "peekOfCode": "Learner.interpret = _learner_interpret\nclass MultiLabelClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,",
        "detail": "DL_Model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.version",
        "description": "DL_Model.deoldify.fastai.version",
        "peekOfCode": "__all__ = [\"__version__\"]\n__version__ = \"1.0.56.dev0\"",
        "detail": "DL_Model.deoldify.fastai.version",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "DL_Model.deoldify.fastai.version",
        "description": "DL_Model.deoldify.fastai.version",
        "peekOfCode": "__version__ = \"1.0.56.dev0\"",
        "detail": "DL_Model.deoldify.fastai.version",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "DL_Model.deoldify.inference",
        "description": "DL_Model.deoldify.inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_unique_output_path(input_path, output_dir, artistic=True):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    model_type = \"artistic\" if artistic else \"stable\"\n    output_subdir = os.path.join(output_dir, model_type)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")",
        "detail": "DL_Model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "DL_Model.deoldify.inference",
        "description": "DL_Model.deoldify.inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, artistic=True):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    model_type = \"artistic\" if artistic else \"stable\"\n    output_subdir = os.path.join(output_dir, model_type)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(",
        "detail": "DL_Model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "DL_Model.deoldify.inference",
        "description": "DL_Model.deoldify.inference",
        "peekOfCode": "def process_image(input_path, render_factor=35, watermarked=True, artistic=True):\n    \"\"\"if not torch.cuda.is_available():\n    print('GPU not available.')\n    return None\"\"\"\n    colorizer = get_image_colorizer(artistic=artistic)\n    output_path = get_unique_output_path(input_path, \"outputs\", artistic)\n    result = colorizer.plot_transformed_image(\n        path=input_path,\n        render_factor=render_factor,\n        compare=False,",
        "detail": "DL_Model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "get_model_name",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(\n        os.path.join(output_subdir, f\"{input_filename}_{counter}.jpg\")",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def detect(img):\n    batch_boxes, batch_probs, batch_points = mtcnn.detect(img, landmarks=True)\n    if not mtcnn.keep_all:\n        batch_boxes, batch_probs, batch_points = mtcnn.select_boxes(\n            batch_boxes, batch_probs, batch_points, img, method=mtcnn.selection_method\n        )\n    return batch_boxes, batch_points\ndef makeEven(_x):\n    return int(_x) if (_x % 2 == 0) else int(_x + 1)\ndef scale(",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "makeEven",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def makeEven(_x):\n    return int(_x) if (_x % 2 == 0) else int(_x + 1)\ndef scale(\n    boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2\n):\n    x, y = _img.size\n    ratio = 2\n    if (boxes is not None) and len(boxes) > 0:\n        ratio = target_face / max(boxes[0][2:] - boxes[0][:2])\n        ratio = min(ratio, max_upscale)",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "scale",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def scale(\n    boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2\n):\n    x, y = _img.size\n    ratio = 2\n    if (boxes is not None) and len(boxes) > 0:\n        ratio = target_face / max(boxes[0][2:] - boxes[0][:2])\n        ratio = min(ratio, max_upscale)\n    if fixed_ratio > 0:\n        ratio = fixed_ratio",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "scale_by_face_size",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def scale_by_face_size(\n    _img, max_res=1_500_000, target_face=256, fix_ratio=0, max_upscale=2\n):\n    boxes, _ = detect(_img)\n    return scale(boxes, _img, max_res, target_face, fix_ratio, max_upscale)\nmeans = [0.485, 0.456, 0.406]\nstds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "tensor2im",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2\n    )\n    model_name = get_model_name(model_path)\n    output_path = get_unique_output_path(input_path, \"outputs\", model_name)",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2\n    )\n    model_name = get_model_name(model_path)\n    output_path = get_unique_output_path(input_path, \"outputs\", model_name)\n    transformed_image = img_transforms(input_image)[None, ...].cuda().half()\n    with torch.no_grad():",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "mtcnn",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "mtcnn = MTCNN(image_size=256, margin=80)\ndef check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "means",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "means = [0.485, 0.456, 0.406]\nstds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "stds",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "stds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "t_stds",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "t_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "t_means",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "t_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "img_transforms",
        "kind": 5,
        "importPath": "DL_Model.image_to_cartoon.arcane_inference",
        "description": "DL_Model.image_to_cartoon.arcane_inference",
        "peekOfCode": "img_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2",
        "detail": "DL_Model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "get_model_name",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(\n        os.path.join(output_subdir, f\"{input_filename}_{counter}.jpg\")",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def process_image(img, model_name):\n    h, w = img.shape[:2]\n    def to_8s(x):\n        if \"tiny\" in os.path.basename(model_name):\n            return 256 if x < 256 else x - x % 16\n        else:\n            return 256 if x < 256 else x - x % 8\n    img = cv2.resize(img, (to_8s(w), to_8s(h)))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0\n    return img",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def load_test_data(image_path, model_name):\n    img0 = cv2.imread(image_path).astype(np.float32)\n    img = process_image(img0, model_name)\n    img = np.expand_dims(img, axis=0)\n    return img, img0.shape\ndef save_images(images, image_path, size):\n    images = (np.squeeze(images) + 1.0) / 2 * 255\n    images = np.clip(images, 0, 255).astype(np.uint8)\n    images = cv2.resize(images, size)\n    cv2.imwrite(image_path, cv2.cvtColor(images, cv2.COLOR_RGB2BGR))",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "save_images",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def save_images(images, image_path, size):\n    images = (np.squeeze(images) + 1.0) / 2 * 255\n    images = np.clip(images, 0, 255).astype(np.uint8)\n    images = cv2.resize(images, size)\n    cv2.imwrite(image_path, cv2.cvtColor(images, cv2.COLOR_RGB2BGR))\ndef process_single_image(input_path, model_path, device=\"gpu\"):\n    if ort.get_device() == \"GPU\" and device == \"gpu\":\n        session = ort.InferenceSession(\n            model_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n        )",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "process_single_image",
        "kind": 2,
        "importPath": "DL_Model.image_to_cartoon.onnx_inference",
        "description": "DL_Model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def process_single_image(input_path, model_path, device=\"gpu\"):\n    if ort.get_device() == \"GPU\" and device == \"gpu\":\n        session = ort.InferenceSession(\n            model_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n        )\n    else:\n        session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n    x = session.get_inputs()[0].name\n    y = session.get_outputs()[0].name\n    model_name = get_model_name(model_path)",
        "detail": "DL_Model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "REBNCONV",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class REBNCONV(nn.Module):\n    def __init__(self, in_ch=3, out_ch=3, dirate=1, stride=1):\n        super(REBNCONV, self).__init__()\n        self.conv_s1 = nn.Conv2d(\n            in_ch, out_ch, 3, padding=1 * dirate, dilation=1 * dirate, stride=stride\n        )\n        self.bn_s1 = nn.BatchNorm2d(out_ch)\n        self.relu_s1 = nn.ReLU(inplace=True)\n    def forward(self, x):\n        hx = x",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU7",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class RSU7(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3, img_size=512):\n        super(RSU7, self).__init__()\n        self.in_ch = in_ch\n        self.mid_ch = mid_ch\n        self.out_ch = out_ch\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)  ## 1 -> 1/2\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU6",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class RSU6(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU6, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU5",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class RSU5(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU5, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class RSU4(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4F",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class RSU4F(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4F, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "myrebnconv",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class myrebnconv(nn.Module):\n    def __init__(\n        self,\n        in_ch=3,\n        out_ch=1,\n        kernel_size=3,\n        stride=1,\n        padding=1,\n        dilation=1,\n        groups=1,",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetGTEncoder",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class ISNetGTEncoder(nn.Module):\n    def __init__(self, in_ch=1, out_ch=1):\n        super(ISNetGTEncoder, self).__init__()\n        self.conv_in = myrebnconv(\n            in_ch, 16, 3, stride=2, padding=1\n        )  # nn.Conv2d(in_ch,64,3,stride=2,padding=1)\n        self.stage1 = RSU7(16, 16, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 16, 64)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetDIS",
        "kind": 6,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "class ISNetDIS(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1):\n        super(ISNetDIS, self).__init__()\n        self.conv_in = nn.Conv2d(in_ch, 64, 3, stride=2, padding=1)\n        self.pool_in = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage1 = RSU7(64, 32, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 32, 128)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage3 = RSU5(128, 64, 256)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion",
        "kind": 2,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "def muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion_kl",
        "kind": 2,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "def muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "bce_loss",
        "kind": 5,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "bce_loss = nn.BCELoss(size_average=True)\ndef muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "fea_loss",
        "kind": 5,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "fea_loss = nn.MSELoss(size_average=True)\nkl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "kl_loss",
        "kind": 5,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "kl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "kind": 5,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "l1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "kind": 5,
        "importPath": "background_remover.is_net.models.isnet",
        "description": "background_remover.is_net.models.isnet",
        "peekOfCode": "smooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "background_remover.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "kind": 2,
        "importPath": "background_remover.is_net.data_loader_cache",
        "description": "background_remover.is_net.data_loader_cache",
        "peekOfCode": "def img_reader(img_path):\n    return io.imread(img_path)\ndef img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:",
        "detail": "background_remover.is_net.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "kind": 2,
        "importPath": "background_remover.is_net.data_loader_cache",
        "description": "background_remover.is_net.data_loader_cache",
        "peekOfCode": "def img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:\n        return img_tensor, img.shape[:2]\n    img_tensor = torch.unsqueeze(img_tensor, 0)",
        "detail": "background_remover.is_net.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "GOSNormalize",
        "kind": 6,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "class GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"\n    def __init__(self, mean=None, std=None):",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "load_image",
        "kind": 2,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "def load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "build_model",
        "kind": 2,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "def build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()\n        for layer in net.modules():\n            if isinstance(layer, nn.BatchNorm2d):\n                layer.float()\n    net.to(device)\n    if hypar[\"restore_model\"] != \"\":\n        net.load_state_dict(",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "def predict(net, inputs_val, shapes_val, hypar, device):\n    \"\"\"\n    Predicts the mask for the given input image.\n    Arguments:\n    net -- the neural network model used for prediction\n    inputs_val -- tensor of input images (shape: (1, C, H, W))\n    shapes_val -- tensor containing the original shape of the image\n    hypar -- dictionary of hyperparameters\n    device -- the device on which to perform the computations ('cuda' or 'cpu')\n    Returns:",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "save_inference",
        "kind": 2,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "def save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)\n    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nclass GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "transform = transforms.Compose([GOSNormalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])])\ndef load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "hypar",
        "kind": 5,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "hypar = {\n    \"model_path\": \"saved_models\",\n    \"restore_model\": \"isnet.pth\",\n    \"interm_sup\": False,\n    \"model_digit\": \"full\",\n    \"seed\": 0,\n    \"cache_size\": [1024, 1024],\n    \"input_size\": [1024, 1024],\n    \"crop_size\": [1024, 1024],\n    \"model\": ISNetDIS(),",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "net = build_model(hypar, device)\ndef save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "input_path",
        "kind": 5,
        "importPath": "background_remover.is_net.isnet_inference",
        "description": "background_remover.is_net.isnet_inference",
        "peekOfCode": "input_path = \"your_image_path\"\nmask_path, rgba_path = save_inference(input_path)",
        "detail": "background_remover.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "BackgroundRemoverConfig",
        "kind": 6,
        "importPath": "background_remover.apps",
        "description": "background_remover.apps",
        "peekOfCode": "class BackgroundRemoverConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'background_remover'",
        "detail": "background_remover.apps",
        "documentation": {}
    },
    {
        "label": "app_name",
        "kind": 5,
        "importPath": "background_remover.urls",
        "description": "background_remover.urls",
        "peekOfCode": "app_name = \"background-remover\"\nurlpatterns = [path(\"\", views.background_remover_view, name=\"background_remover_view\")]",
        "detail": "background_remover.urls",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "background_remover.urls",
        "description": "background_remover.urls",
        "peekOfCode": "urlpatterns = [path(\"\", views.background_remover_view, name=\"background_remover_view\")]",
        "detail": "background_remover.urls",
        "documentation": {}
    },
    {
        "label": "background_remover_view",
        "kind": 2,
        "importPath": "background_remover.views",
        "description": "background_remover.views",
        "peekOfCode": "def background_remover_view(request):\n    return render(request, \"pages/background_remover.html\")",
        "detail": "background_remover.views",
        "documentation": {}
    },
    {
        "label": "Calendar",
        "kind": 6,
        "importPath": "components.toast.toast",
        "description": "components.toast.toast",
        "peekOfCode": "class Calendar(Component):\n    template_name = \"template.html\"\n    def get_context_data(self, title, content):\n        return {\n            \"title\": title,\n            \"content\": content,\n        }",
        "detail": "components.toast.toast",
        "documentation": {}
    },
    {
        "label": "DeviceException",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify._device",
        "description": "dashboard.dl_model.deoldify.deoldify._device",
        "peekOfCode": "class DeviceException(Exception):\n    pass\nclass _Device:\n    def __init__(self):\n        self.set(DeviceId.CPU)\n    def is_gpu(self):\n        \"\"\"Returns `True` if the current device is GPU, `False` otherwise.\"\"\"\n        return self.current() is not DeviceId.CPU\n    def current(self):\n        return self._current_device",
        "detail": "dashboard.dl_model.deoldify.deoldify._device",
        "documentation": {}
    },
    {
        "label": "_Device",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify._device",
        "description": "dashboard.dl_model.deoldify.deoldify._device",
        "peekOfCode": "class _Device:\n    def __init__(self):\n        self.set(DeviceId.CPU)\n    def is_gpu(self):\n        \"\"\"Returns `True` if the current device is GPU, `False` otherwise.\"\"\"\n        return self.current() is not DeviceId.CPU\n    def current(self):\n        return self._current_device\n    def set(self, device: DeviceId):\n        if device == DeviceId.CPU:",
        "detail": "dashboard.dl_model.deoldify.deoldify._device",
        "documentation": {}
    },
    {
        "label": "DeviceId",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.device_id",
        "description": "dashboard.dl_model.deoldify.deoldify.device_id",
        "peekOfCode": "class DeviceId(IntEnum):\n    GPU0 = (0,)\n    GPU1 = (1,)\n    GPU2 = (2,)\n    GPU3 = (3,)\n    GPU4 = (4,)\n    GPU5 = (5,)\n    GPU6 = (6,)\n    GPU7 = (7,)\n    CPU = 99",
        "detail": "dashboard.dl_model.deoldify.deoldify.device_id",
        "documentation": {}
    },
    {
        "label": "IFilter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.filters",
        "description": "dashboard.dl_model.deoldify.deoldify.filters",
        "peekOfCode": "class IFilter(ABC):\n    @abstractmethod\n    def filter(\n        self, orig_image: PilImage, filtered_image: PilImage, render_factor: int\n    ) -> PilImage:\n        pass\nclass BaseFilter(IFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__()\n        self.learn = learn",
        "detail": "dashboard.dl_model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "BaseFilter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.filters",
        "description": "dashboard.dl_model.deoldify.deoldify.filters",
        "peekOfCode": "class BaseFilter(IFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__()\n        self.learn = learn\n        if not device_settings.is_gpu():\n            self.learn.model = self.learn.model.cpu()\n        self.device = next(self.learn.model.parameters()).device\n        self.norm, self.denorm = normalize_funcs(*stats)\n    def _transform(self, image: PilImage) -> PilImage:\n        return image",
        "detail": "dashboard.dl_model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "ColorizerFilter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.filters",
        "description": "dashboard.dl_model.deoldify.deoldify.filters",
        "peekOfCode": "class ColorizerFilter(BaseFilter):\n    def __init__(self, learn: Learner, stats: tuple = imagenet_stats):\n        super().__init__(learn=learn, stats=stats)\n        self.render_base = 16\n    def filter(\n        self,\n        orig_image: PilImage,\n        filtered_image: PilImage,\n        render_factor: int,\n        post_process: bool = True,",
        "detail": "dashboard.dl_model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "MasterFilter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.filters",
        "description": "dashboard.dl_model.deoldify.deoldify.filters",
        "peekOfCode": "class MasterFilter(BaseFilter):\n    def __init__(self, filters: List[IFilter], render_factor: int):\n        self.filters = filters\n        self.render_factor = render_factor\n    def filter(\n        self,\n        orig_image: PilImage,\n        filtered_image: PilImage,\n        render_factor: int = None,\n        post_process: bool = True,",
        "detail": "dashboard.dl_model.deoldify.deoldify.filters",
        "documentation": {}
    },
    {
        "label": "gen_inference_wide",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_inference_wide(\n    root_folder: Path, weights_name: str, nf_factor: int = 2, arch=models.resnet101\n) -> Learner:\n    data = get_dummy_databunch()\n    learn = gen_learner_wide(\n        data=data, gen_loss=F.l1_loss, nf_factor=nf_factor, arch=arch\n    )\n    learn.path = root_folder\n    learn.load(weights_name)\n    learn.model.eval()",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_learner_wide",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_learner_wide(\n    data: ImageDataBunch, gen_loss, arch=models.resnet101, nf_factor: int = 2\n) -> Learner:\n    return unet_learner_wide(\n        data,\n        arch=arch,\n        wd=1e-3,\n        blur=True,\n        norm_type=NormType.Spectral,\n        self_attention=True,",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "unet_learner_wide",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def unet_learner_wide(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_inference_deep",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_inference_deep(\n    root_folder: Path, weights_name: str, arch=models.resnet34, nf_factor: float = 1.5\n) -> Learner:\n    data = get_dummy_databunch()\n    learn = gen_learner_deep(\n        data=data, gen_loss=F.l1_loss, arch=arch, nf_factor=nf_factor\n    )\n    learn.path = root_folder\n    learn.load(weights_name)\n    learn.model.eval()",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "gen_learner_deep",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def gen_learner_deep(\n    data: ImageDataBunch, gen_loss, arch=models.resnet34, nf_factor: float = 1.5\n) -> Learner:\n    return unet_learner_deep(\n        data,\n        arch,\n        wd=1e-3,\n        blur=True,\n        norm_type=NormType.Spectral,\n        self_attention=True,",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "unet_learner_deep",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.generators",
        "description": "dashboard.dl_model.deoldify.deoldify.generators",
        "peekOfCode": "def unet_learner_deep(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "dashboard.dl_model.deoldify.deoldify.generators",
        "documentation": {}
    },
    {
        "label": "ModelImageVisualizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "class ModelImageVisualizer:\n    def __init__(self, filter: IFilter, results_dir: str = None):\n        self.filter = filter\n        self.results_dir = None if results_dir is None else Path(results_dir)\n        self.results_dir.mkdir(parents=True, exist_ok=True)\n    def _clean_mem(self):\n        torch.cuda.empty_cache()\n        # gc.collect()\n    def _open_pil_image(self, path: Path) -> Image:\n        return PIL.Image.open(path).convert(\"RGB\")",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "VideoColorizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "class VideoColorizer:\n    def __init__(self, vis: ModelImageVisualizer):\n        self.vis = vis\n        workfolder = Path(\"./video\")\n        self.source_folder = workfolder / \"source\"\n        self.bwframes_root = workfolder / \"bwframes\"\n        self.audio_root = workfolder / \"audio\"\n        self.colorframes_root = workfolder / \"colorframes\"\n        self.result_folder = workfolder / \"result\"\n    def _purge_images(self, dir):",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_watermarked",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_watermarked(pil_image: Image) -> Image:\n    try:\n        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n        (h, w) = image.shape[:2]\n        image = np.dstack([image, np.ones((h, w), dtype=\"uint8\") * 255])\n        pct = 0.05\n        full_watermark = cv2.imread(\n            \"./resource_images/watermark.png\", cv2.IMREAD_UNCHANGED\n        )\n        (fwH, fwW) = full_watermark.shape[:2]",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_video_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_video_colorizer(render_factor: int = 21) -> VideoColorizer:\n    return get_stable_video_colorizer(render_factor=render_factor)\ndef get_artistic_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> VideoColorizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_artistic_video_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_artistic_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> VideoColorizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n    return VideoColorizer(vis)",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_stable_video_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_stable_video_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeVideo_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 21,\n) -> VideoColorizer:\n    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n    return VideoColorizer(vis)",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_image_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_image_colorizer(\n    root_folder: Path = Path(\"./\"), render_factor: int = 35, artistic: bool = True\n) -> ModelImageVisualizer:\n    if artistic:\n        return get_artistic_image_colorizer(\n            root_folder=root_folder, render_factor=render_factor\n        )\n    else:\n        return get_stable_image_colorizer(\n            root_folder=root_folder, render_factor=render_factor",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_stable_image_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_stable_image_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeStable_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> ModelImageVisualizer:\n    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    return ModelImageVisualizer(filtr, results_dir=results_dir)\ndef get_artistic_image_colorizer(",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "get_artistic_image_colorizer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def get_artistic_image_colorizer(\n    root_folder: Path = Path(\"./\"),\n    weights_name: str = \"ColorizeArtistic_gen\",\n    results_dir=\"result_images\",\n    render_factor: int = 35,\n) -> ModelImageVisualizer:\n    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n    return ModelImageVisualizer(filtr, results_dir=results_dir)\ndef show_image_in_notebook(image_path: Path):",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "show_image_in_notebook",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def show_image_in_notebook(image_path: Path):\n    ipythondisplay.display(ipythonimage(str(image_path)))\ndef show_video_in_notebook(video_path: Path):\n    video = io.open(video_path, \"r+b\").read()\n    encoded = base64.b64encode(video)\n    ipythondisplay.display(\n        HTML(\n            data=\"\"\"<video alt=\"test\" autoplay\n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "show_video_in_notebook",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.deoldify.visualize",
        "description": "dashboard.dl_model.deoldify.deoldify.visualize",
        "peekOfCode": "def show_video_in_notebook(video_path: Path):\n    video = io.open(video_path, \"r+b\").read()\n    encoded = base64.b64encode(video)\n    ipythondisplay.display(\n        HTML(\n            data=\"\"\"<video alt=\"test\" autoplay\n                loop controls style=\"height: 400px;\">\n                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n             </video>\"\"\".format(\n                encoded.decode(\"ascii\")",
        "detail": "dashboard.dl_model.deoldify.deoldify.visualize",
        "documentation": {}
    },
    {
        "label": "CSVLogger",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "peekOfCode": "class CSVLogger(LearnerCallback):\n    \"A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.\"\n    def __init__(self, learn: Learner, filename: str = \"history\", append: bool = False):\n        super().__init__(learn)\n        self.filename, self.path, self.append = (\n            filename,\n            self.learn.path / f\"{filename}.csv\",\n            append,\n        )\n        self.add_time = True",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "peekOfCode": "__all__ = [\"CSVLogger\"]\nclass CSVLogger(LearnerCallback):\n    \"A `LearnerCallback` that saves history of metrics while training `learn` into CSV `filename`.\"\n    def __init__(self, learn: Learner, filename: str = \"history\", append: bool = False):\n        super().__init__(learn)\n        self.filename, self.path, self.append = (\n            filename,\n            self.learn.path / f\"{filename}.csv\",\n            append,\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.csv_logger",
        "documentation": {}
    },
    {
        "label": "MixedPrecision",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "class MixedPrecision(LearnerCallback):\n    _order = 999  # Need to run after things that could call on_backward_begin and change the loss\n    \"Callback that handles mixed-precision training.\"\n    def __init__(\n        self,\n        learn: Learner,\n        loss_scale: float = None,\n        max_noskip: int = 1000,\n        dynamic: bool = True,\n        clip: float = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "get_master",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def get_master(\n    layer_groups: ModuleList, flat_master: bool = False\n) -> Tuple[List[List[Tensor]], List[List[Tensor]]]:\n    \"Return two lists, one for the model parameters in FP16 and one for the master parameters in FP32.\"\n    split_params = split_no_wd_params(layer_groups)\n    model_params = [\n        [param for param in pg if param.requires_grad] for pg in split_params\n    ]\n    if flat_master:\n        master_params = []",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "model_g2master_g",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def model_g2master_g(\n    model_params: Sequence[Tensor],\n    master_params: Sequence[Tensor],\n    flat_master: bool = False,\n) -> None:\n    \"Copy the `model_params` gradients to `master_params` for the optimizer step.\"\n    if flat_master:\n        for model_group, master_group in zip(model_params, master_params):\n            if len(master_group) != 0:\n                if master_group[0].grad is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "master2model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def master2model(\n    model_params: Sequence[Tensor],\n    master_params: Sequence[Tensor],\n    flat_master: bool = False,\n) -> None:\n    \"Copy `master_params` to `model_params`.\"\n    if flat_master:\n        for model_group, master_group in zip(model_params, master_params):\n            if len(model_group) != 0:\n                for model, master in zip(",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "grad_overflow",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "def grad_overflow(param_group):\n    for group in param_group:\n        for p in group:\n            if p.grad is not None:\n                s = float(p.grad.data.float().sum())\n                if s == float(\"inf\") or s == float(\"-inf\") or s != s:\n                    return True\n    return False\nclass MixedPrecision(LearnerCallback):\n    _order = 999  # Need to run after things that could call on_backward_begin and change the loss",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "peekOfCode": "__all__ = [\"MixedPrecision\"]\ndef get_master(\n    layer_groups: ModuleList, flat_master: bool = False\n) -> Tuple[List[List[Tensor]], List[List[Tensor]]]:\n    \"Return two lists, one for the model parameters in FP16 and one for the master parameters in FP32.\"\n    split_params = split_no_wd_params(layer_groups)\n    model_params = [\n        [param for param in pg if param.requires_grad] for pg in split_params\n    ]\n    if flat_master:",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.fp16",
        "documentation": {}
    },
    {
        "label": "TrainingPhase",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "class TrainingPhase:\n    \"Schedule hyper-parameters for a phase of `length` iterations.\"\n    length: int\n    def __post_init__(self):\n        self.scheds = dict()\n    def schedule_hp(self, name, vals, anneal=None):\n        \"Adds a schedule for `name` between `vals` using `anneal`.\"\n        self.scheds[name] = Scheduler(vals, self.length, anneal)\n        return self\nclass GeneralScheduler(LearnerCallback):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "GeneralScheduler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "class GeneralScheduler(LearnerCallback):\n    \"Schedule multiple `TrainingPhase` for a `Learner`.\"\n    def __init__(\n        self, learn: Learner, phases: Collection[TrainingPhase], start_epoch: int = None\n    ):\n        super().__init__(learn)\n        self.phases, self.start_epoch = phases, start_epoch\n    def on_train_begin(self, epoch: int, **kwargs: Any) -> None:\n        \"Initialize the schedulers for training.\"\n        res = {\"epoch\": self.start_epoch} if self.start_epoch is not None else None",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "peekOfCode": "__all__ = [\"GeneralScheduler\", \"TrainingPhase\"]\n@dataclass\nclass TrainingPhase:\n    \"Schedule hyper-parameters for a phase of `length` iterations.\"\n    length: int\n    def __post_init__(self):\n        self.scheds = dict()\n    def schedule_hp(self, name, vals, anneal=None):\n        \"Adds a schedule for `name` between `vals` using `anneal`.\"\n        self.scheds[name] = Scheduler(vals, self.length, anneal)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.general_sched",
        "documentation": {}
    },
    {
        "label": "Hook",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class Hook:\n    \"Create a hook on `m` with `hook_func`.\"\n    def __init__(\n        self,\n        m: nn.Module,\n        hook_func: HookFunc,\n        is_forward: bool = True,\n        detach: bool = True,\n    ):\n        self.hook_func, self.detach, self.stored = hook_func, detach, None",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "Hooks",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class Hooks:\n    \"Create several hooks on the modules in `ms` with `hook_func`.\"\n    def __init__(\n        self,\n        ms: Collection[nn.Module],\n        hook_func: HookFunc,\n        is_forward: bool = True,\n        detach: bool = True,\n    ):\n        self.hooks = [Hook(m, hook_func, is_forward, detach) for m in ms]",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "HookCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"\n    def __init__(\n        self,\n        learn: Learner,\n        modules: Sequence[nn.Module] = None,\n        do_remove: bool = True,\n    ):\n        super().__init__(learn)\n        self.modules, self.do_remove = modules, do_remove",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "ActivationStats",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "class ActivationStats(HookCallback):\n    \"Callback that record the mean and std of activations.\"\n    def on_train_begin(self, **kwargs):\n        \"Initialize stats.\"\n        super().on_train_begin(**kwargs)\n        self.stats = []\n    def hook(\n        self, m: nn.Module, i: Tensors, o: Tensors\n    ) -> Tuple[Rank0Tensor, Rank0Tensor]:\n        \"Take the mean and std of `o`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_output",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_output(module: nn.Module, detach: bool = True, grad: bool = False) -> Hook:\n    \"Return a `Hook` that stores activations of `module` in `self.stored`\"\n    return Hook(module, _hook_inner, detach=detach, is_forward=not grad)\ndef hook_outputs(\n    modules: Collection[nn.Module], detach: bool = True, grad: bool = False\n) -> Hooks:\n    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)\nclass HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_outputs",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_outputs(\n    modules: Collection[nn.Module], detach: bool = True, grad: bool = False\n) -> Hooks:\n    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)\nclass HookCallback(LearnerCallback):\n    \"Callback that can be used to register hooks on `modules`. Implement the corresponding function in `self.hook`.\"\n    def __init__(\n        self,\n        learn: Learner,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "dummy_batch",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def dummy_batch(m: nn.Module, size: tuple = (64, 64)) -> Tensor:\n    \"Create a dummy batch to go through `m` with `size`.\"\n    ch_in = in_channels(m)\n    return one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.0, 1.0)\ndef dummy_eval(m: nn.Module, size: tuple = (64, 64)):\n    \"Pass a `dummy_batch` in evaluation mode in `m` with `size`.\"\n    m.eval()\n    return m(dummy_batch(m, size))\n    # return m.eval()(dummy_batch(m, size))\ndef model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "dummy_eval",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def dummy_eval(m: nn.Module, size: tuple = (64, 64)):\n    \"Pass a `dummy_batch` in evaluation mode in `m` with `size`.\"\n    m.eval()\n    return m(dummy_batch(m, size))\n    # return m.eval()(dummy_batch(m, size))\ndef model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model `m` to get the various sizes of activations.\"\n    with hook_outputs(m) as hooks:\n        x = dummy_eval(m, size)\n        return [o.stored.shape for o in hooks]",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "model_sizes",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def model_sizes(m: nn.Module, size: tuple = (64, 64)) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model `m` to get the various sizes of activations.\"\n    with hook_outputs(m) as hooks:\n        x = dummy_eval(m, size)\n        return [o.stored.shape for o in hooks]\ndef num_features_model(m: nn.Module) -> int:\n    \"Return the number of output features for `model`.\"\n    sz = 64\n    while True:\n        try:",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "num_features_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def num_features_model(m: nn.Module) -> int:\n    \"Return the number of output features for `model`.\"\n    sz = 64\n    while True:\n        try:\n            return model_sizes(m, size=(sz, sz))[-1][1]\n        except Exception as e:\n            sz *= 2\n            if sz > 2048:\n                raise",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "total_params",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def total_params(m: nn.Module) -> int:\n    params, trainable = 0, False\n    if hasattr(m, \"weight\") and hasattr(m.weight, \"size\"):\n        params += m.weight.numel()\n        trainable = m.weight.requires_grad\n    if hasattr(m, \"bias\") and hasattr(m.bias, \"size\"):\n        params += m.bias.numel()\n    return params, trainable\ndef hook_params(modules: Collection[nn.Module]) -> Hooks:\n    return Hooks(modules, lambda m, i, o: total_params(m))",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "hook_params",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def hook_params(modules: Collection[nn.Module]) -> Hooks:\n    return Hooks(modules, lambda m, i, o: total_params(m))\ndef params_size(\n    m: Union[nn.Module, Learner], size: tuple = (3, 64, 64)\n) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model to get the various sizes. Returns (res,x,hooks) if `full`\"\n    if isinstance(m, Learner):\n        if m.data.is_empty:\n            raise Exception(\n                \"This is an empty `Learner` and `Learner.summary` requires some data to pass through the model.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "params_size",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def params_size(\n    m: Union[nn.Module, Learner], size: tuple = (3, 64, 64)\n) -> Tuple[Sizes, Tensor, Hooks]:\n    \"Pass a dummy input through the model to get the various sizes. Returns (res,x,hooks) if `full`\"\n    if isinstance(m, Learner):\n        if m.data.is_empty:\n            raise Exception(\n                \"This is an empty `Learner` and `Learner.summary` requires some data to pass through the model.\"\n            )\n        ds_type = (",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "get_layer_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def get_layer_name(layer: nn.Module) -> str:\n    return str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\ndef layers_info(m: Collection[nn.Module]) -> Collection[namedtuple]:\n    func = lambda m: list(map(get_layer_name, flatten_model(m)))\n    layers_names = func(m.model) if isinstance(m, Learner) else func(m)\n    layers_sizes, layers_params, layers_trainable = params_size(m)\n    layer_info = namedtuple(\n        \"Layer_Information\", [\"Layer\", \"OutputSize\", \"Params\", \"Trainable\"]\n    )\n    return list(",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "layers_info",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def layers_info(m: Collection[nn.Module]) -> Collection[namedtuple]:\n    func = lambda m: list(map(get_layer_name, flatten_model(m)))\n    layers_names = func(m.model) if isinstance(m, Learner) else func(m)\n    layers_sizes, layers_params, layers_trainable = params_size(m)\n    layer_info = namedtuple(\n        \"Layer_Information\", [\"Layer\", \"OutputSize\", \"Params\", \"Trainable\"]\n    )\n    return list(\n        map(layer_info, layers_names, layers_sizes, layers_params, layers_trainable)\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "model_summary",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "def model_summary(m: Learner, n: int = 70):\n    \"Print a summary of `m` using a output text width of `n` chars\"\n    info = layers_info(m)\n    header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Trainable\"]\n    res = m.model.__class__.__name__ + \"\\n\"\n    res += \"=\" * n + \"\\n\"\n    res += f\"{header[0]:<20} {header[1]:<20} {header[2]:<10} {header[3]:<10}\\n\"\n    res += \"=\" * n + \"\\n\"\n    total_params = 0\n    total_trainable_params = 0",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "__all__ = [\n    \"ActivationStats\",\n    \"Hook\",\n    \"HookCallback\",\n    \"Hooks\",\n    \"hook_output\",\n    \"hook_outputs\",\n    \"model_sizes\",\n    \"num_features_model\",\n    \"model_summary\",",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "Learner.summary",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "peekOfCode": "Learner.summary = model_summary",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.hooks",
        "documentation": {}
    },
    {
        "label": "LossMetrics",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "peekOfCode": "class LossMetrics(LearnerCallback):\n    \"Add `loss_func.metrics` to metrics named by `loss_func.metric_names`\"\n    _order = -20  # Needs to run before the recorder\n    def on_train_begin(self, **kwargs):\n        \"Add the metrics names to the `Recorder`.\"\n        self.names = ifnone(self.learn.loss_func.metric_names, [])\n        if not self.names:\n            warn(\"LossMetrics requested but no loss_func.metric_names provided\")\n        self.learn.recorder.add_metric_names(self.names)\n    def on_epoch_begin(self, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "peekOfCode": "__all__ = [\"LossMetrics\"]\nclass LossMetrics(LearnerCallback):\n    \"Add `loss_func.metrics` to metrics named by `loss_func.metric_names`\"\n    _order = -20  # Needs to run before the recorder\n    def on_train_begin(self, **kwargs):\n        \"Add the metrics names to the `Recorder`.\"\n        self.names = ifnone(self.learn.loss_func.metric_names, [])\n        if not self.names:\n            warn(\"LossMetrics requested but no loss_func.metric_names provided\")\n        self.learn.recorder.add_metric_names(self.names)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.loss_metrics",
        "documentation": {}
    },
    {
        "label": "LRFinder",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "peekOfCode": "class LRFinder(LearnerCallback):\n    \"Causes `learn` to go on a mock training from `start_lr` to `end_lr` for `num_it` iterations.\"\n    def __init__(\n        self,\n        learn: Learner,\n        start_lr: float = 1e-7,\n        end_lr: float = 10,\n        num_it: int = 100,\n        stop_div: bool = True,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "peekOfCode": "__all__ = [\"LRFinder\"]\nclass LRFinder(LearnerCallback):\n    \"Causes `learn` to go on a mock training from `start_lr` to `end_lr` for `num_it` iterations.\"\n    def __init__(\n        self,\n        learn: Learner,\n        start_lr: float = 1e-7,\n        end_lr: float = 10,\n        num_it: int = 100,\n        stop_div: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.lr_finder",
        "documentation": {}
    },
    {
        "label": "PeakMemMetric",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.mem",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.mem",
        "peekOfCode": "class PeakMemMetric(LearnerCallback):\n    \"Callback that measures used and peaked general and GPU memory.\"\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner):\n        super().__init__(learn)\n        assert torch.cuda.is_available(), \"pytorch CUDA is required\"\n        preload_pytorch()\n    def peak_monitor_start(self):\n        self.peak_monitoring = True\n        # start RAM tracing",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.mem",
        "documentation": {}
    },
    {
        "label": "StopAfterNBatches",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.misc",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.misc",
        "peekOfCode": "class StopAfterNBatches(Callback):\n    \"Stop training after n batches of the first epoch.\"\n    def __init__(self, n_batches: int = 2):\n        self.stop, self.n_batches = False, n_batches - 1  # iteration starts from 0\n    def on_batch_end(self, iteration, **kwargs):\n        if iteration == self.n_batches:\n            return {\"stop_epoch\": True, \"stop_training\": True, \"skip_validate\": True}",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.misc",
        "documentation": {}
    },
    {
        "label": "MixUpCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "peekOfCode": "class MixUpCallback(LearnerCallback):\n    \"Callback that creates the mixed-up input and target.\"\n    def __init__(\n        self,\n        learn: Learner,\n        alpha: float = 0.4,\n        stack_x: bool = False,\n        stack_y: bool = True,\n    ):\n        super().__init__(learn)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "documentation": {}
    },
    {
        "label": "MixUpLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "peekOfCode": "class MixUpLoss(Module):\n    \"Adapt the loss function `crit` to go with mixup.\"\n    def __init__(self, crit, reduction=\"mean\"):\n        super().__init__()\n        if hasattr(crit, \"reduction\"):\n            self.crit = crit\n            self.old_red = crit.reduction\n            setattr(self.crit, \"reduction\", \"none\")\n        else:\n            self.crit = partial(crit, reduction=\"none\")",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.mixup",
        "documentation": {}
    },
    {
        "label": "MLFlowTracker",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.mlflow",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.mlflow",
        "peekOfCode": "class MLFlowTracker(LearnerCallback):\n    \"A `TrackerCallback` that tracks the loss and metrics into MLFlow\"\n    def __init__(\n        self,\n        learn: Learner,\n        exp_name: str,\n        params: dict,\n        nb_path: str,\n        uri: str = \"http://localhost:5000\",\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.mlflow",
        "documentation": {}
    },
    {
        "label": "OneCycleScheduler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "peekOfCode": "class OneCycleScheduler(LearnerCallback):\n    \"Manage 1-Cycle style training as outlined in Leslie Smith's [paper](https://arxiv.org/pdf/1803.09820.pdf).\"\n    def __init__(\n        self,\n        learn: Learner,\n        lr_max: float,\n        moms: Floats = (0.95, 0.85),\n        div_factor: float = 25.0,\n        pct_start: float = 0.3,\n        final_div: float = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "peekOfCode": "__all__ = [\"OneCycleScheduler\"]\nclass OneCycleScheduler(LearnerCallback):\n    \"Manage 1-Cycle style training as outlined in Leslie Smith's [paper](https://arxiv.org/pdf/1803.09820.pdf).\"\n    def __init__(\n        self,\n        learn: Learner,\n        lr_max: float,\n        moms: Floats = (0.95, 0.85),\n        div_factor: float = 25.0,\n        pct_start: float = 0.3,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.one_cycle",
        "documentation": {}
    },
    {
        "label": "OverSamplingCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "peekOfCode": "class OverSamplingCallback(LearnerCallback):\n    def __init__(self, learn: Learner, weights: torch.Tensor = None):\n        super().__init__(learn)\n        self.labels = self.learn.data.train_dl.dataset.y.items\n        _, counts = np.unique(self.labels, return_counts=True)\n        self.weights = (\n            weights\n            if weights is not None\n            else torch.DoubleTensor((1 / counts)[self.labels])\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "peekOfCode": "__all__ = [\"OverSamplingCallback\"]\nclass OverSamplingCallback(LearnerCallback):\n    def __init__(self, learn: Learner, weights: torch.Tensor = None):\n        super().__init__(learn)\n        self.labels = self.learn.data.train_dl.dataset.y.items\n        _, counts = np.unique(self.labels, return_counts=True)\n        self.weights = (\n            weights\n            if weights is not None\n            else torch.DoubleTensor((1 / counts)[self.labels])",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.oversampling",
        "documentation": {}
    },
    {
        "label": "RNNTrainer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "peekOfCode": "class RNNTrainer(LearnerCallback):\n    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n    def __init__(self, learn: Learner, alpha: float = 0.0, beta: float = 0.0):\n        super().__init__(learn)\n        self.not_min += [\"raw_out\", \"out\"]\n        self.alpha, self.beta = alpha, beta\n    def on_epoch_begin(self, **kwargs):\n        \"Reset the hidden state of the model.\"\n        self.learn.model.reset()\n    def on_loss_begin(self, last_output: Tuple[Tensor, Tensor, Tensor], **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "peekOfCode": "__all__ = [\"RNNTrainer\"]\nclass RNNTrainer(LearnerCallback):\n    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n    def __init__(self, learn: Learner, alpha: float = 0.0, beta: float = 0.0):\n        super().__init__(learn)\n        self.not_min += [\"raw_out\", \"out\"]\n        self.alpha, self.beta = alpha, beta\n    def on_epoch_begin(self, **kwargs):\n        \"Reset the hidden state of the model.\"\n        self.learn.model.reset()",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.rnn",
        "documentation": {}
    },
    {
        "label": "LearnerTensorboardWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class LearnerTensorboardWriter(LearnerCallback):\n    \"Broadly useful callback for Learners that writes to Tensorboard.  Writes model histograms, losses/metrics, and gradient stats.\"\n    def __init__(\n        self,\n        learn: Learner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GANTensorboardWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GANTensorboardWriter(LearnerTensorboardWriter):\n    \"Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(\n        self,\n        learn: GANLearner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageGenTensorboardWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageGenTensorboardWriter(LearnerTensorboardWriter):\n    \"Callback for non-GAN image generating Learners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(\n        self,\n        learn: Learner,\n        base_dir: Path,\n        name: str,\n        loss_iters: int = 25,\n        hist_iters: int = 500,\n        stats_iters: int = 100,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "TBWriteRequest",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class TBWriteRequest(ABC):\n    \"A request object for Tensorboard writes.  Useful for queuing up and executing asynchronous writes.\"\n    def __init__(self, tbwriter: SummaryWriter, iteration: int):\n        super().__init__()\n        self.tbwriter = tbwriter\n        self.iteration = iteration\n    @abstractmethod\n    def write(self) -> None:\n        pass\n# SummaryWriter writes tend to block quite a bit.  This gets around that and greatly boosts performance.",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "AsyncTBWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class AsyncTBWriter:\n    \"Callback for GANLearners that writes to Tensorboard.  Extends LearnerTensorboardWriter and adds output image writes.\"\n    def __init__(self):\n        super().__init__()\n        self.stop_request = Event()\n        self.queue = Queue()\n        self.thread = Thread(target=self._queue_processor, daemon=True)\n        self.thread.start()\n    def request_write(self, request: TBWriteRequest) -> None:\n        \"Queues up an asynchronous write request to Tensorboard.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelImageSet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelImageSet:\n    \"Convenience object that holds the original, real(target) and generated versions of a single image fed to a model.\"\n    @staticmethod\n    def get_list_from_model(learn: Learner, ds_type: DatasetType, batch: Tuple) -> []:\n        \"Factory method to convert a batch of model images to a list of ModelImageSet.\"\n        image_sets = []\n        x, y = batch[0], batch[1]\n        preds = []\n        preds = learn.pred_batch(ds_type=ds_type, batch=(x, y), reconstruct=True)\n        for orig_px, real_px, gen in zip(x, y, preds):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "HistogramTBRequest",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class HistogramTBRequest(TBWriteRequest):\n    \"Request object for model histogram writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, iteration: int, tbwriter: SummaryWriter, name: str\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.params = [\n            (name, values.clone().detach().cpu())\n            for (name, values) in model.named_parameters()\n        ]",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "HistogramTBWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class HistogramTBWriter:\n    \"Writes model histograms to Tensorboard.\"\n    def __init__(self):\n        super().__init__()\n    def write(\n        self,\n        model: nn.Module,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        name: str = \"model\",",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelStatsTBRequest",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelStatsTBRequest(TBWriteRequest):\n    \"Request object for model gradient statistics writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, iteration: int, tbwriter: SummaryWriter, name: str\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=iteration)\n        self.gradients = [\n            x.grad.clone().detach().cpu()\n            for x in model.parameters()\n            if x.grad is not None",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ModelStatsTBWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ModelStatsTBWriter:\n    \"Writes model gradient statistics to Tensorboard.\"\n    def write(\n        self,\n        model: nn.Module,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        name: str = \"model_stats\",\n    ) -> None:\n        \"Writes model gradient statistics to Tensorboard.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageTBRequest",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageTBRequest(TBWriteRequest):\n    \"Request object for model image output writes to Tensorboard.\"\n    def __init__(\n        self,\n        learn: Learner,\n        batch: Tuple,\n        iteration: int,\n        tbwriter: SummaryWriter,\n        ds_type: DatasetType,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "ImageTBWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class ImageTBWriter:\n    \"Writes model image output to Tensorboard.\"\n    def __init__(self):\n        super().__init__()\n    def write(\n        self,\n        learn: Learner,\n        trn_batch: Tuple,\n        val_batch: Tuple,\n        iteration: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GraphTBRequest",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GraphTBRequest(TBWriteRequest):\n    \"Request object for model histogram writes to Tensorboard.\"\n    def __init__(\n        self, model: nn.Module, tbwriter: SummaryWriter, input_to_model: torch.Tensor\n    ):\n        super().__init__(tbwriter=tbwriter, iteration=0)\n        self.model, self.input_to_model = model, input_to_model\n    def write(self) -> None:\n        \"Writes single model graph to Tensorboard.\"\n        self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "GraphTBWriter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "class GraphTBWriter:\n    \"Writes model network graph to Tensorboard.\"\n    def write(\n        self, model: nn.Module, tbwriter: SummaryWriter, input_to_model: torch.Tensor\n    ) -> None:\n        \"Writes model graph to Tensorboard.\"\n        request = GraphTBRequest(\n            model=model, tbwriter=tbwriter, input_to_model=input_to_model\n        )\n        asyncTBWriter.request_write(request)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "__all__ = [\n    \"LearnerTensorboardWriter\",\n    \"GANTensorboardWriter\",\n    \"ImageGenTensorboardWriter\",\n]\n# ---Example usage (applies to any of the callbacks)---\n# proj_id = 'Colorize'\n# tboard_path = Path('data/tensorboard/' + proj_id)\n# learn.callback_fns.append(partial(GANTensorboardWriter, base_dir=tboard_path, name='GanLearner'))\nclass LearnerTensorboardWriter(LearnerCallback):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "asyncTBWriter",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "peekOfCode": "asyncTBWriter = AsyncTBWriter()\nclass ModelImageSet:\n    \"Convenience object that holds the original, real(target) and generated versions of a single image fed to a model.\"\n    @staticmethod\n    def get_list_from_model(learn: Learner, ds_type: DatasetType, batch: Tuple) -> []:\n        \"Factory method to convert a batch of model images to a list of ModelImageSet.\"\n        image_sets = []\n        x, y = batch[0], batch[1]\n        preds = []\n        preds = learn.pred_batch(ds_type=ds_type, batch=(x, y), reconstruct=True)",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "TerminateOnNaNCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TerminateOnNaNCallback(Callback):\n    \"A `Callback` that terminates training if loss is NaN.\"\n    def __init__(self):\n        self.stop = False\n    def on_batch_end(self, last_loss, epoch, num_batch, **kwargs: Any) -> None:\n        \"Test if `last_loss` is NaN and interrupts training.\"\n        if self.stop:\n            return True  # to skip validation after stopping during training\n        if torch.isnan(last_loss):\n            print(",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "TrackerCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TrackerCallback(LearnerCallback):\n    \"A `LearnerCallback` that keeps track of the best value in `monitor`.\"\n    def __init__(self, learn: Learner, monitor: str = \"valid_loss\", mode: str = \"auto\"):\n        super().__init__(learn)\n        self.monitor, self.mode = monitor, mode\n        if self.mode not in [\"auto\", \"min\", \"max\"]:\n            warn(\n                f'{self.__class__} mode {self.mode} is invalid, falling back to \"auto\" mode.'\n            )\n            self.mode = \"auto\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "EarlyStoppingCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class EarlyStoppingCallback(TrackerCallback):\n    \"A `TrackerCallback` that terminates training when monitored quantity stops improving.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        min_delta: int = 0,\n        patience: int = 0,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "SaveModelCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class SaveModelCallback(TrackerCallback):\n    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        every: str = \"improvement\",\n        name: str = \"bestmodel\",\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateauCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class ReduceLROnPlateauCallback(TrackerCallback):\n    \"A `TrackerCallback` that reduces learning rate when a metric has stopped improving.\"\n    def __init__(\n        self,\n        learn: Learner,\n        monitor: str = \"valid_loss\",\n        mode: str = \"auto\",\n        patience: int = 0,\n        factor: float = 0.2,\n        min_delta: int = 0,",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "TrackEpochCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "class TrackEpochCallback(LearnerCallback):\n    _order = -20  # Need to run before fit_one_cycle\n    def __init__(self, learn: Learner, name: str = \"epoch\", epoch_offset: int = None):\n        \"Store completed epoch number in `learn.model_dir/name`.\"\n        super().__init__(learn)\n        learn._test_writeable_path()\n        self.path = learn.path / learn.model_dir / name\n        if epoch_offset is None:\n            if os.path.isfile(self.path):\n                with self.path.open(\"r\") as f:",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "description": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "peekOfCode": "__all__ = [\n    \"TerminateOnNaNCallback\",\n    \"EarlyStoppingCallback\",\n    \"SaveModelCallback\",\n    \"TrackerCallback\",\n    \"ReduceLROnPlateauCallback\",\n    \"TrackEpochCallback\",\n]\nclass TerminateOnNaNCallback(Callback):\n    \"A `Callback` that terminates training if loss is NaN.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.callbacks.tracker",
        "documentation": {}
    },
    {
        "label": "read_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,\n        remove_undoc_cells,\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "convert_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,\n        remove_undoc_cells,\n    )\n    nb = read_nb(fname)\n    nb[\"cells\"] = remove_undoc_cells(nb[\"cells\"])\n    nb[\"cells\"] = remove_code_cell_jupyter_widget_state_elem(nb[\"cells\"])\n    fname = Path(fname).absolute()",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "convert_all",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "def convert_all(folder, dest_path=\".\", force_all=False):\n    \"Convert modified notebooks in `folder` to html pages in `dest_path`.\"\n    path = Path(folder)\n    changed_cnt = 0\n    for fname in path.glob(\"*.ipynb\"):\n        # only rebuild modified files\n        fname_out = Path(dest_path) / fname.with_suffix(\".html\").name\n        if not force_all and fname_out.exists():\n            in_mod = os.path.getmtime(fname)\n            out_mod = os.path.getmtime(fname_out)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "__all__ = [\"read_nb\", \"convert_nb\", \"convert_all\"]\nexporter = HTMLExporter(Config())\nexporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter = HTMLExporter(Config())\nexporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.exclude_input_prompt",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.exclude_input_prompt = True\nexporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.exclude_output_prompt",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.exclude_output_prompt = True\n# Loads the template to deal with hidden cells.\nexporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "exporter.template_file",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "exporter.template_file = \"jekyll.tpl\"\npath = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "peekOfCode": "path = Path(__file__).parent\nexporter.template_path.append(str(path))\ndef read_nb(fname):\n    \"Read the notebook in `fname`.\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\ndef convert_nb(fname, dest_path=\".\"):\n    \"Convert a notebook `fname` to html file in `dest_path`.\"\n    from .gen_notebooks import (\n        remove_code_cell_jupyter_widget_state_elem,",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.convert2html",
        "documentation": {}
    },
    {
        "label": "strip_fastai",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.core",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.core",
        "peekOfCode": "def strip_fastai(s):\n    return re.sub(r\"^fastai\\.\", \"\", s)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.core",
        "documentation": {}
    },
    {
        "label": "InfoMixin",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "class InfoMixin(object):\n    @classmethod\n    def _get_doc(cls):\n        \"\"\"Return documentary of class\n        By default it returns docstring of class, but it can be overridden\n        for example for cases like merging own docstring with parent\n        \"\"\"\n        return cls.__doc__\n    @classmethod\n    def get_info(cls):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "trim",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"\n    # Convert tabs to spaces (following the normal Python rules)\n    # and split into a list of lines:\n    lines = docstring.expandtabs().splitlines()\n    # Determine minimum indentation (first line doesn't count):\n    indent = sys.maxsize\n    for line in lines[1:]:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "reindent",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def reindent(string):\n    return \"\\n\".join(l.strip() for l in string.strip().split(\"\\n\"))\ndef parse_docstring(docstring):\n    \"\"\"Parse the docstring into its components.\n    :return: a dictionary of form\n              {\n                  \"short_description\": ...,\n                  \"long_description\": ...,\n                  \"params\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"vals\": [{\"name\": ..., \"doc\": ...}, ...],",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "parse_docstring",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "def parse_docstring(docstring):\n    \"\"\"Parse the docstring into its components.\n    :return: a dictionary of form\n              {\n                  \"short_description\": ...,\n                  \"long_description\": ...,\n                  \"params\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"vals\": [{\"name\": ..., \"doc\": ...}, ...],\n                  \"return\": ...\n              }",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "__all__ = [\"parse_docstring\"]\nFIELDS = \"param|val\"  # supported fields\nPARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "FIELDS",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "FIELDS = \"param|val\"  # supported fields\nPARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "PARAM_OR_RETURN_REGEX",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "PARAM_OR_RETURN_REGEX = re.compile(f\":(?:{FIELDS}|return)\")\nRETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "RETURN_REGEX",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "RETURN_REGEX = re.compile(\":return: (?P<doc>.*)\", re.S)\nNEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "NEW_REGEX",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "peekOfCode": "NEW_REGEX = re.compile(\n    f\":(?P<field>{FIELDS}) (?P<name>[\\*\\w]+): (?P<doc>.*?)\"\n    f\"(?:(?=:(?:{FIELDS}|return|raises))|\\Z)\",\n    re.S,\n)\ndef trim(docstring):\n    \"\"\"trim function from PEP-257\"\"\"\n    if not docstring:\n        return \"\"\n    # Convert tabs to spaces (following the normal Python rules)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.docstrings",
        "documentation": {}
    },
    {
        "label": "TestRegistry",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "class TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None\n    missing_this_tests = set()\n    # logic for checking whether each test calls `this_tests`:\n    # 1. `this_tests_check` is set to True during test's 'setup' stage if it wasn't skipped\n    # 2. if the test is dynamically skipped `this_tests_check` is set to False\n    # 3. `this_tests` sets this flag to False when it's successfully completes\n    # 4. if during the 'teardown' stage `this_tests_check` is still True then we",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "a2k",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def a2k(a):\n    return \"::\".join([a[\"file\"], a[\"test\"]]), a[\"line\"]\ndef k2a(k, v):\n    f, t = k.split(\"::\")\n    return {\"file\": f, \"line\": v, \"test\": t}\n# merge by key that is a combination of 2 values: test, file\ndef merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "k2a",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def k2a(k, v):\n    f, t = k.split(\"::\")\n    return {\"file\": f, \"line\": v, \"test\": t}\n# merge by key that is a combination of 2 values: test, file\ndef merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "merge_lists",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def merge_lists(a, b):\n    x = dict(map(a2k, [*a, *b]))  # pack + merge\n    return [k2a(k, v) for k, v in x.items()]  # unpack\ndef merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]\n    return a\ndef this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "merge_registries",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def merge_registries(a, b):\n    for i in b:\n        a[i] = merge_lists(a[i], b[i]) if i in a else b[i]\n    return a\ndef this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "this_tests",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def this_tests(*funcs):\n    TestRegistry.this_tests(*funcs)\ndef str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")\n    else:\n        return None\n    module = subpaths.pop(0)\n    if module in sys.modules:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "str2func",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def str2func(name):\n    \"Converts 'fastai.foo.bar' into an function 'object' if such exists\"\n    if isinstance(name, str):\n        subpaths = name.split(\".\")\n    else:\n        return None\n    module = subpaths.pop(0)\n    if module in sys.modules:\n        obj = sys.modules[module]\n    else:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_func_fq_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_func_fq_name(func):\n    if ismodule(func):\n        return func.__name__\n    if isinstance(func, str):\n        func = str2func(func)\n    name = None\n    if hasattr(func, \"__qualname__\"):\n        name = func.__qualname__\n    elif hasattr(func, \"__name__\"):\n        name = func.__name__",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_parent_func",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_parent_func(lineno, lines, ignore_missing=False):\n    \"Find any lines where `elt` is called and return the parent test function\"\n    for idx, l in enumerate(reversed(lines[:lineno])):\n        if re.match(f\"\\s*def test\", l):\n            return (lineno - idx), l  # 1 based index for github\n        if re.match(f\"\\w+\", l):\n            break  # top level indent - out of function scope\n    if ignore_missing:\n        return None\n    raise LookupError(",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "relative_test_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def relative_test_path(test_file: Path) -> str:\n    \"Path relative to the `fastai` parent directory\"\n    test_file = Path(test_file)\n    testdir_idx = list(reversed(test_file.parts)).index(\"tests\")\n    return \"/\".join(test_file.parts[-(testdir_idx + 1) :])\ndef get_lines(file):\n    with open(file, \"r\") as f:\n        return f.readlines()",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "get_lines",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "def get_lines(file):\n    with open(file, \"r\") as f:\n        return f.readlines()",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "__all__ = [\"this_tests\"]\nDB_NAME = \"test_registry.json\"\ndef _json_set_default(obj):\n    if isinstance(obj, set):\n        return list(obj)\n    raise TypeError\nclass TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "DB_NAME",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "peekOfCode": "DB_NAME = \"test_registry.json\"\ndef _json_set_default(obj):\n    if isinstance(obj, set):\n        return list(obj)\n    raise TypeError\nclass TestRegistry:\n    \"Tests register which API they validate using this class.\"\n    registry = defaultdict(list)\n    this_tests_check = None\n    missing_this_tests = set()",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.doctest",
        "documentation": {}
    },
    {
        "label": "ExecuteShowDocPreprocessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "class ExecuteShowDocPreprocessor(ExecutePreprocessor):\n    \"An ExecutePreprocessor that only executes show_doc cells\"\n    def preprocess_cell(self, cell, resources, index):\n        if \"source\" in cell and cell.cell_type == \"code\":\n            if IMPORT_RE.search(cell[\"source\"]) or SHOW_DOC_RE.search(cell[\"source\"]):\n                return super().preprocess_cell(cell, resources, index)\n        return cell, resources\ndef execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    \"Execute notebook `fname` with `metadata` for preprocessing.\"\n    # Any module used in the notebook that isn't inside must be in the same directory as this script",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_empty_notebook",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_empty_notebook():\n    \"Default notbook with the minimum metadata.\"\n    # TODO: check python version and nbformat\n    return {\n        \"metadata\": {\n            \"kernelspec\": {\n                \"display_name\": \"Python 3\",\n                \"language\": \"python\",\n                \"name\": \"python3\",\n            },",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_md_cell",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_md_cell(source, metadata=None):\n    \"Markdown cell containing `source` with `metadata`.\"\n    return {\n        \"cell_type\": \"markdown\",\n        \"metadata\": {} if metadata is None else metadata,\n        \"source\": source,\n    }\ndef get_empty_cell(ctype=\"markdown\"):\n    \"Empty cell of type `ctype`.\"\n    return {\"cell_type\": ctype, \"metadata\": {}, \"source\": []}",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_empty_cell",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_empty_cell(ctype=\"markdown\"):\n    \"Empty cell of type `ctype`.\"\n    return {\"cell_type\": ctype, \"metadata\": {}, \"source\": []}\ndef get_code_cell(code, hidden=False):\n    \"Code cell containing `code` that may be `hidden`.\"\n    return {\n        \"cell_type\": \"code\",\n        \"execution_count\": 0,\n        \"metadata\": {\"hide_input\": hidden, \"trusted\": True},\n        \"source\": code,",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_code_cell",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_code_cell(code, hidden=False):\n    \"Code cell containing `code` that may be `hidden`.\"\n    return {\n        \"cell_type\": \"code\",\n        \"execution_count\": 0,\n        \"metadata\": {\"hide_input\": hidden, \"trusted\": True},\n        \"source\": code,\n        \"outputs\": [],\n    }\ndef get_doc_cell(func_name):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_doc_cell",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_doc_cell(func_name):\n    \"Code cell with the command to show the doc of `func_name`.\"\n    code = f\"show_doc({func_name})\"\n    return get_code_cell(code, True)\ndef get_global_vars(mod):\n    \"Return globally assigned variables.\"\n    # https://stackoverflow.com/questions/8820276/docstring-for-variable/31764368#31764368\n    import ast\n    import re\n    with open(mod.__file__, \"r\") as f:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_global_vars",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_global_vars(mod):\n    \"Return globally assigned variables.\"\n    # https://stackoverflow.com/questions/8820276/docstring-for-variable/31764368#31764368\n    import ast\n    import re\n    with open(mod.__file__, \"r\") as f:\n        fstr = f.read()\n    flines = fstr.splitlines()\n    d = {}\n    for node in ast.walk(ast.parse(fstr)):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "write_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def write_nb(nb, nb_path, mode=\"w\"):\n    with open(nb_path, mode) as f:\n        f.write(nbformat.writes(nbformat.from_dict(nb), version=4))\nclass ExecuteShowDocPreprocessor(ExecutePreprocessor):\n    \"An ExecutePreprocessor that only executes show_doc cells\"\n    def preprocess_cell(self, cell, resources, index):\n        if \"source\" in cell and cell.cell_type == \"code\":\n            if IMPORT_RE.search(cell[\"source\"]) or SHOW_DOC_RE.search(cell[\"source\"]):\n                return super().preprocess_cell(cell, resources, index)\n        return cell, resources",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "execute_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    \"Execute notebook `fname` with `metadata` for preprocessing.\"\n    # Any module used in the notebook that isn't inside must be in the same directory as this script\n    with open(fname) as f:\n        nb = nbformat.read(f, as_version=4)\n    ep_class = ExecuteShowDocPreprocessor if show_doc_only else ExecutePreprocessor\n    ep = ep_class(timeout=600, kernel_name=\"python3\")\n    metadata = metadata or {}\n    ep.preprocess(nb, metadata)\n    if save:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "create_module_page",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def create_module_page(mod, dest_path, force=False):\n    \"Create the documentation notebook for module `mod_name` in path `dest_path`\"\n    nb = get_empty_notebook()\n    mod_name = mod.__name__\n    strip_name = strip_fastai(mod_name)\n    init_cell = [\n        get_md_cell(f\"## Title for {strip_name} (use plain english, not module name!)\"),\n        get_md_cell(\"Type an introduction of the package here.\"),\n    ]\n    cells = [",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_module_names",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_module_names(path_dir, exclude=None):\n    if exclude is None:\n        exclude = _default_exclude\n    \"Search a given `path_dir` and return all the modules contained inside except those in `exclude`\"\n    files = sorted(\n        path_dir.glob(\"*\"), key=lambda x: (x.is_dir(), x.name), reverse=True\n    )  # directories first\n    res = [f\"{path_dir.name}\"]\n    for f in files:\n        if f.is_dir() and f.name in exclude:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb(fname):\n    \"Read a notebook in `fname` and return its corresponding json\"\n    with open(fname, \"r\") as f:\n        return nbformat.reads(f.read(), as_version=4)\nSHOW_DOC_RE = re.compile(r\"show_doc\\(([\\w\\.]*)\")\ndef read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb_content",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":\n            for match in SHOW_DOC_RE.findall(cell[\"source\"]):\n                doc_fns[match] = i\n    return doc_fns\ndef read_nb_types(cells):\n    doc_fns = {}",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "read_nb_types",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def read_nb_types(cells):\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"markdown\":\n            match = re.match(r\"^(?:<code>|`)?(\\w*)\\s*=\\s*\", cell[\"source\"])\n            if match is not None:\n                doc_fns[match.group(1)] = i\n    return doc_fns\ndef link_markdown_cells(cells, modules):\n    \"Create documentation links for all cells in markdown with backticks.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "link_markdown_cells",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def link_markdown_cells(cells, modules):\n    \"Create documentation links for all cells in markdown with backticks.\"\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"markdown\":\n            cell[\"source\"] = link_docstring(modules, cell[\"source\"])\ndef get_insert_idx(pos_dict, name):\n    \"Return the position to insert a given function doc in a notebook.\"\n    keys, i = list(pos_dict.keys()), 0\n    while i < len(keys) and str.lower(keys[i]) < str.lower(name):\n        i += 1",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_insert_idx",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_insert_idx(pos_dict, name):\n    \"Return the position to insert a given function doc in a notebook.\"\n    keys, i = list(pos_dict.keys()), 0\n    while i < len(keys) and str.lower(keys[i]) < str.lower(name):\n        i += 1\n    if i == len(keys):\n        return -1\n    else:\n        return pos_dict[keys[i]]\ndef update_pos(pos_dict, start_key, nbr=2):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_pos",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_pos(pos_dict, start_key, nbr=2):\n    \"Update the `pos_dict` by moving all positions after `start_key` by `nbr`.\"\n    for key, idx in pos_dict.items():\n        if str.lower(key) >= str.lower(start_key):\n            pos_dict[key] += nbr\n    return pos_dict\ndef insert_cells(cells, pos_dict, ft_name, append=False):\n    \"Insert the function doc `cells` at their correct position and updates `pos_dict`.\"\n    idx = get_insert_idx(pos_dict, ft_name)\n    if append or idx == -1:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "insert_cells",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def insert_cells(cells, pos_dict, ft_name, append=False):\n    \"Insert the function doc `cells` at their correct position and updates `pos_dict`.\"\n    idx = get_insert_idx(pos_dict, ft_name)\n    if append or idx == -1:\n        cells += [get_doc_cell(ft_name), get_empty_cell()]\n    else:\n        cells.insert(idx, get_doc_cell(ft_name))\n        cells.insert(idx + 1, get_empty_cell())\n        pos_dict = update_pos(pos_dict, ft_name, 2)\n    return cells, pos_dict",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_doc_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_doc_path(mod, dest_path):\n    strip_name = strip_fastai(mod.__name__)\n    return os.path.join(dest_path, f\"{strip_name}.ipynb\")\ndef generate_missing_metadata(dest_file):\n    fn = Path(dest_file)\n    meta_fn = fn.parent / \"jekyll_metadata.ipynb\"\n    if not fn.exists() or not meta_fn.exists():\n        return print(\"Could not find notebooks:\", fn, meta_fn)\n    metadata_nb = read_nb(meta_fn)\n    if has_metadata_cell(metadata_nb[\"cells\"], fn.name):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "generate_missing_metadata",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def generate_missing_metadata(dest_file):\n    fn = Path(dest_file)\n    meta_fn = fn.parent / \"jekyll_metadata.ipynb\"\n    if not fn.exists() or not meta_fn.exists():\n        return print(\"Could not find notebooks:\", fn, meta_fn)\n    metadata_nb = read_nb(meta_fn)\n    if has_metadata_cell(metadata_nb[\"cells\"], fn.name):\n        return\n    nb = read_nb(fn)\n    jmd = nb[\"metadata\"].get(\"jekyll\", {})",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_nb_metadata",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_nb_metadata(\n    nb_path=None, title=None, summary=None, keywords=\"fastai\", overwrite=True, **kwargs\n):\n    \"Creates jekyll metadata for given notebook path.\"\n    nb = read_nb(nb_path)\n    data = {\"title\": title, \"summary\": summary, \"keywords\": keywords, **kwargs}\n    data = {k: v for (k, v) in data.items() if v is not None}  # remove none values\n    if not data:\n        return\n    nb[\"metadata\"][\"jekyll\"] = data",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "has_metadata_cell",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def has_metadata_cell(cells, fn):\n    for c in cells:\n        if re.search(f\"update_nb_metadata\\('{fn}'\", c[\"source\"]):\n            return c\ndef stringify(s):\n    return f\"'{s}'\" if isinstance(s, str) else s\nIMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def stringify(s):\n    return f\"'{s}'\" if isinstance(s, str) else s\nIMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_imported_modules",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])\n        if cell[\"cell_type\"] == \"code\"\n    ]\n    parts = nb_module_name.split(\".\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_top_level_modules",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_top_level_modules(num_levels=1):\n    mod_dir = Path(import_mod(\"fastai\").__file__).parent\n    filtered_n = filter(lambda x: x.count(\".\") <= num_levels, get_module_names(mod_dir))\n    return sorted(\n        filtered_n, key=lambda s: s.count(\".\"), reverse=True\n    )  # Submodules first (sorted by periods)\nNEW_FT_HEADER = \"## New Methods - Please document or move to the undocumented section\"\nUNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "parse_sections",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):\n                current_section = new_cells\n        current_section.append(cell)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "remove_undoc_cells",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def remove_undoc_cells(cells):\n    old, _, _ = parse_sections(cells)\n    return old\n# currently code vbox sub-cells mainly\ndef remove_code_cell_jupyter_widget_state_elem(cells):\n    for c in cells:\n        if c[\"cell_type\"] == \"code\":\n            if \"outputs\" in c:\n                c[\"outputs\"] = [\n                    l",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "remove_code_cell_jupyter_widget_state_elem",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def remove_code_cell_jupyter_widget_state_elem(cells):\n    for c in cells:\n        if c[\"cell_type\"] == \"code\":\n            if \"outputs\" in c:\n                c[\"outputs\"] = [\n                    l\n                    for l in c[\"outputs\"]\n                    if not (\n                        \"data\" in l\n                        and \"application/vnd.jupyter.widget-view+json\" in l.data",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_module_page",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_module_page(mod, dest_path=\".\"):\n    \"Update the documentation notebook of a given module.\"\n    doc_path = get_doc_path(mod, dest_path)\n    strip_name = strip_fastai(mod.__name__)\n    nb = read_nb(doc_path)\n    cells = nb[\"cells\"]\n    link_markdown_cells(cells, get_imported_modules(cells, mod.__name__))\n    type_dict = read_nb_types(cells)\n    gvar_map = get_global_vars(mod)\n    for name in get_exports(mod):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "link_nb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def link_nb(nb_path):\n    nb = read_nb(nb_path)\n    cells = nb[\"cells\"]\n    link_markdown_cells(cells, get_imported_modules(cells, Path(nb_path).stem))\n    write_nb(nb, nb_path)\n    NotebookNotary().sign(read_nb(nb_path))\ndef get_module_from_notebook(doc_path):\n    \"Find module given a source path. Assume it belongs to fastai directory\"\n    return f\"fastai.{Path(doc_path).stem}\"\ndef check_nbconvert_version():",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "get_module_from_notebook",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def get_module_from_notebook(doc_path):\n    \"Find module given a source path. Assume it belongs to fastai directory\"\n    return f\"fastai.{Path(doc_path).stem}\"\ndef check_nbconvert_version():\n    import nbconvert\n    assert nbconvert.version_info >= (\n        5,\n        4,\n        0,\n    ), \"Please update nbconvert to >=5.4 for consistent .html output\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "check_nbconvert_version",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def check_nbconvert_version():\n    import nbconvert\n    assert nbconvert.version_info >= (\n        5,\n        4,\n        0,\n    ), \"Please update nbconvert to >=5.4 for consistent .html output\"\ndef update_notebooks(\n    source_path,\n    dest_path=None,",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "update_notebooks",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "def update_notebooks(\n    source_path,\n    dest_path=None,\n    update_html=True,\n    document_new_fns=False,\n    update_nb_links=True,\n    html_path=None,\n    force=False,\n):\n    \"`source_path` can be a directory or a file. Assume all modules reside in the fastai directory.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "__all__ = [\n    \"create_module_page\",\n    \"update_module_page\",\n    \"import_mod\",\n    \"link_nb\",\n    \"update_notebooks\",\n    \"generate_missing_metadata\",\n    \"update_nb_metadata\",\n]\ndef get_empty_notebook():",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "_default_exclude",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "_default_exclude = [\".ipynb_checkpoints\", \"__pycache__\", \"__init__.py\", \"imports\"]\ndef get_module_names(path_dir, exclude=None):\n    if exclude is None:\n        exclude = _default_exclude\n    \"Search a given `path_dir` and return all the modules contained inside except those in `exclude`\"\n    files = sorted(\n        path_dir.glob(\"*\"), key=lambda x: (x.is_dir(), x.name), reverse=True\n    )  # directories first\n    res = [f\"{path_dir.name}\"]\n    for f in files:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "SHOW_DOC_RE",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "SHOW_DOC_RE = re.compile(r\"show_doc\\(([\\w\\.]*)\")\ndef read_nb_content(cells, mod_name):\n    \"Build a dictionary containing the position of the `cells`.\"\n    doc_fns = {}\n    for i, cell in enumerate(cells):\n        if cell[\"cell_type\"] == \"code\":\n            for match in SHOW_DOC_RE.findall(cell[\"source\"]):\n                doc_fns[match] = i\n    return doc_fns\ndef read_nb_types(cells):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "IMPORT_RE",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "IMPORT_RE = re.compile(r\"from (fastai[\\.\\w_]*)\")\ndef get_imported_modules(cells, nb_module_name=\"\"):\n    \"Finds all submodules of notebook - sorted by submodules > top level modules > manual imports. This gives notebook imports priority\"\n    module_names = get_top_level_modules()\n    nb_imports = [\n        match.group(1)\n        for cell in cells\n        for match in IMPORT_RE.finditer(cell[\"source\"])\n        if cell[\"cell_type\"] == \"code\"\n    ]",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "NEW_FT_HEADER",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "NEW_FT_HEADER = \"## New Methods - Please document or move to the undocumented section\"\nUNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "UNDOC_HEADER",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "peekOfCode": "UNDOC_HEADER = \"## Undocumented Methods - Methods moved below this line will intentionally be hidden\"\ndef parse_sections(cells):\n    old_cells, undoc_cells, new_cells = [], [], []\n    current_section = old_cells\n    for cell in cells:\n        if cell[\"cell_type\"] == \"markdown\":\n            if re.match(UNDOC_HEADER, cell[\"source\"]):\n                current_section = undoc_cells\n            if re.match(NEW_FT_HEADER, cell[\"source\"]):\n                current_section = new_cells",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.gen_notebooks",
        "documentation": {}
    },
    {
        "label": "is_enum",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"\n    if is_fastai_class(arg_type):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "link_type",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"\n    if is_fastai_class(arg_type):\n        return f\"[{arg_name}]({get_fn_link(arg_type)})\"\n    return arg_name",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "is_fastai_class",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def is_fastai_class(t):\n    return belongs_to_module(t, MODULE_NAME)\ndef belongs_to_module(t, module_name):\n    \"Check if `t` belongs to `module_name`.\"\n    if hasattr(t, \"__func__\"):\n        return belongs_to_module(t.__func__, module_name)\n    if not inspect.getmodule(t):\n        return False\n    return inspect.getmodule(t).__name__.startswith(module_name)\ndef code_esc(s):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "belongs_to_module",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def belongs_to_module(t, module_name):\n    \"Check if `t` belongs to `module_name`.\"\n    if hasattr(t, \"__func__\"):\n        return belongs_to_module(t.__func__, module_name)\n    if not inspect.getmodule(t):\n        return False\n    return inspect.getmodule(t).__name__.startswith(module_name)\ndef code_esc(s):\n    return f\"`{s}`\"\ndef type_repr(t):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "code_esc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def code_esc(s):\n    return f\"`{s}`\"\ndef type_repr(t):\n    if t in _typing_names:\n        return link_type(t, _typing_names[t])\n    if isinstance(t, partial):\n        return partial_repr(t)\n    if hasattr(t, \"__forward_arg__\"):\n        return link_type(t.__forward_arg__)\n    elif getattr(t, \"__args__\", None):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "type_repr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def type_repr(t):\n    if t in _typing_names:\n        return link_type(t, _typing_names[t])\n    if isinstance(t, partial):\n        return partial_repr(t)\n    if hasattr(t, \"__forward_arg__\"):\n        return link_type(t.__forward_arg__)\n    elif getattr(t, \"__args__\", None):\n        args = t.__args__\n        if len(args) == 2 and args[1] == type(None):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "partial_repr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def partial_repr(t):\n    args = (t.func,) + t.args + tuple([f\"{k}={v}\" for k, v in t.keywords.items()])\n    reprs = \", \".join([link_type(o) for o in args])\n    return f\"<code>partial(</code>{reprs}<code>)</code>\"\ndef anno_repr(a):\n    return type_repr(a)\ndef format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "anno_repr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def anno_repr(a):\n    return type_repr(a)\ndef format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"\n    if hasattr(p, \"annotation\") and p.annotation != p.empty:\n        res += f\":{anno_repr(p.annotation)}\"\n    if p.default != p.empty:\n        default = getattr(p.default, \"func\", p.default)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_param",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_param(p):\n    \"Formats function param to `param1:Type=val`. Font weights: param1=bold, val=bold+italic\"\n    arg_prefix = arg_prefixes.get(p.kind, \"\")  # asterisk prefix for *args and **kwargs\n    res = f\"**{arg_prefix}{code_esc(p.name)}**\"\n    if hasattr(p, \"annotation\") and p.annotation != p.empty:\n        res += f\":{anno_repr(p.annotation)}\"\n    if p.default != p.empty:\n        default = getattr(p.default, \"func\", p.default)\n        default = getattr(default, \"__name__\", default)\n        res += f\"=***`{repr(default)}`***\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_ft_def",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_ft_def(func, full_name: str = None) -> str:\n    \"Format and link `func` definition to show in documentation\"\n    sig = inspect.signature(func)\n    name = f\"<code>{full_name or func.__name__}</code>\"\n    fmt_params = [\n        format_param(param)\n        for name, param in sig.parameters.items()\n        if name not in (\"self\", \"cls\")\n    ]\n    arg_str = f\"({', '.join(fmt_params)})\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_enum_doc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_enum_doc(elt, full_name: str) -> str:\n    \"Formatted enum documentation.\"\n    vals = \", \".join(elt.__members__.keys())\n    return f\"{code_esc(full_name)}\", f\"<code>Enum</code> = [{vals}]\"\ndef get_cls_doc(elt, full_name: str) -> str:\n    \"Class definition.\"\n    parent_class = inspect.getclasstree([elt])[-1][0][1][0]\n    name, args = format_ft_def(elt, full_name)\n    if parent_class != object:\n        args += f\" :: {link_type(parent_class, include_bt=True)}\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_cls_doc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_cls_doc(elt, full_name: str) -> str:\n    \"Class definition.\"\n    parent_class = inspect.getclasstree([elt])[-1][0][1][0]\n    name, args = format_ft_def(elt, full_name)\n    if parent_class != object:\n        args += f\" :: {link_type(parent_class, include_bt=True)}\"\n    return name, args\ndef show_doc(\n    elt,\n    doc_string: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_doc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_doc(\n    elt,\n    doc_string: bool = True,\n    full_name: str = None,\n    arg_comments: dict = None,\n    title_level=None,\n    alt_doc_string: str = \"\",\n    ignore_warn: bool = False,\n    markdown=True,\n    show_tests=True,",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "md2html",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def md2html(md):\n    if nbconvert.__version__ < \"5.5.0\":\n        return HTMLExporter().markdown2html(md)\n    else:\n        return HTMLExporter().markdown2html(defaultdict(lambda: defaultdict(dict)), md)\ndef doc(elt):\n    \"Show `show_doc` info in preview window along with link to full docs.\"\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, \"__func__\", elt)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def doc(elt):\n    \"Show `show_doc` info in preview window along with link to full docs.\"\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, \"__func__\", elt)\n    md = show_doc(elt, markdown=False)\n    if is_fastai_class(elt):\n        md += f'\\n\\n<a href=\"{get_fn_link(elt)}\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a>'\n    output = md2html(md)\n    use_relative_links = True",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "format_docstring",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def format_docstring(\n    elt, arg_comments: dict = {}, alt_doc_string: str = \"\", ignore_warn: bool = False\n) -> str:\n    \"Merge and format the docstring definition with `arg_comments` and `alt_doc_string`.\"\n    parsed = \"\"\n    doc = parse_docstring(inspect.getdoc(elt))\n    description = (\n        alt_doc_string or f\"{doc['short_description']} {doc['long_description']}\"\n    )\n    if description:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "replace_link",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def replace_link(m):\n    keyword = m.group(1) or m.group(2)\n    elt = find_elt(_modvars, keyword)\n    if elt is None:\n        return m.group()\n    return link_type(elt, arg_name=keyword)\n# Finds all places with a backtick but only if it hasn't already been linked\nBT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"\n)  # matches [`key`](link) or `key`",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "link_docstring",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def link_docstring(modules, docstring: str, overwrite: bool = False) -> str:\n    \"Search `docstring` for backticks and attempt to link those functions to respective documentation.\"\n    mods = listify(modules)\n    for mod in mods:\n        _modvars.update(mod.__dict__)  # concat all module definitions\n    return re.sub(BT_REGEX, replace_link, docstring)\ndef find_elt(modvars, keyword, match_last=False):\n    \"Attempt to resolve keywords such as Learner.lr_find. `match_last` starts matching from last component.\"\n    keyword = strip_fastai(keyword)\n    if keyword in modvars:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "find_elt",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def find_elt(modvars, keyword, match_last=False):\n    \"Attempt to resolve keywords such as Learner.lr_find. `match_last` starts matching from last component.\"\n    keyword = strip_fastai(keyword)\n    if keyword in modvars:\n        return modvars[keyword]\n    comps = keyword.split(\".\")\n    comp_elt = modvars.get(comps[0])\n    if hasattr(comp_elt, \"__dict__\"):\n        return find_elt(comp_elt.__dict__, \".\".join(comps[1:]), match_last=match_last)\ndef import_mod(mod_name: str, ignore_errors=False):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "import_mod",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def import_mod(mod_name: str, ignore_errors=False):\n    \"Return module from `mod_name`.\"\n    splits = str.split(mod_name, \".\")\n    try:\n        if len(splits) > 1:\n            mod = importlib.import_module(\".\" + \".\".join(splits[1:]), splits[0])\n        else:\n            mod = importlib.import_module(mod_name)\n        return mod\n    except:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_doc_from_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_doc_from_name(\n    mod_name,\n    ft_name: str,\n    doc_string: bool = True,\n    arg_comments: dict = {},\n    alt_doc_string: str = \"\",\n):\n    \"Show documentation for `ft_name`, see `show_doc`.\"\n    mod = import_mod(mod_name)\n    splits = str.split(ft_name, \".\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_exports",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_exports(mod):\n    public_names = mod.__all__ if hasattr(mod, \"__all__\") else dir(mod)\n    # public_names.sort(key=str.lower)\n    return [o for o in public_names if not o.startswith(\"_\")]\ndef get_ft_names(mod, include_inner=False) -> List[str]:\n    \"Return all the functions of module `mod`.\"\n    # If the module has an attribute __all__, it picks those.\n    # Otherwise, it returns all the functions defined inside a module.\n    fn_names = []\n    for elt_name in get_exports(mod):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_ft_names",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_ft_names(mod, include_inner=False) -> List[str]:\n    \"Return all the functions of module `mod`.\"\n    # If the module has an attribute __all__, it picks those.\n    # Otherwise, it returns all the functions defined inside a module.\n    fn_names = []\n    for elt_name in get_exports(mod):\n        elt = getattr(mod, elt_name)\n        # This removes the files imported from elsewhere\n        try:\n            fname = inspect.getfile(elt)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_inner_fts",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_inner_fts(elt) -> List[str]:\n    \"List the inner functions of a class.\"\n    fts = []\n    for ft_name in elt.__dict__.keys():\n        if ft_name.startswith(\"_\"):\n            continue\n        ft = getattr(elt, ft_name)\n        if inspect.isfunction(ft):\n            fts.append(f\"{elt.__name__}.{ft_name}\")\n        if inspect.ismethod(ft):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_module_toc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_module_toc(mod_name):\n    \"Display table of contents for given `mod_name`.\"\n    mod = import_mod(mod_name)\n    ft_names = mod.__all__ if hasattr(mod, \"__all__\") else get_ft_names(mod)\n    ft_names.sort(key=str.lower)\n    tabmat = \"\"\n    for ft_name in ft_names:\n        tabmat += f\"- [{ft_name}](#{ft_name})\\n\"\n        elt = getattr(mod, ft_name)\n        if inspect.isclass(elt) and not is_enum(elt.__class__):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_video",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_video(url):\n    \"Display video in `url`.\"\n    data = f'<iframe width=\"560\" height=\"315\" src=\"{url}\" frameborder=\"0\" allowfullscreen></iframe>'\n    return display(HTML(data))\ndef show_video_from_youtube(code, start=0):\n    \"Display video from Youtube with a `code` and a `start` time.\"\n    url = f\"https://www.youtube.com/embed/{code}?start={start}&amp;rel=0&amp;controls=0&amp;showinfo=0\"\n    return show_video(url)\ndef get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_video_from_youtube",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def show_video_from_youtube(code, start=0):\n    \"Display video from Youtube with a `code` and a `start` time.\"\n    url = f\"https://www.youtube.com/embed/{code}?start={start}&amp;rel=0&amp;controls=0&amp;showinfo=0\"\n    return show_video(url)\ndef get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):\n        return fn.__qualname__\n    if inspect.ismethod(fn):\n        return fn_name(fn.__self__) + \".\" + fn_name(fn)\n    return fn_name(fn)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_anchor",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_anchor(fn) -> str:\n    if hasattr(fn, \"__qualname__\"):\n        return fn.__qualname__\n    if inspect.ismethod(fn):\n        return fn_name(fn.__self__) + \".\" + fn_name(fn)\n    return fn_name(fn)\ndef fn_name(ft) -> str:\n    if ft.__hash__ and ft in _typing_names:\n        return _typing_names[ft]\n    if hasattr(ft, \"__name__\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "fn_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def fn_name(ft) -> str:\n    if ft.__hash__ and ft in _typing_names:\n        return _typing_names[ft]\n    if hasattr(ft, \"__name__\"):\n        return ft.__name__\n    elif hasattr(ft, \"_name\") and ft._name:\n        return ft._name\n    elif hasattr(ft, \"__origin__\"):\n        return str(ft.__origin__).split(\".\")[-1]\n    else:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_fn_link",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_fn_link(ft) -> str:\n    \"Return function link to notebook documentation of `ft`. Private functions link to source code\"\n    ft = getattr(ft, \"__func__\", ft)\n    anchor = strip_fastai(get_anchor(ft))\n    module_name = strip_fastai(get_module_name(ft))\n    base = \"\" if use_relative_links else FASTAI_DOCS\n    return f\"{base}/{module_name}.html#{anchor}\"\ndef get_module_name(ft) -> str:\n    return inspect.getmodule(ft).__name__\ndef get_pytorch_link(ft) -> str:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_module_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_module_name(ft) -> str:\n    return inspect.getmodule(ft).__name__\ndef get_pytorch_link(ft) -> str:\n    \"Returns link to pytorch docs of `ft`.\"\n    name = ft.__name__\n    ext = \".html\"\n    if name == \"device\":\n        return f\"{PYTORCH_DOCS}tensor_attributes{ext}#torch-device\"\n    if name == \"Tensor\":\n        return f\"{PYTORCH_DOCS}tensors{ext}#torch-tensor\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_pytorch_link",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_pytorch_link(ft) -> str:\n    \"Returns link to pytorch docs of `ft`.\"\n    name = ft.__name__\n    ext = \".html\"\n    if name == \"device\":\n        return f\"{PYTORCH_DOCS}tensor_attributes{ext}#torch-device\"\n    if name == \"Tensor\":\n        return f\"{PYTORCH_DOCS}tensors{ext}#torch-tensor\"\n    if name.startswith(\"torchvision\"):\n        doc_path = get_module_name(ft).replace(\".\", \"/\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_source_link",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_source_link(file, line, display_text=\"[source]\", **kwargs) -> str:\n    \"Returns github link for given file\"\n    link = f\"{SOURCE_URL}{file}#L{line}\"\n    if display_text is None:\n        return link\n    return (\n        f'<a href=\"{link}\" class=\"source_link\" style=\"float:right\">{display_text}</a>'\n    )\ndef get_function_source(ft, **kwargs) -> str:\n    \"Returns link to `ft` in source code.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "get_function_source",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def get_function_source(ft, **kwargs) -> str:\n    \"Returns link to `ft` in source code.\"\n    try:\n        line = inspect.getsourcelines(ft)[1]\n    except Exception:\n        return \"\"\n    mod_path = get_module_name(ft).replace(\".\", \"/\") + \".py\"\n    return get_source_link(mod_path, line, **kwargs)\ndef title_md(s: str, title_level: int, markdown=True):\n    res = \"#\" * title_level",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "title_md",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def title_md(s: str, title_level: int, markdown=True):\n    res = \"#\" * title_level\n    if title_level:\n        res += \" \"\n    return Markdown(res + s) if markdown else (res + s)\ndef jekyll_div(s, c, h, icon=None):\n    icon = ifnone(icon, c)\n    res = f'<div markdown=\"span\" class=\"alert alert-{c}\" role=\"alert\"><i class=\"fa fa-{c}-circle\"></i> <b>{h}: </b>{s}</div>'\n    display(Markdown(res))\ndef jekyll_note(s):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_div",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_div(s, c, h, icon=None):\n    icon = ifnone(icon, c)\n    res = f'<div markdown=\"span\" class=\"alert alert-{c}\" role=\"alert\"><i class=\"fa fa-{c}-circle\"></i> <b>{h}: </b>{s}</div>'\n    display(Markdown(res))\ndef jekyll_note(s):\n    return jekyll_div(s, \"info\", \"Note\")\ndef jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_note",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_note(s):\n    return jekyll_div(s, \"info\", \"Note\")\ndef jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_warn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_warn(s):\n    return jekyll_div(s, \"danger\", \"Warning\", \"exclamation\")\ndef jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "jekyll_important",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "def jekyll_important(s):\n    return jekyll_div(s, \"warning\", \"Important\")",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "__all__ = [\n    \"get_fn_link\",\n    \"link_docstring\",\n    \"show_doc\",\n    \"get_ft_names\",\n    \"md2html\",\n    \"get_exports\",\n    \"show_video\",\n    \"show_video_from_youtube\",\n    \"import_mod\",",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "MODULE_NAME",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "MODULE_NAME = \"fastai\"\nSOURCE_URL = \"https://github.com/fastai/fastai/blob/master/\"\nPYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "SOURCE_URL",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "SOURCE_URL = \"https://github.com/fastai/fastai/blob/master/\"\nPYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "PYTORCH_DOCS",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "PYTORCH_DOCS = \"https://pytorch.org/docs/stable/\"\nFASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "FASTAI_DOCS",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "FASTAI_DOCS = \"https://docs.fast.ai\"\nuse_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "use_relative_links",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "use_relative_links = True\n_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "_typing_names",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "_typing_names = {t: n for t, n in fastai_types.items() if t.__module__ == \"typing\"}\narg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "arg_prefixes",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "arg_prefixes = {inspect._VAR_POSITIONAL: \"\\*\", inspect._VAR_KEYWORD: \"\\*\\*\"}\ndef is_enum(cls):\n    return cls == enum.Enum or cls == enum.EnumMeta\ndef link_type(arg_type, arg_name=None, include_bt: bool = True):\n    \"Create link to documentation.\"\n    arg_name = arg_name or fn_name(arg_type)\n    if include_bt:\n        arg_name = code_esc(arg_name)\n    if belongs_to_module(arg_type, \"torch\") and (\"Tensor\" not in arg_name):\n        return f\"[{arg_name}]({get_pytorch_link(arg_type)})\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "_modvars",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "_modvars = {}\ndef replace_link(m):\n    keyword = m.group(1) or m.group(2)\n    elt = find_elt(_modvars, keyword)\n    if elt is None:\n        return m.group()\n    return link_type(elt, arg_name=keyword)\n# Finds all places with a backtick but only if it hasn't already been linked\nBT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "BT_REGEX",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "peekOfCode": "BT_REGEX = re.compile(\n    \"\\[`([^`]*)`\\](?:\\([^)]*\\))|`([^`]*)`\"\n)  # matches [`key`](link) or `key`\ndef link_docstring(modules, docstring: str, overwrite: bool = False) -> str:\n    \"Search `docstring` for backticks and attempt to link those functions to respective documentation.\"\n    mods = listify(modules)\n    for mod in mods:\n        _modvars.update(mod.__dict__)  # concat all module definitions\n    return re.sub(BT_REGEX, replace_link, docstring)\ndef find_elt(modvars, keyword, match_last=False):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbdoc",
        "documentation": {}
    },
    {
        "label": "show_test",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def show_test(elt) -> str:\n    \"Show associated tests for a fastai function/class\"\n    md = build_tests_markdown(elt)\n    display(Markdown(md))\ndef doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:\n        page.page({\"text/html\": output})",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "doctest",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:\n        page.page({\"text/html\": output})\n    except:\n        display(Markdown(md))\ndef build_tests_markdown(elt):\n    fn_name = nbdoc.fn_name(elt)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "build_tests_markdown",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def build_tests_markdown(elt):\n    fn_name = nbdoc.fn_name(elt)\n    md = \"\"\n    db_matches = [get_links(t) for t in lookup_db(elt)]\n    md += tests2md(db_matches, \"\")\n    try:\n        related = [get_links(t) for t in find_related_tests(elt)]\n        other_tests = [k for k in OrderedDict.fromkeys(related) if k not in db_matches]\n        md += tests2md(other_tests, f\"Some other tests where `{fn_name}` is used:\")\n    except OSError as e:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "tests2md",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def tests2md(tests, type_label: str):\n    if not tests:\n        return \"\"\n    md = [f\"\\n\\n{type_label}\"] + [\n        f\"* `{cmd}` {link}\" for link, cmd in sorted(tests, key=lambda k: k[1])\n    ]\n    return \"\\n\".join(md)\ndef get_pytest_html(elt, anchor_id: str) -> Tuple[str, str]:\n    md = build_tests_markdown(elt)\n    html = nbdoc.md2html(md).replace(",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_pytest_html",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_pytest_html(elt, anchor_id: str) -> Tuple[str, str]:\n    md = build_tests_markdown(elt)\n    html = nbdoc.md2html(md).replace(\n        \"\\n\", \"\"\n    )  # nbconverter fails to parse markdown if it has both html and '\\n'\n    anchor_id = anchor_id.replace(\".\", \"-\") + \"-pytest\"\n    link, body = get_pytest_card(html, anchor_id)\n    return link, body\ndef get_pytest_card(html, anchor_id):\n    \"creates a collapsible bootstrap card for `show_test`\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_pytest_card",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_pytest_card(html, anchor_id):\n    \"creates a collapsible bootstrap card for `show_test`\"\n    link = f'<a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#{anchor_id}\" style=\"float:right; padding-right:10px\">[test]</a>'\n    body = (\n        f'<div class=\"collapse\" id=\"{anchor_id}\"><div class=\"card card-body pytest_card\">'\n        f'<a type=\"button\" data-toggle=\"collapse\" data-target=\"#{anchor_id}\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a>'\n        f\"{html}\"\n        \"</div></div>\"\n    )\n    return link, body",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "lookup_db",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def lookup_db(elt) -> List[Dict]:\n    \"Finds `this_test` entries from test_registry.json\"\n    db_file = Path(abspath(join(dirname(__file__), \"..\"))) / DB_NAME\n    if not db_file.exists():\n        raise Exception(\n            f'Could not find {db_file}. Please make sure it exists at \"{db_file}\" or run `make test`'\n        )\n    with open(db_file, \"r\") as f:\n        db = json.load(f)\n    key = get_func_fq_name(elt)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_related_tests",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_related_tests(elt) -> Tuple[List[Dict], List[Dict]]:\n    \"Searches `fastai/tests` folder for any test functions related to `elt`\"\n    related_matches = []\n    for test_file in find_test_files(elt):\n        fuzzy_matches = find_test_matches(elt, test_file)\n        related_matches.extend(fuzzy_matches)\n    return related_matches\ndef get_tests_dir(elt) -> Path:\n    \"Absolute path of `fastai/tests` directory\"\n    test_dir = Path(__file__).parent.parent.parent.resolve() / \"tests\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_tests_dir",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_tests_dir(elt) -> Path:\n    \"Absolute path of `fastai/tests` directory\"\n    test_dir = Path(__file__).parent.parent.parent.resolve() / \"tests\"\n    if not test_dir.exists():\n        raise OSError(\"Could not find test directory at this location:\", test_dir)\n    return test_dir\ndef get_file(elt) -> str:\n    if hasattr(elt, \"__wrapped__\"):\n        elt = elt.__wrapped__\n    if not nbdoc.is_fastai_class(elt):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_file",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_file(elt) -> str:\n    if hasattr(elt, \"__wrapped__\"):\n        elt = elt.__wrapped__\n    if not nbdoc.is_fastai_class(elt):\n        return None\n    return inspect.getfile(elt)\ndef find_test_files(elt, exact_match: bool = False) -> List[Path]:\n    \"Searches in `fastai/tests` directory for module tests\"\n    test_dir = get_tests_dir(elt)\n    matches = [",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_test_files",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_test_files(elt, exact_match: bool = False) -> List[Path]:\n    \"Searches in `fastai/tests` directory for module tests\"\n    test_dir = get_tests_dir(elt)\n    matches = [\n        test_dir / o.name for o in os.scandir(test_dir) if _is_file_match(elt, o.name)\n    ]\n    # if len(matches) != 1: raise Error('Could not find exact file match:', matches)\n    return matches\ndef _is_file_match(elt, file_name: str, exact_match: bool = False) -> bool:\n    fp = get_file(elt)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "find_test_matches",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def find_test_matches(elt, test_file: Path) -> Tuple[List[Dict], List[Dict]]:\n    \"Find all functions in `test_file` related to `elt`\"\n    lines = get_lines(test_file)\n    rel_path = relative_test_path(test_file)\n    fn_name = get_qualname(elt) if not inspect.ismodule(elt) else \"\"\n    return fuzzy_test_match(fn_name, lines, rel_path)\ndef get_qualname(elt):\n    return elt.__qualname__ if hasattr(elt, \"__qualname__\") else fn_name(elt)\ndef separate_comp(qualname: str):\n    if not isinstance(qualname, str):",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_qualname",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_qualname(elt):\n    return elt.__qualname__ if hasattr(elt, \"__qualname__\") else fn_name(elt)\ndef separate_comp(qualname: str):\n    if not isinstance(qualname, str):\n        qualname = get_qualname(qualname)\n    parts = qualname.split(\".\")\n    parts[-1] = remove_underscore(parts[-1])\n    if len(parts) == 1:\n        return [], parts[0]\n    return parts[:-1], parts[-1]",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "separate_comp",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def separate_comp(qualname: str):\n    if not isinstance(qualname, str):\n        qualname = get_qualname(qualname)\n    parts = qualname.split(\".\")\n    parts[-1] = remove_underscore(parts[-1])\n    if len(parts) == 1:\n        return [], parts[0]\n    return parts[:-1], parts[-1]\ndef remove_underscore(fn_name):\n    if fn_name and fn_name[0] == \"_\":",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "remove_underscore",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def remove_underscore(fn_name):\n    if fn_name and fn_name[0] == \"_\":\n        return fn_name[1:]  # remove private method underscore prefix\n    return fn_name\ndef fuzzy_test_match(\n    fn_name: str, lines: List[Dict], rel_path: str\n) -> List[TestFunctionMatch]:\n    \"Find any lines where `fn_name` is invoked and return the parent test function\"\n    fuzzy_line_matches = _fuzzy_line_match(fn_name, lines)\n    fuzzy_matches = [",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "fuzzy_test_match",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def fuzzy_test_match(\n    fn_name: str, lines: List[Dict], rel_path: str\n) -> List[TestFunctionMatch]:\n    \"Find any lines where `fn_name` is invoked and return the parent test function\"\n    fuzzy_line_matches = _fuzzy_line_match(fn_name, lines)\n    fuzzy_matches = [\n        get_parent_func(lno, lines, ignore_missing=True)\n        for lno, _ in fuzzy_line_matches\n    ]\n    fuzzy_matches = list(filter(None.__ne__, fuzzy_matches))",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_lines",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_lines(file: Path) -> List[str]:\n    with open(file, \"r\") as f:\n        return f.readlines()\ndef map_test(test_file, line, line_text):\n    \"Creates dictionary test format to match doctest api\"\n    test_name = re.match(f\"\\s*def (test_\\w*)\", line_text).groups(0)[0]\n    return {\"file\": test_file, \"line\": line, \"test\": test_name}\ndef get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "map_test",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def map_test(test_file, line, line_text):\n    \"Creates dictionary test format to match doctest api\"\n    test_name = re.match(f\"\\s*def (test_\\w*)\", line_text).groups(0)[0]\n    return {\"file\": test_file, \"line\": line, \"test\": test_name}\ndef get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)\ndef pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "get_links",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def get_links(metadata) -> Tuple[str, str]:\n    \"Returns source code link and pytest command\"\n    return nbdoc.get_source_link(**metadata), pytest_command(**metadata)\ndef pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "pytest_command",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "def pytest_command(file: str, test: str, **kwargs) -> str:\n    \"Returns CLI command to run specific test function\"\n    return f\"pytest -sv {file}::{test}\"",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "__all__ = [\n    \"show_test\",\n    \"doctest\",\n    \"find_related_tests\",\n    \"lookup_db\",\n    \"find_test_matches\",\n    \"find_test_files\",\n    \"fuzzy_test_match\",\n    \"get_pytest_html\",\n]",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "TestFunctionMatch",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "description": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "peekOfCode": "TestFunctionMatch = namedtuple(\"TestFunctionMatch\", [\"line_number\", \"line\"])\ndef show_test(elt) -> str:\n    \"Show associated tests for a fastai function/class\"\n    md = build_tests_markdown(elt)\n    display(Markdown(md))\ndef doctest(elt):\n    \"Inline notebook popup for `show_test`\"\n    md = build_tests_markdown(elt)\n    output = nbdoc.md2html(md)\n    try:",
        "detail": "dashboard.dl_model.deoldify.fastai.gen_doc.nbtest",
        "documentation": {}
    },
    {
        "label": "try_import",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.imports.core",
        "description": "dashboard.dl_model.deoldify.fastai.imports.core",
        "peekOfCode": "def try_import(module):\n    \"Try to import `module`. Returns module's object on success, None on failure\"\n    try:\n        return importlib.import_module(module)\n    except:\n        return None\ndef have_min_pkg_version(package, version):\n    \"Check whether we have at least `version` of `package`. Returns True on success, False otherwise.\"\n    try:\n        pkg_resources.require(f\"{package}>={version}\")",
        "detail": "dashboard.dl_model.deoldify.fastai.imports.core",
        "documentation": {}
    },
    {
        "label": "have_min_pkg_version",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.imports.core",
        "description": "dashboard.dl_model.deoldify.fastai.imports.core",
        "peekOfCode": "def have_min_pkg_version(package, version):\n    \"Check whether we have at least `version` of `package`. Returns True on success, False otherwise.\"\n    try:\n        pkg_resources.require(f\"{package}>={version}\")\n        return True\n    except:\n        return False",
        "detail": "dashboard.dl_model.deoldify.fastai.imports.core",
        "documentation": {}
    },
    {
        "label": "TabularLine",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularLine(ItemBase):\n    \"Basic item for tabular data.\"\n    def __init__(self, cats, conts, classes, names):\n        self.cats, self.conts, self.classes, self.names = cats, conts, classes, names\n        self.data = [tensor(cats), tensor(conts)]\n    def __str__(self):\n        res = \"\"\n        for c, n in zip(self.cats, self.names[: len(self.cats)]):\n            res += f\"{n} {(self.classes[n][c])}; \"\n        for c, n in zip(self.conts, self.names[len(self.cats) :]):",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularProcessor(PreProcessor):\n    \"Regroup the `procs` in one `PreProcessor`.\"\n    def __init__(self, ds: ItemBase = None, procs=None):\n        procs = ifnone(procs, ds.procs if ds is not None else None)\n        self.procs = listify(procs)\n    def process_one(self, item):\n        df = pd.DataFrame([item, item])\n        for proc in self.procs:\n            proc(df, test=True)\n        if len(self.cat_names) != 0:",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularDataBunch(DataBunch):\n    \"Create a `DataBunch` suitable for tabular data.\"\n    @classmethod\n    def from_df(\n        cls,\n        path,\n        df: DataFrame,\n        dep_var: str,\n        valid_idx: Collection[int],\n        procs: OptTabTfms = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "class TabularList(ItemList):\n    \"Basic `ItemList` for tabular data.\"\n    _item_cls = TabularLine\n    _processor = TabularProcessor\n    _bunch = TabularDataBunch\n    def __init__(\n        self,\n        items: Iterator,\n        cat_names: OptStrList = None,\n        cont_names: OptStrList = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "emb_sz_rule",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "def emb_sz_rule(n_cat: int) -> int:\n    return min(600, round(1.6 * n_cat**0.56))\ndef def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz\nclass TabularLine(ItemBase):\n    \"Basic item for tabular data.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "def_emb_sz",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "def def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz\nclass TabularLine(ItemBase):\n    \"Basic item for tabular data.\"\n    def __init__(self, cats, conts, classes, names):\n        self.cats, self.conts, self.classes, self.names = cats, conts, classes, names",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "tabular_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "def tabular_learner(\n    data: DataBunch,\n    layers: Collection[int],\n    emb_szs: Dict[str, int] = None,\n    metrics=None,\n    ps: Collection[float] = None,\n    emb_drop: float = 0.0,\n    y_range: OptRange = None,\n    use_bn: bool = True,\n    **learn_kwargs,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "__all__ = [\n    \"TabularDataBunch\",\n    \"TabularLine\",\n    \"TabularList\",\n    \"TabularProcessor\",\n    \"tabular_learner\",\n]\nOptTabTfms = Optional[Collection[TabularProc]]\n# def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat//2)+1)\ndef emb_sz_rule(n_cat: int) -> int:",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "OptTabTfms",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "peekOfCode": "OptTabTfms = Optional[Collection[TabularProc]]\n# def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat//2)+1)\ndef emb_sz_rule(n_cat: int) -> int:\n    return min(600, round(1.6 * n_cat**0.56))\ndef def_emb_sz(classes, n, sz_dict=None):\n    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n    sz_dict = ifnone(sz_dict, {})\n    n_cat = len(classes[n])\n    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n    return n_cat, sz",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.data",
        "documentation": {}
    },
    {
        "label": "TabularModel",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "peekOfCode": "class TabularModel(Module):\n    \"Basic model for tabular data.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        n_cont: int,\n        out_sz: int,\n        layers: Collection[int],\n        ps: Collection[float] = None,\n        emb_drop: float = 0.0,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "peekOfCode": "__all__ = [\"TabularModel\"]\nclass TabularModel(Module):\n    \"Basic model for tabular data.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        n_cont: int,\n        out_sz: int,\n        layers: Collection[int],\n        ps: Collection[float] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.from_learner",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "peekOfCode": "ClassificationInterpretation.from_learner = _cl_int_from_learner\nClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\ndef _learner_interpret(learn: Learner, ds_type: DatasetType = DatasetType.Valid):\n    \"Create a 'ClassificationInterpretation' object from 'learner' on 'ds_type'.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\nLearner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_top_losses",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "peekOfCode": "ClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\ndef _learner_interpret(learn: Learner, ds_type: DatasetType = DatasetType.Valid):\n    \"Create a 'ClassificationInterpretation' object from 'learner' on 'ds_type'.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type)\nLearner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "peekOfCode": "Learner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.models",
        "documentation": {}
    },
    {
        "label": "TabularProc",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class TabularProc:\n    \"A processor for tabular dataframes.\"\n    cat_names: StrList\n    cont_names: StrList\n    def __call__(self, df: DataFrame, test: bool = False):\n        \"Apply the correct function to `df` depending on `test`.\"\n        func = self.apply_test if test else self.apply_train\n        func(df)\n    def apply_train(self, df: DataFrame):\n        \"Function applied to `df` if it's the train set.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "Categorify",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class Categorify(TabularProc):\n    \"Transform the categorical variables to that type.\"\n    def apply_train(self, df: DataFrame):\n        \"Transform `self.cat_names` columns in categorical.\"\n        self.categories = {}\n        for n in self.cat_names:\n            df.loc[:, n] = df.loc[:, n].astype(\"category\").cat.as_ordered()\n            self.categories[n] = df[n].cat.categories\n    def apply_test(self, df: DataFrame):\n        \"Transform `self.cat_names` columns in categorical using the codes decided in `apply_train`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "FillMissing",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class FillMissing(TabularProc):\n    \"Fill the missing values in continuous columns.\"\n    fill_strategy: FillStrategy = FillStrategy.MEDIAN\n    add_col: bool = True\n    fill_val: float = 0.0\n    def apply_train(self, df: DataFrame):\n        \"Fill missing values in `self.cont_names` according to `self.fill_strategy`.\"\n        self.na_dict = {}\n        for name in self.cont_names:\n            if pd.isnull(df[name]).sum():",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "Normalize",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "class Normalize(TabularProc):\n    \"Normalize the continuous variables.\"\n    def apply_train(self, df: DataFrame):\n        \"Compute the means and stds of `self.cont_names` columns to normalize them.\"\n        self.means, self.stds = {}, {}\n        for n in self.cont_names:\n            assert is_numeric_dtype(\n                df[n]\n            ), f\"\"\"Cannot normalize '{n}' column as it isn't numerical.\n                Are you sure it doesn't belong in the categorical set of columns?\"\"\"",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "make_date",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def make_date(df: DataFrame, date_field: str):\n    \"Make sure `df[field_name]` is of the right date type.\"\n    field_dtype = df[date_field].dtype\n    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        field_dtype = np.datetime64\n    if not np.issubdtype(field_dtype, np.datetime64):\n        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\ndef cyclic_dt_feat_names(time: bool = True, add_linear: bool = False) -> List[str]:\n    \"Return feature names of date/time cycles as produced by `cyclic_dt_features`.\"\n    fs = [\"cos\", \"sin\"]",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cyclic_dt_feat_names",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cyclic_dt_feat_names(time: bool = True, add_linear: bool = False) -> List[str]:\n    \"Return feature names of date/time cycles as produced by `cyclic_dt_features`.\"\n    fs = [\"cos\", \"sin\"]\n    attr = [\n        f\"{r}_{f}\" for r in \"weekday day_month month_year day_year\".split() for f in fs\n    ]\n    if time:\n        attr += [f\"{r}_{f}\" for r in \"hour clock min sec\".split() for f in fs]\n    if add_linear:\n        attr.append(\"year_lin\")",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cyclic_dt_features",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cyclic_dt_features(\n    d: Union[date, datetime], time: bool = True, add_linear: bool = False\n) -> List[float]:\n    \"Calculate the cos and sin of date/time cycles.\"\n    tt, fs = d.timetuple(), [np.cos, np.sin]\n    day_year, days_month = tt.tm_yday, calendar.monthrange(d.year, d.month)[1]\n    days_year = 366 if calendar.isleap(d.year) else 365\n    rs = (\n        d.weekday() / 7,\n        (d.day - 1) / days_month,",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_cyclic_datepart",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_cyclic_datepart(\n    df: DataFrame,\n    field_name: str,\n    prefix: str = None,\n    drop: bool = True,\n    time: bool = False,\n    add_linear: bool = False,\n):\n    \"Helper function that adds trigonometric date/time features to a date in the column `field_name` of `df`.\"\n    make_date(df, field_name)",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_datepart",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_datepart(\n    df: DataFrame,\n    field_name: str,\n    prefix: str = None,\n    drop: bool = True,\n    time: bool = False,\n):\n    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n    make_date(df, field_name)\n    field = df[field_name]",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "add_elapsed_times",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def add_elapsed_times(\n    df: DataFrame, field_names: Collection[str], date_field: str, base_field: str\n):\n    field_names = listify(field_names)\n    # Make sure date_field is a date and base_field a bool\n    df[field_names] = df[field_names].astype(\"bool\")\n    make_date(df, date_field)\n    work_df = df[field_names + [date_field, base_field]]\n    work_df = work_df.sort_values([base_field, date_field])\n    work_df = _get_elapsed(work_df, field_names, date_field, base_field, \"After\")",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "cont_cat_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "def cont_cat_split(df, max_card=20, dep_var=None) -> Tuple[List, List]:\n    \"Helper function that returns column names of cont and cat variables from given df.\"\n    cont_names, cat_names = [], []\n    for label in df:\n        if label == dep_var:\n            continue\n        if (\n            df[label].dtype == int\n            and df[label].unique().shape[0] > max_card\n            or df[label].dtype == float",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "__all__ = [\n    \"add_datepart\",\n    \"cont_cat_split\",\n    \"Categorify\",\n    \"FillMissing\",\n    \"FillStrategy\",\n    \"Normalize\",\n    \"TabularProc\",\n    \"add_elapsed_times\",\n    \"make_date\",",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "FillStrategy",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "description": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "peekOfCode": "FillStrategy = IntEnum(\"FillStrategy\", \"MEDIAN COMMON CONSTANT\")\n@dataclass\nclass FillMissing(TabularProc):\n    \"Fill the missing values in continuous columns.\"\n    fill_strategy: FillStrategy = FillStrategy.MEDIAN\n    add_col: bool = True\n    fill_val: float = 0.0\n    def apply_train(self, df: DataFrame):\n        \"Fill missing values in `self.cont_names` according to `self.fill_strategy`.\"\n        self.na_dict = {}",
        "detail": "dashboard.dl_model.deoldify.fastai.tabular.transform",
        "documentation": {}
    },
    {
        "label": "RNNDropout",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class RNNDropout(Module):\n    \"Dropout with probability `p` that is consistent on the seq_len dimension.\"\n    def __init__(self, p: float = 0.5):\n        self.p = p\n    def forward(self, x: Tensor) -> Tensor:\n        if not self.training or self.p == 0.0:\n            return x\n        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n        return x * m\nclass WeightDropout(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "WeightDropout",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class WeightDropout(Module):\n    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n    def __init__(\n        self,\n        module: nn.Module,\n        weight_p: float,\n        layer_names: Collection[str] = [\"weight_hh_l0\"],\n    ):\n        self.module, self.weight_p, self.layer_names = module, weight_p, layer_names\n        for layer in self.layer_names:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "EmbeddingDropout",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class EmbeddingDropout(Module):\n    \"Apply dropout with probabily `embed_p` to an embedding layer `emb`.\"\n    def __init__(self, emb: nn.Module, embed_p: float):\n        self.emb, self.embed_p = emb, embed_p\n        self.pad_idx = self.emb.padding_idx\n        if self.pad_idx is None:\n            self.pad_idx = -1\n    def forward(self, words: LongTensor, scale: Optional[float] = None) -> Tensor:\n        if self.training and self.embed_p != 0:\n            size = (self.emb.weight.size(0), 1)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "AWD_LSTM",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class AWD_LSTM(Module):\n    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182.\"\n    initrange = 0.1\n    def __init__(\n        self,\n        vocab_sz: int,\n        emb_sz: int,\n        n_hid: int,\n        n_layers: int,\n        pad_token: int = 1,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "LinearDecoder",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class LinearDecoder(Module):\n    \"To go on top of a RNNCore module and create a Language Model.\"\n    initrange = 0.1\n    def __init__(\n        self,\n        n_out: int,\n        n_hid: int,\n        output_p: float,\n        tie_encoder: nn.Module = None,\n        bias: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "SequentialRNN",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class SequentialRNN(nn.Sequential):\n    \"A sequential module that passes the reset call to its children.\"\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \"reset\"):\n                c.reset()\ndef awd_lstm_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n    return groups + [[model[0].encoder, model[0].encoder_dp, model[1]]]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "TextClassificationInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "class TextClassificationInterpretation(ClassificationInterpretation):\n    \"\"\"Provides an interpretation of classification based on input sensitivity.\n    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n    \"\"\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "dropout_mask",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def dropout_mask(x: Tensor, sz: Collection[int], p: float):\n    \"Return a dropout mask of the same type as `x`, size `sz`, with probability `p` to cancel an element.\"\n    return x.new(*sz).bernoulli_(1 - p).div_(1 - p)\nclass RNNDropout(Module):\n    \"Dropout with probability `p` that is consistent on the seq_len dimension.\"\n    def __init__(self, p: float = 0.5):\n        self.p = p\n    def forward(self, x: Tensor) -> Tensor:\n        if not self.training or self.p == 0.0:\n            return x",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_lm_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def awd_lstm_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n    return groups + [[model[0].encoder, model[0].encoder_dp, model[1]]]\ndef awd_lstm_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[model[0].module.encoder, model[0].module.encoder_dp]]\n    groups += [\n        [rnn, dp] for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)\n    ]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_clas_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def awd_lstm_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    groups = [[model[0].module.encoder, model[0].module.encoder_dp]]\n    groups += [\n        [rnn, dp] for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)\n    ]\n    return groups + [[model[1]]]\nawd_lstm_lm_config = dict(\n    emb_sz=400,\n    n_hid=1152,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "value2rgba",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "piece_attn_html",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(\n            f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>'\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "show_piece_attn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "def show_piece_attn(*args, **kwargs):\n    from IPython.display import HTML, display\n    display(HTML(piece_attn_html(*args, **kwargs)))\ndef _eval_dropouts(mod):\n    module_name = mod.__class__.__name__\n    if \"Dropout\" in module_name or \"BatchNorm\" in module_name:\n        mod.training = False\n    for module in mod.children():\n        _eval_dropouts(module)\nclass TextClassificationInterpretation(ClassificationInterpretation):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "__all__ = [\n    \"EmbeddingDropout\",\n    \"LinearDecoder\",\n    \"AWD_LSTM\",\n    \"RNNDropout\",\n    \"SequentialRNN\",\n    \"WeightDropout\",\n    \"dropout_mask\",\n    \"awd_lstm_lm_split\",\n    \"awd_lstm_clas_split\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_lm_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "awd_lstm_lm_config = dict(\n    emb_sz=400,\n    n_hid=1152,\n    n_layers=3,\n    pad_token=1,\n    qrnn=False,\n    bidir=False,\n    output_p=0.1,\n    hidden_p=0.15,\n    input_p=0.25,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "awd_lstm_clas_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "peekOfCode": "awd_lstm_clas_config = dict(\n    emb_sz=400,\n    n_hid=1152,\n    n_layers=3,\n    pad_token=1,\n    qrnn=False,\n    bidir=False,\n    output_p=0.4,\n    hidden_p=0.3,\n    input_p=0.4,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.awd_lstm",
        "documentation": {}
    },
    {
        "label": "ForgetMultGPU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class ForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,\n    ):\n        if batch_first:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "BwdForgetMultGPU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class BwdForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,\n    ):\n        if batch_first:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "QRNNLayer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class QRNNLayer(Module):\n    \"Apply a single layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\"\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int = None,\n        save_prev_x: bool = False,\n        zoneout: float = 0,\n        window: int = 1,\n        output_gate: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "QRNN",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "class QRNN(Module):\n    \"Apply a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\"\n    def __init__(\n        self,\n        input_size: int,\n        hidden_size: int,\n        n_layers: int = 1,\n        bias: bool = True,\n        batch_first: bool = True,\n        dropout: float = 0,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "dispatch_cuda",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "def dispatch_cuda(cuda_class, cpu_func, x):\n    return cuda_class.apply if x.device.type == \"cuda\" else cpu_func\nclass ForgetMultGPU(Function):\n    @staticmethod\n    def forward(\n        ctx,\n        x: Tensor,\n        f: Tensor,\n        hidden_init: Optional[Tensor] = None,\n        batch_first: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "forget_mult_CPU",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "def forget_mult_CPU(\n    x: Tensor,\n    f: Tensor,\n    hidden_init: Optional[Tensor] = None,\n    batch_first: bool = True,\n    backward: bool = False,\n):\n    result = []\n    dim = 1 if batch_first else 0\n    forgets = f.split(1, dim=dim)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "peekOfCode": "__all__ = [\"QRNNLayer\", \"QRNN\"]\nimport fastai\nif torch.cuda.is_available():\n    fastai_path = Path(fastai.__path__[0]) / \"text\" / \"models\"\n    files = [\"forget_mult_cuda.cpp\", \"forget_mult_cuda_kernel.cu\"]\n    forget_mult_cuda = load(\n        name=\"forget_mult_cuda\", sources=[fastai_path / f for f in files]\n    )\n    files = [\"bwd_forget_mult_cuda.cpp\", \"bwd_forget_mult_cuda_kernel.cu\"]\n    bwd_forget_mult_cuda = load(",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.qrnn",
        "documentation": {}
    },
    {
        "label": "PositionalEncoding",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class PositionalEncoding(Module):\n    \"Encode the position with a sinusoid.\"\n    def __init__(self, d: int):\n        self.register_buffer(\"freq\", 1 / (10000 ** (torch.arange(0.0, d, 2.0) / d)))\n    def forward(self, pos: Tensor):\n        inp = torch.ger(pos, self.freq)\n        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n        return enc\nclass GeLU(Module):\n    def forward(self, x):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "GeLU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class GeLU(Module):\n    def forward(self, x):\n        return (\n            0.5\n            * x\n            * (\n                1\n                + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))\n            )\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Swish",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class Swish(Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n_activ_func = {\n    Activation.ReLU: nn.ReLU(inplace=True),\n    Activation.GeLU: GeLU(),\n    Activation.Swish: Swish(),\n}\ndef feed_forward(\n    d_model: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "MultiHeadAttention",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class MultiHeadAttention(Module):\n    \"MutiHeadAttention.\"\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int = None,\n        resid_p: float = 0.0,\n        attn_p: float = 0.0,\n        bias: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "MultiHeadRelativeAttention",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class MultiHeadRelativeAttention(MultiHeadAttention):\n    \"MutiHeadAttention with relative positional encoding.\"\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int,\n        resid_p: float = 0.0,\n        attn_p: float = 0.0,\n        bias: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "DecoderLayer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class DecoderLayer(Module):\n    \"Basic block of a Transformer model.\"\n    # Can't use Sequential directly cause more than one input...\n    def __init__(\n        self,\n        n_heads: int,\n        d_model: int,\n        d_head: int,\n        d_inner: int,\n        resid_p: float = 0.0,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Transformer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class Transformer(Module):\n    \"Transformer model: https://arxiv.org/abs/1706.03762.\"\n    def __init__(\n        self,\n        vocab_sz: int,\n        ctx_len: int,\n        n_layers: int,\n        n_heads: int,\n        d_model: int,\n        d_head: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "TransformerXL",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "class TransformerXL(Module):\n    \"TransformerXL model: https://arxiv.org/abs/1901.02860.\"\n    def __init__(\n        self,\n        vocab_sz: int,\n        ctx_len: int,\n        n_layers: int,\n        n_heads: int,\n        d_model: int,\n        d_head: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "feed_forward",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def feed_forward(\n    d_model: int,\n    d_ff: int,\n    ff_p: float = 0.0,\n    act: Activation = Activation.ReLU,\n    double_drop: bool = True,\n):\n    layers = [nn.Linear(d_model, d_ff), _activ_func[act]]\n    if double_drop:\n        layers.append(nn.Dropout(ff_p))",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "init_transformer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def init_transformer(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Linear\") != -1:\n        if hasattr(m, \"weight\") and m.weight is not None:\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        if hasattr(m, \"bias\") and m.bias is not None:\n            nn.init.constant_(m.bias, 0.0)\n    elif classname.find(\"LayerNorm\") != -1:\n        if hasattr(m, \"weight\") and m.weight is not None:\n            nn.init.normal_(m.weight, 1.0, 0.02)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_lm_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmer_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0]\n    n = len(encoder.layers) // 3\n    groups = [\n        list(encoder.layers[:n]),\n        list(encoder.layers[n : 2 * n]),\n        list(encoder.layers[2 * n :]),\n    ]\n    return groups + [[encoder.encoder, model[1]]]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_clas_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmer_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0].module\n    n = len(encoder.layers) // 3\n    groups = [\n        [encoder.encoder],\n        list(encoder.layers[:n]),\n        list(encoder.layers[n : 2 * n]),\n        list(encoder.layers[2 * n :]),\n    ]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_lm_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmerXL_lm_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0]\n    n = len(encoder.layers) // 3\n    groups = [\n        list(encoder.layers[:n])\n        + [ParameterModule(encoder.u), ParameterModule(encoder.v)]\n    ]\n    return groups + [\n        list(encoder.layers[n : 2 * n]),",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_clas_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "def tfmerXL_clas_split(model: nn.Module) -> List[nn.Module]:\n    \"Split a RNN `model` in groups for differential learning rates.\"\n    encoder = model[0].module\n    n = len(encoder.layers) // 3\n    groups = [\n        [encoder.encoder],\n        list(encoder.layers[:n])\n        + [ParameterModule(encoder.u), ParameterModule(encoder.v)],\n    ]\n    return groups + [",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "__all__ = [\n    \"Activation\",\n    \"PositionalEncoding\",\n    \"GeLU\",\n    \"Swish\",\n    \"feed_forward\",\n    \"MultiHeadAttention\",\n    \"MultiHeadRelativeAttention\",\n    \"DecoderLayer\",\n    \"Transformer\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "Activation",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "Activation = Enum(\"Activation\", \"ReLU Swish GeLU\")\nclass PositionalEncoding(Module):\n    \"Encode the position with a sinusoid.\"\n    def __init__(self, d: int):\n        self.register_buffer(\"freq\", 1 / (10000 ** (torch.arange(0.0, d, 2.0) / d)))\n    def forward(self, pos: Tensor):\n        inp = torch.ger(pos, self.freq)\n        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n        return enc\nclass GeLU(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "_activ_func",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "_activ_func = {\n    Activation.ReLU: nn.ReLU(inplace=True),\n    Activation.GeLU: GeLU(),\n    Activation.Swish: Swish(),\n}\ndef feed_forward(\n    d_model: int,\n    d_ff: int,\n    ff_p: float = 0.0,\n    act: Activation = Activation.ReLU,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_lm_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmer_lm_config = dict(\n    ctx_len=512,\n    n_layers=12,\n    n_heads=12,\n    d_model=768,\n    d_head=64,\n    d_inner=3072,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmer_clas_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmer_clas_config = dict(\n    ctx_len=512,\n    n_layers=12,\n    n_heads=12,\n    d_model=768,\n    d_head=64,\n    d_inner=3072,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_lm_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmerXL_lm_config = dict(\n    ctx_len=150,\n    n_layers=12,\n    n_heads=10,\n    d_model=410,\n    d_head=41,\n    d_inner=2100,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "tfmerXL_clas_config",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "description": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "peekOfCode": "tfmerXL_clas_config = dict(\n    ctx_len=150,\n    n_layers=12,\n    n_heads=10,\n    d_model=410,\n    d_head=41,\n    d_inner=2100,\n    resid_p=0.1,\n    attn_p=0.1,\n    ff_p=0.1,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.models.transformer",
        "documentation": {}
    },
    {
        "label": "LanguageModelPreLoader",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[\n                i % len(self.idx)\n                if self.forward",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SortSampler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class SortSampler(Sampler):\n    \"Go through the text data by order of length.\"\n    def __init__(self, data_source: NPArrayList, key: KeyFunc):\n        self.data_source, self.key = data_source, key\n    def __len__(self) -> int:\n        return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range_of(self.data_source), key=self.key, reverse=True))\nclass SortishSampler(Sampler):\n    \"Go through the text data by order of length with a bit of randomness.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SortishSampler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class SortishSampler(Sampler):\n    \"Go through the text data by order of length with a bit of randomness.\"\n    def __init__(self, data_source: NPArrayList, key: KeyFunc, bs: int):\n        self.data_source, self.key, self.bs = data_source, key, bs\n    def __len__(self) -> int:\n        return len(self.data_source)\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs * 50\n        ck_idx = [idxs[i : i + sz] for i in range(0, len(idxs), sz)]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class TextDataBunch(DataBunch):\n    \"General class to get a `DataBunch` for NLP. Subclassed by `TextLMDataBunch` and `TextClasDataBunch`.\"\n    @classmethod\n    def from_ids(\n        cls,\n        path: PathOrStr,\n        vocab: Vocab,\n        train_ids: Collection[Collection[int]],\n        valid_ids: Collection[Collection[int]],\n        test_ids: Collection[Collection[int]] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextLMDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class TextLMDataBunch(TextDataBunch):\n    \"Create a `TextDataBunch` suitable for training a language model.\"\n    @classmethod\n    def create(\n        cls,\n        train_ds,\n        valid_ds,\n        test_ds=None,\n        path: PathOrStr = \".\",\n        no_check: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextClasDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class TextClasDataBunch(TextDataBunch):\n    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n    @classmethod\n    def create(\n        cls,\n        train_ds,\n        valid_ds,\n        test_ds=None,\n        path: PathOrStr = \".\",\n        bs: int = 32,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "Text",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class Text(ItemBase):\n    \"Basic item for <code>text</code> data in numericalized `ids`.\"\n    def __init__(self, ids, text):\n        self.data, self.text = np.array(ids, dtype=np.int64), text\n    def __str__(self):\n        return str(self.text)\nclass TokenizeProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes the texts in `ds`.\"\n    def __init__(\n        self,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TokenizeProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class TokenizeProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes the texts in `ds`.\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        tokenizer: Tokenizer = None,\n        chunksize: int = 10000,\n        mark_fields: bool = False,\n        include_bos: bool = True,\n        include_eos: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "NumericalizeProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class NumericalizeProcessor(PreProcessor):\n    \"`PreProcessor` that numericalizes the tokens in `ds`.\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        vocab: Vocab = None,\n        max_vocab: int = 60000,\n        min_freq: int = 3,\n    ):\n        vocab = ifnone(vocab, ds.vocab if ds is not None else None)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "OpenFileProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class OpenFileProcessor(PreProcessor):\n    \"`PreProcessor` that opens the filenames and read the texts.\"\n    def process(self, ds: Collection):\n        ds.items = array([self.process_one(item) for item in ds.items], dtype=np.object)\n    def process_one(self, item):\n        return open_text(item) if isinstance(item, Path) else item\nclass TextList(ItemList):\n    \"Basic `ItemList` for text data.\"\n    _bunch = TextClasDataBunch\n    _processor = [TokenizeProcessor, NumericalizeProcessor]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class TextList(ItemList):\n    \"Basic `ItemList` for text data.\"\n    _bunch = TextClasDataBunch\n    _processor = [TokenizeProcessor, NumericalizeProcessor]\n    _is_lm = False\n    def __init__(\n        self, items: Iterator, vocab: Vocab = None, pad_idx: int = 1, sep=\" \", **kwargs\n    ):\n        super().__init__(items, **kwargs)\n        self.vocab, self.pad_idx, self.sep = vocab, pad_idx, sep",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "LMLabelList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class LMLabelList(EmptyLabelList):\n    \"Basic `ItemList` for dummy labels.\"\n    def __init__(self, items: Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = CrossEntropyFlat()\nclass LMTextList(TextList):\n    \"Special `TextList` for a language model.\"\n    _bunch = TextLMDataBunch\n    _is_lm = True\ndef _join_texts(",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "LMTextList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class LMTextList(TextList):\n    \"Special `TextList` for a language model.\"\n    _bunch = TextLMDataBunch\n    _is_lm = True\ndef _join_texts(\n    texts: Collection[str],\n    mark_fields: bool = False,\n    include_bos: bool = True,\n    include_eos: bool = False,\n):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "SPProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "class SPProcessor(PreProcessor):\n    \"`PreProcessor` that tokenizes and numericalizes with `sentencepiece`\"\n    def __init__(\n        self,\n        ds: ItemList = None,\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        vocab_sz: int = None,\n        max_vocab_sz: int = 30000,\n        model_type: str = \"unigram\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "pad_collate",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "def pad_collate(\n    samples: BatchSamples,\n    pad_idx: int = 1,\n    pad_first: bool = True,\n    backwards: bool = False,\n) -> Tuple[LongTensor, LongTensor]:\n    \"Function that collect samples and adds padding. Flips token order if needed\"\n    samples = to_data(samples)\n    max_len = max([len(s[0]) for s in samples])\n    res = torch.zeros(len(samples), max_len).long() + pad_idx",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "open_text",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "def open_text(fn: PathOrStr, enc=\"utf-8\"):\n    \"Read the text in `fn`.\"\n    with open(fn, \"r\", encoding=enc) as f:\n        return \"\".join(f.readlines())\nclass Text(ItemBase):\n    \"Basic item for <code>text</code> data in numericalized `ids`.\"\n    def __init__(self, ids, text):\n        self.data, self.text = np.array(ids, dtype=np.int64), text\n    def __str__(self):\n        return str(self.text)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "apply_rules",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "def apply_rules(text, pre_rules=None, post_rules=None):\n    \"Apply `pre_rules` and `post_rules` to `text`\"\n    text = text.strip(\" \")\n    for r in ifnone(pre_rules, defaults.text_pre_rules):\n        text = r(text)\n    toks = text.split()\n    for r in ifnone(post_rules, defaults.text_post_rules):\n        toks = r(toks)\n    return \" \".join(toks)\ndef get_default_size(texts, max_vocab_sz):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "get_default_size",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "def get_default_size(texts, max_vocab_sz):\n    \"Either max_vocab_sz or one quarter of the number of unique words in `texts`\"\n    cnt = Counter()\n    for t in texts:\n        cnt.update(t.split())\n        if len(cnt) // 4 > max_vocab_sz:\n            return max_vocab_sz\n    res = len(cnt) // 4\n    while res % 8 != 0:\n        res += 1",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "train_sentencepiece",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "def train_sentencepiece(\n    texts: Collection[str],\n    path: PathOrStr,\n    pre_rules: ListRules = None,\n    post_rules: ListRules = None,\n    vocab_sz: int = None,\n    max_vocab_sz: int = 30000,\n    model_type: str = \"unigram\",\n    max_sentence_len: int = 20480,\n    lang=\"en\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "__all__ = [\n    \"LanguageModelPreLoader\",\n    \"SortSampler\",\n    \"SortishSampler\",\n    \"TextList\",\n    \"pad_collate\",\n    \"TextDataBunch\",\n    \"TextLMDataBunch\",\n    \"TextClasDataBunch\",\n    \"Text\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextMtd",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "TextMtd = IntEnum(\"TextMtd\", \"DF TOK IDS\")\ntext_extensions = {\".txt\"}\nclass LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "text_extensions",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "text_extensions = {\".txt\"}\nclass LanguageModelPreLoader(Callback):\n    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n    class CircularIndex:\n        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n        def __init__(self, length: int, forward: bool):\n            self.idx, self.forward = np.arange(length), forward\n        def __getitem__(self, i):\n            return self.idx[\n                i % len(self.idx)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "full_char_coverage_langs",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.data",
        "description": "dashboard.dl_model.deoldify.fastai.text.data",
        "peekOfCode": "full_char_coverage_langs = [\n    \"bg\",\n    \"cs\",\n    \"da\",\n    \"de\",\n    \"el\",\n    \"en\",\n    \"es\",\n    \"et\",\n    \"fi\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.data",
        "documentation": {}
    },
    {
        "label": "TextClassificationInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "peekOfCode": "class TextClassificationInterpretation(ClassificationInterpretation):\n    \"\"\"Provides an interpretation of classification based on input sensitivity.\n    This was designed for AWD-LSTM only for the moment, because Transformer already has its own attentional model.\n    \"\"\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "value2rgba",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "peekOfCode": "def value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []",
        "detail": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "piece_attn_html",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "peekOfCode": "def piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:\n    html_code, spans = ['<span style=\"font-family: monospace;\">'], []\n    for p, a in zip(pieces, attns):\n        p = html.escape(p)\n        c = str(value2rgba(a, alpha_mult=0.5, **kwargs))\n        spans.append(\n            f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>'\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "show_piece_attn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "peekOfCode": "def show_piece_attn(*args, **kwargs):\n    from IPython.display import HTML, display\n    display(HTML(piece_attn_html(*args, **kwargs)))\ndef _eval_dropouts(mod):\n    module_name = mod.__class__.__name__\n    if \"Dropout\" in module_name or \"BatchNorm\" in module_name:\n        mod.training = False\n    for module in mod.children():\n        _eval_dropouts(module)\nclass TextClassificationInterpretation(ClassificationInterpretation):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "peekOfCode": "__all__ = [\"TextClassificationInterpretation\"]\ndef value2rgba(x: float, cmap: Callable = cm.RdYlGn, alpha_mult: float = 1.0) -> Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])\ndef piece_attn_html(\n    pieces: List[str], attns: List[float], sep: str = \" \", **kwargs\n) -> str:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.interpret",
        "documentation": {}
    },
    {
        "label": "RNNLearner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "class RNNLearner(Learner):\n    \"Basic class for a `Learner` in NLP.\"\n    def __init__(\n        self,\n        data: DataBunch,\n        model: nn.Module,\n        split_func: OptSplitFunc = None,\n        clip: float = None,\n        alpha: float = 2.0,\n        beta: float = 1.0,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "LanguageLearner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "class LanguageLearner(RNNLearner):\n    \"Subclass of RNNLearner for predictions.\"\n    def predict(\n        self,\n        text: str,\n        n_words: int = 1,\n        no_unk: bool = True,\n        temperature: float = 1.0,\n        min_p: float = None,\n        sep: str = \" \",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "PoolingLinearClassifier",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "class PoolingLinearClassifier(Module):\n    \"Create a linear classifier with pooling.\"\n    def __init__(self, layers: Collection[int], drops: Collection[float]):\n        mod_layers = []\n        if len(drops) != len(layers) - 1:\n            raise ValueError(\"Number of layers and dropout values do not match.\")\n        activs = [nn.ReLU(inplace=True)] * (len(layers) - 2) + [None]\n        for n_in, n_out, p, actn in zip(layers[:-1], layers[1:], drops, activs):\n            mod_layers += bn_drop_lin(n_in, n_out, p=p, actn=actn)\n        self.layers = nn.Sequential(*mod_layers)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "MultiBatchEncoder",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "class MultiBatchEncoder(Module):\n    \"Create an encoder over `module` that can process a full sentence.\"\n    def __init__(self, bptt: int, max_len: int, module: nn.Module, pad_idx: int = 1):\n        self.max_len, self.bptt, self.module, self.pad_idx = (\n            max_len,\n            bptt,\n            module,\n            pad_idx,\n        )\n    def concat(self, arrs: Collection[Tensor]) -> Tensor:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "convert_weights",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def convert_weights(\n    wgts: Weights, stoi_wgts: Dict[str, int], itos_new: Collection[str]\n) -> Weights:\n    \"Convert the model `wgts` to go with a new vocabulary.\"\n    dec_bias, enc_wgts = wgts.get(\"1.decoder.bias\", None), wgts[\"0.encoder.weight\"]\n    wgts_m = enc_wgts.mean(0)\n    if dec_bias is not None:\n        bias_m = dec_bias.mean(0)\n    new_w = enc_wgts.new_zeros((len(itos_new), enc_wgts.size(1))).zero_()\n    if dec_bias is not None:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "decode_spec_tokens",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def decode_spec_tokens(tokens):\n    new_toks, rule, arg = [], None, None\n    for t in tokens:\n        if t in [TK_MAJ, TK_UP, TK_REP, TK_WREP]:\n            rule = t\n        elif rule is None:\n            new_toks.append(t)\n        elif rule == TK_MAJ:\n            new_toks.append(t[:1].upper() + t[1:].lower())\n            rule = None",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "get_language_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def get_language_model(\n    arch: Callable, vocab_sz: int, config: dict = None, drop_mult: float = 1.0\n):\n    \"Create a language model from `arch` and its `config`, maybe `pretrained`.\"\n    meta = _model_meta[arch]\n    config = ifnone(config, meta[\"config_lm\"]).copy()\n    for k in config.keys():\n        if k.endswith(\"_p\"):\n            config[k] *= drop_mult\n    tie_weights, output_p, out_bias = map(",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "language_model_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def language_model_learner(\n    data: DataBunch,\n    arch,\n    config: dict = None,\n    drop_mult: float = 1.0,\n    pretrained: bool = True,\n    pretrained_fnames: OptStrTuple = None,\n    **learn_kwargs,\n) -> \"LanguageLearner\":\n    \"Create a `Learner` with a language model from `data` and `arch`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "masked_concat_pool",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def masked_concat_pool(outputs, mask):\n    \"Pool MultiBatchEncoder outputs into one vector [last_hidden, max_pool, avg_pool].\"\n    output = outputs[-1]\n    avg_pool = output.masked_fill(mask[:, :, None], 0).mean(dim=1)\n    avg_pool *= (\n        output.size(1)\n        / (output.size(1) - mask.type(avg_pool.dtype).sum(dim=1))[:, None]\n    )\n    max_pool = output.masked_fill(mask[:, :, None], -float(\"inf\")).max(dim=1)[0]\n    x = torch.cat([output[:, -1], max_pool, avg_pool], 1)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "get_text_classifier",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def get_text_classifier(\n    arch: Callable,\n    vocab_sz: int,\n    n_class: int,\n    bptt: int = 70,\n    max_len: int = 20 * 70,\n    config: dict = None,\n    drop_mult: float = 1.0,\n    lin_ftrs: Collection[int] = None,\n    ps: Collection[float] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "text_classifier_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "def text_classifier_learner(\n    data: DataBunch,\n    arch: Callable,\n    bptt: int = 70,\n    max_len: int = 70 * 20,\n    config: dict = None,\n    pretrained: bool = True,\n    drop_mult: float = 1.0,\n    lin_ftrs: Collection[int] = None,\n    ps: Collection[float] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "__all__ = [\n    \"RNNLearner\",\n    \"LanguageLearner\",\n    \"convert_weights\",\n    \"decode_spec_tokens\",\n    \"get_language_model\",\n    \"language_model_learner\",\n    \"MultiBatchEncoder\",\n    \"get_text_classifier\",\n    \"text_classifier_learner\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "_model_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.learner",
        "description": "dashboard.dl_model.deoldify.fastai.text.learner",
        "peekOfCode": "_model_meta = {\n    AWD_LSTM: {\n        \"hid_name\": \"emb_sz\",\n        \"url\": URLs.WT103_FWD,\n        \"url_bwd\": URLs.WT103_BWD,\n        \"config_lm\": awd_lstm_lm_config,\n        \"split_lm\": awd_lstm_lm_split,\n        \"config_clas\": awd_lstm_clas_config,\n        \"split_clas\": awd_lstm_clas_split,\n    },",
        "detail": "dashboard.dl_model.deoldify.fastai.text.learner",
        "documentation": {}
    },
    {
        "label": "BaseTokenizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "class BaseTokenizer:\n    \"Basic class for a tokenizer function.\"\n    def __init__(self, lang: str):\n        self.lang = lang\n    def tokenizer(self, t: str) -> List[str]:\n        return t.split(\" \")\n    def add_special_cases(self, toks: Collection[str]):\n        pass\nclass SpacyTokenizer(BaseTokenizer):\n    \"Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "SpacyTokenizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "class SpacyTokenizer(BaseTokenizer):\n    \"Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.\"\n    def __init__(self, lang: str):\n        self.tok = spacy.blank(lang, disable=[\"parser\", \"tagger\", \"ner\"])\n    def tokenizer(self, t: str) -> List[str]:\n        return [t.text for t in self.tok.tokenizer(t)]\n    def add_special_cases(self, toks: Collection[str]):\n        for w in toks:\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\ndef spec_add_spaces(t: str) -> str:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "Tokenizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "class Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"\n    def __init__(\n        self,\n        tok_func: Callable = SpacyTokenizer,\n        lang: str = \"en\",\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        special_cases: Collection[str] = None,\n        n_cpus: int = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "Vocab",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "class Vocab:\n    \"Contain the correspondence between numbers and tokens and numericalize.\"\n    def __init__(self, itos: Collection[str]):\n        self.itos = itos\n        self.stoi = collections.defaultdict(\n            int, {v: k for k, v in enumerate(self.itos)}\n        )\n    def numericalize(self, t: Collection[str]) -> List[int]:\n        \"Convert a list of tokens `t` to their ids.\"\n        return [self.stoi[w] for w in t]",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "spec_add_spaces",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def spec_add_spaces(t: str) -> str:\n    \"Add spaces around / and # in `t`. \\n\"\n    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\ndef rm_useless_spaces(t: str) -> str:\n    \"Remove multiple spaces in `t`.\"\n    return re.sub(\" {2,}\", \" \", t)\ndef replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "rm_useless_spaces",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def rm_useless_spaces(t: str) -> str:\n    \"Remove multiple spaces in `t`.\"\n    return re.sub(\" {2,}\", \" \", t)\ndef replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_REP} {len(cc)+1} {c} \"\n    re_rep = re.compile(r\"(\\S)(\\1{3,})\")\n    return re_rep.sub(_replace_rep, t)",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_rep",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_rep(t: str) -> str:\n    \"Replace repetitions at the character level in `t`.\"\n    def _replace_rep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_REP} {len(cc)+1} {c} \"\n    re_rep = re.compile(r\"(\\S)(\\1{3,})\")\n    return re_rep.sub(_replace_rep, t)\ndef replace_wrep(t: str) -> str:\n    \"Replace word repetitions in `t`.\"\n    def _replace_wrep(m: Collection[str]) -> str:",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_wrep",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_wrep(t: str) -> str:\n    \"Replace word repetitions in `t`.\"\n    def _replace_wrep(m: Collection[str]) -> str:\n        c, cc = m.groups()\n        return f\" {TK_WREP} {len(cc.split())+1} {c} \"\n    re_wrep = re.compile(r\"(\\b\\w+\\W+)(\\1{3,})\")\n    return re_wrep.sub(_replace_wrep, t)\ndef fix_html(x: str) -> str:\n    \"List of replacements from html strings in `x`.\"\n    re1 = re.compile(r\"  +\")",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "fix_html",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def fix_html(x: str) -> str:\n    \"List of replacements from html strings in `x`.\"\n    re1 = re.compile(r\"  +\")\n    x = (\n        x.replace(\"#39;\", \"'\")\n        .replace(\"amp;\", \"&\")\n        .replace(\"#146;\", \"'\")\n        .replace(\"nbsp;\", \" \")\n        .replace(\"#36;\", \"$\")\n        .replace(\"\\\\n\", \"\\n\")",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "replace_all_caps",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def replace_all_caps(x: Collection[str]) -> Collection[str]:\n    \"Replace tokens in ALL CAPS in `x` by their lower version and add `TK_UP` before.\"\n    res = []\n    for t in x:\n        if t.isupper() and len(t) > 1:\n            res.append(TK_UP)\n            res.append(t.lower())\n        else:\n            res.append(t)\n    return res",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "deal_caps",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "def deal_caps(x: Collection[str]) -> Collection[str]:\n    \"Replace all Capitalized tokens in `x` by their lower version and add `TK_MAJ` before.\"\n    res = []\n    for t in x:\n        if t == \"\":\n            continue\n        if t[0].isupper() and len(t) > 1 and t[1:].islower():\n            res.append(TK_MAJ)\n        res.append(t.lower())\n    return res",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "__all__ = [\n    \"BaseTokenizer\",\n    \"SpacyTokenizer\",\n    \"Tokenizer\",\n    \"Vocab\",\n    \"fix_html\",\n    \"replace_all_caps\",\n    \"replace_rep\",\n    \"replace_wrep\",\n    \"rm_useless_spaces\",",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_spec_tok",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_spec_tok = [UNK, PAD, BOS, EOS, FLD, TK_MAJ, TK_UP, TK_REP, TK_WREP]\nclass BaseTokenizer:\n    \"Basic class for a tokenizer function.\"\n    def __init__(self, lang: str):\n        self.lang = lang\n    def tokenizer(self, t: str) -> List[str]:\n        return t.split(\" \")\n    def add_special_cases(self, toks: Collection[str]):\n        pass\nclass SpacyTokenizer(BaseTokenizer):",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_pre_rules",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_pre_rules = [\n    fix_html,\n    replace_rep,\n    replace_wrep,\n    spec_add_spaces,\n    rm_useless_spaces,\n]\ndefaults.text_post_rules = [replace_all_caps, deal_caps]\nclass Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "defaults.text_post_rules",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.text.transform",
        "description": "dashboard.dl_model.deoldify.fastai.text.transform",
        "peekOfCode": "defaults.text_post_rules = [replace_all_caps, deal_caps]\nclass Tokenizer:\n    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"\n    def __init__(\n        self,\n        tok_func: Callable = SpacyTokenizer,\n        lang: str = \"en\",\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        special_cases: Collection[str] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.text.transform",
        "documentation": {}
    },
    {
        "label": "get_env",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "description": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def get_env(name):\n    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n    res = os.environ.get(name, \"\")\n    return res if len(res) else \"Unknown\"\ndef show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []\n    opt_mods = []",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "show_install",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "description": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []\n    opt_mods = []\n    rep.append([\"=== Software ===\", None])\n    rep.append([\"python\", platform.python_version()])\n    rep.append([\"fastai\", fastai.__version__])\n    rep.append([\"fastprogress\", fastprogress.__version__])",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "pypi_module_version_is_available",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "description": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def pypi_module_version_is_available(module, version):\n    \"Check whether module==version is available on pypi\"\n    # returns True/False (or None if failed to execute the check)\n    # using a hack that when passing \"module==\" w/ no version number to pip\n    # it \"fails\" and returns all the available versions in stderr\n    try:\n        cmd = f\"pip install {module}==\"\n        result = subprocess.run(\n            cmd.split(),\n            shell=False,",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "check_perf",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "description": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "def check_perf():\n    \"Suggest how to improve the setup to speed things up\"\n    from packaging import version\n    from PIL import Image, features\n    print(\"Running performance checks.\")\n    # libjpeg_turbo check\n    print(\"\\n*** libjpeg-turbo status\")\n    if version.parse(Image.PILLOW_VERSION) >= version.parse(\"5.3.9\"):\n        if features.check_feature(\"libjpeg_turbo\"):\n            print(\" libjpeg-turbo is on\")",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "description": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "peekOfCode": "__all__ = [\"show_install\", \"check_perf\"]\ndef get_env(name):\n    \"Return env var value if it's defined and not an empty string, or return Unknown\"\n    res = os.environ.get(name, \"\")\n    return res if len(res) else \"Unknown\"\ndef show_install(show_nvidia_smi: bool = False):\n    \"Print user's setup information\"\n    import platform\n    import fastai.version\n    rep = []",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.collect_env",
        "documentation": {}
    },
    {
        "label": "gpu_mem_restore_ctx",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "class gpu_mem_restore_ctx:\n    \"context manager to reclaim RAM if an exception happened under ipython\"\n    def __enter__(self):\n        return self\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if not exc_val:\n            return True\n        traceback.clear_frames(exc_tb)\n        gc.collect()\n        raise exc_type(exc_val).with_traceback(exc_tb) from None",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "is_in_ipython",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def is_in_ipython():\n    \"Is the code running in the ipython environment (jupyter including)\"\n    program_name = os.path.basename(os.getenv(\"_\", \"\"))\n    if (\n        \"jupyter-notebook\" in program_name\n        or \"ipython\" in program_name  # jupyter-notebook\n        or \"JPY_PARENT_PID\" in os.environ  # ipython\n    ):  # ipython-notebook\n        return True\n    else:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "is_in_colab",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def is_in_colab():\n    \"Is the code running in Google Colaboratory?\"\n    if not IS_IN_IPYTHON:\n        return False\n    try:\n        from google import colab\n        return True\n    except:\n        return False\nIS_IN_COLAB = is_in_colab()",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "get_ref_free_exc_info",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def get_ref_free_exc_info():\n    \"Free traceback from references to locals() in each frame to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n    type, val, tb = sys.exc_info()\n    traceback.clear_frames(tb)\n    return (type, val, tb)\ndef gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        tb_clear_frames = os.environ.get(\"FASTAI_TB_CLEAR_FRAMES\", None)",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "gpu_mem_restore",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "def gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        tb_clear_frames = os.environ.get(\"FASTAI_TB_CLEAR_FRAMES\", None)\n        if not IS_IN_IPYTHON or tb_clear_frames == \"0\":\n            return func(*args, **kwargs)\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "IS_IN_IPYTHON",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "IS_IN_IPYTHON = is_in_ipython()\ndef is_in_colab():\n    \"Is the code running in Google Colaboratory?\"\n    if not IS_IN_IPYTHON:\n        return False\n    try:\n        from google import colab\n        return True\n    except:\n        return False",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "IS_IN_COLAB",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "description": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "peekOfCode": "IS_IN_COLAB = is_in_colab()\ndef get_ref_free_exc_info():\n    \"Free traceback from references to locals() in each frame to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n    type, val, tb = sys.exc_info()\n    traceback.clear_frames(tb)\n    return (type, val, tb)\ndef gpu_mem_restore(func):\n    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.ipython",
        "documentation": {}
    },
    {
        "label": "GPUMemTrace",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "class GPUMemTrace:\n    \"Trace allocated and peaked GPU memory usage (deltas).\"\n    def __init__(self, silent=False, ctx=None, on_exit_report=True):\n        assert torch.cuda.is_available(), \"pytorch CUDA is required\"\n        self.silent = silent  # shortcut to turn off all reports from constructor\n        self.ctx = ctx  # default context note in report\n        self.on_exit_report = (\n            on_exit_report  # auto-report on ctx manager exit (default: True)\n        )\n        self.start()",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "preload_pytorch",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "b2mb",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:\n        id = torch.cuda.current_device()\n    try:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"\n    if not use_gpu:\n        return GPUMemory(0, 0, 0)\n    if id is None:\n        id = torch.cuda.current_device()\n    try:\n        handle = pynvml.nvmlDeviceGetHandleByIndex(id)\n        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n        return GPUMemory(*(map(b2mb, [info.total, info.free, info.used])))",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_all",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_all():\n    \"get total, used and free memory (in MBs) for each available gpu\"\n    if not use_gpu:\n        return []\n    return list(map(gpu_mem_get, range(pynvml.nvmlDeviceGetCount())))\ndef gpu_mem_get_free():\n    \"get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().free\ndef gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_free",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_free():\n    \"get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().free\ndef gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().free\ndef gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_free_no_cache",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_free_no_cache():\n    \"get free memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().free\ndef gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used\ndef gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used():\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache\"\n    return gpu_mem_get().used\ndef gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n    return b2mb(info.used)\ndef gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used_fast",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used_fast(gpu_handle):\n    \"get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the `gpu_handle` arg\"\n    info = pynvml.nvmlDeviceGetMemoryInfo(gpu_handle)\n    return b2mb(info.used)\ndef gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().used\ndef gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_get_used_no_cache",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_get_used_no_cache():\n    \"get used memory (in MBs) for the currently selected gpu id, after emptying the cache\"\n    torch.cuda.empty_cache()\n    return gpu_mem_get().used\ndef gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"\n    mem_all = gpu_mem_get_all()\n    if not len(mem_all):\n        return None, 0\n    free_all = np.array([x.free for x in mem_all])",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_with_max_free_mem",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_with_max_free_mem():\n    \"get [gpu_id, its_free_ram] for the first gpu with highest available RAM\"\n    mem_all = gpu_mem_get_all()\n    if not len(mem_all):\n        return None, 0\n    free_all = np.array([x.free for x in mem_all])\n    id = np.argmax(free_all)\n    return id, free_all[id]\nclass GPUMemTrace:\n    \"Trace allocated and peaked GPU memory usage (deltas).\"",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "gpu_mem_trace",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def gpu_mem_trace(func):\n    \"A decorator that runs `GPUMemTrace` w/ report on func\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        with GPUMemTrace(ctx=func.__qualname__, on_exit_report=True):\n            return func(*args, **kwargs)\n    return wrapper\ndef reduce_mem_usage(df):\n    \"\"\"iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "reduce_mem_usage",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "def reduce_mem_usage(df):\n    \"\"\"iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    # Removed from debugging\n    columns = df.columns\n    # .drop('index')\n    for col in columns:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "use_gpu",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "use_gpu = torch.cuda.is_available()\nGPUMemory = namedtuple(\"GPUMemory\", [\"total\", \"free\", \"used\"])\nif use_gpu:\n    pynvml = load_pynvml_env()\ndef preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "GPUMemory",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "peekOfCode": "GPUMemory = namedtuple(\"GPUMemory\", [\"total\", \"free\", \"used\"])\nif use_gpu:\n    pynvml = load_pynvml_env()\ndef preload_pytorch():\n    torch.ones((1, 1)).cuda()\ndef b2mb(num):\n    \"\"\"convert Bs to MBs and round down\"\"\"\n    return int(num / 2**20)\ndef gpu_mem_get(id=None):\n    \"get total, used and free memory (in MBs) for gpu `id`. if `id` is not passed, currently selected torch device is used\"",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mem",
        "documentation": {}
    },
    {
        "label": "progress_disabled_ctx",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "peekOfCode": "class progress_disabled_ctx:\n    \"Context manager to disable the progress update bar and Recorder print.\"\n    def __init__(self, learn: Learner):\n        self.learn = learn\n    def __enter__(self):\n        # silence progress bar\n        fastprogress.fastprogress.NO_BAR = True\n        (\n            fastai.basic_train.master_bar,\n            fastai.basic_train.progress_bar,",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "description": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "peekOfCode": "__all__ = [\"progress_disabled_ctx\"]\nclass progress_disabled_ctx:\n    \"Context manager to disable the progress update bar and Recorder print.\"\n    def __init__(self, learn: Learner):\n        self.learn = learn\n    def __enter__(self):\n        # silence progress bar\n        fastprogress.fastprogress.NO_BAR = True\n        (\n            fastai.basic_train.master_bar,",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.mod_display",
        "documentation": {}
    },
    {
        "label": "load_pynvml_env",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "description": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "def load_pynvml_env():\n    import pynvml  # nvidia-ml-py3\n    #\n    # BEGIN: Temporary workaround for nvml.dll load issue in Win10 (continued)\n    _LoadNvmlLibrary()\n    pynvml.nvmlLib = nvmlLib\n    #\n    # END: Temporary workaround for nvml.dll load issue in Win10\n    #\n    if platform.system() == \"Darwin\":",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "nvmlLib",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "description": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "nvmlLib = None\nlibLoadLock = threading.Lock()\ndef _LoadNvmlLibrary():\n    \"\"\"\n    Load the library if it isn't loaded already\n    \"\"\"\n    global nvmlLib\n    if nvmlLib == None:\n        libLoadLock.acquire()\n        try:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "libLoadLock",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "description": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "peekOfCode": "libLoadLock = threading.Lock()\ndef _LoadNvmlLibrary():\n    \"\"\"\n    Load the library if it isn't loaded already\n    \"\"\"\n    global nvmlLib\n    if nvmlLib == None:\n        libLoadLock.acquire()\n        try:\n            if nvmlLib == None:",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.pynvml_gate",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.utils.show_install",
        "description": "dashboard.dl_model.deoldify.fastai.utils.show_install",
        "peekOfCode": "def main(show_nvidia_smi: Param(opt=False, nargs=\"?\", type=bool) = False):\n    return show_install(show_nvidia_smi)",
        "detail": "dashboard.dl_model.deoldify.fastai.utils.show_install",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def get_model(\n    model_name: str,\n    pretrained: bool,\n    seq: bool = False,\n    pname: str = \"imagenet\",\n    **kwargs,\n):\n    pretrained = pname if pretrained else None\n    model = getattr(pretrainedmodels, model_name)(pretrained=pretrained, **kwargs)\n    return nn.Sequential(*model.children()) if seq else model",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "inceptionv4",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def inceptionv4(pretrained: bool = False):\n    model = get_model(\"inceptionv4\", pretrained)\n    all_layers = list(model.children())\n    return nn.Sequential(*all_layers[0], *all_layers[1:])\nmodel_meta[inceptionv4] = {\"cut\": -2, \"split\": lambda m: (m[0][11], m[1])}\ndef nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "nasnetamobile",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "pnasnet5large",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[pnasnet5large] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "inceptionresnetv2",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)\ndef dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "dpn92",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "xception_cadene",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)\ndef se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnet50",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnet50(pretrained: bool = False):\n    return get_model(\"se_resnet50\", pretrained)\ndef se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnet101",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnet101(pretrained: bool = False):\n    return get_model(\"se_resnet101\", pretrained)\ndef se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnext50_32x4d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnext50_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext50_32x4d\", pretrained)\ndef se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "se_resnext101_32x4d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def se_resnext101_32x4d(pretrained: bool = False):\n    return get_model(\"se_resnext101_32x4d\", pretrained)\ndef senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "senet154",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "def senet154(pretrained: bool = False):\n    return get_model(\"senet154\", pretrained)\nmodel_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "pretrainedmodels",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "pretrainedmodels = try_import(\"pretrainedmodels\")\nif not pretrainedmodels:\n    raise Exception(\n        \"Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`\"\n    )\n__all__ = [\n    \"inceptionv4\",\n    \"inceptionresnetv2\",\n    \"nasnetamobile\",\n    \"dpn92\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "__all__ = [\n    \"inceptionv4\",\n    \"inceptionresnetv2\",\n    \"nasnetamobile\",\n    \"dpn92\",\n    \"xception_cadene\",\n    \"se_resnet50\",\n    \"se_resnet101\",\n    \"se_resnext50_32x4d\",\n    \"senet154\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[inceptionv4]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[inceptionv4] = {\"cut\": -2, \"split\": lambda m: (m[0][11], m[1])}\ndef nasnetamobile(pretrained: bool = False):\n    model = get_model(\"nasnetamobile\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[nasnetamobile]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[nasnetamobile] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef pnasnet5large(pretrained: bool = False):\n    model = get_model(\"pnasnet5large\", pretrained, num_classes=1000)\n    model.logits = noop\n    return nn.Sequential(model)\nmodel_meta[pnasnet5large] = {\n    \"cut\": noop,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[pnasnet5large]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[pnasnet5large] = {\n    \"cut\": noop,\n    \"split\": lambda m: (list(m[0][0].children())[8], m[1]),\n}\ndef inceptionresnetv2(pretrained: bool = False):\n    return get_model(\"inceptionresnetv2\", pretrained, seq=True)\ndef dpn92(pretrained: bool = False):\n    return get_model(\"dpn92\", pretrained, pname=\"imagenet+5k\", seq=True)\ndef xception_cadene(pretrained=False):\n    return get_model(\"xception\", pretrained, seq=True)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[inceptionresnetv2]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[inceptionresnetv2] = {\"cut\": -2, \"split\": lambda m: (m[0][9], m[1])}\nmodel_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[dpn92]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[dpn92] = {\"cut\": -1, \"split\": lambda m: (m[0][0][16], m[1])}\nmodel_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[xception_cadene]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[xception_cadene] = {\"cut\": -1, \"split\": lambda m: (m[0][11], m[1])}\nmodel_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[senet154]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[senet154] = {\"cut\": -3, \"split\": lambda m: (m[0][3], m[1])}\n_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "_se_resnet_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "_se_resnet_meta = {\"cut\": -2, \"split\": lambda m: (m[0][3], m[1])}\nmodel_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnet50]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnet50] = _se_resnet_meta\nmodel_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnet101]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnet101] = _se_resnet_meta\nmodel_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnext50_32x4d]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnext50_32x4d] = _se_resnet_meta\nmodel_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "model_meta[se_resnext101_32x4d]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "peekOfCode": "model_meta[se_resnext101_32x4d] = _se_resnet_meta\n# TODO: add \"resnext101_32x4d\" \"resnext101_64x4d\" after serialization issue is fixed:\n# https://github.com/Cadene/pretrained-models.pytorch/pull/128",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.cadene_models",
        "documentation": {}
    },
    {
        "label": "ResLayer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "class ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"\n    def __init__(self, ni: int):\n        self.conv1 = conv_bn_lrelu(ni, ni // 2, ks=1)\n        self.conv2 = conv_bn_lrelu(ni // 2, ni, ks=3)\n    def forward(self, x):\n        return x + self.conv2(self.conv1(x))\nclass Darknet(Module):\n    \"https://github.com/pjreddie/darknet\"\n    def make_group_layer(self, ch_in: int, num_blocks: int, stride: int = 1):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "Darknet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "class Darknet(Module):\n    \"https://github.com/pjreddie/darknet\"\n    def make_group_layer(self, ch_in: int, num_blocks: int, stride: int = 1):\n        \"starts with conv layer - `ch_in` channels in - then has `num_blocks` `ResLayer`\"\n        return [conv_bn_lrelu(ch_in, ch_in * 2, stride=stride)] + [\n            (ResLayer(ch_in * 2)) for i in range(num_blocks)\n        ]\n    def __init__(self, num_blocks: Collection[int], num_classes: int, nf=32):\n        \"create darknet with `nf` and `num_blocks` layers\"\n        layers = [conv_bn_lrelu(3, nf, ks=3, stride=1)]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "conv_bn_lrelu",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "def conv_bn_lrelu(ni: int, nf: int, ks: int = 3, stride: int = 1) -> nn.Sequential:\n    \"Create a seuence Conv2d->BatchNorm2d->LeakyReLu layer.\"\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks // 2),\n        nn.BatchNorm2d(nf),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True),\n    )\nclass ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"\n    def __init__(self, ni: int):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "peekOfCode": "__all__ = [\"Darknet\", \"ResLayer\"]\ndef conv_bn_lrelu(ni: int, nf: int, ks: int = 3, stride: int = 1) -> nn.Sequential:\n    \"Create a seuence Conv2d->BatchNorm2d->LeakyReLu layer.\"\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks // 2),\n        nn.BatchNorm2d(nf),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True),\n    )\nclass ResLayer(Module):\n    \"Resnet style layer with `ni` inputs.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.darknet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):\n        identity = x if self.downsample is None else self.downsample(x)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class Bottleneck(Module):\n    expansion = 4\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = act_conv(ni, nf, 1)\n        self.conv2 = act_conv(nf, nf, stride=stride)\n        self.conv3 = act_conv(nf, nf * self.expansion, 1)\n        self.downsample = downsample\n        self.stride = stride\n    def forward(self, x):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "PResNet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "class PResNet(Module):\n    def __init__(self, block, layers, num_classes=1000):\n        self.ni = 64\n        super().__init__()\n        self.conv1 = conv_act(3, 16, stride=2)\n        self.conv2 = conv_act(16, 32)\n        self.conv3 = conv_act(32, 64)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "init_cnn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():\n        init_cnn(l)\ndef conv(ni, nf, ks=3, stride=1, bias=False):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef conv_layer(conv_1st, ni, nf, ks=3, stride=1, zero_bn=False, bias=False):\n    bn = nn.BatchNorm2d(nf if conv_1st else ni)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    res = [act_fn(), bn]\n    cn = conv(ni, nf, ks, stride=stride, bias=bias)\n    res.insert(0 if conv_1st else 2, cn)\n    return nn.Sequential(*res)\ndef conv_act(*args, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv_layer(conv_1st, ni, nf, ks=3, stride=1, zero_bn=False, bias=False):\n    bn = nn.BatchNorm2d(nf if conv_1st else ni)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    res = [act_fn(), bn]\n    cn = conv(ni, nf, ks, stride=stride, bias=bias)\n    res.insert(0 if conv_1st else 2, cn)\n    return nn.Sequential(*res)\ndef conv_act(*args, **kwargs):\n    return conv_layer(True, *args, **kwargs)\ndef act_conv(*args, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "conv_act",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def conv_act(*args, **kwargs):\n    return conv_layer(True, *args, **kwargs)\ndef act_conv(*args, **kwargs):\n    return conv_layer(False, *args, **kwargs)\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "act_conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def act_conv(*args, **kwargs):\n    return conv_layer(False, *args, **kwargs)\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, ni, nf, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = act_conv(ni, nf, stride=stride)\n        self.conv2 = act_conv(nf, nf, zero_bn=True)\n        self.downsample = downsample\n        self.stride = stride",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet(block, n_layers, name, pre=False, **kwargs):\n    model = PResNet(block, n_layers, **kwargs)\n    # if pre: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    if pre:\n        model.load_state_dict(torch.load(model_urls[name]))\n    return model\ndef presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet18",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)\ndef presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet34",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet34(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [3, 4, 6, 3], \"presnet34\", pre=pretrained, **kwargs)\ndef presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet50",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet50(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 6, 3], \"presnet50\", pre=pretrained, **kwargs)\ndef presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet101",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet101(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 4, 23, 3], \"presnet101\", pre=pretrained, **kwargs)\ndef presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "presnet152",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "def presnet152(pretrained=False, **kwargs):\n    return presnet(Bottleneck, [3, 8, 36, 3], \"presnet152\", pre=pretrained, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "__all__ = [\"PResNet\", \"presnet18\", \"presnet34\", \"presnet50\", \"presnet101\", \"presnet152\"]\nact_fn = nn.ReLU\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "act_fn",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "act_fn = nn.ReLU\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight)\n    elif isinstance(m, nn.Linear):\n        m.weight.data.normal_(0, 0.01)\n    for l in m.children():\n        init_cnn(l)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "model_urls",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "peekOfCode": "model_urls = dict(presnet34=\"presnet34\", presnet50=\"presnet50\")\ndef presnet(block, n_layers, name, pre=False, **kwargs):\n    model = PResNet(block, n_layers, **kwargs)\n    # if pre: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    if pre:\n        model.load_state_dict(torch.load(model_urls[name]))\n    return model\ndef presnet18(pretrained=False, **kwargs):\n    return presnet(BasicBlock, [2, 2, 2, 2], \"presnet18\", pre=pretrained, **kwargs)\ndef presnet34(pretrained=False, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.presnet",
        "documentation": {}
    },
    {
        "label": "UnetBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "class UnetBlock(Module):\n    \"A quasi-UNet block, using `PixelShuffle_ICNR upsampling`.\"\n    def __init__(\n        self,\n        up_in_c: int,\n        x_in_c: int,\n        hook: Hook,\n        final_div: bool = True,\n        blur: bool = False,\n        leaky: float = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "DynamicUnet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "class DynamicUnet(SequentialEx):\n    \"Create a U-Net from a given architecture.\"\n    def __init__(\n        self,\n        encoder: nn.Module,\n        n_classes: int,\n        img_size: Tuple[int, int] = (256, 256),\n        blur: bool = False,\n        blur_final=True,\n        self_attention: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "peekOfCode": "__all__ = [\"DynamicUnet\", \"UnetBlock\"]\ndef _get_sfs_idxs(sizes: Sizes) -> List[int]:\n    \"Get the indexes of the layers where the size of the activation changes.\"\n    feature_szs = [size[-1] for size in sizes]\n    sfs_idxs = list(\n        np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0]\n    )\n    if feature_szs[0] != feature_szs[1]:\n        sfs_idxs = [0] + sfs_idxs\n    return sfs_idxs",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.unet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "class BasicBlock(Module):\n    \"Block to from a wide ResNet.\"\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv2d(ni, nf, 1, stride) if ni != nf else noop\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "WideResNet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "class WideResNet(Module):\n    \"Wide ResNet with `num_groups` and a width of `k`.\"\n    def __init__(\n        self,\n        num_groups: int,\n        N: int,\n        num_classes: int,\n        k: int = 1,\n        drop_p: float = 0.0,\n        start_nf: int = 16,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "bn_relu_conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "def bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = _bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv2d(ni, nf, ks, stride))\nclass BasicBlock(Module):\n    \"Block to from a wide ResNet.\"\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "wrn_22",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "def wrn_22():\n    \"Wide ResNet with 22 layers.\"\n    return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.0)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "peekOfCode": "__all__ = [\"BasicBlock\", \"WideResNet\", \"wrn_22\"]\ndef _bn(ni, init_zero=False):\n    \"Batchnorm layer with 0 initialization\"\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = _bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv2d(ni, nf, ks, stride))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.wrn",
        "documentation": {}
    },
    {
        "label": "ConvSkip",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "class ConvSkip(Module):\n    def __init__(self, ni, nf=None, act=True):\n        self.nf, self.ni = nf, ni\n        if self.nf is None:\n            self.nf = ni\n        self.conv = conv(ni, nf, stride=2, act=False)\n        self.m = nn.Sequential(sep_conv(ni, ni, act=act), sep_conv(ni, nf, pool=True))\n    def forward(self, x):\n        return self.conv(x) + self.m(x)\ndef middle_flow(nf):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "sep_conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def sep_conv(ni, nf, pad=None, pool=False, act=True):\n    layers = [nn.ReLU()] if act else []\n    layers += [\n        nn.Conv2d(ni, ni, 3, 1, 1, groups=ni, bias=False),\n        nn.Conv2d(ni, nf, 1, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if pool:\n        layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def conv(ni, nf, ks=1, stride=1, pad=None, act=True):\n    if pad is None:\n        pad = ks // 2\n    layers = [\n        nn.Conv2d(ni, nf, ks, stride, pad, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if act:\n        layers.append(nn.ReLU())\n    return nn.Sequential(*layers)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "middle_flow",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def middle_flow(nf):\n    layers = [sep_conv(nf, nf) for i in range(3)]\n    return SequentialEx(*layers, MergeLayer())\ndef xception(c, k=8, n_middle=8):\n    \"Preview version of Xception network. Not tested yet - use at own risk. No pretrained model yet.\"\n    layers = [\n        conv(3, k * 4, 3, 2),\n        conv(k * 4, k * 8, 3),\n        ConvSkip(k * 8, k * 16, act=False),\n        ConvSkip(k * 16, k * 32),",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "xception",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "def xception(c, k=8, n_middle=8):\n    \"Preview version of Xception network. Not tested yet - use at own risk. No pretrained model yet.\"\n    layers = [\n        conv(3, k * 4, 3, 2),\n        conv(k * 4, k * 8, 3),\n        ConvSkip(k * 8, k * 16, act=False),\n        ConvSkip(k * 16, k * 32),\n        ConvSkip(k * 32, k * 91),\n    ]\n    for i in range(n_middle):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "peekOfCode": "__all__ = [\"xception\"]\ndef sep_conv(ni, nf, pad=None, pool=False, act=True):\n    layers = [nn.ReLU()] if act else []\n    layers += [\n        nn.Conv2d(ni, ni, 3, 1, 1, groups=ni, bias=False),\n        nn.Conv2d(ni, nf, 1, bias=False),\n        nn.BatchNorm2d(nf),\n    ]\n    if pool:\n        layers.append(nn.MaxPool2d(2))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xception",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():\n        init_cnn(l)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "ResBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class ResBlock(Module):\n    def __init__(self, expansion, ni, nh, stride=1):\n        nf, ni = nh * expansion, ni * expansion\n        layers = (\n            [\n                conv_layer(ni, nh, 3, stride=stride),\n                conv_layer(nh, nf, 3, zero_bn=True, act=False),\n            ]\n            if expansion == 1\n            else [",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "XResNet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "class XResNet(nn.Sequential):\n    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n        stem = []\n        sizes = [c_in, 32, 32, 64]\n        for i in range(3):\n            stem.append(conv_layer(sizes[i], sizes[i + 1], stride=2 if i == 0 else 1))\n            # nf = filt_sz(c_in*9)\n            # stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n            # c_in = nf\n        block_szs = [64 // expansion, 64, 128, 256, 512]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "init_cnn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():\n        init_cnn(l)\ndef conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef noop(x):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "conv",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def conv(ni, nf, ks=3, stride=1, bias=False):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks // 2, bias=bias)\ndef noop(x):\n    return x\ndef conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "noop",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def noop(x):\n    return x\ndef conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)\n    return nn.Sequential(*layers)\nclass ResBlock(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n    bn = nn.BatchNorm2d(nf)\n    nn.init.constant_(bn.weight, 0.0 if zero_bn else 1.0)\n    layers = [conv(ni, nf, ks, stride=stride), bn]\n    if act:\n        layers.append(act_fn)\n    return nn.Sequential(*layers)\nclass ResBlock(Module):\n    def __init__(self, expansion, ni, nh, stride=1):\n        nf, ni = nh * expansion, ni * expansion",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "filt_sz",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def filt_sz(recep):\n    return min(64, 2 ** math.floor(math.log2(recep * 0.75)))\nclass XResNet(nn.Sequential):\n    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n        stem = []\n        sizes = [c_in, 32, 32, 64]\n        for i in range(3):\n            stem.append(conv_layer(sizes[i], sizes[i + 1], stride=2 if i == 0 else 1))\n            # nf = filt_sz(c_in*9)\n            # stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "xresnet",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "def xresnet(expansion, n_layers, name, pretrained=False, **kwargs):\n    model = XResNet(expansion, n_layers, **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\nme = sys.modules[__name__]\nfor n, e, l in [\n    [18, 1, [2, 2, 2, 2]],\n    [34, 1, [3, 4, 6, 3]],\n    [50, 4, [3, 4, 6, 3]],",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "__all__ = [\"XResNet\", \"xresnet18\", \"xresnet34\", \"xresnet50\", \"xresnet101\", \"xresnet152\"]\n# or: ELU+init (a=0.54; gain=1.55)\nact_fn = nn.ReLU(inplace=True)\nclass Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "act_fn",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "act_fn = nn.ReLU(inplace=True)\nclass Flatten(Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\ndef init_cnn(m):\n    if getattr(m, \"bias\", None) is not None:\n        nn.init.constant_(m.bias, 0)\n    if isinstance(m, (nn.Conv2d, nn.Linear)):\n        nn.init.kaiming_normal_(m.weight)\n    for l in m.children():",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "me",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "peekOfCode": "me = sys.modules[__name__]\nfor n, e, l in [\n    [18, 1, [2, 2, 2, 2]],\n    [34, 1, [3, 4, 6, 3]],\n    [50, 4, [3, 4, 6, 3]],\n    [101, 4, [3, 4, 23, 3]],\n    [152, 4, [3, 8, 36, 3]],\n]:\n    name = f\"xresnet{n}\"\n    setattr(me, name, partial(xresnet, expansion=e, n_layers=l, name=name))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet",
        "documentation": {}
    },
    {
        "label": "BasicBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class BasicBlock(Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class Bottleneck(Module):\n    expansion = 4\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(\n            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(planes)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "XResNet",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "class XResNet(Module):\n    def __init__(self, block, layers, c_out=1000):\n        self.inplanes = 64\n        super(XResNet, self).__init__()\n        self.conv1 = conv2d(3, 32, 2)\n        self.conv2 = conv2d(32, 32, 1)\n        self.conv3 = conv2d(32, 64, 1)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "conv3x3",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(\n        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n    )\nclass BasicBlock(Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "conv2d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def conv2d(ni, nf, stride):\n    return nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=3, stride=stride, padding=1, bias=False),\n        nn.BatchNorm2d(nf),\n        nn.ReLU(inplace=True),\n    )\nclass XResNet(Module):\n    def __init__(self, block, layers, c_out=1000):\n        self.inplanes = 64\n        super(XResNet, self).__init__()",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet18",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet18\"]))\n    return model\ndef xresnet34_2(pretrained=False, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet34_2",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet34_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet34\"]))\n    return model\ndef xresnet50_2(pretrained=False, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet50_2",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet50_2(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet50\"]))\n    return model\ndef xresnet101(pretrained=False, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet101",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet101\"]))\n    return model\ndef xresnet152(pretrained=False, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "xresnet152",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "def xresnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a XResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = XResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\"xresnet152\"]))\n    return model",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "description": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "peekOfCode": "__all__ = [\n    \"XResNet\",\n    \"xresnet18\",\n    \"xresnet34_2\",\n    \"xresnet50_2\",\n    \"xresnet101\",\n    \"xresnet152\",\n]\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.models.xresnet2",
        "documentation": {}
    },
    {
        "label": "ResnetBlock",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class ResnetBlock(Module):\n    def __init__(\n        self,\n        dim: int,\n        pad_mode: str = \"reflection\",\n        norm_layer: nn.Module = None,\n        dropout: float = 0.0,\n        bias: bool = True,\n    ):\n        assert pad_mode in [",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGAN",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGAN(Module):\n    def __init__(\n        self,\n        ch_in: int,\n        ch_out: int,\n        n_features: int = 64,\n        disc_layers: int = 3,\n        gen_blocks: int = 6,\n        lsgan: bool = True,\n        drop: float = 0.0,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "AdaptiveLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class AdaptiveLoss(Module):\n    def __init__(self, crit):\n        self.crit = crit\n    def forward(self, output, target: bool):\n        targ = (\n            output.new_ones(*output.size())\n            if target\n            else output.new_zeros(*output.size())\n        )\n        return self.crit(output, targ)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGanLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGanLoss(Module):\n    def __init__(\n        self,\n        cgan: nn.Module,\n        lambda_A: float = 10.0,\n        lambda_B: float = 10,\n        lambda_idt: float = 0.5,\n        lsgan: bool = True,\n    ):\n        self.cgan, self.l_A, self.l_B, self.l_idt = cgan, lambda_A, lambda_B, lambda_idt",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "CycleGANTrainer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "class CycleGANTrainer(LearnerCallback):\n    \"`LearnerCallback` that handles cycleGAN Training.\"\n    _order = -20\n    def _set_trainable(self, D_A=False, D_B=False):\n        gen = (not D_A) and (not D_B)\n        requires_grad(self.learn.model.G_A, gen)\n        requires_grad(self.learn.model.G_B, gen)\n        requires_grad(self.learn.model.D_A, D_A)\n        requires_grad(self.learn.model.D_B, D_B)\n        if not gen:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "convT_norm_relu",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def convT_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    stride: int = 2,\n    bias: bool = True,\n):\n    return [\n        nn.ConvTranspose2d(",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "pad_conv_norm_relu",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def pad_conv_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    pad_mode: str,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    bias: bool = True,\n    pad=1,\n    stride: int = 1,\n    activ: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "resnet_generator",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def resnet_generator(\n    ch_in: int,\n    ch_out: int,\n    n_ftrs: int = 64,\n    norm_layer: nn.Module = None,\n    dropout: float = 0.0,\n    n_blocks: int = 6,\n    pad_mode: str = \"reflection\",\n) -> nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "conv_norm_lr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def conv_norm_lr(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module = None,\n    ks: int = 3,\n    bias: bool = True,\n    pad: int = 1,\n    stride: int = 1,\n    activ: bool = True,\n    slope: float = 0.2,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "critic",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "def critic(\n    ch_in: int,\n    n_ftrs: int = 64,\n    n_layers: int = 3,\n    norm_layer: nn.Module = None,\n    sigmoid: bool = False,\n) -> nn.Module:\n    norm_layer = ifnone(norm_layer, nn.InstanceNorm2d)\n    bias = norm_layer == nn.InstanceNorm2d\n    layers = conv_norm_lr(ch_in, n_ftrs, ks=4, stride=2, pad=1)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "peekOfCode": "__all__ = [\"CycleGAN\", \"CycleGanLoss\", \"AdaptiveLoss\", \"CycleGANTrainer\"]\ndef convT_norm_relu(\n    ch_in: int,\n    ch_out: int,\n    norm_layer: nn.Module,\n    ks: int = 3,\n    stride: int = 2,\n    bias: bool = True,\n):\n    return [",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.cyclegan",
        "documentation": {}
    },
    {
        "label": "ImageDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,\n        lls: LabelLists,\n        bs: int = 64,\n        val_bs: int = None,\n        ds_tfms: Optional[TfmList] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ImageList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageList(ItemList):\n    \"`ItemList` suitable for computer vision.\"\n    _bunch, _square_show, _square_show_res = ImageDataBunch, True, True\n    def __init__(\n        self, *args, convert_mode=\"RGB\", after_open: Callable = None, **kwargs\n    ):\n        super().__init__(*args, **kwargs)\n        self.convert_mode, self.after_open = convert_mode, after_open\n        self.copy_new += [\"convert_mode\", \"after_open\"]\n        self.c, self.sizes = 3, {}",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectCategoryProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectCategoryProcessor(MultiCategoryProcessor):\n    \"`PreProcessor` for labelled bounding boxes.\"\n    def __init__(self, ds: ItemList, pad_idx: int = 0):\n        super().__init__(ds)\n        self.pad_idx = pad_idx\n        self.state_attrs.append(\"pad_idx\")\n    def process(self, ds: ItemList):\n        ds.pad_idx = self.pad_idx\n        super().process(ds)\n    def process_one(self, item):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectCategoryList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectCategoryList(MultiCategoryList):\n    \"`ItemList` for labelled bounding boxes.\"\n    _processor = ObjectCategoryProcessor\n    def get(self, i):\n        return ImageBBox.create(\n            *_get_size(self.x, i),\n            *self.items[i],\n            classes=self.classes,\n            pad_idx=self.pad_idx,\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ObjectItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ObjectItemList(ImageList):\n    \"`ItemList` suitable for object detection.\"\n    _label_cls, _square_show_res = ObjectCategoryList, False\nclass SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds: ItemList):\n        self.classes = ds.classes\n    def process(self, ds: ItemList):\n        ds.classes, ds.c = self.classes, len(self.classes)\nclass SegmentationLabelList(ImageList):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds: ItemList):\n        self.classes = ds.classes\n    def process(self, ds: ItemList):\n        ds.classes, ds.c = self.classes, len(self.classes)\nclass SegmentationLabelList(ImageList):\n    \"`ItemList` for segmentation masks.\"\n    _processor = SegmentationProcessor\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationLabelList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationLabelList(ImageList):\n    \"`ItemList` for segmentation masks.\"\n    _processor = SegmentationProcessor\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\"classes\")\n        self.classes, self.loss_func = classes, CrossEntropyFlat(axis=1)\n    def open(self, fn):\n        return open_mask(fn)\n    def analyze_pred(self, pred, thresh: float = 0.5):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "SegmentationItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class SegmentationItemList(ImageList):\n    \"`ItemList` suitable for segmentation tasks.\"\n    _label_cls, _square_show_res = SegmentationLabelList, False\nclass PointsProcessor(PreProcessor):\n    \"`PreProcessor` that stores the number of targets for point regression.\"\n    def __init__(self, ds: ItemList):\n        self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds: ItemList):\n        ds.c = self.c\nclass PointsLabelList(ItemList):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsProcessor(PreProcessor):\n    \"`PreProcessor` that stores the number of targets for point regression.\"\n    def __init__(self, ds: ItemList):\n        self.c = len(ds.items[0].reshape(-1))\n    def process(self, ds: ItemList):\n        ds.c = self.c\nclass PointsLabelList(ItemList):\n    \"`ItemList` for points.\"\n    _processor = PointsProcessor\n    def __init__(self, items: Iterator, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsLabelList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsLabelList(ItemList):\n    \"`ItemList` for points.\"\n    _processor = PointsProcessor\n    def __init__(self, items: Iterator, **kwargs):\n        super().__init__(items, **kwargs)\n        self.loss_func = MSELossFlat()\n    def get(self, i):\n        o = super().get(i)\n        return ImagePoints(FlowField(_get_size(self.x, i), o), scale=True)\n    def analyze_pred(self, pred, thresh: float = 0.5):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "PointsItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class PointsItemList(ImageList):\n    \"`ItemList` for `Image` to `ImagePoints` tasks.\"\n    _label_cls, _square_show_res = PointsLabelList, False\nclass ImageImageList(ImageList):\n    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n    _label_cls, _square_show, _square_show_res = ImageList, False, False\n    def show_xys(\n        self,\n        xs,\n        ys,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "ImageImageList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "class ImageImageList(ImageList):\n    \"`ItemList` suitable for `Image` to `Image` tasks.\"\n    _label_cls, _square_show, _square_show_res = ImageList, False, False\n    def show_xys(\n        self,\n        xs,\n        ys,\n        imgsize: int = 4,\n        figsize: Optional[Tuple[int, int]] = None,\n        **kwargs,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "get_image_files",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def get_image_files(\n    c: PathOrStr, check_ext: bool = True, recurse=False\n) -> FilePathList:\n    \"Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.\"\n    return get_files(\n        c, extensions=(image_extensions if check_ext else None), recurse=recurse\n    )\ndef get_annotations(fname, prefix=None):\n    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n    annot_dict = json.load(open(fname))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "get_annotations",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def get_annotations(fname, prefix=None):\n    \"Open a COCO style json in `fname` and returns the lists of filenames (with maybe `prefix`) and labelled bboxes.\"\n    annot_dict = json.load(open(fname))\n    id2images, id2bboxes, id2cats = (\n        {},\n        collections.defaultdict(list),\n        collections.defaultdict(list),\n    )\n    classes = {}\n    for o in annot_dict[\"categories\"]:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "bb_pad_collate",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def bb_pad_collate(\n    samples: BatchSamples, pad_idx: int = 0\n) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:\n    \"Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.\"\n    if isinstance(samples[0][1], int):\n        return data_collate(samples)\n    max_len = max([len(s[1].data[1]) for s in samples])\n    bboxes = torch.zeros(len(samples), max_len, 4)\n    labels = torch.zeros(len(samples), max_len).long() + pad_idx\n    imgs = []",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def normalize(x: TensorImage, mean, std: Tensor) -> TensorImage:\n    \"Normalize `x` with `mean` and `std`.\"\n    return (x - mean[..., None, None]) / std[..., None, None]\ndef denormalize(x: TensorImage, mean, std: Tensor, do_x: bool = True) -> TensorImage:\n    \"Denormalize `x` with `mean` and `std`.\"\n    return (\n        x.cpu().float() * std[..., None, None] + mean[..., None, None]\n        if do_x\n        else x.cpu()\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "denormalize",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def denormalize(x: TensorImage, mean, std: Tensor, do_x: bool = True) -> TensorImage:\n    \"Denormalize `x` with `mean` and `std`.\"\n    return (\n        x.cpu().float() * std[..., None, None] + mean[..., None, None]\n        if do_x\n        else x.cpu()\n    )\ndef _normalize_batch(\n    b: Tuple[Tensor, Tensor],\n    mean: Tensor,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "normalize_funcs",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def normalize_funcs(\n    mean: Tensor, std: Tensor, do_x: bool = True, do_y: bool = False\n) -> Tuple[Callable, Callable]:\n    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n    mean, std = tensor(mean), tensor(std)\n    return (\n        partial(_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n        partial(denormalize, mean=mean, std=std, do_x=do_x),\n    )\ncifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "channel_view",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,\n        lls: LabelLists,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "download_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def download_image(url, dest, timeout=4):\n    try:\n        r = download_url(\n            url, dest, overwrite=True, show_progress=False, timeout=timeout\n        )\n    except Exception as e:\n        print(f\"Error {url} {e}\")\ndef _download_image_inner(dest, url, i, timeout=4):\n    suffix = re.findall(r\"\\.\\w+?(?=(?:\\?|$))\", url)\n    suffix = suffix[0] if len(suffix) > 0 else \".jpg\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "download_images",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def download_images(\n    urls: Collection[str],\n    dest: PathOrStr,\n    max_pics: int = 1000,\n    max_workers: int = 8,\n    timeout=4,\n):\n    \"Download images listed in text file `urls` to path `dest`, at most `max_pics`\"\n    urls = open(urls).read().strip().split(\"\\n\")[:max_pics]\n    dest = Path(dest)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "resize_to",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def resize_to(img, targ_sz: int, use_min: bool = False):\n    \"Size to resize to, to hit `targ_sz` at same aspect ratio, in PIL coords (i.e w*h)\"\n    w, h = img.size\n    min_sz = (min if use_min else max)(w, h)\n    ratio = targ_sz / min_sz\n    return int(w * ratio), int(h * ratio)\ndef verify_image(\n    file: Path,\n    idx: int,\n    delete: bool,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "verify_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def verify_image(\n    file: Path,\n    idx: int,\n    delete: bool,\n    max_size: Union[int, Tuple[int, int]] = None,\n    dest: Path = None,\n    n_channels: int = 3,\n    interp=PIL.Image.BILINEAR,\n    ext: str = None,\n    img_format: str = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "verify_images",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "def verify_images(\n    path: PathOrStr,\n    delete: bool = True,\n    max_workers: int = 4,\n    max_size: Union[int] = None,\n    recurse: bool = False,\n    dest: PathOrStr = \".\",\n    n_channels: int = 3,\n    interp=PIL.Image.BILINEAR,\n    ext: str = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "__all__ = [\n    \"get_image_files\",\n    \"denormalize\",\n    \"get_annotations\",\n    \"ImageDataBunch\",\n    \"ImageList\",\n    \"normalize\",\n    \"normalize_funcs\",\n    \"resize_to\",\n    \"channel_view\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "image_extensions",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "image_extensions = set(\n    k for k, v in mimetypes.types_map.items() if v.startswith(\"image/\")\n)\ndef get_image_files(\n    c: PathOrStr, check_ext: bool = True, recurse=False\n) -> FilePathList:\n    \"Return list of files in `c` that are images. `check_ext` will filter to `image_extensions`.\"\n    return get_files(\n        c, extensions=(image_extensions if check_ext else None), recurse=recurse\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "cifar_stats",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "cifar_stats = ([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nimagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "imagenet_stats",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nimagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "imagenet_stats_inception",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "imagenet_stats_inception = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nmnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "mnist_stats",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "mnist_stats = ([0.15] * 3, [0.15] * 3)\ndef channel_view(x: Tensor) -> Tensor:\n    \"Make channel the first axis of `x` and flatten remaining axes\"\n    return x.transpose(0, 1).contiguous().view(x.shape[1], -1)\nclass ImageDataBunch(DataBunch):\n    \"DataBunch suitable for computer vision.\"\n    _square_show = True\n    @classmethod\n    def create_from_ll(\n        cls,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "LabelLists.pre_transform",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "LabelLists.pre_transform = _ll_pre_transform\nDataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "DataBunch.pre_transform",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "DataBunch.pre_transform = _db_pre_transform\nLabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "LabelLists.presize",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "LabelLists.presize = _presize\nDataBunch.presize = _presize",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "DataBunch.presize",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.data",
        "description": "dashboard.dl_model.deoldify.fastai.vision.data",
        "peekOfCode": "DataBunch.presize = _presize",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.data",
        "documentation": {}
    },
    {
        "label": "GANModule",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANModule(Module):\n    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n    def __init__(\n        self,\n        generator: nn.Module = None,\n        critic: nn.Module = None,\n        gen_mode: bool = False,\n    ):\n        self.gen_mode = gen_mode\n        if generator:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANLoss(GANModule):\n    \"Wrapper around `loss_funcC` (for the critic) and `loss_funcG` (for the generator).\"\n    def __init__(\n        self, loss_funcG: Callable, loss_funcC: Callable, gan_model: GANModule\n    ):\n        super().__init__()\n        self.loss_funcG, self.loss_funcC, self.gan_model = (\n            loss_funcG,\n            loss_funcC,\n            gan_model,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANTrainer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANTrainer(LearnerCallback):\n    \"Handles GAN Training.\"\n    _order = -20\n    def __init__(\n        self,\n        learn: Learner,\n        switch_eval: bool = False,\n        clip: float = None,\n        beta: float = 0.98,\n        gen_first: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "FixedGANSwitcher",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class FixedGANSwitcher(LearnerCallback):\n    \"Switcher to do `n_crit` iterations of the critic then `n_gen` iterations of the generator.\"\n    def __init__(\n        self,\n        learn: Learner,\n        n_crit: Union[int, Callable] = 1,\n        n_gen: Union[int, Callable] = 1,\n    ):\n        super().__init__(learn)\n        self.n_crit, self.n_gen = n_crit, n_gen",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AdaptiveGANSwitcher",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class AdaptiveGANSwitcher(LearnerCallback):\n    \"Switcher that goes back to generator/critic when the loss goes below `gen_thresh`/`crit_thresh`.\"\n    def __init__(\n        self, learn: Learner, gen_thresh: float = None, critic_thresh: float = None\n    ):\n        super().__init__(learn)\n        self.gen_thresh, self.critic_thresh = gen_thresh, critic_thresh\n    def on_batch_end(self, last_loss, **kwargs):\n        \"Switch the model if necessary.\"\n        if self.gan_trainer.gen_mode:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANLearner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANLearner(Learner):\n    \"A `Learner` suitable for GANs.\"\n    def __init__(\n        self,\n        data: DataBunch,\n        generator: nn.Module,\n        critic: nn.Module,\n        gen_loss_func: LossFunction,\n        crit_loss_func: LossFunction,\n        switcher: Callback = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "NoisyItem",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class NoisyItem(ItemBase):\n    \"An random `ItemBase` of size `noise_sz`.\"\n    def __init__(self, noise_sz):\n        self.obj, self.data = noise_sz, torch.randn(noise_sz, 1, 1)\n    def __str__(self):\n        return \"\"\n    def apply_tfms(self, tfms, **kwargs):\n        return self\nclass GANItemList(ImageList):\n    \"`ItemList` suitable for GANs.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANItemList(ImageList):\n    \"`ItemList` suitable for GANs.\"\n    _label_cls = ImageList\n    def __init__(self, items, noise_sz: int = 100, **kwargs):\n        super().__init__(items, **kwargs)\n        self.noise_sz = noise_sz\n        self.copy_new.append(\"noise_sz\")\n    def get(self, i):\n        return NoisyItem(self.noise_sz)\n    def reconstruct(self, t):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "GANDiscriminativeLR",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class GANDiscriminativeLR(LearnerCallback):\n    \"`Callback` that handles multiplying the learning rate by `mult_lr` for the critic.\"\n    def __init__(self, learn: Learner, mult_lr: float = 5.0):\n        super().__init__(learn)\n        self.mult_lr = mult_lr\n    def on_batch_begin(self, train, **kwargs):\n        \"Multiply the current lr if necessary.\"\n        if not self.learn.gan_trainer.gen_mode and train:\n            self.learn.opt.lr *= self.mult_lr\n    def on_step_end(self, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AdaptiveLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "class AdaptiveLoss(Module):\n    \"Expand the `target` to match the `output` size before applying `crit`.\"\n    def __init__(self, crit):\n        self.crit = crit\n    def forward(self, output, target):\n        return self.crit(output, target[:, None].expand_as(output).float())\ndef accuracy_thresh_expand(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "AvgFlatten",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def AvgFlatten():\n    \"Takes the average of the input.\"\n    return Lambda(lambda x: x.mean(0).view(1))\ndef basic_critic(\n    in_size: int,\n    n_channels: int,\n    n_features: int = 64,\n    n_extra_layers: int = 0,\n    **conv_kwargs,\n):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "basic_critic",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def basic_critic(\n    in_size: int,\n    n_channels: int,\n    n_features: int = 64,\n    n_extra_layers: int = 0,\n    **conv_kwargs,\n):\n    \"A basic critic for images `n_channels` x `in_size` x `in_size`.\"\n    layers = [\n        conv_layer(",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "basic_generator",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def basic_generator(\n    in_size: int,\n    n_channels: int,\n    noise_sz: int = 100,\n    n_features: int = 64,\n    n_extra_layers=0,\n    **conv_kwargs,\n):\n    \"A basic generator from `noise_sz` to images `n_channels` x `in_size` x `in_size`.\"\n    cur_size, cur_ftrs = 4, n_features // 2",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "gan_loss_from_func",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def gan_loss_from_func(loss_gen, loss_crit, weights_gen: Tuple[float, float] = None):\n    \"Define loss functions for a GAN from `loss_gen` and `loss_crit`.\"\n    def _loss_G(fake_pred, output, target, weights_gen=weights_gen):\n        ones = fake_pred.new_ones(fake_pred.shape[0])\n        weights_gen = ifnone(weights_gen, (1.0, 1.0))\n        return weights_gen[0] * loss_crit(fake_pred, ones) + weights_gen[1] * loss_gen(\n            output, target\n        )\n    def _loss_C(real_pred, fake_pred):\n        ones = real_pred.new_ones(real_pred.shape[0])",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "gan_critic",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def gan_critic(n_channels: int = 3, nf: int = 128, n_blocks: int = 3, p: int = 0.15):\n    \"Critic to train a `GAN`.\"\n    layers = [\n        _conv(n_channels, nf, ks=4, stride=2),\n        nn.Dropout2d(p / 2),\n        res_block(nf, dense=True, **_conv_args),\n    ]\n    nf *= 2  # after dense block\n    for i in range(n_blocks):\n        layers += [",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "accuracy_thresh_expand",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "def accuracy_thresh_expand(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"\n    if sigmoid:\n        y_pred = y_pred.sigmoid()\n    return (\n        ((y_pred > thresh) == y_true[:, None].expand_as(y_pred).byte()).float().mean()\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "__all__ = [\n    \"basic_critic\",\n    \"basic_generator\",\n    \"GANModule\",\n    \"GANLoss\",\n    \"GANTrainer\",\n    \"FixedGANSwitcher\",\n    \"AdaptiveGANSwitcher\",\n    \"GANLearner\",\n    \"NoisyItem\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "_conv_args",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "description": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "peekOfCode": "_conv_args = dict(leaky=0.2, norm_type=NormType.Spectral)\ndef _conv(ni: int, nf: int, ks: int = 3, stride: int = 1, **kwargs):\n    return conv_layer(ni, nf, ks=ks, stride=stride, **_conv_args, **kwargs)\ndef gan_critic(n_channels: int = 3, nf: int = 128, n_blocks: int = 3, p: int = 0.15):\n    \"Critic to train a `GAN`.\"\n    layers = [\n        _conv(n_channels, nf, ks=4, stride=2),\n        nn.Dropout2d(p / 2),\n        res_block(nf, dense=True, **_conv_args),\n    ]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.gan",
        "documentation": {}
    },
    {
        "label": "FlowField",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class FlowField:\n    \"Wrap together some coords `flow` with a `size`.\"\n    size: Tuple[int, int]\n    flow: Tensor\nCoordFunc = Callable[[FlowField, ArgStar, KWArgs], LogitTensorImage]\nclass Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "Image",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None\n        self._flow = None\n        self._affine_mat = None\n        self.sample_kwargs = {}\n    def set_sample(self, **kwargs) -> \"ImageBase\":\n        \"Set parameters that control how we `grid_sample` the image after transforms are applied.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImageSegment",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImageSegment(Image):\n    \"Support applying transforms to segmentation masks data in `px`.\"\n    def lighting(self, func: LightingFunc, *args: Any, **kwargs: Any) -> \"Image\":\n        return self\n    def refresh(self):\n        self.sample_kwargs[\"mode\"] = \"nearest\"\n        return super().refresh()\n    @property\n    def data(self) -> TensorImage:\n        \"Return this image pixels as a `LongTensor`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImagePoints",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImagePoints(Image):\n    \"Support applying transforms to a `flow` of points.\"\n    def __init__(self, flow: FlowField, scale: bool = True, y_first: bool = True):\n        if scale:\n            flow = scale_flow(flow)\n        if y_first:\n            flow.flow = flow.flow.flip(1)\n        self._flow = flow\n        self._affine_mat = None\n        self.flow_func = []",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ImageBBox",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class ImageBBox(ImagePoints):\n    \"Support applying transforms to a `flow` of bounding boxes.\"\n    def __init__(\n        self,\n        flow: FlowField,\n        scale: bool = True,\n        y_first: bool = True,\n        labels: Collection = None,\n        classes: dict = None,\n        pad_idx: int = 0,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "Transform",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class Transform:\n    \"Utility class for adding probability and wrapping support to transform `func`.\"\n    _wrap = None\n    order = 0\n    def __init__(self, func: Callable, order: Optional[int] = None):\n        \"Create a transform for `func` and assign it an priority `order`, attach to `Image` class.\"\n        if order is not None:\n            self.order = order\n        self.func = func\n        self.func.__name__ = func.__name__[",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "RandTransform",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class RandTransform:\n    \"Wrap `Transform` to add randomized execution.\"\n    tfm: Transform\n    kwargs: dict\n    p: float = 1.0\n    resolved: dict = field(default_factory=dict)\n    do_run: bool = True\n    is_random: bool = True\n    use_on_y: bool = True\n    def __post_init__(self):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmAffine",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmAffine(Transform):\n    \"Decorator for affine tfm funcs.\"\n    order, _wrap = 5, \"affine\"\nclass TfmPixel(Transform):\n    \"Decorator for pixel tfm funcs.\"\n    order, _wrap = 10, \"pixel\"\nclass TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmPixel",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmPixel(Transform):\n    \"Decorator for pixel tfm funcs.\"\n    order, _wrap = 10, \"pixel\"\nclass TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmCoord",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmCoord(Transform):\n    \"Decorator for coord tfm funcs.\"\n    order, _wrap = 4, \"coord\"\nclass TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmCrop",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmCrop(TfmPixel):\n    \"Decorator for crop tfm funcs.\"\n    order = 99\nclass TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:\n    \"Calc `x` to nearest multiple of `mult`.\"\n    return (int(x / mult + 0.5) * mult) if mult is not None else x\ndef _get_crop_target(",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "TfmLighting",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "class TfmLighting(Transform):\n    \"Decorator for lighting tfm funcs.\"\n    order, _wrap = 8, \"lighting\"\ndef _round_multiple(x: int, mult: int = None) -> int:\n    \"Calc `x` to nearest multiple of `mult`.\"\n    return (int(x / mult + 0.5) * mult) if mult is not None else x\ndef _get_crop_target(\n    target_px: Union[int, TensorImageSize], mult: int = None\n) -> Tuple[int, int]:\n    \"Calc crop shape of `target_px` to nearest multiple of `mult`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "pil2tensor",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def pil2tensor(image: Union[NPImage, NPArray], dtype: np.dtype) -> TensorImage:\n    \"Convert PIL style `image` array to torch style image tensor.\"\n    a = np.asarray(image)\n    if a.ndim == 2:\n        a = np.expand_dims(a, 2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False))\ndef image2np(image: Tensor) -> np.ndarray:\n    \"Convert from torch style `image` to numpy/matplotlib style.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "image2np",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def image2np(image: Tensor) -> np.ndarray:\n    \"Convert from torch style `image` to numpy/matplotlib style.\"\n    res = image.cpu().permute(1, 2, 0).numpy()\n    return res[..., 0] if res.shape[2] == 1 else res\ndef bb2hw(a: Collection[int]) -> np.ndarray:\n    \"Convert bounding box points from (width,height,center) to (height,width,top,left).\"\n    return np.array([a[1], a[0], a[3] - a[1], a[2] - a[0]])\ndef tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "bb2hw",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def bb2hw(a: Collection[int]) -> np.ndarray:\n    \"Convert bounding box points from (width,height,center) to (height,width,top,left).\"\n    return np.array([a[1], a[0], a[3] - a[1], a[2] - a[0]])\ndef tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:\n        raise RuntimeError(\"Expected size to be an int or a tuple, got a string.\")\n    return listify(size, 2) if isinstance(size, int) else listify(size[-2:], 2)\ndef _draw_outline(o: Patch, lw: int):\n    \"Outline bounding box onto image `Patch`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "tis2hw",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def tis2hw(size: Union[int, TensorImageSize]) -> Tuple[int, int]:\n    \"Convert `int` or `TensorImageSize` to (height,width) of an image.\"\n    if type(size) is str:\n        raise RuntimeError(\"Expected size to be an int or a tuple, got a string.\")\n    return listify(size, 2) if isinstance(size, int) else listify(size[-2:], 2)\ndef _draw_outline(o: Patch, lw: int):\n    \"Outline bounding box onto image `Patch`.\"\n    o.set_path_effects(\n        [patheffects.Stroke(linewidth=lw, foreground=\"black\"), patheffects.Normal()]\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_image(\n    fn: PathOrStr,\n    div: bool = True,\n    convert_mode: str = \"RGB\",\n    cls: type = Image,\n    after_open: Callable = None,\n) -> Image:\n    \"Return `Image` object created from image in file `fn`.\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)  # EXIF warning from TiffPlugin",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_mask",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_mask(\n    fn: PathOrStr, div=False, convert_mode=\"L\", after_open: Callable = None\n) -> ImageSegment:\n    \"Return `ImageSegment` object create from mask in file `fn`. If `div`, divides pixel values by 255.\"\n    return open_image(\n        fn, div=div, convert_mode=convert_mode, cls=ImageSegment, after_open=after_open\n    )\ndef open_mask_rle(mask_rle: str, shape: Tuple[int, int]) -> ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "open_mask_rle",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def open_mask_rle(mask_rle: str, shape: Tuple[int, int]) -> ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(shape[1], shape[0], -1)\n    return ImageSegment(x.permute(2, 0, 1))\ndef rle_encode(img: NPArrayMask) -> str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(), [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "rle_encode",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def rle_encode(img: NPArrayMask) -> str:\n    \"Return run-length encoding string from `img`.\"\n    pixels = np.concatenate([[0], img.flatten(), [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(str(x) for x in runs)\ndef rle_decode(mask_rle: str, shape: Tuple[int, int]) -> NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "rle_decode",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def rle_decode(mask_rle: str, shape: Tuple[int, int]) -> NPArrayMask:\n    \"Return an image array from run-length encoded string `mask_rle` with `shape`.\"\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n    for low, up in zip(starts, ends):\n        img[low:up] = 1\n    return img.reshape(shape)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_image(\n    img: Image,\n    ax: plt.Axes = None,\n    figsize: tuple = (3, 3),\n    hide_axis: bool = True,\n    cmap: str = \"binary\",\n    alpha: float = None,\n    **kwargs,\n) -> plt.Axes:\n    \"Display `Image` in notebook.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "scale_flow",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def scale_flow(flow, to_unit=True):\n    \"Scale the coords in `flow` to -1/1 or the image size depending on `to_unit`.\"\n    s = tensor([flow.size[0] / 2, flow.size[1] / 2])[None]\n    if to_unit:\n        flow.flow = flow.flow / s - 1\n    else:\n        flow.flow = (flow.flow + 1) * s\n    return flow\ndef _remove_points_out(flow: FlowField):\n    pad_mask = (",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "plot_flat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def plot_flat(r, c, figsize):\n    \"Shortcut for `enumerate(subplots.flatten())`\"\n    return enumerate(plt.subplots(r, c, figsize=figsize)[1].flatten())\ndef plot_multi(\n    func: Callable[[int, int, plt.Axes], None],\n    r: int = 1,\n    c: int = 1,\n    figsize: Tuple = (12, 6),\n):\n    \"Call `func` for every combination of `r,c` on a subplot\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "plot_multi",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def plot_multi(\n    func: Callable[[int, int, plt.Axes], None],\n    r: int = 1,\n    c: int = 1,\n    figsize: Tuple = (12, 6),\n):\n    \"Call `func` for every combination of `r,c` on a subplot\"\n    axes = plt.subplots(r, c, figsize=figsize)[1]\n    for i in range(r):\n        for j in range(c):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_multi",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_multi(\n    func: Callable[[int, int], Image], r: int = 1, c: int = 1, figsize: Tuple = (9, 9)\n):\n    \"Call `func(i,j).show(ax)` for every combination of `r,c`\"\n    plot_multi(lambda i, j, ax: func(i, j).show(ax), r, c, figsize=figsize)\ndef show_all(\n    imgs: Collection[Image], r: int = 1, c: Optional[int] = None, figsize=(12, 6)\n):\n    \"Show all `imgs` using `r` rows\"\n    imgs = listify(imgs)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "show_all",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "def show_all(\n    imgs: Collection[Image], r: int = 1, c: Optional[int] = None, figsize=(12, 6)\n):\n    \"Show all `imgs` using `r` rows\"\n    imgs = listify(imgs)\n    if c is None:\n        c = len(imgs) // r\n    for i, ax in plot_flat(r, c, figsize):\n        imgs[i].show(ax)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "__all__ = [\n    \"PIL\",\n    \"Image\",\n    \"ImageBBox\",\n    \"ImageSegment\",\n    \"ImagePoints\",\n    \"FlowField\",\n    \"RandTransform\",\n    \"TfmAffine\",\n    \"TfmCoord\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "ResizeMethod",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "ResizeMethod = IntEnum(\"ResizeMethod\", \"CROP PAD SQUISH NO\")\ndef pil2tensor(image: Union[NPImage, NPArray], dtype: np.dtype) -> TensorImage:\n    \"Convert PIL style `image` array to torch style image tensor.\"\n    a = np.asarray(image)\n    if a.ndim == 2:\n        a = np.expand_dims(a, 2)\n    a = np.transpose(a, (1, 0, 2))\n    a = np.transpose(a, (2, 1, 0))\n    return torch.from_numpy(a.astype(dtype, copy=False))\ndef image2np(image: Tensor) -> np.ndarray:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "CoordFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.image",
        "description": "dashboard.dl_model.deoldify.fastai.vision.image",
        "peekOfCode": "CoordFunc = Callable[[FlowField, ArgStar, KWArgs], LogitTensorImage]\nclass Image(ItemBase):\n    \"Support applying transforms to image data in `px`.\"\n    def __init__(self, px: Tensor):\n        self._px = px\n        self._logit_px = None\n        self._flow = None\n        self._affine_mat = None\n        self.sample_kwargs = {}\n    def set_sample(self, **kwargs) -> \"ImageBase\":",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.image",
        "documentation": {}
    },
    {
        "label": "SegmentationInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "peekOfCode": "class SegmentationInterpretation(Interpretation):\n    \"Interpretation methods for segmenatation models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "ObjectDetectionInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "peekOfCode": "class ObjectDetectionInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "description": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "peekOfCode": "__all__ = [\"SegmentationInterpretation\", \"ObjectDetectionInterpretation\"]\nclass SegmentationInterpretation(Interpretation):\n    \"Interpretation methods for segmenatation models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.interpret",
        "documentation": {}
    },
    {
        "label": "cnn_config",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def cnn_config(arch):\n    \"Get the metadata associated with `arch`.\"\n    # torch.backends.cudnn.benchmark = True\n    return model_meta.get(arch, _default_meta)\ndef has_pool_type(m):\n    if is_pool_type(m):\n        return True\n    for l in m.children():\n        if has_pool_type(l):\n            return True",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "has_pool_type",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def has_pool_type(m):\n    if is_pool_type(m):\n        return True\n    for l in m.children():\n        if has_pool_type(l):\n            return True\n    return False\ndef create_body(\n    arch: Callable, pretrained: bool = True, cut: Optional[Union[int, Callable]] = None\n):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_body",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_body(\n    arch: Callable, pretrained: bool = True, cut: Optional[Union[int, Callable]] = None\n):\n    \"Cut off the body of a typically pretrained `model` at `cut` (int) or cut the model as specified by `cut(model)` (function).\"\n    model = arch(pretrained=pretrained)\n    cut = ifnone(cut, cnn_config(arch)[\"cut\"])\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_head",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_head(\n    nf: int,\n    nc: int,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    concat_pool: bool = True,\n    bn_final: bool = False,\n):\n    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_cnn_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_cnn_model(\n    base_arch: Callable,\n    nc: int,\n    cut: Union[int, Callable] = None,\n    pretrained: bool = True,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    custom_head: Optional[nn.Module] = None,\n    bn_final: bool = False,\n    concat_pool: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "cnn_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def cnn_learner(\n    data: DataBunch,\n    base_arch: Callable,\n    cut: Union[int, Callable] = None,\n    pretrained: bool = True,\n    lin_ftrs: Optional[Collection[int]] = None,\n    ps: Floats = 0.5,\n    custom_head: Optional[nn.Module] = None,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    bn_final: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "create_cnn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def create_cnn(data, base_arch, **kwargs):\n    warn(\"`create_cnn` is deprecated and is now named `cnn_learner`.\")\n    return cnn_learner(data, base_arch, **kwargs)\ndef unet_learner(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "unet_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "def unet_learner(\n    data: DataBunch,\n    arch: Callable,\n    pretrained: bool = True,\n    blur_final: bool = True,\n    norm_type: Optional[NormType] = NormType,\n    split_on: Optional[SplitFuncOrIdxList] = None,\n    blur: bool = False,\n    self_attention: bool = False,\n    y_range: Optional[Tuple[float, float]] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "__all__ = [\n    \"cnn_learner\",\n    \"create_cnn\",\n    \"create_cnn_model\",\n    \"create_body\",\n    \"create_head\",\n    \"unet_learner\",\n]\n# By default split models between first and second layer\ndef _default_split(m: nn.Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_default_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_default_meta = {\"cut\": None, \"split\": _default_split}\n_resnet_meta = {\"cut\": -2, \"split\": _resnet_split}\n_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_resnet_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_resnet_meta = {\"cut\": -2, \"split\": _resnet_split}\n_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_squeezenet_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_squeezenet_meta = {\"cut\": -1, \"split\": _squeezenet_split}\n_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_densenet_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_densenet_meta = {\"cut\": -1, \"split\": _densenet_split}\n_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_vgg_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_vgg_meta = {\"cut\": -1, \"split\": _vgg_split}\n_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "_alexnet_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "_alexnet_meta = {\"cut\": -1, \"split\": _alexnet_split}\nmodel_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},\n    models.densenet121: {**_densenet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "model_meta",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "model_meta = {\n    models.resnet18: {**_resnet_meta},\n    models.resnet34: {**_resnet_meta},\n    models.resnet50: {**_resnet_meta},\n    models.resnet101: {**_resnet_meta},\n    models.resnet152: {**_resnet_meta},\n    models.squeezenet1_0: {**_squeezenet_meta},\n    models.squeezenet1_1: {**_squeezenet_meta},\n    models.densenet121: {**_densenet_meta},\n    models.densenet169: {**_densenet_meta},",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.GradCAM",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.GradCAM = _cl_int_gradcam\ndef _cl_int_plot_top_losses(\n    self,\n    k,\n    largest=True,\n    figsize=(12, 12),\n    heatmap: bool = False,\n    heatmap_thresh: int = 16,\n    return_fig: bool = None,\n) -> Optional[plt.Figure]:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.from_learner",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.from_learner = _cl_int_from_learner\nClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\nClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_top_losses",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.plot_top_losses = _cl_int_plot_top_losses\nClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation.plot_multi_top_losses",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "ClassificationInterpretation.plot_multi_top_losses = _cl_int_plot_multi_top_losses\ndef _learner_interpret(\n    learn: Learner, ds_type: DatasetType = DatasetType.Valid, tta=False\n):\n    \"Create a `ClassificationInterpretation` object from `learner` on `ds_type` with `tta`.\"\n    return ClassificationInterpretation.from_learner(learn, ds_type=ds_type, tta=tta)\nLearner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "description": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "peekOfCode": "Learner.interpret = _learner_interpret",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.learner",
        "documentation": {}
    },
    {
        "label": "rand_pad",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_zoom",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_crop",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)\ndef zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad\n    return [zoom_fn(scale=scale, p=p), crop_fn()]\ndef _find_coeffs(orig_pts: Points, targ_pts: Points) -> Tensor:\n    \"Find 8 coeff mentioned [here](https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/).\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom_crop",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def zoom_crop(scale: float, do_rand: bool = False, p: float = 1.0):\n    \"Randomly zoom and/or crop.\"\n    zoom_fn = rand_zoom if do_rand else zoom\n    crop_fn = rand_crop if do_rand else crop_pad\n    return [zoom_fn(scale=scale, p=p), crop_fn()]\ndef _find_coeffs(orig_pts: Points, targ_pts: Points) -> Tensor:\n    \"Find 8 coeff mentioned [here](https://web.archive.org/web/20150222120106/xenia.media.mit.edu/~cwren/interpolator/).\"\n    matrix = []\n    # The equations we'll need to solve.\n    for p1, p2 in zip(targ_pts, orig_pts):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "get_transforms",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def get_transforms(\n    do_flip: bool = True,\n    flip_vert: bool = False,\n    max_rotate: float = 10.0,\n    max_zoom: float = 1.1,\n    max_lighting: float = 0.2,\n    max_warp: float = 0.2,\n    p_affine: float = 0.75,\n    p_lighting: float = 0.75,\n    xtra_tfms: Optional[Collection[Transform]] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_resize_crop",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "def rand_resize_crop(\n    size: int, max_scale: float = 2.0, ratios: Tuple[float, float] = (0.75, 1.33)\n):\n    \"Randomly resize and crop the image to a ratio in `ratios` after a zoom of `max_scale`.\"\n    return [\n        zoom_squish(\n            scale=(1.0, max_scale, 8),\n            squish=(*ratios, 8),\n            invert=(0.5, 8),\n            row_pct=(0.0, 1.0),",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "__all__ = [\n    \"brightness\",\n    \"contrast\",\n    \"crop\",\n    \"crop_pad\",\n    \"cutout\",\n    \"dihedral\",\n    \"dihedral_affine\",\n    \"flip_affine\",\n    \"flip_lr\",",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "_pad_mode_convert",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "_pad_mode_convert = {\n    \"reflection\": \"reflect\",\n    \"zeros\": \"constant\",\n    \"border\": \"replicate\",\n}\n# NB: Although TfmLighting etc can be used as decorators, that doesn't work in Windows,\n#    so we do it manually for now.\ndef _brightness(x, change: uniform):\n    \"Apply `change` in brightness of image `x`.\"\n    return x.add_(scipy.special.logit(change))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "brightness",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "brightness = TfmLighting(_brightness)\ndef _contrast(x, scale: log_uniform):\n    \"Apply `scale` to contrast of image `x`.\"\n    return x.mul_(scale)\ncontrast = TfmLighting(_contrast)\ndef _rotate(degrees: uniform):\n    \"Rotate image by `degrees`.\"\n    angle = degrees * math.pi / 180\n    return [\n        [float(cos(angle)), float(-sin(angle)), 0.0],",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "contrast",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "contrast = TfmLighting(_contrast)\ndef _rotate(degrees: uniform):\n    \"Rotate image by `degrees`.\"\n    angle = degrees * math.pi / 180\n    return [\n        [float(cos(angle)), float(-sin(angle)), 0.0],\n        [float(sin(angle)), float(cos(angle)), 0.0],\n        [0.0, 0.0, 1.0],\n    ]\nrotate = TfmAffine(_rotate)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rotate",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "rotate = TfmAffine(_rotate)\ndef _get_zoom_mat(sw: float, sh: float, c: float, r: float) -> AffineMatrix:\n    \"`sw`,`sh` scale width,height - `c`,`r` focus col,row.\"\n    return [[sw, 0, c], [0, sh, r], [0, 0, 1.0]]\ndef _zoom(scale: uniform = 1.0, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Zoom image by `scale`. `row_pct`,`col_pct` select focal point of zoom.\"\n    s = 1 - 1 / scale\n    col_c = s * (2 * col_pct - 1)\n    row_c = s * (2 * row_pct - 1)\n    return _get_zoom_mat(1 / scale, 1 / scale, col_c, row_c)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "zoom = TfmAffine(_zoom)\ndef _squish(scale: uniform = 1.0, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Squish image by `scale`. `row_pct`,`col_pct` select focal point of zoom.\"\n    if scale <= 1:\n        col_c = (1 - scale) * (2 * col_pct - 1)\n        return _get_zoom_mat(scale, 1, col_c, 0.0)\n    else:\n        row_c = (1 - 1 / scale) * (2 * row_pct - 1)\n        return _get_zoom_mat(1, 1 / scale, 0.0, row_c)\nsquish = TfmAffine(_squish)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "squish",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "squish = TfmAffine(_squish)\ndef _jitter(c, magnitude: uniform):\n    \"Replace pixels by random neighbors at `magnitude`.\"\n    c.flow.add_((torch.rand_like(c.flow) - 0.5) * magnitude * 2)\n    return c\njitter = TfmCoord(_jitter)\ndef _flip_lr(x):\n    \"Flip `x` horizontally.\"\n    # return x.flip(2)\n    if isinstance(x, ImagePoints):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "jitter",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "jitter = TfmCoord(_jitter)\ndef _flip_lr(x):\n    \"Flip `x` horizontally.\"\n    # return x.flip(2)\n    if isinstance(x, ImagePoints):\n        x.flow.flow[..., 0] *= -1\n        return x\n    return tensor(np.ascontiguousarray(np.array(x)[..., ::-1]))\nflip_lr = TfmPixel(_flip_lr)\ndef _flip_affine() -> TfmAffine:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "flip_lr",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "flip_lr = TfmPixel(_flip_lr)\ndef _flip_affine() -> TfmAffine:\n    \"Flip `x` horizontally.\"\n    return [[-1, 0, 0.0], [0, 1, 0], [0, 0, 1.0]]\nflip_affine = TfmAffine(_flip_affine)\ndef _dihedral(x, k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    flips = []\n    if k & 1:\n        flips.append(1)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "flip_affine",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "flip_affine = TfmAffine(_flip_affine)\ndef _dihedral(x, k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    flips = []\n    if k & 1:\n        flips.append(1)\n    if k & 2:\n        flips.append(2)\n    if flips:\n        x = torch.flip(x, flips)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "dihedral",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "dihedral = TfmPixel(_dihedral)\ndef _dihedral_affine(k: partial(uniform_int, 0, 7)):\n    \"Randomly flip `x` image based on `k`.\"\n    x = -1 if k & 1 else 1\n    y = -1 if k & 2 else 1\n    if k & 4:\n        return [[0, x, 0.0], [y, 0, 0], [0, 0, 1.0]]\n    return [[x, 0, 0.0], [0, y, 0], [0, 0, 1.0]]\ndihedral_affine = TfmAffine(_dihedral_affine)\ndef _pad_coord(x, row_pad: int, col_pad: int, mode=\"zeros\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "dihedral_affine",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "dihedral_affine = TfmAffine(_dihedral_affine)\ndef _pad_coord(x, row_pad: int, col_pad: int, mode=\"zeros\"):\n    # TODO: implement other padding modes than zeros?\n    h, w = x.size\n    pad = torch.Tensor([w / (w + 2 * col_pad), h / (h + 2 * row_pad)])\n    x.flow = FlowField((h + 2 * row_pad, w + 2 * col_pad), x.flow.flow * pad[None])\n    return x\ndef _pad_default(x, padding: int, mode=\"reflection\"):\n    \"Pad `x` with `padding` pixels. `mode` fills in space ('zeros','reflection','border').\"\n    mode = _pad_mode_convert[mode]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "pad",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "pad = TfmPixel(_pad, order=-10)\ndef _cutout(x, n_holes: uniform_int = 1, length: uniform_int = 40):\n    \"Cut out `n_holes` number of square holes of size `length` in image at random locations.\"\n    h, w = x.shape[1:]\n    for n in range(n_holes):\n        h_y = np.random.randint(0, h)\n        h_x = np.random.randint(0, w)\n        y1 = int(np.clip(h_y - length / 2, 0, h))\n        y2 = int(np.clip(h_y + length / 2, 0, h))\n        x1 = int(np.clip(h_x - length / 2, 0, w))",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "cutout",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "cutout = TfmPixel(_cutout, order=20)\ndef _rgb_randomize(x, channel: int = None, thresh: float = 0.3):\n    \"Randomize one of the channels of the input image\"\n    if channel is None:\n        channel = np.random.randint(0, x.shape[0] - 1)\n    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n    return x\nrgb_randomize = TfmPixel(_rgb_randomize)\ndef _minus_epsilon(row_pct: float, col_pct: float, eps: float = 1e-7):\n    if row_pct == 1.0:",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rgb_randomize",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "rgb_randomize = TfmPixel(_rgb_randomize)\ndef _minus_epsilon(row_pct: float, col_pct: float, eps: float = 1e-7):\n    if row_pct == 1.0:\n        row_pct -= 1e-7\n    if col_pct == 1.0:\n        col_pct -= 1e-7\n    return row_pct, col_pct\ndef _crop_default(x, size, row_pct: uniform = 0.5, col_pct: uniform = 0.5):\n    \"Crop `x` to `size` pixels. `row_pct`,`col_pct` select focal point of crop.\"\n    rows, cols = tis2hw(size)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "crop",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "crop = TfmPixel(_crop)\ndef _crop_pad_default(\n    x, size, padding_mode=\"reflection\", row_pct: uniform = 0.5, col_pct: uniform = 0.5\n):\n    \"Crop and pad tfm - `row_pct`,`col_pct` sets focal point.\"\n    padding_mode = _pad_mode_convert[padding_mode]\n    size = tis2hw(size)\n    if x.shape[1:] == torch.Size(size):\n        return x\n    rows, cols = size",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "crop_pad",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "crop_pad = TfmCrop(_crop_pad)\ndef _image_maybe_add_crop_pad(img, tfms):\n    tfm_names = [tfm.__name__ for tfm in tfms]\n    return [crop_pad()] + tfms if \"crop_pad\" not in tfm_names else tfms\nImage._maybe_add_crop_pad = _image_maybe_add_crop_pad\nrand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "Image._maybe_add_crop_pad",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "Image._maybe_add_crop_pad = _image_maybe_add_crop_pad\nrand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "rand_pos",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "rand_pos = {\"row_pct\": (0, 1), \"col_pct\": (0, 1)}\ndef rand_pad(padding: int, size: int, mode: str = \"reflection\"):\n    \"Fixed `mode` `padding` and random crop of `size`\"\n    return [pad(padding=padding, mode=mode), crop(size=size, **rand_pos)]\ndef rand_zoom(scale: uniform = 1.0, p: float = 1.0):\n    \"Randomized version of `zoom`.\"\n    return zoom(scale=scale, **rand_pos, p=p)\ndef rand_crop(*args, padding_mode=\"reflection\", p: float = 1.0):\n    \"Randomized version of `crop_pad`.\"\n    return crop_pad(*args, **rand_pos, padding_mode=padding_mode, p=p)",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "_orig_pts",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "_orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\ndef _do_perspective_warp(c: FlowField, targ_pts: Points, invert=False):\n    \"Apply warp to `targ_pts` from `_orig_pts` to `c` `FlowField`.\"\n    if invert:\n        return _apply_perspective(c, _find_coeffs(targ_pts, _orig_pts))\n    return _apply_perspective(c, _find_coeffs(_orig_pts, targ_pts))\ndef _perspective_warp(c, magnitude: partial(uniform, size=8) = 0, invert=False):\n    \"Apply warp of `magnitude` to `c`.\"\n    magnitude = magnitude.view(4, 2)\n    targ_pts = [[x + m for x, m in zip(xs, ms)] for xs, ms in zip(_orig_pts, magnitude)]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "perspective_warp",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "perspective_warp = TfmCoord(_perspective_warp)\ndef _symmetric_warp(c, magnitude: partial(uniform, size=4) = 0, invert=False):\n    \"Apply symmetric warp of `magnitude` to `c`.\"\n    m = listify(magnitude, 4)\n    targ_pts = [\n        [-1 - m[3], -1 - m[1]],\n        [-1 - m[2], 1 + m[1]],\n        [1 + m[3], -1 - m[0]],\n        [1 + m[2], 1 + m[0]],\n    ]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "symmetric_warp",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "symmetric_warp = TfmCoord(_symmetric_warp)\ndef _tilt(c, direction: uniform_int, magnitude: uniform = 0, invert=False):\n    \"Tilt `c` field with random `direction` and `magnitude`.\"\n    orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n    if direction == 0:\n        targ_pts = [[-1, -1], [-1, 1], [1, -1 - magnitude], [1, 1 + magnitude]]\n    elif direction == 1:\n        targ_pts = [[-1, -1 - magnitude], [-1, 1 + magnitude], [1, -1], [1, 1]]\n    elif direction == 2:\n        targ_pts = [[-1, -1], [-1 - magnitude, 1], [1, -1], [1 + magnitude, 1]]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "tilt",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "tilt = TfmCoord(_tilt)\ndef _skew(c, direction: uniform_int, magnitude: uniform = 0, invert=False):\n    \"Skew `c` field with random `direction` and `magnitude`.\"\n    orig_pts = [[-1, -1], [-1, 1], [1, -1], [1, 1]]\n    if direction == 0:\n        targ_pts = [[-1 - magnitude, -1], [-1, 1], [1, -1], [1, 1]]\n    elif direction == 1:\n        targ_pts = [[-1, -1 - magnitude], [-1, 1], [1, -1], [1, 1]]\n    elif direction == 2:\n        targ_pts = [[-1, -1], [-1 - magnitude, 1], [1, -1], [1, 1]]",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "skew",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "skew = TfmCoord(_skew)\ndef get_transforms(\n    do_flip: bool = True,\n    flip_vert: bool = False,\n    max_rotate: float = 10.0,\n    max_zoom: float = 1.1,\n    max_lighting: float = 0.2,\n    max_warp: float = 0.2,\n    p_affine: float = 0.75,\n    p_lighting: float = 0.75,",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "zoom_squish",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "description": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "peekOfCode": "zoom_squish = TfmCoord(_zoom_squish)\ndef rand_resize_crop(\n    size: int, max_scale: float = 2.0, ratios: Tuple[float, float] = (0.75, 1.33)\n):\n    \"Randomly resize and crop the image to a ratio in `ratios` after a zoom of `max_scale`.\"\n    return [\n        zoom_squish(\n            scale=(1.0, max_scale, 8),\n            squish=(*ratios, 8),\n            invert=(0.5, 8),",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.transform",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "description": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "peekOfCode": "__all__ = []\ndef _tta_only(\n    learn: Learner,\n    ds_type: DatasetType = DatasetType.Valid,\n    activ: nn.Module = None,\n    scale: float = 1.35,\n) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "Learner.tta_only",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "description": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "peekOfCode": "Learner.tta_only = _tta_only\ndef _TTA(\n    learn: Learner,\n    beta: float = 0.4,\n    scale: float = 1.35,\n    ds_type: DatasetType = DatasetType.Valid,\n    activ: nn.Module = None,\n    with_loss: bool = False,\n) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "Learner.TTA",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "description": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "peekOfCode": "Learner.TTA = _TTA",
        "detail": "dashboard.dl_model.deoldify.fastai.vision.tta",
        "documentation": {}
    },
    {
        "label": "ClassConfusion",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.class_confusion",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.class_confusion",
        "peekOfCode": "class ClassConfusion:\n    \"Plot the most confused datapoints and statistics for the models misses.\"\n    def __init__(\n        self,\n        interp: ClassificationInterpretation,\n        classlist: list,\n        is_ordered: bool = False,\n        cut_off: int = 100,\n        varlist: list = None,\n        figsize: tuple = (8, 8),",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.class_confusion",
        "documentation": {}
    },
    {
        "label": "DatasetFormatter",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "class DatasetFormatter:\n    \"Returns a dataset with the appropriate format and file indices to be displayed.\"\n    @classmethod\n    def from_toplosses(cls, learn, n_imgs=None, **kwargs):\n        \"Gets indices with top losses.\"\n        train_ds, train_idxs = cls.get_toplosses_idxs(learn, n_imgs, **kwargs)\n        return train_ds, train_idxs\n    @classmethod\n    def get_toplosses_idxs(cls, learn, n_imgs, **kwargs):\n        \"Sorts `ds_type` dataset by top losses and returns dataset and sorted indices.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "ImageCleaner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "class ImageCleaner:\n    \"Displays images for relabeling or deletion and saves changes in `path` as 'cleaned.csv'.\"\n    def __init__(self, dataset, fns_idxs, path, batch_size: int = 5, duplicates=False):\n        self._all_images, self._batch = [], []\n        self._path = Path(path)\n        self._batch_size = batch_size\n        if duplicates:\n            self._batch_size = 2\n        self._duplicates = duplicates\n        self._labels = dataset.classes",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "peekOfCode": "__all__ = [\"DatasetFormatter\", \"ImageCleaner\"]\nclass DatasetFormatter:\n    \"Returns a dataset with the appropriate format and file indices to be displayed.\"\n    @classmethod\n    def from_toplosses(cls, learn, n_imgs=None, **kwargs):\n        \"Gets indices with top losses.\"\n        train_ds, train_idxs = cls.get_toplosses_idxs(learn, n_imgs, **kwargs)\n        return train_ds, train_idxs\n    @classmethod\n    def get_toplosses_idxs(cls, learn, n_imgs, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_cleaner",
        "documentation": {}
    },
    {
        "label": "ImageDownloader",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "class ImageDownloader:\n    \"\"\"\n    Displays a widget that allows searching and downloading images from google images search\n    in a Jupyter Notebook or Lab.\n    \"\"\"\n    def __init__(self, path: Union[Path, str] = \"data\"):\n        \"Setup path to save images to, init the UI, and render the widgets.\"\n        self._path = Path(path)\n        self._ui = self._init_ui()\n        self.render()",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "download_google_images",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "def download_google_images(\n    path: PathOrStr,\n    search_term: str,\n    size: str = \">400*300\",\n    n_images: int = 10,\n    format: str = \"jpg\",\n    max_workers: int = defaults.cpus,\n    timeout: int = 4,\n) -> FilePathList:\n    \"\"\"",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "__all__ = [\"ImageDownloader\", \"download_google_images\"]\n_img_sizes = {\n    \">400*300\": \"isz:lt,islt:qsvga\",\n    \">640*480\": \"isz:lt,islt:vga\",\n    \">800*600\": \"isz:lt,islt:svga\",\n    \">1024*768\": \"visz:lt,islt:xga\",\n    \">2MP\": \"isz:lt,islt:2mp\",\n    \">4MP\": \"isz:lt,islt:4mp\",\n    \">6MP\": \"isz:lt,islt:6mp\",\n    \">8MP\": \"isz:lt,islt:8mp\",",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "_img_sizes",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "description": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "peekOfCode": "_img_sizes = {\n    \">400*300\": \"isz:lt,islt:qsvga\",\n    \">640*480\": \"isz:lt,islt:vga\",\n    \">800*600\": \"isz:lt,islt:svga\",\n    \">1024*768\": \"visz:lt,islt:xga\",\n    \">2MP\": \"isz:lt,islt:2mp\",\n    \">4MP\": \"isz:lt,islt:4mp\",\n    \">6MP\": \"isz:lt,islt:6mp\",\n    \">8MP\": \"isz:lt,islt:8mp\",\n    \">10MP\": \"isz:lt,islt:10mp\",",
        "detail": "dashboard.dl_model.deoldify.fastai.widgets.image_downloader",
        "documentation": {}
    },
    {
        "label": "DeviceDataLoader",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "class DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate\n    def __post_init__(self):\n        self.dl.collate_fn = self.collate_fn\n        self.tfms = listify(self.tfms)\n    def __len__(self) -> int:",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "class DataBunch:\n    \"Bind `train_dl`,`valid_dl` and `test_dl` in a data object.\"\n    def __init__(\n        self,\n        train_dl: DataLoader,\n        valid_dl: DataLoader,\n        fix_dl: DataLoader = None,\n        test_dl: Optional[DataLoader] = None,\n        device: torch.device = None,\n        dl_tfms: Optional[Collection[Callable]] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "intercept_args",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "def intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,\n    collate_fn=default_collate,\n    pin_memory=True,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader___getattr__",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "def DataLoader___getattr__(dl, k: str) -> Any:\n    return getattr(dl.dataset, k)\nDataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader___setstate__",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "def DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "def load_data(\n    path: PathOrStr,\n    file: PathLikeOrBinaryStream = \"data_save.pkl\",\n    bs: int = 64,\n    val_bs: int = None,\n    num_workers: int = defaults.cpus,\n    dl_tfms: Optional[Collection[Callable]] = None,\n    device: torch.device = None,\n    collate_fn: Callable = data_collate,\n    no_check: bool = False,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DatasetType",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "DatasetType = Enum(\"DatasetType\", \"Train Valid Test Single Fix\")\n__all__ = [\"DataBunch\", \"DeviceDataLoader\", \"DatasetType\", \"load_data\"]\nold_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "__all__ = [\"DataBunch\", \"DeviceDataLoader\", \"DatasetType\", \"load_data\"]\nold_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "old_dl_init",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "old_dl_init = torch.utils.data.DataLoader.__init__\ndef intercept_args(\n    self,\n    dataset,\n    batch_size=1,\n    shuffle=False,\n    sampler=None,\n    batch_sampler=None,\n    num_workers=0,\n    collate_fn=default_collate,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "torch.utils.data.DataLoader.__init__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "torch.utils.data.DataLoader.__init__ = intercept_args\ndef DataLoader___getattr__(dl, k: str) -> Any:\n    return getattr(dl.dataset, k)\nDataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader.__getattr__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "DataLoader.__getattr__ = DataLoader___getattr__\ndef DataLoader___setstate__(dl, data: Any):\n    dl.__dict__.update(data)\nDataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "DataLoader.__setstate__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_data",
        "description": "dashboard.dl_model.deoldify.fastai.basic_data",
        "peekOfCode": "DataLoader.__setstate__ = DataLoader___setstate__\n@dataclass\nclass DeviceDataLoader:\n    \"Bind a `DataLoader` to a `torch.device`.\"\n    dl: DataLoader\n    device: torch.device\n    tfms: List[Callable] = None\n    collate_fn: Callable = data_collate\n    def __post_init__(self):\n        self.dl.collate_fn = self.collate_fn",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_data",
        "documentation": {}
    },
    {
        "label": "BasicLearner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class BasicLearner:\n    model: nn.Module\n    loss_func: LossFunction\n    opt: optim.Optimizer\n    data: DataBunch\ndef fit(\n    epochs: int,\n    learn: BasicLearner,\n    callbacks: Optional[CallbackList] = None,\n    metrics: OptMetrics = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Learner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class Learner:\n    \"Trainer for `model` using `data` to minimize `loss_func` with optimizer `opt_func`.\"\n    data: DataBunch\n    model: nn.Module\n    opt_func: Callable = AdamW\n    loss_func: Callable = None\n    metrics: Collection[Callable] = None\n    true_wd: bool = True\n    bn_wd: bool = True\n    wd: Floats = defaults.wd",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "RecordOnCPU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class RecordOnCPU(Callback):\n    \"Store the `input` and `target` going through the model on the CPU.\"\n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        self.input, self.target = to_cpu(last_input), to_cpu(last_target)\nclass LearnerCallback(Callback):\n    \"Base class for creating callbacks for a `Learner`.\"\n    def __init__(self, learn):\n        self._learn = weakref.ref(learn)\n        self.exclude, self.not_min = [\"_learn\"], []\n        setattr(self.learn, self.cb_name, self)",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "LearnerCallback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class LearnerCallback(Callback):\n    \"Base class for creating callbacks for a `Learner`.\"\n    def __init__(self, learn):\n        self._learn = weakref.ref(learn)\n        self.exclude, self.not_min = [\"_learn\"], []\n        setattr(self.learn, self.cb_name, self)\n    def __getattr__(self, k):\n        return getattr(self.learn, k)\n    def __setstate__(self, data: Any):\n        self.__dict__.update(data)",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "Recorder",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class Recorder(LearnerCallback):\n    \"A `LearnerCallback` that records epoch, loss, opt and metric data during training.\"\n    _order = -10\n    def __init__(self, learn: Learner, add_time: bool = True, silent: bool = False):\n        super().__init__(learn)\n        self.opt = self.learn.opt\n        self.train_dl = self.learn.data.train_dl\n        self.no_val, self.silent, self.add_time = False, silent, add_time\n    def on_train_begin(\n        self, pbar: PBar, metrics_names: Collection[str], **kwargs: Any",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "FakeOptimizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "class FakeOptimizer:\n    def step(self):\n        pass\n    def zero_grad(self):\n        pass\ndef load_callback(class_func, state, learn: Learner):\n    init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)\n    res = (\n        class_func(learn, **init_kwargs)\n        if issubclass(class_func, LearnerCallback)",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "loss_batch",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],\n    batch_multiplier: int = 1,\n) -> Tuple[Union[Tensor, int, float, str]]:",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "get_preds",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def get_preds(\n    model: nn.Module,\n    dl: DataLoader,\n    pbar: Optional[PBar] = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    activ: nn.Module = None,\n    loss_func: OptLossFunc = None,\n    n_batch: Optional[int] = None,\n) -> List[Tensor]:\n    \"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def validate(\n    model: nn.Module,\n    dl: DataLoader,\n    loss_func: OptLossFunc = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    pbar: Optional[PBar] = None,\n    average=True,\n    n_batch: Optional[int] = None,\n) -> Iterator[Tuple[Union[Tensor, int], ...]]:\n    \"Calculate `loss_func` of `model` on `dl` in evaluation mode.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "train_epoch",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def train_epoch(\n    model: nn.Module, dl: DataLoader, opt: optim.Optimizer, loss_func: LossFunction\n) -> None:\n    \"Simple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`.\"\n    model.train()\n    for xb, yb in dl:\n        loss = loss_func(model(xb), yb)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "fit",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def fit(\n    epochs: int,\n    learn: BasicLearner,\n    callbacks: Optional[CallbackList] = None,\n    metrics: OptMetrics = None,\n    batch_multiplier: int = 1,\n) -> None:\n    \"Fit the `model` on `data` and learn using `loss_func` and `opt`.\"\n    assert (\n        len(learn.data.train_dl) != 0",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "load_callback",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def load_callback(class_func, state, learn: Learner):\n    init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)\n    res = (\n        class_func(learn, **init_kwargs)\n        if issubclass(class_func, LearnerCallback)\n        else class_func(**init_kwargs)\n    )\n    for k, v in others.items():\n        setattr(res, k, v)\n    return res",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "load_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "def load_learner(\n    path: PathOrStr,\n    file: PathLikeOrBinaryStream = \"export.pkl\",\n    test: ItemList = None,\n    **db_kwargs,\n):\n    \"Load a `Learner` object saved with `export_state` in `path/file` with empty data, optionally add `test` and load on `cpu`. `file` can be file-like (file or buffer)\"\n    source = Path(path) / file if is_pathlike(file) else file\n    state = (\n        torch.load(source, map_location=\"cpu\")",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "__all__ = [\n    \"Learner\",\n    \"LearnerCallback\",\n    \"Recorder\",\n    \"RecordOnCPU\",\n    \"fit\",\n    \"loss_batch\",\n    \"train_epoch\",\n    \"validate\",\n    \"get_preds\",",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.lr",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.lr = slice(3e-3)\ndefaults.wd = 1e-2\ndefaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.wd",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.wd = 1e-2\ndefaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.extra_callbacks",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.extra_callbacks = None\ndefaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "defaults.extra_callback_fns",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "defaults.extra_callback_fns = None\ndef loss_batch(\n    model: nn.Module,\n    xb: Tensor,\n    yb: Tensor,\n    loss_func: OptLossFunc = None,\n    opt: OptOptimizer = None,\n    cb_handler: Optional[CallbackHandler] = None,\n    count: [int] = [1],\n    batch_multiplier: int = 1,",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "loss_func_name2activ",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basic_train",
        "description": "dashboard.dl_model.deoldify.fastai.basic_train",
        "peekOfCode": "loss_func_name2activ = {\n    \"cross_entropy_loss\": F.softmax,\n    \"nll_loss\": torch.exp,\n    \"poisson_nll_loss\": torch.exp,\n    \"kl_div_loss\": torch.exp,\n    \"bce_with_logits_loss\": torch.sigmoid,\n    \"cross_entropy\": F.softmax,\n    \"kl_div\": torch.exp,\n    \"binary_cross_entropy_with_logits\": torch.sigmoid,\n}",
        "detail": "dashboard.dl_model.deoldify.fastai.basic_train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.basics",
        "description": "dashboard.dl_model.deoldify.fastai.basics",
        "peekOfCode": "__all__ = [o for o in dir(sys.modules[__name__]) if not o.startswith(\"_\")] + [\n    \"__version__\"\n]",
        "detail": "dashboard.dl_model.deoldify.fastai.basics",
        "documentation": {}
    },
    {
        "label": "OptimWrapper",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class OptimWrapper:\n    \"Basic wrapper around `opt` to simplify hyper-parameters changes.\"\n    def __init__(\n        self,\n        opt: optim.Optimizer,\n        wd: Floats = 0.0,\n        true_wd: bool = False,\n        bn_wd: bool = True,\n    ):\n        assert not isinstance(opt, OptimWrapper)",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "Callback",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class Callback:\n    \"Base class for callbacks that want to record values, dynamically change learner params, etc.\"\n    _order = 0\n    def on_train_begin(self, **kwargs: Any) -> None:\n        \"To initialize constants in the callback.\"\n        pass\n    def on_epoch_begin(self, **kwargs: Any) -> None:\n        \"At the beginning of each epoch.\"\n        pass\n    def on_batch_begin(self, **kwargs: Any) -> None:",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "SmoothenValue",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class SmoothenValue:\n    \"Create a smooth moving average for a value (loss, etc) using `beta`.\"\n    def __init__(self, beta: float):\n        self.beta, self.n, self.mov_avg = beta, 0, 0\n    def add_value(self, val: float) -> None:\n        \"Add `val` to calculate updated smoothed value.\"\n        self.n += 1\n        self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * val\n        self.smooth = self.mov_avg / (1 - self.beta**self.n)\nCallbackList = Collection[Callback]",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CallbackHandler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class CallbackHandler:\n    \"Manage all of the registered `callbacks` and `metrics`, smoothing loss by momentum `beta`.\"\n    callbacks: CallbackList = None\n    metrics: CallbackList = None\n    beta: float = 0.98\n    def __post_init__(self) -> None:\n        \"Initialize smoother and learning stats.\"\n        self.callbacks = ifnone(self.callbacks, [])\n        self.metrics = ifnone(self.metrics, [])\n        self.metrics = [",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "AverageMetric",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class AverageMetric(Callback):\n    \"Wrap a `func` in a callback for metrics computation.\"\n    def __init__(self, func):\n        # If func has a __name__ use this one else it should be a partial\n        name = func.__name__ if hasattr(func, \"__name__\") else func.func.__name__\n        self.func, self.name = func, name\n        self.world = num_distrib()\n    def on_epoch_begin(self, **kwargs):\n        \"Set the inner value to 0.\"\n        self.val, self.count = 0.0, 0",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "Scheduler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "class Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None\n    ):\n        self.start, self.end = (vals[0], vals[1]) if is_tuple(vals) else (vals, 0)\n        self.n_iter = max(1, n_iter)\n        if func is None:\n            self.func = annealing_linear if is_tuple(vals) else annealing_no\n        else:",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_no",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_no(start: Number, end: Number, pct: float) -> Number:\n    \"No annealing, always return `start`.\"\n    return start\ndef annealing_linear(start: Number, end: Number, pct: float) -> Number:\n    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start + pct * (end - start)\ndef annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_linear",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_linear(start: Number, end: Number, pct: float) -> Number:\n    \"Linearly anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start + pct * (end - start)\ndef annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_exp",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_exp(start: Number, end: Number, pct: float) -> Number:\n    \"Exponentially anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return start * (end / start) ** pct\ndef annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out\ndef do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_cos",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_cos(start: Number, end: Number, pct: float) -> Number:\n    \"Cosine anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    cos_out = np.cos(np.pi * pct) + 1\n    return end + (start - end) / 2 * cos_out\ndef do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree\ndef annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "do_annealing_poly",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def do_annealing_poly(start: Number, end: Number, pct: float, degree: Number) -> Number:\n    \"Helper function for `anneal_poly`.\"\n    return end + (start - end) * (1 - pct) ** degree\ndef annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)\nclass Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "annealing_poly",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "def annealing_poly(degree: Number) -> Number:\n    \"Anneal polynomically from `start` to `end` as pct goes from 0.0 to 1.0.\"\n    return functools.partial(do_annealing_poly, degree=degree)\nclass Scheduler:\n    'Used to \"step\" from start,end (`vals`) over `n_iter` iterations on a schedule defined by `func`'\n    def __init__(\n        self, vals: StartOptEnd, n_iter: int, func: Optional[AnnealFunc] = None\n    ):\n        self.start, self.end = (vals[0], vals[1]) if is_tuple(vals) else (vals, 0)\n        self.n_iter = max(1, n_iter)",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "__all__ = [\n    \"AverageMetric\",\n    \"Callback\",\n    \"CallbackHandler\",\n    \"OptimWrapper\",\n    \"SmoothenValue\",\n    \"Scheduler\",\n    \"annealing_cos\",\n    \"CallbackList\",\n    \"annealing_exp\",",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CallbackList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.callback",
        "description": "dashboard.dl_model.deoldify.fastai.callback",
        "peekOfCode": "CallbackList = Collection[Callback]\ndef _get_init_state():\n    return {\"epoch\": 0, \"iteration\": 0, \"num_batch\": 0, \"skip_validate\": False}\n@dataclass\nclass CallbackHandler:\n    \"Manage all of the registered `callbacks` and `metrics`, smoothing loss by momentum `beta`.\"\n    callbacks: CallbackList = None\n    metrics: CallbackList = None\n    beta: float = 0.98\n    def __post_init__(self) -> None:",
        "detail": "dashboard.dl_model.deoldify.fastai.callback",
        "documentation": {}
    },
    {
        "label": "CollabProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class CollabProcessor(TabularProcessor):\n    \"Subclass `TabularProcessor for `process_one`.\"\n    def process_one(self, item):\n        res = super().process_one(item)\n        return CollabLine(res.cats, res.conts, res.classes, res.names)\nclass CollabLine(TabularLine):\n    \"Base item for collaborative filtering, subclasses `TabularLine`.\"\n    def __init__(self, cats, conts, classes, names):\n        super().__init__(cats, conts, classes, names)\n        self.data = [self.data[0][0], self.data[0][1]]",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabLine",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class CollabLine(TabularLine):\n    \"Base item for collaborative filtering, subclasses `TabularLine`.\"\n    def __init__(self, cats, conts, classes, names):\n        super().__init__(cats, conts, classes, names)\n        self.data = [self.data[0][0], self.data[0][1]]\nclass CollabList(TabularList):\n    \"Base `ItemList` for collaborative filtering, subclasses `TabularList`.\"\n    _item_cls, _label_cls, _processor = CollabLine, FloatList, CollabProcessor\n    def reconstruct(self, t: Tensor):\n        return CollabLine(tensor(t), tensor([]), self.classes, self.col_names)",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class CollabList(TabularList):\n    \"Base `ItemList` for collaborative filtering, subclasses `TabularList`.\"\n    _item_cls, _label_cls, _processor = CollabLine, FloatList, CollabProcessor\n    def reconstruct(self, t: Tensor):\n        return CollabLine(tensor(t), tensor([]), self.classes, self.col_names)\nclass EmbeddingNN(TabularModel):\n    \"Subclass `TabularModel` to create a NN suitable for collaborative filtering.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "EmbeddingNN",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class EmbeddingNN(TabularModel):\n    \"Subclass `TabularModel` to create a NN suitable for collaborative filtering.\"\n    def __init__(\n        self,\n        emb_szs: ListSizes,\n        layers: Collection[int] = None,\n        ps: Collection[float] = None,\n        emb_drop: float = 0.0,\n        y_range: OptRange = None,\n        use_bn: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "EmbeddingDotBias",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class EmbeddingDotBias(Module):\n    \"Base dot model for collaborative filtering.\"\n    def __init__(\n        self,\n        n_factors: int,\n        n_users: int,\n        n_items: int,\n        y_range: Tuple[float, float] = None,\n    ):\n        self.y_range = y_range",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabDataBunch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class CollabDataBunch(DataBunch):\n    \"Base `DataBunch` for collaborative filtering.\"\n    @classmethod\n    def from_df(\n        cls,\n        ratings: DataFrame,\n        valid_pct: float = 0.2,\n        user_name: Optional[str] = None,\n        item_name: Optional[str] = None,\n        rating_name: Optional[str] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "CollabLearner",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "class CollabLearner(Learner):\n    \"`Learner` suitable for collaborative filtering.\"\n    def get_idx(self, arr: Collection, is_item: bool = True):\n        \"Fetch item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)\"\n        m = self.model.eval().cpu()\n        requires_grad(m, False)\n        u_class, i_class = self.data.train_ds.x.classes.values()\n        classes = i_class if is_item else u_class\n        c2i = {v: k for k, v in enumerate(classes)}\n        try:",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "collab_learner",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "def collab_learner(\n    data,\n    n_factors: int = None,\n    use_nn: bool = False,\n    emb_szs: Dict[str, int] = None,\n    layers: Collection[int] = None,\n    ps: Collection[float] = None,\n    emb_drop: float = 0.0,\n    y_range: OptRange = None,\n    use_bn: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.collab",
        "description": "dashboard.dl_model.deoldify.fastai.collab",
        "peekOfCode": "__all__ = [\n    *tabular.__all__,\n    \"EmbeddingDotBias\",\n    \"EmbeddingNN\",\n    \"collab_learner\",\n    \"CollabDataBunch\",\n    \"CollabLine\",\n    \"CollabList\",\n    \"CollabLearner\",\n]",
        "detail": "dashboard.dl_model.deoldify.fastai.collab",
        "documentation": {}
    },
    {
        "label": "PrePostInitMeta",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):\n            pass\n        @functools.wraps(old_init)\n        def _init(self, *args, **kwargs):\n            self.__pre_init__()",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ItemBase",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__} {str(self)}\"\n    def show(self, ax: plt.Axes, **kwargs):\n        \"Subclass this method if you want to customize the way this `ItemBase` is shown on `ax`.\"\n        ax.set_title(str(self))\n    def apply_tfms(self, tfms: Collection, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "EmptyLabel",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class EmptyLabel(ItemBase):\n    \"Should be used for a dummy label.\"\n    def __init__(self):\n        self.obj, self.data = 0, 0\n    def __str__(self):\n        return \"\"\n    def __hash__(self):\n        return hash(str(self))\nclass Category(ItemBase):\n    \"Basic class for single classification labels.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Category",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class Category(ItemBase):\n    \"Basic class for single classification labels.\"\n    def __init__(self, data, obj):\n        self.data, self.obj = data, obj\n    def __int__(self):\n        return int(self.data)\n    def __str__(self):\n        return str(self.obj)\n    def __hash__(self):\n        return hash(str(self))",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "MultiCategory",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class MultiCategory(ItemBase):\n    \"Basic class for multi-classification labels.\"\n    def __init__(self, data, obj, raw):\n        self.data, self.obj, self.raw = data, obj, raw\n    def __str__(self):\n        return \";\".join([str(o) for o in self.obj])\n    def __hash__(self):\n        return hash(str(self))\nclass FloatItem(ItemBase):\n    \"Basic class for float items.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "FloatItem",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class FloatItem(ItemBase):\n    \"Basic class for float items.\"\n    def __init__(self, obj):\n        self.data, self.obj = np.array(obj).astype(np.float32), obj\n    def __str__(self):\n        return str(self.obj)\n    def __hash__(self):\n        return hash(str(self))\ndef _treat_html(o: str) -> str:\n    o = str(o)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PrettyString",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "class PrettyString(str):\n    \"Little hack to get strings to show properly in Jupyter.\"\n    def __repr__(self):\n        return self\ndef float_or_x(x):\n    \"Tries to convert to float, returns x if it can't\"\n    try:\n        return float(x)\n    except:\n        return x",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "num_cpus",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_listy",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_tuple",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_dict",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is_pathlike",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def is_pathlike(x: Any) -> bool:\n    return isinstance(x, (str, Path))\ndef noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "noop",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def noop(x):\n    return x\nclass PrePostInitMeta(type):\n    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n    def __new__(cls, name, bases, dct):\n        x = super().__new__(cls, name, bases, dct)\n        old_init = x.__init__\n        def _pass(self):\n            pass\n        @functools.wraps(old_init)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def chunks(l: Collection, n: int) -> Iterable:\n    \"Yield successive `n`-sized chunks from `l`.\"\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\ndef recurse(func: Callable, x: Any, *args, **kwargs) -> Any:\n    if is_listy(x):\n        return [recurse(func, o, *args, **kwargs) for o in x]\n    if is_dict(x):\n        return {k: recurse(func, v, *args, **kwargs) for k, v in x.items()}\n    return func(x, *args, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "recurse",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def recurse(func: Callable, x: Any, *args, **kwargs) -> Any:\n    if is_listy(x):\n        return [recurse(func, o, *args, **kwargs) for o in x]\n    if is_dict(x):\n        return {k: recurse(func, v, *args, **kwargs) for k, v in x.items()}\n    return func(x, *args, **kwargs)\ndef first_el(x: Any) -> Any:\n    \"Recursively get the first element of `x`.\"\n    if is_listy(x):\n        return first_el(x[0])",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "first_el",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def first_el(x: Any) -> Any:\n    \"Recursively get the first element of `x`.\"\n    if is_listy(x):\n        return first_el(x[0])\n    if is_dict(x):\n        return first_el(x[list(x.keys())[0]])\n    return x\ndef to_int(b: Any) -> Union[int, List[int]]:\n    \"Recursively convert `b` to an int or list/dict of ints; raises exception if not convertible.\"\n    return recurse(lambda x: int(x), b)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "to_int",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def to_int(b: Any) -> Union[int, List[int]]:\n    \"Recursively convert `b` to an int or list/dict of ints; raises exception if not convertible.\"\n    return recurse(lambda x: int(x), b)\ndef ifnone(a: Any, b: Any) -> Any:\n    \"`a` if `a` is not None, otherwise `b`.\"\n    return b if a is None else a\ndef is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ifnone",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def ifnone(a: Any, b: Any) -> Any:\n    \"`a` if `a` is not None, otherwise `b`.\"\n    return b if a is None else a\ndef is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "is1d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def is1d(a: Collection) -> bool:\n    \"Return `True` if `a` is one-dimensional\"\n    return len(a.shape) == 1 if hasattr(a, \"shape\") else len(np.array(a).shape) == 1\ndef uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:\n        res.sort()\n    return res\ndef idx_dict(a):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "uniqueify",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def uniqueify(x: Series, sort: bool = False) -> List:\n    \"Return sorted unique values of `x`.\"\n    res = list(OrderedDict.fromkeys(x).keys())\n    if sort:\n        res.sort()\n    return res\ndef idx_dict(a):\n    \"Create a dictionary value to index from `a`.\"\n    return {v: k for k, v in enumerate(a)}\ndef find_classes(folder: Path) -> FilePathList:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "idx_dict",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def idx_dict(a):\n    \"Create a dictionary value to index from `a`.\"\n    return {v: k for k, v in enumerate(a)}\ndef find_classes(folder: Path) -> FilePathList:\n    \"List of label subdirectories in imagenet-style `folder`.\"\n    classes = [d for d in folder.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n    assert len(classes) > 0\n    return sorted(classes, key=lambda d: d.name)\ndef arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "find_classes",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def find_classes(folder: Path) -> FilePathList:\n    \"List of label subdirectories in imagenet-style `folder`.\"\n    classes = [d for d in folder.iterdir() if d.is_dir() and not d.name.startswith(\".\")]\n    assert len(classes) > 0\n    return sorted(classes, key=lambda d: d.name)\ndef arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"\n    assert all(\n        [len(arr) == len(arrs[0]) for arr in arrs]\n    ), \"All arrays should have same length\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "arrays_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def arrays_split(mask: NPArrayMask, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Given `arrs` is [a,b,...] and `mask`index - return[(a[mask],a[~mask]),(b[mask],b[~mask]),...].\"\n    assert all(\n        [len(arr) == len(arrs[0]) for arr in arrs]\n    ), \"All arrays should have same length\"\n    mask = array(mask)\n    return list(zip(*[(a[mask], a[~mask]) for a in map(np.array, arrs)]))\ndef random_split(valid_pct: float, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Randomly split `arrs` with `valid_pct` ratio. good for creating validation set.\"\n    assert (",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "random_split",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def random_split(valid_pct: float, *arrs: NPArrayableList) -> SplitArrayList:\n    \"Randomly split `arrs` with `valid_pct` ratio. good for creating validation set.\"\n    assert (\n        valid_pct >= 0 and valid_pct <= 1\n    ), \"Validation set percentage should be between 0 and 1\"\n    is_train = np.random.uniform(size=(len(arrs[0]),)) > valid_pct\n    return arrays_split(is_train, *arrs)\ndef listify(p: OptListOrItem = None, q: OptListOrItem = None):\n    \"Make `p` listy and the same length as `q`.\"\n    if p is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "listify",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def listify(p: OptListOrItem = None, q: OptListOrItem = None):\n    \"Make `p` listy and the same length as `q`.\"\n    if p is None:\n        p = []\n    elif isinstance(p, str):\n        p = [p]\n    elif not isinstance(p, Iterable):\n        p = [p]\n    # Rank 0 tensors in PyTorch are Iterable but don't have a length.\n    else:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "camel2snake",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])\ndef extract_kwargs(names: Collection[str], kwargs: KWArgs):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "even_mults",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])\ndef extract_kwargs(names: Collection[str], kwargs: KWArgs):\n    \"Extract the keys in `names` from the `kwargs`.\"\n    new_kwargs = {}\n    for arg_name in names:\n        if arg_name in kwargs:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "extract_kwargs",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def extract_kwargs(names: Collection[str], kwargs: KWArgs):\n    \"Extract the keys in `names` from the `kwargs`.\"\n    new_kwargs = {}\n    for arg_name in names:\n        if arg_name in kwargs:\n            arg_val = kwargs.pop(arg_name)\n            new_kwargs[arg_name] = arg_val\n    return new_kwargs, kwargs\ndef partition(a: Collection, sz: int) -> List[Collection]:\n    \"Split iterables `a` in equal parts of size `sz`\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "partition",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def partition(a: Collection, sz: int) -> List[Collection]:\n    \"Split iterables `a` in equal parts of size `sz`\"\n    return [a[i : i + sz] for i in range(0, len(a), sz)]\ndef partition_by_cores(a: Collection, n_cpus: int) -> List[Collection]:\n    \"Split data in `a` equally among `n_cpus` cores\"\n    return partition(a, len(a) // n_cpus + 1)\ndef series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "partition_by_cores",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def partition_by_cores(a: Collection, n_cpus: int) -> List[Collection]:\n    \"Split data in `a` equally among `n_cpus` cores\"\n    return partition(a, len(a) // n_cpus + 1)\ndef series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()\nTfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "series2cat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def series2cat(df: DataFrame, *col_names):\n    \"Categorifies the columns `col_names` in `df`.\"\n    for c in listify(col_names):\n        df[c] = df[c].astype(\"category\").cat.as_ordered()\nTfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "recurse_eq",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def recurse_eq(arr1, arr2):\n    if is_listy(arr1):\n        return (\n            is_listy(arr2)\n            and len(arr1) == len(arr2)\n            and np.all([recurse_eq(x, y) for x, y in zip(arr1, arr2)])\n        )\n    else:\n        return np.all(np.atleast_1d(arr1 == arr2))\ndef download_url(",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "download_url",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def download_url(\n    url: str,\n    dest: str,\n    overwrite: bool = False,\n    pbar: ProgressBar = None,\n    show_progress=True,\n    chunk_size=1024 * 1024,\n    timeout=4,\n    retries=5,\n) -> None:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "range_of",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def range_of(x):\n    \"Create a range from 0 to `len(x)`.\"\n    return list(range(len(x)))\ndef arange_of(x):\n    \"Same as `range_of` but returns an array.\"\n    return np.arange(len(x))\nPath.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "arange_of",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def arange_of(x):\n    \"Same as `range_of` but returns an array.\"\n    return np.arange(len(x))\nPath.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "join_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "join_paths",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:\n        lines = f.readlines()\n    return np.array([l.strip() for l in lines])\ndef save_texts(fname: PathOrStr, texts: Collection[str]):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "loadtxt_str",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"\n    with open(path, \"r\") as f:\n        lines = f.readlines()\n    return np.array([l.strip() for l in lines])\ndef save_texts(fname: PathOrStr, texts: Collection[str]):\n    \"Save in `fname` the content of `texts`.\"\n    with open(fname, \"w\") as f:\n        for t in texts:\n            f.write(f\"{t}\\n\")",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "save_texts",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def save_texts(fname: PathOrStr, texts: Collection[str]):\n    \"Save in `fname` the content of `texts`.\"\n    with open(fname, \"w\") as f:\n        for t in texts:\n            f.write(f\"{t}\\n\")\ndef df_names_to_idx(names: IntsOrStrs, df: DataFrame):\n    \"Return the column indexes of `names` in `df`.\"\n    if not is_listy(names):\n        names = [names]\n    if isinstance(names[0], int):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "df_names_to_idx",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def df_names_to_idx(names: IntsOrStrs, df: DataFrame):\n    \"Return the column indexes of `names` in `df`.\"\n    if not is_listy(names):\n        names = [names]\n    if isinstance(names[0], int):\n        return names\n    return [df.columns.get_loc(c) for c in names]\ndef one_hot(x: Collection[int], c: int):\n    \"One-hot encode `x` with `c` classes.\"\n    res = np.zeros((c,), np.float32)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "one_hot",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def one_hot(x: Collection[int], c: int):\n    \"One-hot encode `x` with `c` classes.\"\n    res = np.zeros((c,), np.float32)\n    res[listify(x)] = 1.0\n    return res\ndef index_row(\n    a: Union[Collection, pd.DataFrame, pd.Series], idxs: Collection[int]\n) -> Any:\n    \"Return the slice of `a` corresponding to `idxs`.\"\n    if a is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "index_row",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def index_row(\n    a: Union[Collection, pd.DataFrame, pd.Series], idxs: Collection[int]\n) -> Any:\n    \"Return the slice of `a` corresponding to `idxs`.\"\n    if a is None:\n        return a\n    if isinstance(a, (pd.DataFrame, pd.Series)):\n        res = a.iloc[idxs]\n        if isinstance(res, (pd.DataFrame, pd.Series)):\n            return res.copy()",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "func_args",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def func_args(func) -> bool:\n    \"Return the arguments of `func`.\"\n    code = func.__code__\n    return code.co_varnames[: code.co_argcount]\ndef has_arg(func, arg) -> bool:\n    \"Check if `func` accepts `arg`.\"\n    return arg in func_args(func)\ndef split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "has_arg",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def has_arg(func, arg) -> bool:\n    \"Check if `func` accepts `arg`.\"\n    return arg in func_args(func)\ndef split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)\n    func_kwargs = {a: kwargs.pop(a) for a in args if a in kwargs}\n    return func_kwargs, kwargs\ndef array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "split_kwargs_by_func",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def split_kwargs_by_func(kwargs, func):\n    \"Split `kwargs` between those expected by `func` and the others.\"\n    args = func_args(func)\n    func_kwargs = {a: kwargs.pop(a) for a in args if a in kwargs}\n    return func_kwargs, kwargs\ndef array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"\n    if not isinstance(a, collections.abc.Sized) and not getattr(\n        a, \"__array_interface__\", False\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "array",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def array(a, dtype: type = None, **kwargs) -> np.ndarray:\n    \"Same as `np.array` but also handles generators. `kwargs` are passed to `np.array` with `dtype`.\"\n    if not isinstance(a, collections.abc.Sized) and not getattr(\n        a, \"__array_interface__\", False\n    ):\n        a = list(a)\n    if (\n        np.int_ == np.int32\n        and dtype is None\n        and is_listy(a)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "text2html_table",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def text2html_table(items: Collection[Collection[str]]) -> str:\n    \"Put the texts in `items` in an HTML table, `widths` are the widths of the columns in %.\"\n    html_code = f\"\"\"<table border=\"1\" class=\"dataframe\">\"\"\"\n    html_code += f\"\"\"  <thead>\\n    <tr style=\"text-align: right;\">\\n\"\"\"\n    for i in items[0]:\n        html_code += f\"      <th>{_treat_html(i)}</th>\"\n    html_code += f\"    </tr>\\n  </thead>\\n  <tbody>\"\n    html_code += \"  <tbody>\"\n    for line in items[1:]:\n        html_code += \"    <tr>\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "parallel",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def parallel(func, arr: Collection, max_workers: int = None, leave=False):\n    \"Call `func` on every element of `arr` in parallel using `max_workers`.\"\n    max_workers = ifnone(max_workers, defaults.cpus)\n    if max_workers < 2:\n        results = [\n            func(o, i)\n            for i, o in progress_bar(enumerate(arr), total=len(arr), leave=leave)\n        ]\n    else:\n        with ProcessPoolExecutor(max_workers=max_workers) as ex:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "subplots",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def subplots(\n    rows: int,\n    cols: int,\n    imgsize: int = 4,\n    figsize: Optional[Tuple[int, int]] = None,\n    title=None,\n    **kwargs,\n):\n    \"Like `plt.subplots` but with consistent axs shape, `kwargs` passed to `fig.suptitle` with `title`\"\n    figsize = ifnone(figsize, (imgsize * cols, imgsize * rows))",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "show_some",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def show_some(items: Collection, n_max: int = 5, sep: str = \",\"):\n    \"Return the representation of the first  `n_max` elements in `items`.\"\n    if items is None or len(items) == 0:\n        return \"\"\n    res = sep.join([f\"{o}\" for o in items[:n_max]])\n    if len(items) > n_max:\n        res += \"...\"\n    return res\ndef get_tmp_file(dir=None):\n    \"Create and return a tmp filename, optionally at a specific path. `os.remove` when done with it.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "get_tmp_file",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def get_tmp_file(dir=None):\n    \"Create and return a tmp filename, optionally at a specific path. `os.remove` when done with it.\"\n    with tempfile.NamedTemporaryFile(delete=False, dir=dir) as f:\n        return f.name\ndef compose(funcs: List[Callable]) -> Callable:\n    \"Compose `funcs`\"\n    def compose_(funcs, x, *args, **kwargs):\n        for f in listify(funcs):\n            x = f(x, *args, **kwargs)\n        return x",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "compose",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def compose(funcs: List[Callable]) -> Callable:\n    \"Compose `funcs`\"\n    def compose_(funcs, x, *args, **kwargs):\n        for f in listify(funcs):\n            x = f(x, *args, **kwargs)\n        return x\n    return partial(compose_, funcs)\nclass PrettyString(str):\n    \"Little hack to get strings to show properly in Jupyter.\"\n    def __repr__(self):",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "float_or_x",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def float_or_x(x):\n    \"Tries to convert to float, returns x if it can't\"\n    try:\n        return float(x)\n    except:\n        return x\ndef bunzip(fn: PathOrStr):\n    \"bunzip `fn`, raising exception if output already exists\"\n    fn = Path(fn)\n    assert fn.exists(), f\"{fn} doesn't exist\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "bunzip",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def bunzip(fn: PathOrStr):\n    \"bunzip `fn`, raising exception if output already exists\"\n    fn = Path(fn)\n    assert fn.exists(), f\"{fn} doesn't exist\"\n    out_fn = fn.with_suffix(\"\")\n    assert not out_fn.exists(), f\"{out_fn} already exists\"\n    with bz2.BZ2File(fn, \"rb\") as src, out_fn.open(\"wb\") as dst:\n        for d in iter(lambda: src.read(1024 * 1024), b\"\"):\n            dst.write(d)\n@contextmanager",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "working_directory",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "def working_directory(path: PathOrStr):\n    \"Change working directory to `path` and return to previous on exit.\"\n    prev_cwd = Path.cwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(prev_cwd)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "AnnealFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "AnnealFunc = Callable[[Number, Number, float], Number]\nArgStar = Collection[Any]\nBatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ArgStar",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ArgStar = Collection[Any]\nBatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "BatchSamples",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "BatchSamples = Collection[Tuple[Collection[int], int]]\nDataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "DataFrameOrChunks",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "DataFrameOrChunks = Union[DataFrame, pd.io.parsers.TextFileReader]\nFilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "FilePathList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "FilePathList = Collection[Path]\nFloats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Floats",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Floats = Union[float, Collection[float]]\nImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ImgLabel",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ImgLabel = str\nImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ImgLabels",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ImgLabels = Collection[ImgLabel]\nIntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "IntsOrStrs",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "IntsOrStrs = Union[int, Collection[int], str, Collection[str]]\nKeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "KeyFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "KeyFunc = Callable[[int], int]\nKWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "KWArgs",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "KWArgs = Dict[str, Any]\nListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListOrItem",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ListOrItem = Union[Collection[Any], int, float, str]\nListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListRules",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ListRules = Collection[Callable[[str], str]]\nListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "ListSizes",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "ListSizes = Collection[Tuple[int, int]]\nNPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayableList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "NPArrayableList = Collection[Union[np.ndarray, list]]\nNPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "NPArrayList = Collection[np.ndarray]\nNPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPArrayMask",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "NPArrayMask = np.ndarray\nNPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "NPImage",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "NPImage = np.ndarray\nOptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptDataFrame",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptDataFrame = Optional[DataFrame]\nOptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptListOrItem",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptListOrItem = Optional[ListOrItem]\nOptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptRange",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptRange = Optional[Tuple[float, float]]\nOptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStrTuple",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptStrTuple = Optional[Tuple[str, str]]\nOptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStats",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptStats = Optional[Tuple[np.ndarray, np.ndarray]]\nPathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PathOrStr",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "PathOrStr = Union[Path, str]\nPathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PathLikeOrBinaryStream",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "PathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]\nPBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PBar",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "PBar = Union[MasterBar, ProgressBar]\nPoint = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Point",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Point = Tuple[float, float]\nPoints = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Points",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Points = Collection[Point]\nSizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Sizes",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Sizes = List[List[int]]\nSplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "SplitArrayList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "SplitArrayList = List[Tuple[np.ndarray, np.ndarray]]\nStartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "StartOptEnd",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "StartOptEnd = Union[float, Tuple[float, float]]\nStrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "StrList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "StrList = Collection[str]\nTokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Tokens",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Tokens = Collection[Collection[str]]\nOptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "OptStrList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "OptStrList = Optional[StrList]\nnp.set_printoptions(precision=6, threshold=50, edgeitems=4, linewidth=120)\ndef num_cpus() -> int:\n    \"Get number of cpus\"\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_default_cpus",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)\ndef is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "defaults",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "defaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=\"viridis\", return_fig=False, silent=False\n)\ndef is_listy(x: Any) -> bool:\n    return isinstance(x, (tuple, list))\ndef is_tuple(x: Any) -> bool:\n    return isinstance(x, tuple)\ndef is_dict(x: Any) -> bool:\n    return isinstance(x, dict)\ndef is_pathlike(x: Any) -> bool:",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_camel_re1",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "_camel_re1 = re.compile(\"(.)([A-Z][a-z]+)\")\n_camel_re2 = re.compile(\"([a-z0-9])([A-Z])\")\ndef camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "_camel_re2",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "_camel_re2 = re.compile(\"([a-z0-9])([A-Z])\")\ndef camel2snake(name: str) -> str:\n    \"Change `name` from camel to snake style.\"\n    s1 = re.sub(_camel_re1, r\"\\1_\\2\", name)\n    return re.sub(_camel_re2, r\"\\1_\\2\", s1).lower()\ndef even_mults(start: float, stop: float, n: int) -> np.ndarray:\n    \"Build log-stepped array from `start` to `stop` in `n` steps.\"\n    mult = stop / start\n    step = mult ** (1 / (n - 1))\n    return np.array([start * (step**i) for i in range(n)])",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "TfmList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "TfmList = Union[Callable, Collection[Callable]]\nclass ItemBase:\n    \"Base item type in the fastai library.\"\n    def __init__(self, data: Any):\n        self.data = self.obj = data\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__} {str(self)}\"\n    def show(self, ax: plt.Axes, **kwargs):\n        \"Subclass this method if you want to customize the way this `ItemBase` is shown on `ax`.\"\n        ax.set_title(str(self))",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "Path.ls",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.core",
        "description": "dashboard.dl_model.deoldify.fastai.core",
        "peekOfCode": "Path.ls = lambda x: list(x.iterdir())\ndef join_path(fname: PathOrStr, path: PathOrStr = \".\") -> Path:\n    \"Return `Path(path)/Path(fname)`, `path` defaults to current dir.\"\n    return Path(path) / Path(fname)\ndef join_paths(fnames: FilePathList, path: PathOrStr = \".\") -> Collection[Path]:\n    \"Join `path` to every file name in `fnames`.\"\n    path = Path(path)\n    return [join_path(o, path) for o in fnames]\ndef loadtxt_str(path: PathOrStr) -> np.ndarray:\n    \"Return `ndarray` of `str` of lines of text from `path`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.core",
        "documentation": {}
    },
    {
        "label": "PreProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class PreProcessor:\n    \"Basic class for a processor that will be applied to items at the end of the data block API.\"\n    def __init__(self, ds: Collection = None):\n        self.ref_ds = ds\n    def process_one(self, item: Any):\n        return item\n    def process(self, ds: Collection):\n        ds.items = array([self.process_one(item) for item in ds.items])\nPreProcessors = Union[PreProcessor, Collection[PreProcessor]]\nfastai_types[PreProcessors] = \"PreProcessors\"",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "ItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,\n    )\n    def __init__(",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "EmptyLabelList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class EmptyLabelList(ItemList):\n    \"Basic `ItemList` for dummy labels.\"\n    def get(self, i):\n        return EmptyLabel()\n    def reconstruct(self, t: Tensor, x: Tensor = None):\n        if len(t.size()) == 0:\n            return EmptyLabel()\n        return (\n            self.x.reconstruct(t, x)\n            if has_arg(self.x.reconstruct, \"x\")",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryProcessor(PreProcessor):\n    \"`PreProcessor` that create `classes` from `ds.items` and handle the mapping.\"\n    def __init__(self, ds: ItemList):\n        self.create_classes(ds.classes)\n        self.state_attrs, self.warns = [\"classes\"], []\n    def create_classes(self, classes):\n        self.classes = classes\n        if classes is not None:\n            self.c2i = {v: k for k, v in enumerate(classes)}\n    def generate_classes(self, items):",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryListBase",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryListBase(ItemList):\n    \"Basic `ItemList` for classification.\"\n    def __init__(self, items: Iterator, classes: Collection = None, **kwargs):\n        self.classes = classes\n        self.filter_missing_y = True\n        super().__init__(items, **kwargs)\n        self.copy_new.append(\"classes\")\n    @property\n    def c(self):\n        return len(self.classes)",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "CategoryList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class CategoryList(CategoryListBase):\n    \"Basic `ItemList` for single classification labels.\"\n    _processor = CategoryProcessor\n    def __init__(\n        self,\n        items: Iterator,\n        classes: Collection = None,\n        label_delim: str = None,\n        **kwargs,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MultiCategoryProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class MultiCategoryProcessor(CategoryProcessor):\n    \"`PreProcessor` that create `classes` from `ds.items` and handle the mapping.\"\n    def __init__(self, ds: ItemList, one_hot: bool = False):\n        super().__init__(ds)\n        self.one_hot = one_hot\n        self.state_attrs.append(\"one_hot\")\n    def process_one(self, item):\n        if self.one_hot or isinstance(item, EmptyLabel):\n            return item\n        res = [super(MultiCategoryProcessor, self).process_one(o) for o in item]",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MultiCategoryList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class MultiCategoryList(CategoryListBase):\n    \"Basic `ItemList` for multi-classification labels.\"\n    _processor = MultiCategoryProcessor\n    def __init__(\n        self,\n        items: Iterator,\n        classes: Collection = None,\n        label_delim: str = None,\n        one_hot: bool = False,\n        **kwargs,",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "FloatList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class FloatList(ItemList):\n    \"`ItemList` suitable for storing the floats in items for regression. Will add a `log` if this flag is `True`.\"\n    def __init__(\n        self, items: Iterator, log: bool = False, classes: Collection = None, **kwargs\n    ):\n        super().__init__(np.array(items, dtype=np.float32), **kwargs)\n        self.log = log\n        self.copy_new.append(\"log\")\n        self.c = self.items.shape[1] if len(self.items.shape) > 1 else 1\n        self.loss_func = MSELossFlat()",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "ItemLists",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class ItemLists:\n    \"An `ItemList` for each of `train` and `valid` (optional `test`).\"\n    def __init__(self, path: PathOrStr, train: ItemList, valid: ItemList):\n        self.path, self.train, self.valid, self.test = Path(path), train, valid, None\n        if not self.train.ignore_empty and len(self.train.items) == 0:\n            warn(\n                \"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\"\n            )\n        if not self.valid.ignore_empty and len(self.valid.items) == 0:\n            warn(",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "LabelLists",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class LabelLists(ItemLists):\n    \"A `LabelList` for each of `train` and `valid` (optional `test`).\"\n    def get_processors(self):\n        \"Read the default class processors if none have been set.\"\n        procs_x, procs_y = listify(self.train.x._processor), listify(\n            self.train.y._processor\n        )\n        xp = ifnone(self.train.x.processor, [p(ds=self.train.x) for p in procs_x])\n        yp = ifnone(self.train.y.processor, [p(ds=self.train.y) for p in procs_y])\n        return xp, yp",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "LabelList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class LabelList(Dataset):\n    \"A list of inputs `x` and labels `y` with optional `tfms`.\"\n    def __init__(\n        self,\n        x: ItemList,\n        y: ItemList,\n        tfms: TfmList = None,\n        tfm_y: bool = False,\n        **kwargs,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedProcessor",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedProcessor(PreProcessor):\n    def __init__(\n        self, procs: Collection[Union[PreProcessor, Collection[PreProcessor]]]\n    ):\n        self.procs = procs\n    def process_one(self, item: Any):\n        res = []\n        for procs, i in zip(self.procs, item):\n            for p in procs:\n                i = p.process_one(i)",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedItem",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedItem(ItemBase):\n    def __init__(self, items):\n        self.obj = items\n        self.data = [item.data for item in items]\n    def __repr__(self):\n        return \"\\n\".join(\n            [f\"{self.__class__.__name__}\"] + [repr(item) for item in self.obj]\n        )\n    def apply_tfms(self, tfms: Collection, **kwargs):\n        self.obj = [item.apply_tfms(t, **kwargs) for item, t in zip(self.obj, tfms)]",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "MixedItemList",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "class MixedItemList(ItemList):\n    def __init__(\n        self,\n        item_lists,\n        path: PathOrStr = None,\n        label_cls: Callable = None,\n        inner_df: Any = None,\n        x: \"ItemList\" = None,\n        ignore_empty: bool = False,\n        processor=None,",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "get_files",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "def get_files(\n    path: PathOrStr,\n    extensions: Collection[str] = None,\n    recurse: bool = False,\n    include: Optional[Collection[str]] = None,\n    presort: bool = False,\n) -> FilePathList:\n    \"Return list of files in `path` that have a suffix in `extensions`; optionally `recurse`.\"\n    if recurse:\n        res = []",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "__all__ = [\n    \"ItemList\",\n    \"CategoryList\",\n    \"MultiCategoryList\",\n    \"MultiCategoryProcessor\",\n    \"LabelList\",\n    \"ItemLists\",\n    \"get_files\",\n    \"PreProcessor\",\n    \"LabelLists\",",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "PreProcessors",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "PreProcessors = Union[PreProcessor, Collection[PreProcessor]]\nfastai_types[PreProcessors] = \"PreProcessors\"\nclass ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "fastai_types[PreProcessors]",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "fastai_types[PreProcessors] = \"PreProcessors\"\nclass ItemList:\n    \"A collection of items with `__len__` and `__getitem__` with `ndarray` indexing semantics.\"\n    _bunch, _processor, _label_cls, _square_show, _square_show_res = (\n        DataBunch,\n        None,\n        None,\n        False,\n        False,\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "DataBunch.load_empty",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.data_block",
        "description": "dashboard.dl_model.deoldify.fastai.data_block",
        "peekOfCode": "DataBunch.load_empty = _databunch_load_empty\nclass MixedProcessor(PreProcessor):\n    def __init__(\n        self, procs: Collection[Union[PreProcessor, Collection[PreProcessor]]]\n    ):\n        self.procs = procs\n    def process_one(self, item: Any):\n        res = []\n        for procs, i in zip(self.procs, item):\n            for p in procs:",
        "detail": "dashboard.dl_model.deoldify.fastai.data_block",
        "documentation": {}
    },
    {
        "label": "URLs",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "class URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"\n    S3_MODEL = f\"{S3}modelzoo/\"\n    # main datasets",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "class Config:\n    \"Creates a default config file 'config.yml' in $FASTAI_HOME (default `~/.fastai/`)\"\n    DEFAULT_CONFIG_LOCATION = os.path.expanduser(os.getenv(\"FASTAI_HOME\", \"~/.fastai\"))\n    DEFAULT_CONFIG_PATH = DEFAULT_CONFIG_LOCATION + \"/config.yml\"\n    DEFAULT_CONFIG = {\n        \"data_path\": DEFAULT_CONFIG_LOCATION + \"/data\",\n        \"data_archive_path\": DEFAULT_CONFIG_LOCATION + \"/data\",\n        \"model_path\": DEFAULT_CONFIG_LOCATION + \"/models\",\n    }\n    @classmethod",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "url2name",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def url2name(url):\n    return url.split(\"/\")[-1]\n# TODO: simplify this mess\ndef url2path(url, data=True, ext: str = \".tgz\"):\n    \"Change `url` to a path.\"\n    name = url2name(url)\n    return (\n        datapath4file(name, ext=ext, archive=False)\n        if data\n        else modelpath4file(name, ext=ext)",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "url2path",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def url2path(url, data=True, ext: str = \".tgz\"):\n    \"Change `url` to a path.\"\n    name = url2name(url)\n    return (\n        datapath4file(name, ext=ext, archive=False)\n        if data\n        else modelpath4file(name, ext=ext)\n    )\ndef _url2tgz(url, data=True, ext: str = \".tgz\"):\n    return (",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "modelpath4file",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def modelpath4file(filename, ext: str = \".tgz\"):\n    \"Return model path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"models\" / filename\n    if local_path.exists() or local_path.with_suffix(ext).exists():\n        return local_path\n    else:\n        return Config.model_path() / filename\ndef datapath4file(filename, ext: str = \".tgz\", archive=True):\n    \"Return data path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"data\" / filename",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "datapath4file",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def datapath4file(filename, ext: str = \".tgz\", archive=True):\n    \"Return data path to `filename`, checking locally first then in the config file.\"\n    local_path = URLs.LOCAL_PATH / \"data\" / filename\n    if local_path.exists() or local_path.with_suffix(ext).exists():\n        return local_path\n    elif archive:\n        return Config.data_archive_path() / filename\n    else:\n        return Config.data_path() / filename\ndef download_data(",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "download_data",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def download_data(\n    url: str, fname: PathOrStr = None, data: bool = True, ext: str = \".tgz\"\n) -> Path:\n    \"Download `url` to destination `fname`.\"\n    fname = Path(ifnone(fname, _url2tgz(url, data, ext=ext)))\n    os.makedirs(fname.parent, exist_ok=True)\n    if not fname.exists():\n        print(f\"Downloading {url}\")\n        download_url(f\"{url}{ext}\", fname)\n    return fname",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "untar_data",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "def untar_data(\n    url: str,\n    fname: PathOrStr = None,\n    dest: PathOrStr = None,\n    data=True,\n    force_download=False,\n) -> Path:\n    \"Download `url` to `fname` if `dest` doesn't exist, and un-tgz to folder `dest`.\"\n    dest = url2path(url, data) if dest is None else Path(dest) / url2name(url)\n    fname = Path(ifnone(fname, _url2tgz(url, data)))",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "__all__ = [\n    \"URLs\",\n    \"Config\",\n    \"untar_data\",\n    \"download_data\",\n    \"datapath4file\",\n    \"url2name\",\n    \"url2path\",\n]\nMODEL_URL = \"http://files.fast.ai/models/\"",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "MODEL_URL",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "MODEL_URL = \"http://files.fast.ai/models/\"\nURL = \"http://files.fast.ai/data/examples/\"\nclass URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "URL = \"http://files.fast.ai/data/examples/\"\nclass URLs:\n    \"Global constants for dataset and model URLs.\"\n    LOCAL_PATH = Path.cwd()\n    S3 = \"https://s3.amazonaws.com/fast-ai-\"\n    S3_IMAGE = f\"{S3}imageclas/\"\n    S3_IMAGELOC = f\"{S3}imagelocal/\"\n    S3_NLP = f\"{S3}nlp/\"\n    S3_COCO = f\"{S3}coco/\"\n    S3_MODEL = f\"{S3}modelzoo/\"",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "_checks",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.datasets",
        "description": "dashboard.dl_model.deoldify.fastai.datasets",
        "peekOfCode": "_checks = {\n    URLs.ADULT_SAMPLE: (968212, \"64eb9d7e23732de0b138f7372d15492f\"),\n    URLs.AG_NEWS: (11784419, \"b86f328f4dbd072486591cb7a5644dcd\"),\n    URLs.AMAZON_REVIEWS_POLARITY: (688339454, \"676f7e5208ec343c8274b4bb085bc938\"),\n    URLs.AMAZON_REVIEWS: (643695014, \"4a1196cf0adaea22f4bc3f592cddde90\"),\n    URLs.BIWI_HEAD_POSE: (452316199, \"00f4ccf66e8cba184bc292fdc08fb237\"),\n    URLs.BIWI_SAMPLE: (593774, \"9179f4c1435f4b291f0d5b072d60c2c9\"),\n    URLs.CALTECH_101: (131740031, \"d673425306e98ee4619fcdeef8a0e876\"),\n    URLs.CAMVID: (598913237, \"648371e4f3a833682afb39b08a3ce2aa\"),\n    URLs.CAMVID_TINY: (2314212, \"2cf6daf91b7a2083ecfa3e9968e9d915\"),",
        "detail": "dashboard.dl_model.deoldify.fastai.datasets",
        "documentation": {}
    },
    {
        "label": "ParallelTrainer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "class ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module\nclass DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):\n        super().__init__(learn)",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedTrainer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "class DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):\n        super().__init__(learn)\n        self.cuda_id, self.train_sampler = cuda_id, None\n    def _change_dl(self, dl, shuffle):\n        old_dl = dl\n        sampler = OurDistributedSampler(dl.dataset, shuffle=shuffle)\n        new_dl = dl.new(shuffle=False, sampler=sampler)\n        return old_dl, new_dl, sampler",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedRecorder",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "class DistributedRecorder(LearnerCallback):\n    def __init__(self, learn: Learner, cuda_id: int = 0, cache_dir: PathOrStr = \"tmp\"):\n        super().__init__(learn)\n        self.cuda_id, self.cache_dir = cuda_id, cache_dir\n    def on_train_begin(self, **kwargs):\n        os.makedirs(self.learn.path / self.cache_dir, exist_ok=True)\n    def on_epoch_end(self, **kwargs):\n        self.save_stats()\n    def on_train_end(self, **kwargs):\n        self.save_stats()",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "OurDistributedSampler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "class OurDistributedSampler(DistributedSampler):\n    \"A sampler for language models with the option to not shuffle.\"\n    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True):\n        super().__init__(dataset, num_replicas=num_replicas, rank=rank)\n        self.shuffle = shuffle\n    def __iter__(self):\n        if self.shuffle:\n            g = torch.Generator()\n            g.manual_seed(self.epoch)\n            indices = torch.randperm(len(self.dataset), generator=g).tolist()",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "rnn_reset",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "def rnn_reset(self):\n    if hasattr(self.module, \"reset\"):\n        self.module.reset()\nDistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "read_metrics",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "def read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)\n    return losses, metrics\ndef setup_distrib(gpu: Any = None):",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "setup_distrib",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "def setup_distrib(gpu: Any = None):\n    if gpu is None:\n        return gpu\n    gpu = int(gpu)\n    torch.cuda.set_device(int(gpu))\n    if num_distrib() > 1:\n        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n    return gpu\nclass OurDistributedSampler(DistributedSampler):\n    \"A sampler for language models with the option to not shuffle.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "__all__ = [\"DistributedRecorder\", \"DistributedTrainer\", \"read_metrics\", \"setup_distrib\"]\ndef rnn_reset(self):\n    if hasattr(self.module, \"reset\"):\n        self.module.reset()\nDistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel.reset",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "DistributedDataParallel.reset = rnn_reset\nclass ParallelTrainer(LearnerCallback):\n    _order = -20\n    def on_train_begin(self, **kwargs):\n        self.learn.model = DataParallel(self.learn.model)\n    def on_train_end(self, **kwargs):\n        self.learn.model = self.learn.model.module\nclass DistributedTrainer(LearnerCallback):\n    _order = -20  # Needs to run before the recorder\n    def __init__(self, learn: Learner, cuda_id: int = 0):",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Learner.to_distributed",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "Learner.to_distributed = _learner_distributed\nLearner.to_parallel = _learner_parallel\ndef read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Learner.to_parallel",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.distributed",
        "description": "dashboard.dl_model.deoldify.fastai.distributed",
        "peekOfCode": "Learner.to_parallel = _learner_parallel\ndef read_metrics(cache_path: PathOrStr, n_gpus: int, reduce: bool = True):\n    losses, metrics = [], []\n    for i in range(n_gpus):\n        losses.append(np.load(cache_path / f\"losses_{i}.npy\")[None])\n        metrics.append(np.load(cache_path / f\"metrics_{i}.npy\")[None])\n    if reduce:\n        losses, metrics = np.concatenate(losses, 0), np.concatenate(metrics, 0)\n        return losses.mean(0), metrics.mean(0)\n    return losses, metrics",
        "detail": "dashboard.dl_model.deoldify.fastai.distributed",
        "documentation": {}
    },
    {
        "label": "Statistic",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class Statistic:\n    name: str\n    param: float = 0.9  # e.g. for exp moving average\n    scope: StatScope = StatScope.Weight\n    init: float = 0.0  # starting value\n    @property\n    def buf(self):\n        return f\"{self.name}_buffer\"\n    def new_step(self):\n        \"Set state when computing statistics for Global or Group\"",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "ConstStatistic",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class ConstStatistic(Statistic):\n    @property\n    def buf(self):\n        return None\n    def new_step(self):\n        pass\n    def accumulate(self):\n        pass\n    def update(self, state, param, val=None, step=None):\n        return param",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "CounterStat",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class CounterStat(Statistic):\n    def __post_init__(self):\n        self.init, self._buf, self.name = 0, self.name, None\n    @property\n    def buf(self):\n        return self._buf\n    def new_step(self):\n        pass\n    def accumulate(self, val):\n        pass",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "AvgStatistic",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class AvgStatistic(Statistic):\n    decay: bool = False\n    debias: bool = False\n    def new_step(self):\n        self.val, self.count = 0.0, 0\n    def accumulate(self, val):\n        self.count += 1\n        self.val += self._get_val1(val)\n    def _get_val1(self, val):\n        return val.mean()",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "AvgSquare",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class AvgSquare(AvgStatistic):\n    def __init__(\n        self,\n        name: str,\n        param: float = 0.9,\n        scope=StatScope.Weight,\n        init: float = 0.0,\n        decay: bool = True,\n        debias: bool = False,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "GeneralOptimizer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "class GeneralOptimizer(Optimizer):\n    def __init__(self, params, stats=None, on_step: Callable = None):\n        defaults = {s.name: s.param for s in listify(stats) if s.name is not None}\n        super().__init__(params, defaults)\n        (\n            self.global_stats,\n            self.group_stats,\n            self.layer_stats,\n            self.channel_stats,\n            self.weight_stats,",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "__all__ = [\n    \"StatScope\",\n    \"Statistic\",\n    \"ConstStatistic\",\n    \"AvgStatistic\",\n    \"AvgSquare\",\n    \"GeneralOptimizer\",\n]\nStatScope = Enum(\"StatScope\", \"Global Group Layer Channel Weight\")\n@dataclass",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "StatScope",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "description": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "peekOfCode": "StatScope = Enum(\"StatScope\", \"Global Group Layer Channel Weight\")\n@dataclass\nclass Statistic:\n    name: str\n    param: float = 0.9  # e.g. for exp moving average\n    scope: StatScope = StatScope.Weight\n    init: float = 0.0  # starting value\n    @property\n    def buf(self):\n        return f\"{self.name}_buffer\"",
        "detail": "dashboard.dl_model.deoldify.fastai.general_optimizer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.launch",
        "description": "dashboard.dl_model.deoldify.fastai.launch",
        "peekOfCode": "def main(\n    gpus: Param(\"The GPUs to use for distributed training\", str) = \"all\",\n    script: Param(\"Script to run\", str, opt=False) = \"\",\n    args: Param(\"Args to pass to script\", nargs=\"...\", opt=False) = \"\",\n):\n    \"PyTorch distributed training launch helper that spawns multiple distributed processes\"\n    # Loosely based on torch.distributed.launch\n    current_env = os.environ.copy()\n    gpus = list(range(torch.cuda.device_count())) if gpus == \"all\" else list(gpus)\n    current_env[\"WORLD_SIZE\"] = str(len(gpus))",
        "detail": "dashboard.dl_model.deoldify.fastai.launch",
        "documentation": {}
    },
    {
        "label": "Lambda",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class Lambda(Module):\n    \"Create a layer that simply calls `func` with `x`\"\n    def __init__(self, func: LambdaFunc):\n        self.func = func\n    def forward(self, x):\n        return self.func(x)\nclass View(Module):\n    \"Reshape `x` to `size`\"\n    def __init__(self, *size: int):\n        self.size = size",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "View",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class View(Module):\n    \"Reshape `x` to `size`\"\n    def __init__(self, *size: int):\n        self.size = size\n    def forward(self, x):\n        return x.view(self.size)\nclass ResizeBatch(Module):\n    \"Reshape `x` to `size`, keeping batch dim the same size\"\n    def __init__(self, *size: int):\n        self.size = size",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "ResizeBatch",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class ResizeBatch(Module):\n    \"Reshape `x` to `size`, keeping batch dim the same size\"\n    def __init__(self, *size: int):\n        self.size = size\n    def forward(self, x):\n        return x.view((x.size(0),) + self.size)\nclass Flatten(Module):\n    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n    def __init__(self, full: bool = False):\n        self.full = full",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class Flatten(Module):\n    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n    def __init__(self, full: bool = False):\n        self.full = full\n    def forward(self, x):\n        return x.view(-1) if self.full else x.view(x.size(0), -1)\ndef PoolFlatten() -> nn.Sequential:\n    \"Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result.\"\n    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())\nNormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PooledSelfAttention2d",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class PooledSelfAttention2d(Module):\n    \"Pooled self attention layer for 2d.\"\n    def __init__(self, n_channels: int):\n        self.n_channels = n_channels\n        self.theta = spectral_norm(conv2d(n_channels, n_channels // 8, 1))  # query\n        self.phi = spectral_norm(conv2d(n_channels, n_channels // 8, 1))  # key\n        self.g = spectral_norm(conv2d(n_channels, n_channels // 2, 1))  # value\n        self.o = spectral_norm(conv2d(n_channels // 2, n_channels, 1))\n        self.gamma = nn.Parameter(tensor([0.0]))\n    def forward(self, x):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SelfAttention",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class SelfAttention(Module):\n    \"Self attention layer for nd.\"\n    def __init__(self, n_channels: int):\n        self.query = conv1d(n_channels, n_channels // 8)\n        self.key = conv1d(n_channels, n_channels // 8)\n        self.value = conv1d(n_channels, n_channels)\n        self.gamma = nn.Parameter(tensor([0.0]))\n    def forward(self, x):\n        # Notation from https://arxiv.org/pdf/1805.08318.pdf\n        size = x.size()",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SequentialEx",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class SequentialEx(Module):\n    \"Like `nn.Sequential`, but with ModuleList semantics, and can access module input\"\n    def __init__(self, *layers):\n        self.layers = nn.ModuleList(layers)\n    def forward(self, x):\n        res = x\n        for l in self.layers:\n            res.orig = x\n            nres = l(res)\n            # print(l. + ' mean: ' + str(nres.abs().mean()))",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "MergeLayer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class MergeLayer(Module):\n    \"Merge a shortcut with the result of the module by adding them or concatenating thme if `dense=True`.\"\n    def __init__(self, dense: bool = False):\n        self.dense = dense\n    def forward(self, x):\n        return torch.cat([x, x.orig], dim=1) if self.dense else (x + x.orig)\ndef res_block(\n    nf,\n    dense: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "SigmoidRange",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class SigmoidRange(Module):\n    \"Sigmoid module with range `(low,x_max)`\"\n    def __init__(self, low: int, high: int):\n        self.low, self.high = low, high\n    def forward(self, x):\n        return sigmoid_range(x, self.low, self.high)\nclass PartialLayer(Module):\n    \"Layer that applies `partial(func, **kwargs)`.\"\n    def __init__(self, func, **kwargs):\n        self.repr, self.func = f\"{func}({kwargs})\", partial(func, **kwargs)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PartialLayer",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class PartialLayer(Module):\n    \"Layer that applies `partial(func, **kwargs)`.\"\n    def __init__(self, func, **kwargs):\n        self.repr, self.func = f\"{func}({kwargs})\", partial(func, **kwargs)\n    def forward(self, x):\n        return self.func(x)\n    def __repr__(self):\n        return self.repr\nclass AdaptiveConcatPool2d(Module):\n    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "AdaptiveConcatPool2d",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class AdaptiveConcatPool2d(Module):\n    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\"\n    def __init__(self, sz: Optional[int] = None):\n        \"Output will be 2*sz or 2 if sz is None\"\n        self.output_size = sz or 1\n        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n    def forward(self, x):\n        return torch.cat([self.mp(x), self.ap(x)], 1)\nclass Debugger(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "Debugger",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class Debugger(Module):\n    \"A module to debug inside a model.\"\n    def forward(self, x: Tensor) -> Tensor:\n        set_trace()\n        return x\ndef icnr(x, scale=2, init=nn.init.kaiming_normal_):\n    \"ICNR init of `x`, with `scale` and `init` function.\"\n    ni, nf, h, w = x.shape\n    ni2 = int(ni / (scale**2))\n    k = init(torch.zeros([ni2, nf, h, w])).transpose(0, 1)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PixelShuffle_ICNR",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class PixelShuffle_ICNR(Module):\n    \"Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`, `icnr` init, and `weight_norm`.\"\n    def __init__(\n        self,\n        ni: int,\n        nf: int = None,\n        scale: int = 2,\n        blur: bool = False,\n        norm_type=NormType.Weight,\n        leaky: float = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "FlattenedLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class FlattenedLoss:\n    \"Same as `func`, but flattens input and target.\"\n    def __init__(\n        self,\n        func,\n        *args,\n        axis: int = -1,\n        floatify: bool = False,\n        is_2d: bool = True,\n        **kwargs,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "NoopLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class NoopLoss(Module):\n    \"Just returns the mean of the `output`.\"\n    def forward(self, output, *args):\n        return output.mean()\nclass WassersteinLoss(Module):\n    \"For WGAN.\"\n    def forward(self, real, fake):\n        return real.mean() - fake.mean()\ndef simple_cnn(\n    actns: Collection[int],",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "WassersteinLoss",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class WassersteinLoss(Module):\n    \"For WGAN.\"\n    def forward(self, real, fake):\n        return real.mean() - fake.mean()\ndef simple_cnn(\n    actns: Collection[int],\n    kernel_szs: Collection[int] = None,\n    strides: Collection[int] = None,\n    bn=False,\n) -> nn.Sequential:",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BatchNorm1dFlat",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class BatchNorm1dFlat(nn.BatchNorm1d):\n    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n    def forward(self, x):\n        if x.dim() == 2:\n            return super().forward(x)\n        *f, l = x.shape\n        x = x.contiguous().view(-1, l)\n        return super().forward(x).view(*f, l)\nclass LabelSmoothingCrossEntropy(Module):\n    def __init__(self, eps: float = 0.1, reduction=\"mean\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "LabelSmoothingCrossEntropy",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "class LabelSmoothingCrossEntropy(Module):\n    def __init__(self, eps: float = 0.1, reduction=\"mean\"):\n        self.eps, self.reduction = eps, reduction\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        if self.reduction == \"sum\":\n            loss = -log_preds.sum()\n        else:\n            loss = -log_preds.sum(dim=-1)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "PoolFlatten",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def PoolFlatten() -> nn.Sequential:\n    \"Apply `nn.AdaptiveAvgPool2d` to `x` and then flatten the result.\"\n    return nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten())\nNormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")\ndef batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "batchnorm_2d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)\n    return bn\ndef bn_drop_lin(\n    n_in: int,\n    n_out: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "bn_drop_lin",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def bn_drop_lin(\n    n_in: int,\n    n_out: int,\n    bn: bool = True,\n    p: float = 0.0,\n    actn: Optional[nn.Module] = None,\n):\n    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n    layers = [nn.BatchNorm1d(n_in)] if bn else []\n    if p != 0:",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv1d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def conv1d(\n    ni: int, no: int, ks: int = 1, stride: int = 1, padding: int = 0, bias: bool = False\n):\n    \"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"\n    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n    nn.init.kaiming_normal_(conv.weight)\n    if bias:\n        conv.bias.data.zero_()\n    return spectral_norm(conv)\nclass PooledSelfAttention2d(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv2d",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def conv2d(\n    ni: int,\n    nf: int,\n    ks: int = 3,\n    stride: int = 1,\n    padding: int = None,\n    bias=False,\n    init: LayerFunc = nn.init.kaiming_normal_,\n) -> nn.Conv2d:\n    \"Create and initialize `nn.Conv2d` layer. `padding` defaults to `ks//2`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv2d_trans",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def conv2d_trans(\n    ni: int, nf: int, ks: int = 2, stride: int = 2, padding: int = 0, bias=False\n) -> nn.ConvTranspose2d:\n    \"Create `nn.ConvTranspose2d` layer.\"\n    return nn.ConvTranspose2d(\n        ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias\n    )\ndef relu(inplace: bool = False, leaky: float = None):\n    \"Return a relu activation, maybe `leaky` and `inplace`.\"\n    return (",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "relu",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def relu(inplace: bool = False, leaky: float = None):\n    \"Return a relu activation, maybe `leaky` and `inplace`.\"\n    return (\n        nn.LeakyReLU(inplace=inplace, negative_slope=leaky)\n        if leaky is not None\n        else nn.ReLU(inplace=inplace)\n    )\ndef conv_layer(\n    ni: int,\n    nf: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "conv_layer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def conv_layer(\n    ni: int,\n    nf: int,\n    ks: int = 3,\n    stride: int = 1,\n    padding: int = None,\n    bias: bool = None,\n    is_1d: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,\n    use_activ: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "res_block",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def res_block(\n    nf,\n    dense: bool = False,\n    norm_type: Optional[NormType] = NormType.Batch,\n    bottle: bool = False,\n    **conv_kwargs,\n):\n    \"Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.\"\n    norm2 = norm_type\n    if not dense and (norm_type == NormType.Batch):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "sigmoid_range",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def sigmoid_range(x: Tensor, low: int, high: int):\n    \"Sigmoid function with range `(low, high)`\"\n    return torch.sigmoid(x) * (high - low) + low\nclass SigmoidRange(Module):\n    \"Sigmoid module with range `(low,x_max)`\"\n    def __init__(self, low: int, high: int):\n        self.low, self.high = low, high\n    def forward(self, x):\n        return sigmoid_range(x, self.low, self.high)\nclass PartialLayer(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "icnr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def icnr(x, scale=2, init=nn.init.kaiming_normal_):\n    \"ICNR init of `x`, with `scale` and `init` function.\"\n    ni, nf, h, w = x.shape\n    ni2 = int(ni / (scale**2))\n    k = init(torch.zeros([ni2, nf, h, w])).transpose(0, 1)\n    k = k.contiguous().view(ni2, nf, -1)\n    k = k.repeat(1, 1, scale**2)\n    k = k.contiguous().view([nf, ni, h, w]).transpose(0, 1)\n    x.data.copy_(k)\nclass PixelShuffle_ICNR(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "CrossEntropyFlat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def CrossEntropyFlat(*args, axis: int = -1, **kwargs):\n    \"Same as `nn.CrossEntropyLoss`, but flattens input and target.\"\n    return FlattenedLoss(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\ndef BCEWithLogitsFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BCEWithLogitsFlat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def BCEWithLogitsFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCEWithLogitsLoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "BCEFlat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def BCEFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.BCELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.BCELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\ndef MSELossFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.MSELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.MSELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "MSELossFlat",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def MSELossFlat(*args, axis: int = -1, floatify: bool = True, **kwargs):\n    \"Same as `nn.MSELoss`, but flattens input and target.\"\n    return FlattenedLoss(\n        nn.MSELoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs\n    )\nclass NoopLoss(Module):\n    \"Just returns the mean of the `output`.\"\n    def forward(self, output, *args):\n        return output.mean()\nclass WassersteinLoss(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "simple_cnn",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def simple_cnn(\n    actns: Collection[int],\n    kernel_szs: Collection[int] = None,\n    strides: Collection[int] = None,\n    bn=False,\n) -> nn.Sequential:\n    \"CNN with `conv_layer` defined by `actns`, `kernel_szs` and `strides`, plus batchnorm if `bn`.\"\n    nl = len(actns) - 1\n    kernel_szs = ifnone(kernel_szs, [3] * nl)\n    strides = ifnone(strides, [2] * nl)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "trunc_normal_",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def trunc_normal_(x: Tensor, mean: float = 0.0, std: float = 1.0) -> Tensor:\n    \"Truncated normal initialization.\"\n    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n    return x.normal_().fmod_(2).mul_(std).add_(mean)\ndef embedding(ni: int, nf: int) -> nn.Module:\n    \"Create an embedding layer.\"\n    emb = nn.Embedding(ni, nf)\n    # See https://arxiv.org/abs/1711.09160\n    with torch.no_grad():\n        trunc_normal_(emb.weight, std=0.01)",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "embedding",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "def embedding(ni: int, nf: int) -> nn.Module:\n    \"Create an embedding layer.\"\n    emb = nn.Embedding(ni, nf)\n    # See https://arxiv.org/abs/1711.09160\n    with torch.no_grad():\n        trunc_normal_(emb.weight, std=0.01)\n    return emb\nclass BatchNorm1dFlat(nn.BatchNorm1d):\n    \"`nn.BatchNorm1d`, but first flattens leading dimensions\"\n    def forward(self, x):",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "__all__ = [\n    \"AdaptiveConcatPool2d\",\n    \"BCEWithLogitsFlat\",\n    \"BCEFlat\",\n    \"MSELossFlat\",\n    \"CrossEntropyFlat\",\n    \"Debugger\",\n    \"Flatten\",\n    \"Lambda\",\n    \"PoolFlatten\",",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "NormType",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.layers",
        "description": "dashboard.dl_model.deoldify.fastai.layers",
        "peekOfCode": "NormType = Enum(\"NormType\", \"Batch BatchZero Weight Spectral Group Instance SpectralGN\")\ndef batchnorm_2d(nf: int, norm_type: NormType = NormType.Batch):\n    \"A batchnorm2d layer with `nf` features initialized depending on `norm_type`.\"\n    bn = nn.BatchNorm2d(nf)\n    with torch.no_grad():\n        bn.bias.fill_(1e-3)\n        bn.weight.fill_(0.0 if norm_type == NormType.BatchZero else 1.0)\n    return bn\ndef bn_drop_lin(\n    n_in: int,",
        "detail": "dashboard.dl_model.deoldify.fastai.layers",
        "documentation": {}
    },
    {
        "label": "RegMetrics",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class RegMetrics(Callback):\n    \"Stores predictions and targets to perform calculations on epoch end.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = Tensor([]), Tensor([])\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        assert (\n            last_output.numel() == last_target.numel()\n        ), \"Expected same numbers of elements in pred & targ\"\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu()))",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "R2Score",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class R2Score(RegMetrics):\n    \"Computes the R2 score (coefficient of determination).\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, r2_score(self.preds, self.targs))\nclass ExplainedVariance(RegMetrics):\n    \"Computes the explained variance.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, explained_variance(self.preds, self.targs))\nclass RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ExplainedVariance",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class ExplainedVariance(RegMetrics):\n    \"Computes the explained variance.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, explained_variance(self.preds, self.targs))\nclass RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(\n            last_metrics, root_mean_squared_error(self.preds, self.targs)\n        )",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "RMSE",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class RMSE(RegMetrics):\n    \"Computes the root mean squared error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(\n            last_metrics, root_mean_squared_error(self.preds, self.targs)\n        )\nclass ExpRMSPE(RegMetrics):\n    \"Computes the exponential of the root mean square error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, exp_rmspe(self.preds, self.targs))",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ExpRMSPE",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class ExpRMSPE(RegMetrics):\n    \"Computes the exponential of the root mean square error.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, exp_rmspe(self.preds, self.targs))\n# Aliases\nmse = mean_squared_error\nmae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.cpu()\n        if self.n_classes == 0:",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "CMScores",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class CMScores(ConfusionMatrix):\n    \"Base class for metrics which rely on the calculation of the precision and/or recall score.\"\n    average: Optional[str] = \"binary\"  # `binary`, `micro`, `macro`, `weigthed` or None\n    pos_label: int = 1  # 0 or 1\n    eps: float = 1e-9\n    def _recall(self):\n        rec = torch.diag(self.cm) / self.cm.sum(dim=1)\n        if self.average is None:\n            return rec\n        else:",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Recall",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class Recall(CMScores):\n    \"Computes the Recall.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._recall())\nclass Precision(CMScores):\n    \"Computes the Precision.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._precision())\n@dataclass\nclass FBeta(CMScores):",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Precision",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class Precision(CMScores):\n    \"Computes the Precision.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, self._precision())\n@dataclass\nclass FBeta(CMScores):\n    \"Computes the F`beta` score.\"\n    beta: float = 2\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "FBeta",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class FBeta(CMScores):\n    \"Computes the F`beta` score.\"\n    beta: float = 2\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n        self.beta2 = self.beta**2\n        self.avg = self.average\n        if self.average != \"micro\":\n            self.average = None\n    def on_epoch_end(self, last_metrics, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "KappaScore",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class KappaScore(ConfusionMatrix):\n    \"Computes the rate of agreement (Cohens Kappa).\"\n    weights: Optional[str] = None  # None, `linear`, or `quadratic`\n    def on_epoch_end(self, last_metrics, **kwargs):\n        sum0 = self.cm.sum(dim=0)\n        sum1 = self.cm.sum(dim=1)\n        expected = torch.einsum(\"i,j->ij\", (sum0, sum1)) / sum0.sum()\n        if self.weights is None:\n            w = torch.ones((self.n_classes, self.n_classes))\n            w[self.x, self.x] = 0",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "MatthewsCorreff",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class MatthewsCorreff(ConfusionMatrix):\n    \"Computes the Matthews correlation coefficient.\"\n    def on_epoch_end(self, last_metrics, **kwargs):\n        t_sum = self.cm.sum(dim=1)\n        p_sum = self.cm.sum(dim=0)\n        n_correct = torch.trace(self.cm)\n        n_samples = p_sum.sum()\n        cov_ytyp = n_correct * n_samples - torch.dot(t_sum, p_sum)\n        cov_ypyp = n_samples**2 - torch.dot(p_sum, p_sum)\n        cov_ytyt = n_samples**2 - torch.dot(t_sum, t_sum)",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Perplexity",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class Perplexity(Callback):\n    \"Perplexity metric for language models.\"\n    def on_epoch_begin(self, **kwargs):\n        self.loss, self.len = 0.0, 0\n    def on_batch_end(self, last_output, last_target, **kwargs):\n        self.loss += last_target.size(1) * CrossEntropyFlat()(last_output, last_target)\n        self.len += last_target.size(1)\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, torch.exp(self.loss / self.len))\ndef auc_roc_score(input: Tensor, targ: Tensor):",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "AUROC",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class AUROC(Callback):\n    \"Computes the area under the curve (AUC) score based on the receiver operator characteristic (ROC) curve. Restricted to binary classification tasks.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = LongTensor([]), Tensor([])\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        last_output = F.softmax(last_output, dim=1)[:, -1]\n        self.preds = torch.cat((self.preds, last_output.cpu()))\n        self.targs = torch.cat((self.targs, last_target.cpu().long()))\n    def on_epoch_end(self, last_metrics, **kwargs):\n        return add_metrics(last_metrics, auc_roc_score(self.preds, self.targs))",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "MultiLabelFbeta",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "class MultiLabelFbeta(LearnerCallback):\n    \"Computes the fbeta score for multilabel classification\"\n    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n    _order = -20\n    def __init__(\n        self, learn, beta=2, eps=1e-15, thresh=0.3, sigmoid=True, average=\"micro\"\n    ):\n        super().__init__(learn)\n        self.eps, self.thresh, self.sigmoid, self.average, self.beta2 = (\n            eps,",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "fbeta",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def fbeta(\n    y_pred: Tensor,\n    y_true: Tensor,\n    thresh: float = 0.2,\n    beta: float = 2,\n    eps: float = 1e-9,\n    sigmoid: bool = True,\n) -> Rank0Tensor:\n    \"Computes the f_beta between `preds` and `targets`\"\n    beta2 = beta**2",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def accuracy(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=-1).view(n, -1)\n    targs = targs.view(n, -1)\n    return (input == targs).float().mean()\ndef accuracy_thresh(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Computes accuracy when `y_pred` and `y_true` are the same size.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_thresh",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def accuracy_thresh(\n    y_pred: Tensor, y_true: Tensor, thresh: float = 0.5, sigmoid: bool = True\n) -> Rank0Tensor:\n    \"Computes accuracy when `y_pred` and `y_true` are the same size.\"\n    if sigmoid:\n        y_pred = y_pred.sigmoid()\n    return ((y_pred > thresh) == y_true.byte()).float().mean()\ndef top_k_accuracy(input: Tensor, targs: Tensor, k: int = 5) -> Rank0Tensor:\n    \"Computes the Top-k accuracy (target is in the top k predictions).\"\n    input = input.topk(k=k, dim=-1)[1]",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "top_k_accuracy",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def top_k_accuracy(input: Tensor, targs: Tensor, k: int = 5) -> Rank0Tensor:\n    \"Computes the Top-k accuracy (target is in the top k predictions).\"\n    input = input.topk(k=k, dim=-1)[1]\n    targs = targs.unsqueeze(dim=-1).expand_as(input)\n    return (input == targs).max(dim=-1)[0].float().mean()\ndef foreground_acc(input, target, void_code):\n    \"Computes non-background accuracy, e.g. camvid for multiclass segmentation\"\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask] == target[mask]).float().mean()",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "foreground_acc",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def foreground_acc(input, target, void_code):\n    \"Computes non-background accuracy, e.g. camvid for multiclass segmentation\"\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask] == target[mask]).float().mean()\ndef error_rate(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"1 - `accuracy`\"\n    return 1 - accuracy(input, targs)\ndef dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "error_rate",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def error_rate(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    \"1 - `accuracy`\"\n    return 1 - accuracy(input, targs)\ndef dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8\n) -> Rank0Tensor:\n    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n, -1)\n    targs = targs.view(n, -1)",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "dice",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def dice(\n    input: Tensor, targs: Tensor, iou: bool = False, eps: float = 1e-8\n) -> Rank0Tensor:\n    \"Dice coefficient metric for binary target. If iou=True, returns iou metric, classic for segmentation problems.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=1).view(n, -1)\n    targs = targs.view(n, -1)\n    intersect = (input * targs).sum().float()\n    union = (input + targs).sum().float()\n    if not iou:",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "psnr",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def psnr(input: Tensor, targs: Tensor) -> Rank0Tensor:\n    return 10 * (1.0 / mean_squared_error(input, targs)).log10()\ndef exp_rmspe(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Exp RMSE between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    pred, targ = torch.exp(pred), torch.exp(targ)\n    pct_var = (targ - pred) / targ\n    return torch.sqrt((pct_var**2).mean())\ndef mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "exp_rmspe",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def exp_rmspe(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Exp RMSE between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    pred, targ = torch.exp(pred), torch.exp(targ)\n    pct_var = (targ - pred) / targ\n    return torch.sqrt((pct_var**2).mean())\ndef mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.abs(targ - pred).mean()",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_absolute_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.abs(targ - pred).mean()\ndef mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(pred, targ)\ndef root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(pred, targ)\ndef root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.sqrt(F.mse_loss(pred, targ))\ndef mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "root_mean_squared_error",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def root_mean_squared_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Root mean squared error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return torch.sqrt(F.mse_loss(pred, targ))\ndef mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(torch.log(1 + pred), torch.log(1 + targ))\ndef explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_logarithmic_error",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def mean_squared_logarithmic_error(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Mean squared logarithmic error between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    return F.mse_loss(torch.log(1 + pred), torch.log(1 + targ))\ndef explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    var_pct = torch.var(targ - pred) / torch.var(targ)\n    return 1 - var_pct\ndef r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "explained_variance",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def explained_variance(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"Explained variance between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    var_pct = torch.var(targ - pred) / torch.var(targ)\n    return 1 - var_pct\ndef r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"R2 score (coefficient of determination) between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    u = torch.sum((targ - pred) ** 2)\n    d = torch.sum((targ - targ.mean()) ** 2)",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def r2_score(pred: Tensor, targ: Tensor) -> Rank0Tensor:\n    \"R2 score (coefficient of determination) between `pred` and `targ`.\"\n    pred, targ = flatten_check(pred, targ)\n    u = torch.sum((targ - pred) ** 2)\n    d = torch.sum((targ - targ.mean()) ** 2)\n    return 1 - u / d\nclass RegMetrics(Callback):\n    \"Stores predictions and targets to perform calculations on epoch end.\"\n    def on_epoch_begin(self, **kwargs):\n        self.targs, self.preds = Tensor([]), Tensor([])",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "auc_roc_score",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def auc_roc_score(input: Tensor, targ: Tensor):\n    \"Computes the area under the receiver operator characteristic (ROC) curve using the trapezoid method. Restricted binary classification tasks.\"\n    fpr, tpr = roc_curve(input, targ)\n    d = fpr[1:] - fpr[:-1]\n    sl1, sl2 = [slice(None)], [slice(None)]\n    sl1[-1], sl2[-1] = slice(1, None), slice(None, -1)\n    return (d * (tpr[tuple(sl1)] + tpr[tuple(sl2)]) / 2.0).sum(-1)\ndef roc_curve(input: Tensor, targ: Tensor):\n    \"Computes the receiver operator characteristic (ROC) curve by determining the true positive ratio (TPR) and false positive ratio (FPR) for various classification thresholds. Restricted binary classification tasks.\"\n    targ = targ == 1",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "def roc_curve(input: Tensor, targ: Tensor):\n    \"Computes the receiver operator characteristic (ROC) curve by determining the true positive ratio (TPR) and false positive ratio (FPR) for various classification thresholds. Restricted binary classification tasks.\"\n    targ = targ == 1\n    desc_score_indices = torch.flip(input.argsort(-1), [-1])\n    input = input[desc_score_indices]\n    targ = targ[desc_score_indices]\n    d = input[1:] - input[:-1]\n    distinct_value_indices = torch.nonzero(d).transpose(0, 1)[0]\n    threshold_idxs = torch.cat(\n        (distinct_value_indices, LongTensor([len(targ) - 1]).to(targ.device))",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "__all__ = [\n    \"error_rate\",\n    \"accuracy\",\n    \"accuracy_thresh\",\n    \"dice\",\n    \"exp_rmspe\",\n    \"fbeta\",\n    \"FBeta\",\n    \"mse\",\n    \"mean_squared_error\",",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "mse = mean_squared_error\nmae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "mae",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "mae = mean_absolute_error\nmsle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "msle",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "msle = mean_squared_logarithmic_error\nrmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.metrics",
        "description": "dashboard.dl_model.deoldify.fastai.metrics",
        "peekOfCode": "rmse = root_mean_squared_error\nclass ConfusionMatrix(Callback):\n    \"Computes the confusion matrix.\"\n    def on_train_begin(self, **kwargs):\n        self.n_classes = 0\n    def on_epoch_begin(self, **kwargs):\n        self.cm = None\n    def on_batch_end(self, last_output: Tensor, last_target: Tensor, **kwargs):\n        preds = last_output.argmax(-1).view(-1).cpu()\n        targs = last_target.cpu()",
        "detail": "dashboard.dl_model.deoldify.fastai.metrics",
        "documentation": {}
    },
    {
        "label": "Param",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.script",
        "description": "dashboard.dl_model.deoldify.fastai.script",
        "peekOfCode": "class Param:\n    \"A parameter in a function used in `anno_parser` or `call_parse`\"\n    help: str = None\n    type: type = None\n    opt: bool = True\n    action: str = None\n    nargs: str = None\n    const: str = None\n    choices: str = None\n    required: bool = None",
        "detail": "dashboard.dl_model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "anno_parser",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.script",
        "description": "dashboard.dl_model.deoldify.fastai.script",
        "peekOfCode": "def anno_parser(func):\n    \"Look at params (annotated with `Param`) in func and return an `ArgumentParser`\"\n    p = ArgumentParser(description=func.__doc__)\n    for k, v in inspect.signature(func).parameters.items():\n        param = func.__annotations__.get(k, Param())\n        kwargs = param.kwargs\n        if v.default != inspect.Parameter.empty:\n            kwargs[\"default\"] = v.default\n        p.add_argument(f\"{param.pre}{k}\", **kwargs)\n    return p",
        "detail": "dashboard.dl_model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "call_parse",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.script",
        "description": "dashboard.dl_model.deoldify.fastai.script",
        "peekOfCode": "def call_parse(func):\n    \"Decorator to create a simple CLI from `func` using `anno_parser`\"\n    name = inspect.currentframe().f_back.f_globals[\"__name__\"]\n    if name == \"__main__\":\n        args = anno_parser(func).parse_args()\n        func(**args.__dict__)\n    else:\n        return func\ndef call_plac(f):\n    \"Decorator to create a simple CLI from `func` using `plac`\"",
        "detail": "dashboard.dl_model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "call_plac",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.script",
        "description": "dashboard.dl_model.deoldify.fastai.script",
        "peekOfCode": "def call_plac(f):\n    \"Decorator to create a simple CLI from `func` using `plac`\"\n    name = inspect.currentframe().f_back.f_globals[\"__name__\"]\n    if name == \"__main__\":\n        import plac\n        res = plac.call(f)\n        if callable(res):\n            res()\n    else:\n        return f",
        "detail": "dashboard.dl_model.deoldify.fastai.script",
        "documentation": {}
    },
    {
        "label": "plot_sixel",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.sixel",
        "description": "dashboard.dl_model.deoldify.fastai.sixel",
        "peekOfCode": "def plot_sixel(fig=None):\n    if not libsixel:\n        warn(\n            \"You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel\"\n        )\n        return\n    if fig is None:\n        fig = plt.gcf()\n    fig.canvas.draw()\n    dpi = fig.get_dpi()",
        "detail": "dashboard.dl_model.deoldify.fastai.sixel",
        "documentation": {}
    },
    {
        "label": "libsixel",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.sixel",
        "description": "dashboard.dl_model.deoldify.fastai.sixel",
        "peekOfCode": "libsixel = try_import(\"libsixel\")\ndef _sixel_encode(data, width, height):\n    s = io.BytesIO()\n    output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)\n    dither = libsixel.sixel_dither_new(256)\n    w, h = int(width), int(height)\n    libsixel.sixel_dither_initialize(\n        dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888\n    )\n    libsixel.sixel_encode(data, w, h, 1, dither, output)",
        "detail": "dashboard.dl_model.deoldify.fastai.sixel",
        "documentation": {}
    },
    {
        "label": "Module",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "class Module(nn.Module, metaclass=PrePostInitMeta):\n    \"Same as `nn.Module`, but no need for subclasses to call `super().__init__`\"\n    def __pre_init__(self):\n        super().__init__()\n    def __init__(self):\n        pass\ndef np_address(x: np.ndarray) -> int:\n    \"Address of `x` in memory.\"\n    return x.__array_interface__[\"data\"][0]\ndef to_detach(b: Tensors, cpu: bool = True):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ParameterModule",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "class ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p\n    def forward(self, x):\n        return x\ndef children_and_parameters(m: nn.Module):\n    \"Return the children of `m` and its direct parameters not registered in modules.\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ModelOnCPU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "class ModelOnCPU:\n    \"A context manager to evaluate `model` on the CPU inside.\"\n    def __init__(self, model: nn.Module):\n        self.model = model\n    def __enter__(self):\n        self.device = one_param(self.model).device\n        return self.model.cpu()\n    def __exit__(self, type, value, traceback):\n        self.model = self.model.to(self.device)\nclass NoneReduceOnCPU:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "NoneReduceOnCPU",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "class NoneReduceOnCPU:\n    \"A context manager to evaluate `loss_func` with none reduce and weights on the CPU inside.\"\n    def __init__(self, loss_func: LossFunction):\n        self.loss_func, self.device, self.old_red = loss_func, None, None\n    def __enter__(self):\n        if hasattr(self.loss_func, \"weight\") and self.loss_func.weight is not None:\n            self.device = self.loss_func.weight.device\n            self.loss_func.weight = self.loss_func.weight.cpu()\n        if hasattr(self.loss_func, \"reduction\"):\n            self.old_red = getattr(self.loss_func, \"reduction\")",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "is_pool_type",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def is_pool_type(l: Callable):\n    return re.search(r\"Pool[123]d$\", l.__class__.__name__)\nno_wd_types = bn_types + (nn.LayerNorm,)\ndefaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "tensor",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):\n        x = (x,) + rest\n    # XXX: Pytorch bug in dataloader using num_workers>0; TODO: create repro and report\n    if is_listy(x) and len(x) == 0:\n        return tensor(0)\n    res = torch.tensor(x) if is_listy(x) else as_tensor(x)\n    if res.dtype is torch.int32:\n        warn(",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np_address",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def np_address(x: np.ndarray) -> int:\n    \"Address of `x` in memory.\"\n    return x.__array_interface__[\"data\"][0]\ndef to_detach(b: Tensors, cpu: bool = True):\n    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n    def _inner(x, cpu=True):\n        if not isinstance(x, Tensor):\n            return x\n        x = x.detach()\n        return x.cpu() if cpu else x",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_detach",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_detach(b: Tensors, cpu: bool = True):\n    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n    def _inner(x, cpu=True):\n        if not isinstance(x, Tensor):\n            return x\n        x = x.detach()\n        return x.cpu() if cpu else x\n    return recurse(_inner, b, cpu=cpu)\ndef to_data(b: ItemsList):\n    \"Recursively map lists of items in `b ` to their wrapped data.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_data",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_data(b: ItemsList):\n    \"Recursively map lists of items in `b ` to their wrapped data.\"\n    return recurse(lambda x: x.data if isinstance(x, ItemBase) else x, b)\ndef to_cpu(b: ItemsList):\n    \"Recursively map lists of tensors in `b ` to the cpu.\"\n    return recurse(lambda x: x.cpu() if isinstance(x, Tensor) else x, b)\ndef to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_cpu",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_cpu(b: ItemsList):\n    \"Recursively map lists of tensors in `b ` to the cpu.\"\n    return recurse(lambda x: x.cpu() if isinstance(x, Tensor) else x, b)\ndef to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_half",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.half()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,\n    )\ndef to_float(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_float",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_float(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Recursively map lists of tensors in `b ` to FP16.\"\n    return recurse(\n        lambda x: x.float()\n        if x.dtype not in [torch.int64, torch.int32, torch.int16]\n        else x,\n        b,\n    )\ndef to_device(b: Tensors, device: torch.device):\n    \"Recursively put `b` on `device`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_device",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_device(b: Tensors, device: torch.device):\n    \"Recursively put `b` on `device`.\"\n    device = ifnone(device, defaults.device)\n    return recurse(lambda x: x.to(device, non_blocking=True), b)\ndef data_collate(batch: ItemsList) -> Tensor:\n    \"Convert `batch` items to tensor data.\"\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\ndef requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "data_collate",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def data_collate(batch: ItemsList) -> Tensor:\n    \"Convert `batch` items to tensor data.\"\n    return torch.utils.data.dataloader.default_collate(to_data(batch))\ndef requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())\n    if not ps:\n        return None\n    if b is None:\n        return ps[0].requires_grad",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "requires_grad",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def requires_grad(m: nn.Module, b: Optional[bool] = None) -> Optional[bool]:\n    \"If `b` is not set return `requires_grad` of first param, else set `requires_grad` on all params as `b`\"\n    ps = list(m.parameters())\n    if not ps:\n        return None\n    if b is None:\n        return ps[0].requires_grad\n    for p in ps:\n        p.requires_grad = b\ndef trainable_params(m: nn.Module) -> ParamList:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "trainable_params",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def trainable_params(m: nn.Module) -> ParamList:\n    \"Return list of trainable params in `m`.\"\n    res = filter(lambda p: p.requires_grad, m.parameters())\n    return res\ndef children(m: nn.Module) -> ModuleList:\n    \"Get children of `m`.\"\n    return list(m.children())\ndef num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "children",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def children(m: nn.Module) -> ModuleList:\n    \"Get children of `m`.\"\n    return list(m.children())\ndef num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))\ndef range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "num_children",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def num_children(m: nn.Module) -> int:\n    \"Get number of children modules in `m`.\"\n    return len(children(m))\ndef range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "range_children",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def range_children(m: nn.Module) -> Iterator[int]:\n    \"Return iterator of len of children of `m`.\"\n    return range(num_children(m))\nclass ParameterModule(Module):\n    \"Register a lone parameter `p` in a module.\"\n    def __init__(self, p: nn.Parameter):\n        self.val = p\n    def forward(self, x):\n        return x\ndef children_and_parameters(m: nn.Module):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "children_and_parameters",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def children_and_parameters(m: nn.Module):\n    \"Return the children of `m` and its direct parameters not registered in modules.\"\n    children = list(m.children())\n    children_p = sum([[id(p) for p in c.parameters()] for c in m.children()], [])\n    for p in m.parameters():\n        if id(p) not in children_p:\n            children.append(ParameterModule(p))\n    return children\ndef flatten_model(m: nn.Module):\n    if num_children(m):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "flatten_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def flatten_model(m: nn.Module):\n    if num_children(m):\n        mapped = map(flatten_model, children_and_parameters(m))\n        return sum(mapped, [])\n    else:\n        return [m]\n# flatten_model = lambda m: sum(map(flatten_model,children_and_parameters(m)),[]) if num_children(m) else [m]\ndef first_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve first layer in a module `m`.\"\n    return flatten_model(m)[0]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "first_layer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def first_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve first layer in a module `m`.\"\n    return flatten_model(m)[0]\ndef last_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve last layer in a module `m`.\"\n    return flatten_model(m)[-1]\ndef split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "last_layer",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def last_layer(m: nn.Module) -> nn.Module:\n    \"Retrieve last layer in a module `m`.\"\n    return flatten_model(m)[-1]\ndef split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:\n        idxs = [0] + idxs\n    if idxs[-1] != len(layers):\n        idxs.append(len(layers))",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_model_idx",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_model_idx(model: nn.Module, idxs: Collection[int]) -> ModuleList:\n    \"Split `model` according to the indexes in `idxs`.\"\n    layers = flatten_model(model)\n    if idxs[0] != 0:\n        idxs = [0] + idxs\n    if idxs[-1] != len(layers):\n        idxs.append(len(layers))\n    return [nn.Sequential(*layers[i:j]) for i, j in zip(idxs[:-1], idxs[1:])]\ndef split_model(\n    model: nn.Module = None, splits: Collection[Union[nn.Module, ModuleList]] = None",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_model(\n    model: nn.Module = None, splits: Collection[Union[nn.Module, ModuleList]] = None\n):\n    \"Split `model` according to the layers in `splits`.\"\n    splits = listify(splits)\n    if isinstance(splits[0], nn.Module):\n        layers = flatten_model(model)\n        idxs = [layers.index(first_layer(s)) for s in splits]\n        return split_model_idx(model, idxs)\n    return [nn.Sequential(*s) for s in splits]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "get_param_groups",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def get_param_groups(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    return [\n        sum([list(trainable_params(c)) for c in l.children()], []) for l in layer_groups\n    ]\ndef split_no_wd_params(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    \"Separate the parameters in `layer_groups` between `no_wd_types` and  bias (`bias_types`) from the rest.\"\n    split_params = []\n    for l in layer_groups:\n        l1, l2 = [], []\n        for c in l.children():",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "split_no_wd_params",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def split_no_wd_params(layer_groups: Collection[nn.Module]) -> List[List[nn.Parameter]]:\n    \"Separate the parameters in `layer_groups` between `no_wd_types` and  bias (`bias_types`) from the rest.\"\n    split_params = []\n    for l in layer_groups:\n        l1, l2 = [], []\n        for c in l.children():\n            if isinstance(c, no_wd_types):\n                l2 += list(trainable_params(c))\n            elif isinstance(c, bias_types):\n                bias = c.bias if hasattr(c, \"bias\") else None",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "set_bn_eval",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def set_bn_eval(m: nn.Module) -> None:\n    \"Set bn layers in eval mode for all recursive children of `m`.\"\n    for l in m.children():\n        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n            l.eval()\n        set_bn_eval(l)\ndef batch_to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Set the input of batch `b` to half precision.\"\n    return [to_half(b[0]), b[1]]\ndef bn2float(module: nn.Module) -> nn.Module:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "batch_to_half",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def batch_to_half(b: Collection[Tensor]) -> Collection[Tensor]:\n    \"Set the input of batch `b` to half precision.\"\n    return [to_half(b[0]), b[1]]\ndef bn2float(module: nn.Module) -> nn.Module:\n    \"If `module` is batchnorm don't use half precision.\"\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        bn2float(child)\n    return module",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bn2float",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def bn2float(module: nn.Module) -> nn.Module:\n    \"If `module` is batchnorm don't use half precision.\"\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        bn2float(child)\n    return module\ndef model2half(model: nn.Module) -> nn.Module:\n    \"Convert `model` to half precision except the batchnorm layers.\"\n    return bn2float(model.half())",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "model2half",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def model2half(model: nn.Module) -> nn.Module:\n    \"Convert `model` to half precision except the batchnorm layers.\"\n    return bn2float(model.half())\ndef init_default(m: nn.Module, func: LayerFunc = nn.init.kaiming_normal_) -> nn.Module:\n    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n    if func:\n        if hasattr(m, \"weight\"):\n            func(m.weight)\n        if hasattr(m, \"bias\") and hasattr(m.bias, \"data\"):\n            m.bias.data.fill_(0.0)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "init_default",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def init_default(m: nn.Module, func: LayerFunc = nn.init.kaiming_normal_) -> nn.Module:\n    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n    if func:\n        if hasattr(m, \"weight\"):\n            func(m.weight)\n        if hasattr(m, \"bias\") and hasattr(m.bias, \"data\"):\n            m.bias.data.fill_(0.0)\n    return m\ndef cond_init(m: nn.Module, init_func: LayerFunc):\n    \"Initialize the non-batchnorm layers of `m` with `init_func`.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "cond_init",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def cond_init(m: nn.Module, init_func: LayerFunc):\n    \"Initialize the non-batchnorm layers of `m` with `init_func`.\"\n    if (not isinstance(m, bn_types)) and requires_grad(m):\n        init_default(m, init_func)\ndef apply_leaf(m: nn.Module, f: LayerFunc):\n    \"Apply `f` to children of `m`.\"\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    for l in c:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_leaf",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def apply_leaf(m: nn.Module, f: LayerFunc):\n    \"Apply `f` to children of `m`.\"\n    c = children(m)\n    if isinstance(m, nn.Module):\n        f(m)\n    for l in c:\n        apply_leaf(l, f)\ndef apply_init(m, init_func: LayerFunc):\n    \"Initialize all non-batchnorm layers of `m` with `init_func`.\"\n    apply_leaf(m, partial(cond_init, init_func=init_func))",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "apply_init",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def apply_init(m, init_func: LayerFunc):\n    \"Initialize all non-batchnorm layers of `m` with `init_func`.\"\n    apply_leaf(m, partial(cond_init, init_func=init_func))\ndef in_channels(m: nn.Module) -> List[int]:\n    \"Return the shape of the first weight layer in `m`.\"\n    for l in flatten_model(m):\n        if hasattr(l, \"weight\"):\n            return l.weight.shape[1]\n    raise Exception(\"No weight layer\")\nclass ModelOnCPU:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "in_channels",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def in_channels(m: nn.Module) -> List[int]:\n    \"Return the shape of the first weight layer in `m`.\"\n    for l in flatten_model(m):\n        if hasattr(l, \"weight\"):\n            return l.weight.shape[1]\n    raise Exception(\"No weight layer\")\nclass ModelOnCPU:\n    \"A context manager to evaluate `model` on the CPU inside.\"\n    def __init__(self, model: nn.Module):\n        self.model = model",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "model_type",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def model_type(dtype):\n    \"Return the torch type corresponding to `dtype`.\"\n    return (\n        torch.float32\n        if np.issubdtype(dtype, np.floating)\n        else torch.int64\n        if np.issubdtype(dtype, np.integer)\n        else None\n    )\ndef np2model_tensor(a):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np2model_tensor",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def np2model_tensor(a):\n    \"Tranform numpy array `a` to a tensor of the same type.\"\n    dtype = model_type(a.dtype)\n    res = as_tensor(a)\n    if not dtype:\n        return res\n    return res.type(dtype)\ndef _pca(x, k=2):\n    \"Compute PCA of `x` with `k` dimensions.\"\n    x = x - torch.mean(x, 0)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "trange_of",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def trange_of(x):\n    \"Create a tensor from `range_of(x)`.\"\n    return torch.arange(len(x))\ndef to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "to_np",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:\n        return res\n    else:\n        return res.astype(dtype, copy=False)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "tensor__array__",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def tensor__array__(self, dtype=None):\n    res = to_np(self)\n    if dtype is None:\n        return res\n    else:\n        return res.astype(dtype, copy=False)\nTensor.__array__ = tensor__array__\nTensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "grab_idx",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)\n    return -(1 / x - 1).log()",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "logit",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)\n    return -(1 / x - 1).log()\ndef logit_(x: Tensor) -> Tensor:\n    \"Inplace logit of `x`, clamped to avoid inf\"\n    x.clamp_(1e-7, 1 - 1e-7)\n    return (x.reciprocal_().sub_(1)).log_().neg_()\ndef set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "logit_",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def logit_(x: Tensor) -> Tensor:\n    \"Inplace logit of `x`, clamped to avoid inf\"\n    x.clamp_(1e-7, 1 - 1e-7)\n    return (x.reciprocal_().sub_(1)).log_().neg_()\ndef set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\ndef uniform(",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "set_all_seed",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def set_all_seed(seed: int) -> None:\n    \"Sets the seeds for all pseudo random generators in fastai lib\"\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    random.seed(seed)\ndef uniform(\n    low: Number, high: Number = None, size: Optional[List[int]] = None\n) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.\"\n    if high is None:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "uniform",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def uniform(\n    low: Number, high: Number = None, size: Optional[List[int]] = None\n) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=`low`, max=`high`.\"\n    if high is None:\n        high = low\n    return (\n        random.uniform(low, high)\n        if size is None\n        else torch.FloatTensor(*listify(size)).uniform_(low, high)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "log_uniform",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def log_uniform(low, high, size: Optional[List[int]] = None) -> FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).\"\n    res = uniform(log(low), log(high), size)\n    return exp(res) if size is None else res.exp_()\ndef rand_bool(p: float, size: Optional[List[int]] = None) -> BoolOrTensor:\n    \"Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).\"\n    return uniform(0, 1, size) < p\ndef uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "rand_bool",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def rand_bool(p: float, size: Optional[List[int]] = None) -> BoolOrTensor:\n    \"Draw 1 or shape=`size` random booleans (`True` occuring with probability `p`).\"\n    return uniform(0, 1, size) < p\ndef uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (\n        random.randint(low, high)\n        if size is None\n        else torch.randint(low, high + 1, size)\n    )",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "uniform_int",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def uniform_int(low: int, high: int, size: Optional[List[int]] = None) -> IntOrTensor:\n    \"Generate int or tensor `size` of ints between `low` and `high` (included).\"\n    return (\n        random.randint(low, high)\n        if size is None\n        else torch.randint(low, high + 1, size)\n    )\ndef one_param(m: nn.Module) -> Tensor:\n    \"Return the first parameter of `m`.\"\n    return next(m.parameters())",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "one_param",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def one_param(m: nn.Module) -> Tensor:\n    \"Return the first parameter of `m`.\"\n    return next(m.parameters())\ndef try_int(o: Any) -> Any:\n    \"Try to convert `o` to int, default to `o` if not possible.\"\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don't want to do this\n    if isinstance(o, (np.ndarray, Tensor)):\n        return o if o.ndim else int(o)\n    if isinstance(o, collections.abc.Sized) or getattr(o, \"__array_interface__\", False):\n        return o",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "try_int",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def try_int(o: Any) -> Any:\n    \"Try to convert `o` to int, default to `o` if not possible.\"\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don't want to do this\n    if isinstance(o, (np.ndarray, Tensor)):\n        return o if o.ndim else int(o)\n    if isinstance(o, collections.abc.Sized) or getattr(o, \"__array_interface__\", False):\n        return o\n    try:\n        return int(o)\n    except:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def get_model(model: nn.Module):\n    \"Return the model maybe wrapped inside `model`.\"\n    return (\n        model.module\n        if isinstance(model, (DistributedDataParallel, nn.DataParallel))\n        else model\n    )\ndef flatten_check(out: Tensor, targ: Tensor) -> Tensor:\n    \"Check that `out` and `targ` have the same number of elements and flatten them.\"\n    out, targ = out.contiguous().view(-1), targ.contiguous().view(-1)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "flatten_check",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def flatten_check(out: Tensor, targ: Tensor) -> Tensor:\n    \"Check that `out` and `targ` have the same number of elements and flatten them.\"\n    out, targ = out.contiguous().view(-1), targ.contiguous().view(-1)\n    assert len(out) == len(\n        targ\n    ), f\"Expected output and target to have the same number of elements but got {len(out)} and {len(targ)}.\"\n    return out, targ\n# Monkey-patch nn.DataParallel.reset\ndef _data_parallel_reset(self):\n    if hasattr(self.module, \"reset\"):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "remove_module_load",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def remove_module_load(state_dict):\n    \"\"\"create new OrderedDict that does not contain `module.`\"\"\"\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        new_state_dict[k[7:]] = v\n    return new_state_dict\ndef num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))\ndef rank_distrib():",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "num_distrib",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))\ndef rank_distrib():\n    \"Return the distributed rank of this process (if applicable).\"\n    return int(os.environ.get(\"RANK\", 0))\ndef add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "rank_distrib",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def rank_distrib():\n    \"Return the distributed rank of this process (if applicable).\"\n    return int(os.environ.get(\"RANK\", 0))\ndef add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):\n    \"Return a dictionary for updating `last_metrics` with `mets`.\"\n    last_metrics, mets = listify(last_metrics), listify(mets)\n    return {\"last_metrics\": last_metrics + mets}",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "add_metrics",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def add_metrics(\n    last_metrics: Collection[Rank0Tensor],\n    mets: Union[Rank0Tensor, Collection[Rank0Tensor]],\n):\n    \"Return a dictionary for updating `last_metrics` with `mets`.\"\n    last_metrics, mets = listify(last_metrics), listify(mets)\n    return {\"last_metrics\": last_metrics + mets}\ndef try_save(state: Dict, path: Path = None, file: PathLikeOrBinaryStream = None):\n    target = open(path / file, \"wb\") if is_pathlike(file) else file\n    try:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "try_save",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def try_save(state: Dict, path: Path = None, file: PathLikeOrBinaryStream = None):\n    target = open(path / file, \"wb\") if is_pathlike(file) else file\n    try:\n        torch.save(state, target)\n    except OSError as e:\n        raise Exception(\n            f\"{e}\\n Can't write {path/file}. Pass an absolute writable pathlib obj `fname`.\"\n        )\ndef np_func(f):\n    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "np_func",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "def np_func(f):\n    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"\n    def _inner(*args, **kwargs):\n        nargs = [to_np(arg) if isinstance(arg, Tensor) else arg for arg in args]\n        return tensor(f(*nargs, **kwargs))\n    functools.update_wrapper(_inner, f)\n    return _inner",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AffineMatrix",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "AffineMatrix = Tensor\nBoolOrTensor = Union[bool, Tensor]\nFloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "BoolOrTensor",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "BoolOrTensor = Union[bool, Tensor]\nFloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "FloatOrTensor",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "FloatOrTensor = Union[float, Tensor]\nIntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "IntOrTensor",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "IntOrTensor = Union[int, Tensor]\nItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ItemsList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "ItemsList = Collection[Union[Tensor, ItemBase, \"ItemsList\", float, int]]\nLambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LambdaFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "LambdaFunc = Callable[[Tensor], Tensor]\nLayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LayerFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "LayerFunc = Callable[[nn.Module], None]\nModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ModuleList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "ModuleList = Collection[nn.Module]\nNPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "NPArray",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "NPArray = np.ndarray\nOptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptOptimizer",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "OptOptimizer = Optional[optim.Optimizer]\nParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ParamList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "ParamList = Collection[nn.Parameter]\nRank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Rank0Tensor",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "Rank0Tensor = NewType(\"OneEltTensor\", Tensor)\nSplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "SplitFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "SplitFunc = Callable[[nn.Module], List[nn.Module]]\nSplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "SplitFuncOrIdxList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "SplitFuncOrIdxList = Union[Callable, Collection[ModuleList]]\nTensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorOrNumber",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorOrNumber = Union[Tensor, Number]\nTensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorOrNumList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorOrNumList = Collection[TensorOrNumber]\nTensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorImage",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorImage = Tensor\nTensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "TensorImageSize",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "TensorImageSize = Tuple[int, int, int]\nTensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensors",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensors = Union[Tensor, Collection[\"Tensors\"]]\nWeights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Weights",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "Weights = Dict[str, Tensor]\nAffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AffineFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "AffineFunc = Callable[[KWArgs], AffineMatrix]\nHookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "HookFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "HookFunc = Callable[[nn.Module, Tensors, Tensors], Any]\nLogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LogitTensorImage",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "LogitTensorImage = TensorImage\nLossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LossFunction",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "LossFunction = Callable[[Tensor, Tensor], Rank0Tensor]\nMetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricFunc = Callable[[Tensor, Tensor], TensorOrNumber]\nMetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricFuncList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricFuncList = Collection[MetricFunc]\nMetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "MetricsList",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "MetricsList = Collection[TensorOrNumber]\nOptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptLossFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "OptLossFunc = Optional[LossFunction]\nOptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptMetrics",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "OptMetrics = Optional[MetricsList]\nOptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "OptSplitFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "OptSplitFunc = Optional[SplitFunc]\nPixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "PixelFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "PixelFunc = Callable[[TensorImage, ArgStar, KWArgs], TensorImage]\nLightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "LightingFunc",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "LightingFunc = Callable[[LogitTensorImage, ArgStar, KWArgs], LogitTensorImage]\nfastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",\n    KeyFunc: \"KeyFunc\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "fastai_types",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "fastai_types = {\n    AnnealFunc: \"AnnealFunc\",\n    ArgStar: \"ArgStar\",\n    BatchSamples: \"BatchSamples\",\n    FilePathList: \"FilePathList\",\n    Floats: \"Floats\",\n    ImgLabel: \"ImgLabel\",\n    ImgLabels: \"ImgLabels\",\n    KeyFunc: \"KeyFunc\",\n    KWArgs: \"KWArgs\",",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bn_types",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\nbias_types = (\n    nn.Linear,\n    nn.Conv1d,\n    nn.Conv2d,\n    nn.Conv3d,\n    nn.ConvTranspose1d,\n    nn.ConvTranspose2d,\n    nn.ConvTranspose3d,\n)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "bias_types",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "bias_types = (\n    nn.Linear,\n    nn.Conv1d,\n    nn.Conv2d,\n    nn.Conv3d,\n    nn.ConvTranspose1d,\n    nn.ConvTranspose2d,\n    nn.ConvTranspose3d,\n)\ndef is_pool_type(l: Callable):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "no_wd_types",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "no_wd_types = bn_types + (nn.LayerNorm,)\ndefaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "defaults.device",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "defaults.device = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\nAdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "AdamW",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "AdamW = partial(optim.Adam, betas=(0.9, 0.99))\n# Monkey-patch `torch.cuda.set_device` so that it updates `defaults.device`\n_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device\n    )\ntorch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "_old_torch_cuda_set_device",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "_old_torch_cuda_set_device = torch.cuda.set_device\ndef _new_torch_cuda_set_device(device):\n    _old_torch_cuda_set_device(device)\n    defaults.device = (\n        torch.device(\"cuda\", device) if isinstance(device, int) else device\n    )\ntorch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "torch.cuda.set_device",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "torch.cuda.set_device = _new_torch_cuda_set_device\ndef tensor(x: Any, *rest) -> Tensor:\n    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n    if len(rest):\n        x = (x,) + rest\n    # XXX: Pytorch bug in dataloader using num_workers>0; TODO: create repro and report\n    if is_listy(x) and len(x) == 0:\n        return tensor(0)\n    res = torch.tensor(x) if is_listy(x) else as_tensor(x)\n    if res.dtype is torch.int32:",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "torch.Tensor.pca",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "torch.Tensor.pca = _pca\ndef trange_of(x):\n    \"Create a tensor from `range_of(x)`.\"\n    return torch.arange(len(x))\ndef to_np(x):\n    \"Convert a tensor to a numpy array.\"\n    return x.data.cpu().numpy()\n# monkey patching to allow matplotlib to plot tensors\ndef tensor__array__(self, dtype=None):\n    res = to_np(self)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensor.__array__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensor.__array__ = tensor__array__\nTensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "Tensor.ndim",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "Tensor.ndim = property(lambda x: len(x.shape))\ndef grab_idx(x, i, batch_first: bool = True):\n    \"Grab the `i`-th batch in `x`, `batch_first` stating the batch dimension.\"\n    if batch_first:\n        return [o[i].cpu() for o in x] if is_listy(x) else x[i].cpu()\n    else:\n        return [o[:, i].cpu() for o in x] if is_listy(x) else x[:, i].cpu()\ndef logit(x: Tensor) -> Tensor:\n    \"Logit of `x`, clamped to avoid inf.\"\n    x = x.clamp(1e-7, 1 - 1e-7)",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "nn.DataParallel.reset",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.torch_core",
        "description": "dashboard.dl_model.deoldify.fastai.torch_core",
        "peekOfCode": "nn.DataParallel.reset = _data_parallel_reset\ndef remove_module_load(state_dict):\n    \"\"\"create new OrderedDict that does not contain `module.`\"\"\"\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        new_state_dict[k[7:]] = v\n    return new_state_dict\ndef num_distrib():\n    \"Return the number of processes in distributed training (if applicable).\"\n    return int(os.environ.get(\"WORLD_SIZE\", 0))",
        "detail": "dashboard.dl_model.deoldify.fastai.torch_core",
        "documentation": {}
    },
    {
        "label": "ShowGraph",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()\n            x_bounds = (\n                0,",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "BnFreeze",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class BnFreeze(LearnerCallback):\n    \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n    def on_epoch_begin(self, **kwargs: Any) -> None:\n        \"Put bn layers in eval mode just after `model.train()`.\"\n        set_bn_eval(self.learn.model)\nclass GradientClipping(LearnerCallback):\n    \"Gradient clipping during training.\"\n    def __init__(self, learn: Learner, clip: float = 0.0):\n        super().__init__(learn)\n        self.clip = clip",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "GradientClipping",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class GradientClipping(LearnerCallback):\n    \"Gradient clipping during training.\"\n    def __init__(self, learn: Learner, clip: float = 0.0):\n        super().__init__(learn)\n        self.clip = clip\n    def on_backward_end(self, **kwargs):\n        \"Clip the gradient before the optimizer step.\"\n        if self.clip:\n            nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)\ndef clip_grad(learn: Learner, clip: float = 0.1) -> Learner:",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "AccumulateScheduler",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last\n    def on_train_begin(self, **kwargs):\n        \"check if loss is reduction\"\n        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n            warn(\"For better gradients consider 'reduction=sum'\")\n    def on_epoch_begin(self, **kwargs):",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Interpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class Interpretation:\n    \"Interpretation base class, can be inherited for task specific Interpretation classes\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "ClassificationInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class ClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n    ):",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "MultiLabelClassificationInterpretation",
        "kind": 6,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "class MultiLabelClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,\n        sigmoid: bool = True,",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "one_cycle_scheduler",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def one_cycle_scheduler(lr_max: float, **kwargs: Any) -> OneCycleScheduler:\n    \"Instantiate a `OneCycleScheduler` with `lr_max`.\"\n    return partial(OneCycleScheduler, lr_max=lr_max, **kwargs)\ndef fit_one_cycle(\n    learn: Learner,\n    cyc_len: int,\n    max_lr: Union[Floats, slice] = defaults.lr,\n    moms: Tuple[float, float] = (0.95, 0.85),\n    div_factor: float = 25.0,\n    pct_start: float = 0.3,",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "fit_one_cycle",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def fit_one_cycle(\n    learn: Learner,\n    cyc_len: int,\n    max_lr: Union[Floats, slice] = defaults.lr,\n    moms: Tuple[float, float] = (0.95, 0.85),\n    div_factor: float = 25.0,\n    pct_start: float = 0.3,\n    final_div: float = None,\n    wd: float = None,\n    callbacks: Optional[CallbackList] = None,",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "lr_find",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def lr_find(\n    learn: Learner,\n    start_lr: Floats = 1e-7,\n    end_lr: Floats = 10,\n    num_it: int = 100,\n    stop_div: bool = True,\n    wd: float = None,\n    batch_multiplier: int = 1,\n):\n    \"Explore lr from `start_lr` to `end_lr` over `num_it` iterations in `learn`. If `stop_div`, stops when loss diverges.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "to_fp16",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def to_fp16(\n    learn: Learner,\n    loss_scale: float = None,\n    max_noskip: int = 1000,\n    dynamic: bool = True,\n    clip: float = None,\n    flat_master: bool = False,\n    max_scale: float = 2**24,\n) -> Learner:\n    \"Put `learn` in FP16 precision mode.\"",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "to_fp32",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def to_fp32(learn: Learner):\n    \"Put `learn` back to FP32 precision mode.\"\n    learn.data.remove_tfm(batch_to_half)\n    for cb in learn.callbacks:\n        if isinstance(cb, MixedPrecision):\n            learn.callbacks.remove(cb)\n    learn.model = learn.model.float()\n    return learn\ndef mixup(\n    learn: Learner, alpha: float = 0.4, stack_x: bool = False, stack_y: bool = True",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "mixup",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def mixup(\n    learn: Learner, alpha: float = 0.4, stack_x: bool = False, stack_y: bool = True\n) -> Learner:\n    \"Add mixup https://arxiv.org/abs/1710.09412 to `learn`.\"\n    learn.callback_fns.append(\n        partial(MixUpCallback, alpha=alpha, stack_x=stack_x, stack_y=stack_y)\n    )\n    return learn\nLearner.fit_one_cycle = fit_one_cycle\nLearner.lr_find = lr_find",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "clip_grad",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "def clip_grad(learn: Learner, clip: float = 0.1) -> Learner:\n    \"Add gradient clipping of `clip` during training.\"\n    learn.callback_fns.append(partial(GradientClipping, clip=clip))\n    return learn\nLearner.clip_grad = clip_grad\nclass AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "__all__ = [\n    \"BnFreeze\",\n    \"GradientClipping\",\n    \"ShowGraph\",\n    \"Interpretation\",\n    \"ClassificationInterpretation\",\n    \"MultiLabelClassificationInterpretation\",\n    \"fit_one_cycle\",\n    \"lr_find\",\n    \"one_cycle_scheduler\",",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.fit_one_cycle",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.fit_one_cycle = fit_one_cycle\nLearner.lr_find = lr_find\nLearner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.lr_find",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.lr_find = lr_find\nLearner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.to_fp16",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.to_fp16 = to_fp16\nLearner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.to_fp32",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.to_fp32 = to_fp32\nLearner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.mixup",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.mixup = mixup\nclass ShowGraph(LearnerCallback):\n    \"Update a graph of learner stats and metrics after each epoch.\"\n    def on_epoch_end(self, n_epochs: int, last_metrics: MetricsList, **kwargs) -> bool:\n        \"If we have `last_metrics` plot them in our pbar graph\"\n        if last_metrics is not None and last_metrics[0] is not None:\n            rec = self.learn.recorder\n            iters = range_of(rec.losses)\n            val_iter = np.array(rec.nb_batches).cumsum()\n            x_bounds = (",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.clip_grad",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.clip_grad = clip_grad\nclass AccumulateScheduler(LearnerCallback):\n    \"Does accumlated step every nth step by accumulating gradients\"\n    def __init__(self, learn: Learner, n_step: int = 1, drop_last: bool = False):\n        super().__init__(learn)\n        self.n_step, self.drop_last = n_step, drop_last\n    def on_train_begin(self, **kwargs):\n        \"check if loss is reduction\"\n        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n            warn(\"For better gradients consider 'reduction=sum'\")",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "Learner.interpret",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.train",
        "description": "dashboard.dl_model.deoldify.fastai.train",
        "peekOfCode": "Learner.interpret = _learner_interpret\nclass MultiLabelClassificationInterpretation(Interpretation):\n    \"Interpretation methods for classification models.\"\n    def __init__(\n        self,\n        learn: Learner,\n        preds: Tensor,\n        y_true: Tensor,\n        losses: Tensor,\n        ds_type: DatasetType = DatasetType.Valid,",
        "detail": "dashboard.dl_model.deoldify.fastai.train",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.version",
        "description": "dashboard.dl_model.deoldify.fastai.version",
        "peekOfCode": "__all__ = [\"__version__\"]\n__version__ = \"1.0.56.dev0\"",
        "detail": "dashboard.dl_model.deoldify.fastai.version",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "dashboard.dl_model.deoldify.fastai.version",
        "description": "dashboard.dl_model.deoldify.fastai.version",
        "peekOfCode": "__version__ = \"1.0.56.dev0\"",
        "detail": "dashboard.dl_model.deoldify.fastai.version",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.inference",
        "description": "dashboard.dl_model.deoldify.inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_unique_output_path(input_path, output_dir, artistic=True):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    model_type = \"artistic\" if artistic else \"stable\"\n    output_subdir = os.path.join(output_dir, model_type)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")",
        "detail": "dashboard.dl_model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.inference",
        "description": "dashboard.dl_model.deoldify.inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, artistic=True):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    model_type = \"artistic\" if artistic else \"stable\"\n    output_subdir = os.path.join(output_dir, model_type)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(",
        "detail": "dashboard.dl_model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.deoldify.inference",
        "description": "dashboard.dl_model.deoldify.inference",
        "peekOfCode": "def process_image(input_path, render_factor=35, watermarked=True, artistic=True):\n    \"\"\"if not torch.cuda.is_available():\n    print('GPU not available.')\n    return None\"\"\"\n    colorizer = get_image_colorizer(artistic=artistic)\n    output_path = get_unique_output_path(input_path, \"outputs\", artistic)\n    result = colorizer.plot_transformed_image(\n        path=input_path,\n        render_factor=render_factor,\n        compare=False,",
        "detail": "dashboard.dl_model.deoldify.inference",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "get_model_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(\n        os.path.join(output_subdir, f\"{input_filename}_{counter}.jpg\")",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def detect(img):\n    batch_boxes, batch_probs, batch_points = mtcnn.detect(img, landmarks=True)\n    if not mtcnn.keep_all:\n        batch_boxes, batch_probs, batch_points = mtcnn.select_boxes(\n            batch_boxes, batch_probs, batch_points, img, method=mtcnn.selection_method\n        )\n    return batch_boxes, batch_points\ndef makeEven(_x):\n    return int(_x) if (_x % 2 == 0) else int(_x + 1)\ndef scale(",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "makeEven",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def makeEven(_x):\n    return int(_x) if (_x % 2 == 0) else int(_x + 1)\ndef scale(\n    boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2\n):\n    x, y = _img.size\n    ratio = 2\n    if (boxes is not None) and len(boxes) > 0:\n        ratio = target_face / max(boxes[0][2:] - boxes[0][:2])\n        ratio = min(ratio, max_upscale)",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "scale",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def scale(\n    boxes, _img, max_res=1_500_000, target_face=256, fixed_ratio=0, max_upscale=2\n):\n    x, y = _img.size\n    ratio = 2\n    if (boxes is not None) and len(boxes) > 0:\n        ratio = target_face / max(boxes[0][2:] - boxes[0][:2])\n        ratio = min(ratio, max_upscale)\n    if fixed_ratio > 0:\n        ratio = fixed_ratio",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "scale_by_face_size",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def scale_by_face_size(\n    _img, max_res=1_500_000, target_face=256, fix_ratio=0, max_upscale=2\n):\n    boxes, _ = detect(_img)\n    return scale(boxes, _img, max_res, target_face, fix_ratio, max_upscale)\nmeans = [0.485, 0.456, 0.406]\nstds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "tensor2im",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2\n    )\n    model_name = get_model_name(model_path)\n    output_path = get_unique_output_path(input_path, \"outputs\", model_name)",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "def process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2\n    )\n    model_name = get_model_name(model_path)\n    output_path = get_unique_output_path(input_path, \"outputs\", model_name)\n    transformed_image = img_transforms(input_image)[None, ...].cuda().half()\n    with torch.no_grad():",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "mtcnn",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "mtcnn = MTCNN(image_size=256, margin=80)\ndef check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "means",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "means = [0.485, 0.456, 0.406]\nstds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "stds",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "stds = [0.229, 0.224, 0.225]\nt_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "t_stds",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "t_stds = torch.tensor(stds).cuda().half()[:, None, None]\nt_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "t_means",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "t_means = torch.tensor(means).cuda().half()[:, None, None]\nimg_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "img_transforms",
        "kind": 5,
        "importPath": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "description": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "peekOfCode": "img_transforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(means, stds)]\n)\ndef tensor2im(var):\n    return var.mul(t_stds).add(t_means).mul(255.0).clamp(0, 255).permute(1, 2, 0)\ndef process_image(input_path, model_path):\n    model = torch.jit.load(model_path).eval().cuda().half()\n    input_image = PIL.Image.open(input_path).convert(\"RGB\")\n    input_image = scale_by_face_size(\n        input_image, target_face=300, max_res=1_500_000, max_upscale=2",
        "detail": "dashboard.dl_model.image_to_cartoon.arcane_inference",
        "documentation": {}
    },
    {
        "label": "check_folder",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def check_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n    return path\ndef get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "get_model_name",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def get_model_name(model_path):\n    return os.path.splitext(os.path.basename(model_path))[0]\ndef get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "get_unique_output_path",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def get_unique_output_path(input_path, output_dir, model_name):\n    input_filename = os.path.splitext(os.path.basename(input_path))[0]\n    output_subdir = os.path.join(output_dir, model_name)\n    check_folder(output_subdir)\n    base_path = os.path.join(output_subdir, f\"{input_filename}.jpg\")\n    if not os.path.exists(base_path):\n        return base_path\n    counter = 1\n    while os.path.exists(\n        os.path.join(output_subdir, f\"{input_filename}_{counter}.jpg\")",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def process_image(img, model_name):\n    h, w = img.shape[:2]\n    def to_8s(x):\n        if \"tiny\" in os.path.basename(model_name):\n            return 256 if x < 256 else x - x % 16\n        else:\n            return 256 if x < 256 else x - x % 8\n    img = cv2.resize(img, (to_8s(w), to_8s(h)))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 127.5 - 1.0\n    return img",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def load_test_data(image_path, model_name):\n    img0 = cv2.imread(image_path).astype(np.float32)\n    img = process_image(img0, model_name)\n    img = np.expand_dims(img, axis=0)\n    return img, img0.shape\ndef save_images(images, image_path, size):\n    images = (np.squeeze(images) + 1.0) / 2 * 255\n    images = np.clip(images, 0, 255).astype(np.uint8)\n    images = cv2.resize(images, size)\n    cv2.imwrite(image_path, cv2.cvtColor(images, cv2.COLOR_RGB2BGR))",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "save_images",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def save_images(images, image_path, size):\n    images = (np.squeeze(images) + 1.0) / 2 * 255\n    images = np.clip(images, 0, 255).astype(np.uint8)\n    images = cv2.resize(images, size)\n    cv2.imwrite(image_path, cv2.cvtColor(images, cv2.COLOR_RGB2BGR))\ndef process_single_image(input_path, model_path, device=\"gpu\"):\n    if ort.get_device() == \"GPU\" and device == \"gpu\":\n        session = ort.InferenceSession(\n            model_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n        )",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "process_single_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "description": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "peekOfCode": "def process_single_image(input_path, model_path, device=\"gpu\"):\n    if ort.get_device() == \"GPU\" and device == \"gpu\":\n        session = ort.InferenceSession(\n            model_path, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n        )\n    else:\n        session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n    x = session.get_inputs()[0].name\n    y = session.get_outputs()[0].name\n    model_name = get_model_name(model_path)",
        "detail": "dashboard.dl_model.image_to_cartoon.onnx_inference",
        "documentation": {}
    },
    {
        "label": "REBNCONV",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class REBNCONV(nn.Module):\n    def __init__(self, in_ch=3, out_ch=3, dirate=1, stride=1):\n        super(REBNCONV, self).__init__()\n        self.conv_s1 = nn.Conv2d(\n            in_ch, out_ch, 3, padding=1 * dirate, dilation=1 * dirate, stride=stride\n        )\n        self.bn_s1 = nn.BatchNorm2d(out_ch)\n        self.relu_s1 = nn.ReLU(inplace=True)\n    def forward(self, x):\n        hx = x",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU7",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class RSU7(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3, img_size=512):\n        super(RSU7, self).__init__()\n        self.in_ch = in_ch\n        self.mid_ch = mid_ch\n        self.out_ch = out_ch\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)  ## 1 -> 1/2\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU6",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class RSU6(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU6, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU5",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class RSU5(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU5, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class RSU4(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "RSU4F",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class RSU4F(nn.Module):\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4F, self).__init__()\n        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "myrebnconv",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class myrebnconv(nn.Module):\n    def __init__(\n        self,\n        in_ch=3,\n        out_ch=1,\n        kernel_size=3,\n        stride=1,\n        padding=1,\n        dilation=1,\n        groups=1,",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetGTEncoder",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class ISNetGTEncoder(nn.Module):\n    def __init__(self, in_ch=1, out_ch=1):\n        super(ISNetGTEncoder, self).__init__()\n        self.conv_in = myrebnconv(\n            in_ch, 16, 3, stride=2, padding=1\n        )  # nn.Conv2d(in_ch,64,3,stride=2,padding=1)\n        self.stage1 = RSU7(16, 16, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 16, 64)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "ISNetDIS",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "class ISNetDIS(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1):\n        super(ISNetDIS, self).__init__()\n        self.conv_in = nn.Conv2d(in_ch, 64, 3, stride=2, padding=1)\n        self.pool_in = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage1 = RSU7(64, 32, 64)\n        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage2 = RSU6(64, 32, 128)\n        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n        self.stage3 = RSU5(128, 64, 256)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "def muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "muti_loss_fusion_kl",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "def muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )\n            loss = loss + bce_loss(preds[i], tmp_target)",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "bce_loss",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "bce_loss = nn.BCELoss(size_average=True)\ndef muti_loss_fusion(preds, target):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "fea_loss",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "fea_loss = nn.MSELoss(size_average=True)\nkl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "kl_loss",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "kl_loss = nn.KLDivLoss(size_average=True)\nl1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "l1_loss = nn.L1Loss(size_average=True)\nsmooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "smooth_l1_loss",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.models.isnet",
        "description": "dashboard.dl_model.is_net.models.isnet",
        "peekOfCode": "smooth_l1_loss = nn.SmoothL1Loss(size_average=True)\ndef muti_loss_fusion_kl(preds, target, dfs, fs, mode=\"MSE\"):\n    loss0 = 0.0\n    loss = 0.0\n    for i in range(len(preds)):\n        if preds[i].shape[2] != target.shape[2] or preds[i].shape[3] != target.shape[3]:\n            # tmp_target = _upsample_like(target,preds[i])\n            tmp_target = F.interpolate(\n                target, size=preds[i].size()[2:], mode=\"bilinear\", align_corners=True\n            )",
        "detail": "dashboard.dl_model.is_net.models.isnet",
        "documentation": {}
    },
    {
        "label": "img_reader",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.data_loader_cache",
        "description": "dashboard.dl_model.is_net.data_loader_cache",
        "peekOfCode": "def img_reader(img_path):\n    return io.imread(img_path)\ndef img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:",
        "detail": "dashboard.dl_model.is_net.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "img_preprocess",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.data_loader_cache",
        "description": "dashboard.dl_model.is_net.data_loader_cache",
        "peekOfCode": "def img_preprocess(img, size):\n    if len(img.shape) < 3:\n        img = img[:, :, np.newaxis]\n    if img.shape[2] == 1:\n        img = np.repeat(img, 3, axis=2)\n    img_tensor = torch.tensor(img.copy(), dtype=torch.float32)\n    img_tensor = torch.transpose(torch.transpose(img_tensor, 1, 2), 0, 1)\n    if len(size) < 2:\n        return img_tensor, img.shape[:2]\n    img_tensor = torch.unsqueeze(img_tensor, 0)",
        "detail": "dashboard.dl_model.is_net.data_loader_cache",
        "documentation": {}
    },
    {
        "label": "GOSNormalize",
        "kind": 6,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "class GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"\n    def __init__(self, mean=None, std=None):",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "load_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "def load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "build_model",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "def build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":\n        net.half()\n        for layer in net.modules():\n            if isinstance(layer, nn.BatchNorm2d):\n                layer.float()\n    net.to(device)\n    if hypar[\"restore_model\"] != \"\":\n        net.load_state_dict(",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "def predict(net, inputs_val, shapes_val, hypar, device):\n    \"\"\"\n    Predicts the mask for the given input image.\n    Arguments:\n    net -- the neural network model used for prediction\n    inputs_val -- tensor of input images (shape: (1, C, H, W))\n    shapes_val -- tensor containing the original shape of the image\n    hypar -- dictionary of hyperparameters\n    device -- the device on which to perform the computations ('cuda' or 'cpu')\n    Returns:",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "save_inference",
        "kind": 2,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "def save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)\n    mask_path = os.path.join(output_dir, f\"{base_name}_mask.png\")",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nclass GOSNormalize(object):\n    \"\"\"\n    Normalizes the image using mean and standard deviation.\n    Arguments:\n    mean -- list of three floats, the mean values for each channel (default: [0.485, 0.456, 0.406])\n    std -- list of three floats, the standard deviation values for each channel (default: [0.229, 0.224, 0.225])\n    Returns:\n    A callable object that takes an image tensor as input and normalizes it.\n    \"\"\"",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "transform = transforms.Compose([GOSNormalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])])\ndef load_image(img_path, hypar):\n    img = img_reader(img_path)\n    img, img_shp = img_preprocess(img, hypar[\"cache_size\"])\n    img = torch.divide(img, 255.0)\n    shape = torch.from_numpy(np.array(img_shp))\n    return transform(img).unsqueeze(0), shape.unsqueeze(0)\ndef build_model(hypar, device):\n    net = hypar[\"model\"]\n    if hypar[\"model_digit\"] == \"half\":",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "hypar",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "hypar = {\n    \"model_path\": \"saved_models\",\n    \"restore_model\": \"isnet.pth\",\n    \"interm_sup\": False,\n    \"model_digit\": \"full\",\n    \"seed\": 0,\n    \"cache_size\": [1024, 1024],\n    \"input_size\": [1024, 1024],\n    \"crop_size\": [1024, 1024],\n    \"model\": ISNetDIS(),",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "net = build_model(hypar, device)\ndef save_inference(input_image_path, output_dir=\"outputs\"):\n    os.makedirs(output_dir, exist_ok=True)\n    base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n    image_tensor, orig_size = load_image(input_image_path, hypar)\n    mask = predict(net, image_tensor, orig_size, hypar, device)\n    pil_mask = Image.fromarray(mask).convert(\"L\")\n    im_rgb = Image.open(input_image_path).convert(\"RGB\")\n    im_rgba = im_rgb.copy()\n    im_rgba.putalpha(pil_mask)",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "input_path",
        "kind": 5,
        "importPath": "dashboard.dl_model.is_net.isnet_inference",
        "description": "dashboard.dl_model.is_net.isnet_inference",
        "peekOfCode": "input_path = \"./logo.jpeg\"\nmask_path, rgba_path = save_inference(input_path)",
        "detail": "dashboard.dl_model.is_net.isnet_inference",
        "documentation": {}
    },
    {
        "label": "NeuralStyleTransfer",
        "kind": 6,
        "importPath": "dashboard.dl_model.nst.nst",
        "description": "dashboard.dl_model.nst.nst",
        "peekOfCode": "class NeuralStyleTransfer:\n    def __init__(self, model_path=None):\n        self.img_size = 400\n        self.pp = pprint.PrettyPrinter(indent=4)\n        self.model_path = model_path\n        self.vgg = self._load_vgg_model()\n        self.content_image = None\n        self.style_image = None\n        self.generated_image = None\n        self.optimizer = tf.keras.optimizers.Adam(",
        "detail": "dashboard.dl_model.nst.nst",
        "documentation": {}
    },
    {
        "label": "upscale_image",
        "kind": 2,
        "importPath": "dashboard.dl_model.real_ersgan.ersgan_inference",
        "description": "dashboard.dl_model.real_ersgan.ersgan_inference",
        "peekOfCode": "def upscale_image(input_path, output_path, model_name=\"RealESRGAN_x4plus\"):\n    if model_name == \"RealESRGAN_x4plus\":\n        model = RRDBNet(\n            num_in_ch=3,\n            num_out_ch=3,\n            num_feat=64,\n            num_block=23,\n            num_grow_ch=32,\n            scale=4,\n        )",
        "detail": "dashboard.dl_model.real_ersgan.ersgan_inference",
        "documentation": {}
    },
    {
        "label": "RealESRGANer",
        "kind": 6,
        "importPath": "dashboard.dl_model.real_ersgan.utils",
        "description": "dashboard.dl_model.real_ersgan.utils",
        "peekOfCode": "class RealESRGANer:\n    \"\"\"\n    Implements Real-ESRGAN super-resolution model functionality\n    Arguments:\n    scale -- integer defining the upscaling factor\n    model_path -- string path to the model weights file\n    dni_weight -- optional weights for deep network interpolation\n    model -- the neural network model to be used\n    tile -- integer size of tiles for processing large images\n    tile_pad -- integer padding size for tiles",
        "detail": "dashboard.dl_model.real_ersgan.utils",
        "documentation": {}
    },
    {
        "label": "ROOT_DIR",
        "kind": 5,
        "importPath": "dashboard.dl_model.real_ersgan.utils",
        "description": "dashboard.dl_model.real_ersgan.utils",
        "peekOfCode": "ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nclass RealESRGANer:\n    \"\"\"\n    Implements Real-ESRGAN super-resolution model functionality\n    Arguments:\n    scale -- integer defining the upscaling factor\n    model_path -- string path to the model weights file\n    dni_weight -- optional weights for deep network interpolation\n    model -- the neural network model to be used\n    tile -- integer size of tiles for processing large images",
        "detail": "dashboard.dl_model.real_ersgan.utils",
        "documentation": {}
    },
    {
        "label": "DashboardConfig",
        "kind": 6,
        "importPath": "dashboard.apps",
        "description": "dashboard.apps",
        "peekOfCode": "class DashboardConfig(AppConfig):\n    default_auto_field = \"django.db.models.BigAutoField\"\n    name = \"dashboard\"",
        "detail": "dashboard.apps",
        "documentation": {}
    },
    {
        "label": "app_name",
        "kind": 5,
        "importPath": "dashboard.urls",
        "description": "dashboard.urls",
        "peekOfCode": "app_name = \"dashboard\"\nurlpatterns = [path(\"dashboard/\", views.dashboard_view, name=\"dashboard_view\")]",
        "detail": "dashboard.urls",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "dashboard.urls",
        "description": "dashboard.urls",
        "peekOfCode": "urlpatterns = [path(\"dashboard/\", views.dashboard_view, name=\"dashboard_view\")]",
        "detail": "dashboard.urls",
        "documentation": {}
    },
    {
        "label": "dashboard_view",
        "kind": 2,
        "importPath": "dashboard.views",
        "description": "dashboard.views",
        "peekOfCode": "def dashboard_view(request):\n    return render(request, \"pages/dashboard.html\")",
        "detail": "dashboard.views",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "deepfx_studio.asgi",
        "description": "deepfx_studio.asgi",
        "peekOfCode": "application = get_asgi_application()",
        "detail": "deepfx_studio.asgi",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent\n# setup ENV Variables\ndotenv_file = os.path.join(BASE_DIR, \".env\")\nif os.path.isfile(dotenv_file):\n    dotenv.load_dotenv(dotenv_file)\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/5.1/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = os.environ[\"SECRET_KEY\"]\n# SECURITY WARNING: don't run with debug turned on in production!",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "dotenv_file",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "dotenv_file = os.path.join(BASE_DIR, \".env\")\nif os.path.isfile(dotenv_file):\n    dotenv.load_dotenv(dotenv_file)\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/5.1/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = os.environ[\"SECRET_KEY\"]\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n# Production",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "SECRET_KEY = os.environ[\"SECRET_KEY\"]\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n# Production\n# DEBUG = False\n# ALLOWED_HOSTS = [\"*\"]\n# Application definition\nEXTERNAL_INSTALLED_APP = [\n    \"website\",\n    \"background_remover\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "DEBUG = True\n# Production\n# DEBUG = False\n# ALLOWED_HOSTS = [\"*\"]\n# Application definition\nEXTERNAL_INSTALLED_APP = [\n    \"website\",\n    \"background_remover\",\n    \"user_auth\",\n    \"dashboard\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "EXTERNAL_INSTALLED_APP",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "EXTERNAL_INSTALLED_APP = [\n    \"website\",\n    \"background_remover\",\n    \"user_auth\",\n    \"dashboard\",\n    \"tailwind\",\n    \"theme\",\n    \"django_browser_reload\",\n    # django-components\n    \"django_components\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "INSTALLED_APPS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "INSTALLED_APPS = [\n    \"django.contrib.admin\",\n    \"django.contrib.auth\",\n    \"django.contrib.contenttypes\",\n    \"django.contrib.sessions\",\n    \"django.contrib.sites\",\n    \"django.contrib.messages\",\n    \"django.contrib.staticfiles\",\n] + EXTERNAL_INSTALLED_APP\nTAILWIND_APP_NAME = \"theme\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "TAILWIND_APP_NAME",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "TAILWIND_APP_NAME = \"theme\"\nNPM_BIN_PATH = which(\"npm\")\n# allauth-ui settings.py\nALLAUTH_UI_THEME = \"dark\"\nMIDDLEWARE = [\n    \"django.middleware.security.SecurityMiddleware\",\n    \"django.contrib.sessions.middleware.SessionMiddleware\",\n    \"django.middleware.common.CommonMiddleware\",\n    \"django.middleware.csrf.CsrfViewMiddleware\",\n    \"django.contrib.auth.middleware.AuthenticationMiddleware\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "NPM_BIN_PATH",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "NPM_BIN_PATH = which(\"npm\")\n# allauth-ui settings.py\nALLAUTH_UI_THEME = \"dark\"\nMIDDLEWARE = [\n    \"django.middleware.security.SecurityMiddleware\",\n    \"django.contrib.sessions.middleware.SessionMiddleware\",\n    \"django.middleware.common.CommonMiddleware\",\n    \"django.middleware.csrf.CsrfViewMiddleware\",\n    \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n    \"django.contrib.messages.middleware.MessageMiddleware\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "ALLAUTH_UI_THEME",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "ALLAUTH_UI_THEME = \"dark\"\nMIDDLEWARE = [\n    \"django.middleware.security.SecurityMiddleware\",\n    \"django.contrib.sessions.middleware.SessionMiddleware\",\n    \"django.middleware.common.CommonMiddleware\",\n    \"django.middleware.csrf.CsrfViewMiddleware\",\n    \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n    \"django.contrib.messages.middleware.MessageMiddleware\",\n    \"django.middleware.clickjacking.XFrameOptionsMiddleware\",\n    \"django_browser_reload.middleware.BrowserReloadMiddleware\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "MIDDLEWARE",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "MIDDLEWARE = [\n    \"django.middleware.security.SecurityMiddleware\",\n    \"django.contrib.sessions.middleware.SessionMiddleware\",\n    \"django.middleware.common.CommonMiddleware\",\n    \"django.middleware.csrf.CsrfViewMiddleware\",\n    \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n    \"django.contrib.messages.middleware.MessageMiddleware\",\n    \"django.middleware.clickjacking.XFrameOptionsMiddleware\",\n    \"django_browser_reload.middleware.BrowserReloadMiddleware\",\n    # django-component middleware",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "ROOT_URLCONF",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "ROOT_URLCONF = \"deepfx_studio.urls\"\nTEMPLATES = [\n    {\n        \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n        \"DIRS\": [os.path.join(BASE_DIR, \"templates\")],\n        \"OPTIONS\": {\n            \"context_processors\": [\n                \"django.template.context_processors.debug\",\n                \"django.template.context_processors.request\",\n                \"django.contrib.auth.context_processors.auth\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "TEMPLATES = [\n    {\n        \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n        \"DIRS\": [os.path.join(BASE_DIR, \"templates\")],\n        \"OPTIONS\": {\n            \"context_processors\": [\n                \"django.template.context_processors.debug\",\n                \"django.template.context_processors.request\",\n                \"django.contrib.auth.context_processors.auth\",\n                \"django.contrib.messages.context_processors.messages\",",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "AUTHENTICATION_BACKENDS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "AUTHENTICATION_BACKENDS = [\n    \"django.contrib.auth.backends.ModelBackend\",\n    \"allauth.account.auth_backends.AuthenticationBackend\",\n]\nSOCIALACCOUNT_PROVIDERS = {\n    \"google\": {\n        \"SCOPE\": [\"profile\", \"email\"],\n        \"APP\": {\n            \"client_id\": os.environ[\"GOOGLE_CLIENT_ID\"],\n            \"secret\": os.environ[\"GOOGLE_CLIENT_SECRET\"],",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "SOCIALACCOUNT_PROVIDERS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "SOCIALACCOUNT_PROVIDERS = {\n    \"google\": {\n        \"SCOPE\": [\"profile\", \"email\"],\n        \"APP\": {\n            \"client_id\": os.environ[\"GOOGLE_CLIENT_ID\"],\n            \"secret\": os.environ[\"GOOGLE_CLIENT_SECRET\"],\n        },\n        \"AUTH_PARAMS\": {\n            \"access_type\": \"online\",\n        },",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "COMPONENTS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "COMPONENTS = {\n    \"dirs\": [\n        os.path.join(BASE_DIR, \"components\"),\n    ],\n}\nSTATICFILES_FINDERS = [\n    # Default finders\n    \"django.contrib.staticfiles.finders.FileSystemFinder\",\n    \"django.contrib.staticfiles.finders.AppDirectoriesFinder\",\n    # Django components",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "STATICFILES_FINDERS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "STATICFILES_FINDERS = [\n    # Default finders\n    \"django.contrib.staticfiles.finders.FileSystemFinder\",\n    \"django.contrib.staticfiles.finders.AppDirectoriesFinder\",\n    # Django components\n    \"django_components.finders.ComponentsFileSystemFinder\",\n]\nWSGI_APPLICATION = \"deepfx_studio.wsgi.application\"\n# Database\n# https://docs.djangoproject.com/en/5.1/ref/settings/#databases",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "WSGI_APPLICATION",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "WSGI_APPLICATION = \"deepfx_studio.wsgi.application\"\n# Database\n# https://docs.djangoproject.com/en/5.1/ref/settings/#databases\nDATABASES = {\n    \"default\": {\n        \"ENGINE\": \"django.db.backends.sqlite3\",\n        \"NAME\": BASE_DIR / \"db.sqlite3\",\n    }\n}\n# Password validation",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "DATABASES",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "DATABASES = {\n    \"default\": {\n        \"ENGINE\": \"django.db.backends.sqlite3\",\n        \"NAME\": BASE_DIR / \"db.sqlite3\",\n    }\n}\n# Password validation\n# https://docs.djangoproject.com/en/5.1/ref/settings/#auth-password-validators\nAUTH_PASSWORD_VALIDATORS = [\n    {",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "AUTH_PASSWORD_VALIDATORS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "AUTH_PASSWORD_VALIDATORS = [\n    {\n        \"NAME\": \"django.contrib.auth.password_validation.MinimumLengthValidator\",\n        \"OPTIONS\": {\n            \"min_length\": 9,\n        },\n    }\n]\n# Internationalization\n# https://docs.djangoproject.com/en/5.1/topics/i18n/",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_CODE",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "LANGUAGE_CODE = \"en-us\"\nTIME_ZONE = \"UTC\"\nUSE_I18N = True\nUSE_TZ = True\nSITE_ID = 2\nACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "TIME_ZONE = \"UTC\"\nUSE_I18N = True\nUSE_TZ = True\nSITE_ID = 2\nACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "USE_I18N",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "USE_I18N = True\nUSE_TZ = True\nSITE_ID = 2\nACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "USE_TZ",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "USE_TZ = True\nSITE_ID = 2\nACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "SITE_ID",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "SITE_ID = 2\nACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "ACCOUNT_EMAIL_VERIFICATION",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "ACCOUNT_EMAIL_VERIFICATION = \"none\"\nLOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),\n]",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "LOGIN_REDIRECT_URL",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "LOGIN_REDIRECT_URL = \"http://localhost:8000/dashboard/\"\nLOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),\n]\n# Directory where collected static files will be stored during deployment",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "LOGOUT_REDIRECT_URL",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "LOGOUT_REDIRECT_URL = \"/\"\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.1/howto/static-files/\nSTATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),\n]\n# Directory where collected static files will be stored during deployment\nSTATIC_ROOT = os.path.join(BASE_DIR, \"staticfiles\")",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_URL",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "STATIC_URL = \"static/\"\n# Directory for global static files\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),\n]\n# Directory where collected static files will be stored during deployment\nSTATIC_ROOT = os.path.join(BASE_DIR, \"staticfiles\")\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.1/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "STATICFILES_DIRS",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "STATICFILES_DIRS = [\n    os.path.join(BASE_DIR, \"static\"),\n]\n# Directory where collected static files will be stored during deployment\nSTATIC_ROOT = os.path.join(BASE_DIR, \"staticfiles\")\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.1/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_ROOT",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "STATIC_ROOT = os.path.join(BASE_DIR, \"staticfiles\")\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.1/ref/settings/#default-auto-field\nDEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_AUTO_FIELD",
        "kind": 5,
        "importPath": "deepfx_studio.settings",
        "description": "deepfx_studio.settings",
        "peekOfCode": "DEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"",
        "detail": "deepfx_studio.settings",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "deepfx_studio.urls",
        "description": "deepfx_studio.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"admin/\", admin.site.urls),\n    path(\"\", include(\"website.urls\")),\n    path(\"\", include(\"dashboard.urls\")),\n    path(\"\", include(\"user_auth.urls\")),\n    path(\"\", include(\"django_components.urls\")),\n    path(\"background-remover/\",include(\"background_remover.urls\")), # background-remover\n    path(\"accounts/\", include(\"allauth.urls\")),  # all OAuth operations will be performed under this route\n    path(\"__reload__/\", include(\"django_browser_reload.urls\")),\n]",
        "detail": "deepfx_studio.urls",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "deepfx_studio.wsgi",
        "description": "deepfx_studio.wsgi",
        "peekOfCode": "application = get_wsgi_application()",
        "detail": "deepfx_studio.wsgi",
        "documentation": {}
    },
    {
        "label": "ThemeConfig",
        "kind": 6,
        "importPath": "theme.apps",
        "description": "theme.apps",
        "peekOfCode": "class ThemeConfig(AppConfig):\n    name = \"theme\"",
        "detail": "theme.apps",
        "documentation": {}
    },
    {
        "label": "UserAuthConfig",
        "kind": 6,
        "importPath": "user_auth.apps",
        "description": "user_auth.apps",
        "peekOfCode": "class UserAuthConfig(AppConfig):\n    default_auto_field = \"django.db.models.BigAutoField\"\n    name = \"user_auth\"",
        "detail": "user_auth.apps",
        "documentation": {}
    },
    {
        "label": "app_name",
        "kind": 5,
        "importPath": "user_auth.urls",
        "description": "user_auth.urls",
        "peekOfCode": "app_name = \"user_auth\"\nurlpatterns = [\n    path(\"signin/\", views.signin_view, name=\"signin_view\"),\n    path(\"signup/\", views.signup_view, name=\"signup_view\"),\n    path(\"signout/\", views.signout, name=\"signout\"),\n    path(\"forgot_password/\", views.forgot_password_view, name=\"forgot_password_view\"),\n]",
        "detail": "user_auth.urls",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "user_auth.urls",
        "description": "user_auth.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"signin/\", views.signin_view, name=\"signin_view\"),\n    path(\"signup/\", views.signup_view, name=\"signup_view\"),\n    path(\"signout/\", views.signout, name=\"signout\"),\n    path(\"forgot_password/\", views.forgot_password_view, name=\"forgot_password_view\"),\n]",
        "detail": "user_auth.urls",
        "documentation": {}
    },
    {
        "label": "forgot_password_view",
        "kind": 2,
        "importPath": "user_auth.views",
        "description": "user_auth.views",
        "peekOfCode": "def forgot_password_view(request):\n    return render(request, \"pages/forgot_password.html\")\ndef signup_view(request):\n    if request.method == \"POST\":\n        username = request.POST.get(\"username\")\n        email = request.POST.get(\"email\")\n        password = request.POST.get(\"password\")\n        repeat_password = request.POST.get(\"confirm-password\")\n        # Ensure passwords match\n        if password != repeat_password:",
        "detail": "user_auth.views",
        "documentation": {}
    },
    {
        "label": "signup_view",
        "kind": 2,
        "importPath": "user_auth.views",
        "description": "user_auth.views",
        "peekOfCode": "def signup_view(request):\n    if request.method == \"POST\":\n        username = request.POST.get(\"username\")\n        email = request.POST.get(\"email\")\n        password = request.POST.get(\"password\")\n        repeat_password = request.POST.get(\"confirm-password\")\n        # Ensure passwords match\n        if password != repeat_password:\n            return render(\n                request,",
        "detail": "user_auth.views",
        "documentation": {}
    },
    {
        "label": "signin_view",
        "kind": 2,
        "importPath": "user_auth.views",
        "description": "user_auth.views",
        "peekOfCode": "def signin_view(request):\n    if request.method == \"POST\":\n        username = request.POST.get(\"username\")\n        password = request.POST.get(\"password\")\n        # Authenticate the user\n        user = authenticate(request, username=username, password=password)\n        if user is not None:\n            login(request, user)\n            return redirect(reverse(\"dashboard:dashboard_view\"))\n        else:",
        "detail": "user_auth.views",
        "documentation": {}
    },
    {
        "label": "signout",
        "kind": 2,
        "importPath": "user_auth.views",
        "description": "user_auth.views",
        "peekOfCode": "def signout(request):\n    logout(request)\n    return redirect(\"website:index_view\")",
        "detail": "user_auth.views",
        "documentation": {}
    },
    {
        "label": "WebsiteConfig",
        "kind": 6,
        "importPath": "website.apps",
        "description": "website.apps",
        "peekOfCode": "class WebsiteConfig(AppConfig):\n    default_auto_field = \"django.db.models.BigAutoField\"\n    name = \"website\"",
        "detail": "website.apps",
        "documentation": {}
    },
    {
        "label": "app_name",
        "kind": 5,
        "importPath": "website.urls",
        "description": "website.urls",
        "peekOfCode": "app_name = \"website\"\nurlpatterns = [\n    path(\"\", views.index_view, name=\"index_view\"),\n    path(\"service/\", views.service_view, name=\"service_view\"),\n    path(\"about/\", views.about_view, name=\"about_view\"),\n    path(\"privacy/\", views.privacy_view, name=\"privacy_view\"),\n    path(\"terms/\", views.terms_view, name=\"terms_view\"),\n]",
        "detail": "website.urls",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "website.urls",
        "description": "website.urls",
        "peekOfCode": "urlpatterns = [\n    path(\"\", views.index_view, name=\"index_view\"),\n    path(\"service/\", views.service_view, name=\"service_view\"),\n    path(\"about/\", views.about_view, name=\"about_view\"),\n    path(\"privacy/\", views.privacy_view, name=\"privacy_view\"),\n    path(\"terms/\", views.terms_view, name=\"terms_view\"),\n]",
        "detail": "website.urls",
        "documentation": {}
    },
    {
        "label": "index_view",
        "kind": 2,
        "importPath": "website.views",
        "description": "website.views",
        "peekOfCode": "def index_view(request):\n    return render(request, \"pages/landing.html\")\ndef about_view(request):\n    return render(request, \"pages/about.html\")\ndef service_view(request):\n    return render(request, \"pages/service.html\")\ndef privacy_view(request):\n    return render(request, \"pages/privacy.html\")\ndef terms_view(request):\n    return render(request, \"pages/terms_and_conditions.html\")",
        "detail": "website.views",
        "documentation": {}
    },
    {
        "label": "about_view",
        "kind": 2,
        "importPath": "website.views",
        "description": "website.views",
        "peekOfCode": "def about_view(request):\n    return render(request, \"pages/about.html\")\ndef service_view(request):\n    return render(request, \"pages/service.html\")\ndef privacy_view(request):\n    return render(request, \"pages/privacy.html\")\ndef terms_view(request):\n    return render(request, \"pages/terms_and_conditions.html\")",
        "detail": "website.views",
        "documentation": {}
    },
    {
        "label": "service_view",
        "kind": 2,
        "importPath": "website.views",
        "description": "website.views",
        "peekOfCode": "def service_view(request):\n    return render(request, \"pages/service.html\")\ndef privacy_view(request):\n    return render(request, \"pages/privacy.html\")\ndef terms_view(request):\n    return render(request, \"pages/terms_and_conditions.html\")",
        "detail": "website.views",
        "documentation": {}
    },
    {
        "label": "privacy_view",
        "kind": 2,
        "importPath": "website.views",
        "description": "website.views",
        "peekOfCode": "def privacy_view(request):\n    return render(request, \"pages/privacy.html\")\ndef terms_view(request):\n    return render(request, \"pages/terms_and_conditions.html\")",
        "detail": "website.views",
        "documentation": {}
    },
    {
        "label": "terms_view",
        "kind": 2,
        "importPath": "website.views",
        "description": "website.views",
        "peekOfCode": "def terms_view(request):\n    return render(request, \"pages/terms_and_conditions.html\")",
        "detail": "website.views",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "manage",
        "description": "manage",
        "peekOfCode": "def main():\n    \"\"\"Run administrative tasks.\"\"\"\n    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"deepfx_studio.settings\")\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\n            \"Couldn't import Django. Are you sure it's installed and \"\n            \"available on your PYTHONPATH environment variable? Did you \"\n            \"forget to activate a virtual environment?\"",
        "detail": "manage",
        "documentation": {}
    }
]